nohup: ignoring input
01/03/2024 21:03:14 - WARNING - root -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
Some weights of BertEstorCrf were not initialized from the model checkpoint at /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/prev_trained_model/roberta-large-chinese and are newly initialized: ['estor.ff_norm.bias', 'estor.feed_forward.0.weight', 'estor.reshape_linear.bias', 'estor.attention.out_proj.weight', 'estor.output_linear.weight', 'estor.attention.in_proj_bias', 'estor.positional_embedding.embeddings', 'estor.self_attention.out_proj.bias', 'crf.start_transitions', 'estor.reshape_linear.weight', 'estor.self_attention.in_proj_bias', 'estor.output_linear.bias', 'estor.gate_linear.bias', 'crf.transitions', 'estor.self_attention.out_proj.weight', 'classifier.weight', 'estor.self_attention.in_proj_weight', 'estor.tag_embedding_layer.weight', 'estor.att_norm.bias', 'estor.ff_norm.weight', 'estor.feed_forward.2.weight', 'classifier.bias', 'estor.feed_forward.2.bias', 'crf.end_transitions', 'estor.attention.out_proj.bias', 'estor.attention.in_proj_weight', 'estor.feed_forward.0.bias', 'estor.gate_linear.weight', 'estor.att_norm.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/03/2024 21:03:24 - INFO - root -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, adv_epsilon=1.0, adv_name='word_embeddings', backbone='bert_estor_crf', cache_dir='', config_name='', contrastive_alpha=0.1, crf_learning_rate=0.001, data_dir='/mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/', device=device(type='cuda'), do_adv=False, do_eval=False, do_lower_case=True, do_predict=False, do_train=True, enumerate_mode='attention', eval_all_checkpoints=False, eval_max_seq_length=512, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', freeze_backbone_epoch=30, gate_dropout_rate=0.5, gate_scaling_rate=0.6, gradient_accumulation_steps=1, id2label={0: 'X', 1: 'O', 2: '[START]', 3: '[END]', 4: 'B-PER.NAM', 5: 'I-PER.NAM', 6: 'B-PER.NOM', 7: 'I-PER.NOM', 8: 'B-LOC.NAM', 9: 'I-LOC.NAM', 10: 'B-LOC.NOM', 11: 'I-LOC.NOM', 12: 'B-GPE.NAM', 13: 'I-GPE.NAM', 14: 'B-GPE.NOM', 15: 'I-GPE.NOM', 16: 'B-ORG.NAM', 17: 'I-ORG.NAM', 18: 'B-ORG.NOM', 19: 'I-ORG.NOM'}, id2tag={0: 'loc', 1: 'gpe', 2: 'pre', 3: 'human', 4: 'org'}, if_add_a_self_attention=True, if_contrastive_learn=True, if_merge_by_add=True, label2id={'X': 0, 'O': 1, '[START]': 2, '[END]': 3, 'B-PER.NAM': 4, 'I-PER.NAM': 5, 'B-PER.NOM': 6, 'I-PER.NOM': 7, 'B-LOC.NAM': 8, 'I-LOC.NAM': 9, 'B-LOC.NOM': 10, 'I-LOC.NOM': 11, 'B-GPE.NAM': 12, 'I-GPE.NAM': 13, 'B-GPE.NOM': 14, 'I-GPE.NOM': 15, 'B-ORG.NAM': 16, 'I-ORG.NAM': 17, 'B-ORG.NOM': 18, 'I-ORG.NOM': 19}, learning_rate=3e-05, local_rank=-1, logging_steps=-1, loss_type='ce', markup='bio', max_grad_norm=1.0, max_steps=-1, model_name_or_path='/mnt/storage/wubinghong.wbh/deepl/torch_ner_new/prev_trained_model/roberta-large-chinese', n_gpu=1, no_cuda=False, num_train_epochs=50.0, output_dir='/mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=24, per_gpu_train_batch_size=24, pos_learning_rate=5e-05, predict_checkpoints=0, save_steps=-1, seed=42, tag2id={'loc': 0, 'gpe': 1, 'pre': 2, 'human': 3, 'org': 4}, tagging_rate=1.0, task_name='weibo', tokenizer_name='', train_max_seq_length=128, warmup_proportion=0.1, weight_decay=0.01)
01/03/2024 21:03:24 - INFO - root -   Creating features from dataset file at /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/
['X', 'O', '[START]', '[END]', 'B-PER.NAM', 'I-PER.NAM', 'B-PER.NOM', 'I-PER.NOM', 'B-LOC.NAM', 'I-LOC.NAM', 'B-LOC.NOM', 'I-LOC.NOM', 'B-GPE.NAM', 'I-GPE.NAM', 'B-GPE.NOM', 'I-GPE.NOM', 'B-ORG.NAM', 'I-ORG.NAM', 'B-ORG.NOM', 'I-ORG.NOM'] ['loc', 'gpe', 'pre', 'human', 'org']
  0%|          | 0/5 [00:00<?, ?it/s] 60%|██████    | 3/5 [00:00<00:00, 18.00it/s]100%|██████████| 5/5 [00:00<00:00, 26.96it/s]
  0%|          | 0/5 [00:00<?, ?it/s]100%|██████████| 5/5 [00:00<00:00, 187.02it/s]
['loc', 'gpe', 'pre', 'human', 'org']
  0%|          | 0/1349 [00:00<?, ?it/s]01/03/2024 21:03:24 - INFO - processors.ner_seq -   Writing example 0 of 1349
01/03/2024 21:03:24 - INFO - processors.ner_seq -   *** Example ***
01/03/2024 21:03:24 - INFO - processors.ner_seq -   guid: train-1
01/03/2024 21:03:24 - INFO - processors.ner_seq -   tokens: [CLS] 对 ， 输 给 一 个 女 人 ， 的 成 绩 。 失 望 [SEP]
01/03/2024 21:03:24 - INFO - processors.ner_seq -   input_ids: 101 2190 8024 6783 5314 671 702 1957 782 8024 4638 2768 5327 511 1927 3307 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 21:03:24 - INFO - processors.ner_seq -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 21:03:24 - INFO - processors.ner_seq -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 21:03:24 - INFO - processors.ner_seq -   label_ids: 1 1 1 1 1 1 1 6 7 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 21:03:24 - INFO - processors.ner_seq -   idx: 0
01/03/2024 21:03:24 - INFO - processors.ner_seq -   tag_to_spans: defaultdict(<class 'list'>, {3: [[7, 8], [8, 9], [7, 9]]})
01/03/2024 21:03:24 - INFO - processors.ner_seq -   *** Example ***
01/03/2024 21:03:24 - INFO - processors.ner_seq -   guid: train-2
01/03/2024 21:03:24 - INFO - processors.ner_seq -   tokens: [CLS] 今 天 下 午 起 来 看 到 外 面 的 太 阳 。 。 。 。 我 第 一 反 应 竟 然 是 强 烈 的 想 回 家 泪 想 我 们 一 起 在 嘉 鱼 个 时 候 了 。 。 。 。 有 好 多 好 多 的 话 想 对 你 说 李 巾 凡 想 要 瘦 瘦 瘦 成 李 帆 我 是 想 切 开 云 朵 的 心 [SEP]
01/03/2024 21:03:24 - INFO - processors.ner_seq -   input_ids: 101 791 1921 678 1286 6629 3341 4692 1168 1912 7481 4638 1922 7345 511 511 511 511 2769 5018 671 1353 2418 4994 4197 3221 2487 4164 4638 2682 1726 2157 3801 2682 2769 812 671 6629 1762 1649 7824 702 3198 952 749 511 511 511 511 3300 1962 1914 1962 1914 4638 6413 2682 2190 872 6432 3330 2353 1127 2682 6206 4607 4607 4607 2768 3330 2359 2769 3221 2682 1147 2458 756 3321 4638 2552 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 21:03:24 - INFO - processors.ner_seq -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 21:03:24 - INFO - processors.ner_seq -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 21:03:24 - INFO - processors.ner_seq -   label_ids: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 8 9 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 5 5 1 1 1 1 1 1 4 5 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 21:03:24 - INFO - processors.ner_seq -   idx: 1
01/03/2024 21:03:24 - INFO - processors.ner_seq -   tag_to_spans: defaultdict(<class 'list'>, {3: [[21, 22], [31, 32]], 2: [[51, 52], [53, 54], [60, 61], [62, 63], [69, 70], [74, 75]], 1: [[39, 41]]})
01/03/2024 21:03:24 - INFO - processors.ner_seq -   *** Example ***
01/03/2024 21:03:24 - INFO - processors.ner_seq -   guid: train-3
01/03/2024 21:03:24 - INFO - processors.ner_seq -   tokens: [CLS] 今 年 拜 年 不 短 信 ， 就 在 微 博 拜 大 年 寻 龙 记 [SEP]
01/03/2024 21:03:24 - INFO - processors.ner_seq -   input_ids: 101 791 2399 2876 2399 679 4764 928 8024 2218 1762 2544 1300 2876 1920 2399 2192 7987 6381 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 21:03:24 - INFO - processors.ner_seq -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 21:03:24 - INFO - processors.ner_seq -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 21:03:24 - INFO - processors.ner_seq -   label_ids: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 21:03:24 - INFO - processors.ner_seq -   idx: 2
01/03/2024 21:03:24 - INFO - processors.ner_seq -   tag_to_spans: defaultdict(<class 'list'>, {2: [[12, 13]]})
01/03/2024 21:03:24 - INFO - processors.ner_seq -   *** Example ***
01/03/2024 21:03:24 - INFO - processors.ner_seq -   guid: train-4
01/03/2024 21:03:24 - INFO - processors.ner_seq -   tokens: [CLS] 浑 身 酸 疼 ， 两 腿 无 力 ， 眼 神 呆 滞 ， 怎 么 了 [SEP]
01/03/2024 21:03:24 - INFO - processors.ner_seq -   input_ids: 101 3847 6716 7000 4563 8024 697 5597 3187 1213 8024 4706 4868 1438 4005 8024 2582 720 749 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 21:03:24 - INFO - processors.ner_seq -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 21:03:24 - INFO - processors.ner_seq -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 21:03:24 - INFO - processors.ner_seq -   label_ids: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 21:03:24 - INFO - processors.ner_seq -   idx: 3
01/03/2024 21:03:24 - INFO - processors.ner_seq -   tag_to_spans: defaultdict(<class 'list'>, {})
01/03/2024 21:03:24 - INFO - processors.ner_seq -   *** Example ***
01/03/2024 21:03:24 - INFO - processors.ner_seq -   guid: train-5
01/03/2024 21:03:24 - INFO - processors.ner_seq -   tokens: [CLS] 明 显 紧 张 状 态 没 出 来 ， 失 误 多 。 [SEP]
01/03/2024 21:03:24 - INFO - processors.ner_seq -   input_ids: 101 3209 3227 5165 2476 4307 2578 3766 1139 3341 8024 1927 6428 1914 511 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 21:03:24 - INFO - processors.ner_seq -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 21:03:24 - INFO - processors.ner_seq -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 21:03:24 - INFO - processors.ner_seq -   label_ids: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 21:03:24 - INFO - processors.ner_seq -   idx: 4
01/03/2024 21:03:24 - INFO - processors.ner_seq -   tag_to_spans: defaultdict(<class 'list'>, {2: [[4, 5], [13, 14]]})
 26%|██▌       | 354/1349 [00:00<00:00, 3531.01it/s] 52%|█████▏    | 708/1349 [00:00<00:00, 3260.91it/s] 77%|███████▋  | 1036/1349 [00:00<00:00, 3119.68it/s]100%|██████████| 1349/1349 [00:00<00:00, 2994.45it/s]100%|██████████| 1349/1349 [00:00<00:00, 3083.45it/s]
01/03/2024 21:03:25 - INFO - root -   Saving features into cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-train_roberta-large-chinese_128_weibo
01/03/2024 21:03:25 - INFO - root -   The model with entity_enumerator
/mnt/storage/wubinghong.wbh/project/pytorch-3.8/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
01/03/2024 21:03:25 - INFO - root -   ***** Running training *****
01/03/2024 21:03:25 - INFO - root -     Num examples = 1349
01/03/2024 21:03:25 - INFO - root -     Num Epochs = 50
01/03/2024 21:03:25 - INFO - root -     Instantaneous batch size per GPU = 24
01/03/2024 21:03:25 - INFO - root -     Total train batch size (w. parallel, distributed & accumulation) = 24
01/03/2024 21:03:25 - INFO - root -     Gradient Accumulation steps = 1
01/03/2024 21:03:25 - INFO - root -     Total optimization steps = 2850
01/03/2024 21:03:25 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 0/50
[Training] 1/57 [..............................] - ETA: 2:10  [ loss=154.4511 ][Training] 2/57 [>.............................] - ETA: 1:46  [ loss=123.8722 ][Training] 3/57 [>.............................] - ETA: 1:37  [ loss=82.4106 ][Training] 4/57 [=>............................] - ETA: 1:26  [ loss=41.4136 ][Training] 5/57 [=>............................] - ETA: 1:23  [ loss=42.2440 ][Training] 6/57 [==>...........................] - ETA: 1:19  [ loss=26.5365 ][Training] 7/57 [==>...........................] - ETA: 1:20  [ loss=30.6941 ][Training] 8/57 [===>..........................] - ETA: 1:17  [ loss=33.6023 ][Training] 9/57 [===>..........................] - ETA: 1:13  [ loss=26.0129 ][Training] 10/57 [====>.........................] - ETA: 1:11  [ loss=17.9566 ][Training] 11/57 [====>.........................] - ETA: 1:08  [ loss=30.9497 ][Training] 12/57 [=====>........................] - ETA: 1:05  [ loss=9.9518 ][Training] 13/57 [=====>........................] - ETA: 1:03  [ loss=24.9559 ][Training] 14/57 [======>.......................] - ETA: 1:02  [ loss=17.9457 ][Training] 15/57 [======>.......................] - ETA: 59s  [ loss=19.3919 ][Training] 16/57 [=======>......................] - ETA: 57s  [ loss=25.9321 ][Training] 17/57 [=======>......................] - ETA: 56s  [ loss=17.4977 ][Training] 18/57 [========>.....................] - ETA: 53s  [ loss=12.2572 ][Training] 19/57 [=========>....................] - ETA: 52s  [ loss=20.3018 ][Training] 20/57 [=========>....................] - ETA: 50s  [ loss=13.6591 ][Training] 21/57 [==========>...................] - ETA: 48s  [ loss=13.0678 ][Training] 22/57 [==========>...................] - ETA: 47s  [ loss=26.4216 ][Training] 23/57 [===========>..................] - ETA: 46s  [ loss=17.9437 ][Training] 24/57 [===========>..................] - ETA: 44s  [ loss=17.3911 ][Training] 25/57 [============>.................] - ETA: 43s  [ loss=13.6491 ][Training] 26/57 [============>.................] - ETA: 41s  [ loss=18.4417 ][Training] 27/57 [=============>................] - ETA: 40s  [ loss=10.8688 ][Training] 28/57 [=============>................] - ETA: 38s  [ loss=15.0634 ][Training] 29/57 [==============>...............] - ETA: 37s  [ loss=16.7728 ][Training] 30/57 [==============>...............] - ETA: 35s  [ loss=16.9676 ][Training] 31/57 [===============>..............] - ETA: 34s  [ loss=6.6743 ][Training] 32/57 [===============>..............] - ETA: 32s  [ loss=11.4457 ][Training] 33/57 [================>.............] - ETA: 31s  [ loss=12.0064 ][Training] 34/57 [================>.............] - ETA: 30s  [ loss=18.2454 ][Training] 35/57 [=================>............] - ETA: 28s  [ loss=13.5678 ][Training] 36/57 [=================>............] - ETA: 27s  [ loss=7.7574 ][Training] 37/57 [==================>...........] - ETA: 25s  [ loss=7.3046 ][Training] 38/57 [===================>..........] - ETA: 24s  [ loss=22.7891 ][Training] 39/57 [===================>..........] - ETA: 23s  [ loss=10.9832 ][Training] 40/57 [====================>.........] - ETA: 22s  [ loss=13.9903 ][Training] 41/57 [====================>.........] - ETA: 20s  [ loss=10.6823 ][Training] 42/57 [=====================>........] - ETA: 19s  [ loss=5.2899 ][Training] 43/57 [=====================>........] - ETA: 18s  [ loss=12.9313 ][Training] 44/57 [======================>.......] - ETA: 17s  [ loss=8.4980 ][Training] 45/57 [======================>.......] - ETA: 15s  [ loss=9.8784 ][Training] 46/57 [=======================>......] - ETA: 14s  [ loss=10.1555 ][Training] 47/57 [=======================>......] - ETA: 13s  [ loss=11.7136 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=8.5886 ][Training] 49/57 [========================>.....] - ETA: 10s  [ loss=14.5638 ][Training] 50/57 [=========================>....] - ETA: 9s  [ loss=12.0456 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=6.1146 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=10.9803 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=15.0321 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=11.3678 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=8.1594 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=7.3479 ][Training] 57/57 [==============================] 1.3s/step  [ loss=7.9341 ]
/mnt/storage/wubinghong.wbh/deepl/torch_ner_new/models/layers/crf.py:233: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at ../aten/src/ATen/native/TensorCompare.cpp:493.)
  score = torch.where(mask[i].unsqueeze(1), next_score, score)
01/03/2024 21:04:39 - INFO - root -   Creating features from dataset file at /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/
 
  0%|          | 0/5 [00:00<?, ?it/s] 60%|██████    | 3/5 [00:00<00:00, 20.66it/s]100%|██████████| 5/5 [00:00<00:00, 30.33it/s]
  0%|          | 0/5 [00:00<?, ?it/s]100%|██████████| 5/5 [00:00<00:00, 187.06it/s]
['loc', 'gpe', 'pre', 'human', 'org']
  0%|          | 0/269 [00:00<?, ?it/s]01/03/2024 21:04:39 - INFO - processors.ner_seq -   Writing example 0 of 269
01/03/2024 21:04:39 - INFO - processors.ner_seq -   *** Example ***
01/03/2024 21:04:39 - INFO - processors.ner_seq -   guid: test-1
01/03/2024 21:04:39 - INFO - processors.ner_seq -   tokens: [CLS] 回 复 支 持 ， 赞 成 ， 哈 哈 米 八 吴 够 历 史 要 的 陈 小 奥 丁 丁 我 爱 小 肥 肥 一 族 大 头 仔 大 家 团 结 一 致 ， 誓 要 去 台 湾 饮 喜 酒 ， 由 包 机 ， 团 结 的 力 量 大 [SEP]
01/03/2024 21:04:39 - INFO - processors.ner_seq -   input_ids: 101 1726 1908 3118 2898 8024 6614 2768 8024 1506 1506 5101 1061 1426 1916 1325 1380 6206 4638 7357 2207 1952 672 672 2769 4263 2207 5503 5503 671 3184 1920 1928 798 1920 2157 1730 5310 671 5636 8024 6292 6206 1343 1378 3968 7650 1599 6983 8024 4507 1259 3322 8024 1730 5310 4638 1213 7030 1920 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 21:04:39 - INFO - processors.ner_seq -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 21:04:39 - INFO - processors.ner_seq -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 21:04:39 - INFO - processors.ner_seq -   label_ids: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 5 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 12 13 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 21:04:39 - INFO - processors.ner_seq -   idx: 0
01/03/2024 21:04:39 - INFO - processors.ner_seq -   tag_to_spans: defaultdict(<class 'list'>, {2: [[19, 20], [21, 22], [22, 23], [23, 24]], 3: [[22, 23], [23, 24], [32, 33], [33, 34], [35, 36], [31, 33], [34, 36]], 1: [[36, 38], [44, 46], [54, 56]]})
01/03/2024 21:04:39 - INFO - processors.ner_seq -   *** Example ***
01/03/2024 21:04:39 - INFO - processors.ner_seq -   guid: test-2
01/03/2024 21:04:39 - INFO - processors.ner_seq -   tokens: [CLS] 剑 网 乱 世 长 安 公 测 盛 典 今 日 开 启 ， 海 量 豪 礼 火 爆 开 送 精 美 挂 件 、 听 雨 · 汉 服 娃 娃 、 诙 谐 双 骑 独 轮 车 等 你 来 拿 ， 更 有 千 台 红 米 手 机 、 等 十 四 重 惊 喜 转 发 即 抽 活 动 地 址 ： 已 有 人 参 与 剑 网 官 方 微 博 剑 网 客 户 服 务 [SEP]
01/03/2024 21:04:39 - INFO - processors.ner_seq -   input_ids: 101 1187 5381 744 686 7270 2128 1062 3844 4670 1073 791 3189 2458 1423 8024 3862 7030 6498 4851 4125 4255 2458 6843 5125 5401 2899 816 510 1420 7433 185 3727 3302 2015 2015 510 6410 6455 1352 7744 4324 6762 6756 5023 872 3341 2897 8024 3291 3300 1283 1378 5273 5101 2797 3322 510 5023 1282 1724 7028 2661 1599 6760 1355 1315 2853 3833 1220 1765 1770 8038 2347 3300 782 1346 680 1187 5381 2135 3175 2544 1300 1187 5381 2145 2787 3302 1218 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 21:04:39 - INFO - processors.ner_seq -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 21:04:39 - INFO - processors.ner_seq -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 21:04:39 - INFO - processors.ner_seq -   label_ids: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 21:04:39 - INFO - processors.ner_seq -   idx: 1
01/03/2024 21:04:39 - INFO - processors.ner_seq -   tag_to_spans: defaultdict(<class 'list'>, {3: [[5, 6], [7, 8], [18, 19], [32, 33], [34, 35], [35, 36], [55, 56], [75, 76], [80, 81], [86, 87], [34, 36], [86, 88]], 2: [[6, 7], [7, 8], [83, 84], [34, 36]], 1: [[5, 7]]})
01/03/2024 21:04:39 - INFO - processors.ner_seq -   *** Example ***
01/03/2024 21:04:39 - INFO - processors.ner_seq -   guid: test-3
01/03/2024 21:04:39 - INFO - processors.ner_seq -   tokens: [CLS] 在 街 上 听 见 音 乐 我 舞 动 起 来 很 丢 人 ？ 真 的 很 丢 人 吗 ？ [SEP]
01/03/2024 21:04:39 - INFO - processors.ner_seq -   input_ids: 101 1762 6125 677 1420 6224 7509 727 2769 5659 1220 6629 3341 2523 696 782 8043 4696 4638 2523 696 782 1408 8043 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 21:04:39 - INFO - processors.ner_seq -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 21:04:39 - INFO - processors.ner_seq -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 21:04:39 - INFO - processors.ner_seq -   label_ids: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 21:04:39 - INFO - processors.ner_seq -   idx: 2
01/03/2024 21:04:39 - INFO - processors.ner_seq -   tag_to_spans: defaultdict(<class 'list'>, {3: [[15, 16], [21, 22]]})
01/03/2024 21:04:39 - INFO - processors.ner_seq -   *** Example ***
01/03/2024 21:04:39 - INFO - processors.ner_seq -   guid: test-4
01/03/2024 21:04:39 - INFO - processors.ner_seq -   tokens: [CLS] 三 毛 说 我 唯 一 锲 而 不 舍 ， 愿 意 以 自 己 的 生 命 去 努 力 的 ， 只 不 过 是 保 守 我 个 人 的 心 怀 意 念 ， 在 我 有 生 之 日 ， 做 一 个 真 诚 的 人 ， 不 放 弃 对 生 活 的 热 爱 和 执 着 ， 在 有 限 的 时 空 里 ， 过 无 限 广 [SEP]
01/03/2024 21:04:39 - INFO - processors.ner_seq -   input_ids: 101 676 3688 6432 2769 1546 671 7244 5445 679 5650 8024 2703 2692 809 5632 2346 4638 4495 1462 1343 1222 1213 4638 8024 1372 679 6814 3221 924 2127 2769 702 782 4638 2552 2577 2692 2573 8024 1762 2769 3300 4495 722 3189 8024 976 671 702 4696 6411 4638 782 8024 679 3123 2461 2190 4495 3833 4638 4178 4263 1469 2809 4708 8024 1762 3300 7361 4638 3198 4958 7027 8024 6814 3187 7361 2408 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 21:04:39 - INFO - processors.ner_seq -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 21:04:39 - INFO - processors.ner_seq -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 21:04:39 - INFO - processors.ner_seq -   label_ids: 1 4 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 21:04:39 - INFO - processors.ner_seq -   idx: 3
01/03/2024 21:04:39 - INFO - processors.ner_seq -   tag_to_spans: defaultdict(<class 'list'>, {3: [[18, 19], [29, 30], [33, 34], [43, 44], [53, 54], [59, 60], [32, 34]], 2: [[1, 3]]})
01/03/2024 21:04:39 - INFO - processors.ner_seq -   *** Example ***
01/03/2024 21:04:39 - INFO - processors.ner_seq -   guid: test-5
01/03/2024 21:04:39 - INFO - processors.ner_seq -   tokens: [CLS] 星 期 天 的 早 晨 七 点 学 车 ， 驾 校 太 给 力 。 我 的 头 发 都 没 有 洗 [SEP]
01/03/2024 21:04:39 - INFO - processors.ner_seq -   input_ids: 101 3215 3309 1921 4638 3193 3247 673 4157 2110 6756 8024 7730 3413 1922 5314 1213 511 2769 4638 1928 1355 6963 3766 3300 3819 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 21:04:39 - INFO - processors.ner_seq -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 21:04:39 - INFO - processors.ner_seq -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 21:04:39 - INFO - processors.ner_seq -   label_ids: 1 1 1 1 1 1 1 1 1 1 1 1 18 19 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 21:04:39 - INFO - processors.ner_seq -   idx: 4
01/03/2024 21:04:39 - INFO - processors.ner_seq -   tag_to_spans: defaultdict(<class 'list'>, {3: [[1, 2], [20, 21]]})
 97%|█████████▋| 261/269 [00:00<00:00, 2609.78it/s]100%|██████████| 269/269 [00:00<00:00, 2610.34it/s]
01/03/2024 21:04:39 - INFO - root -   Saving features into cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 21:04:39 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 21:04:39 - INFO - root -     Num examples = 269
01/03/2024 21:04:39 - INFO - root -     Batch size = 24
[Evaluating] 1/12 [=>............................] - ETA: 5s[Evaluating] 2/12 [====>.........................] - ETA: 5s[Evaluating] 3/12 [======>.......................] - ETA: 4s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 2s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 555.8ms/step
01/03/2024 21:04:46 - INFO - root -   

01/03/2024 21:04:46 - INFO - root -   ***** Eval results  *****
01/03/2024 21:04:46 - INFO - root -    acc: 0.5524 - recall: 0.3826 - f1: 0.4521 - loss: 10.3097 
01/03/2024 21:04:46 - INFO - root -   ***** Entity results  *****
01/03/2024 21:04:46 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 21:04:46 - INFO - root -    acc: 0.5500 - recall: 0.2340 - f1: 0.3284 
01/03/2024 21:04:46 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 21:04:46 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 21:04:46 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 21:04:46 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 21:04:46 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 21:04:46 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 21:04:46 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 21:04:46 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 21:04:46 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 21:04:46 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 21:04:46 - INFO - root -   ******* PER.NAM results ********
01/03/2024 21:04:46 - INFO - root -    acc: 0.6180 - recall: 0.5000 - f1: 0.5528 
01/03/2024 21:04:46 - INFO - root -   ******* PER.NOM results ********
01/03/2024 21:04:46 - INFO - root -    acc: 0.5198 - recall: 0.5412 - f1: 0.5303 
01/03/2024 21:04:52 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-57
01/03/2024 21:04:52 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-57
01/03/2024 21:04:52 - INFO - root -   

01/03/2024 21:04:52 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 1/50
[Training] 1/57 [..............................] - ETA: 1:06  [ loss=9.0109 ][Training] 2/57 [>.............................] - ETA: 1:03  [ loss=9.7514 ][Training] 3/57 [>.............................] - ETA: 1:08  [ loss=11.8511 ][Training] 4/57 [=>............................] - ETA: 1:03  [ loss=5.6773 ][Training] 5/57 [=>............................] - ETA: 1:02  [ loss=8.2017 ][Training] 6/57 [==>...........................] - ETA: 59s  [ loss=9.2218 ][Training] 7/57 [==>...........................] - ETA: 1:00  [ loss=7.1642 ][Training] 8/57 [===>..........................] - ETA: 59s  [ loss=7.7375 ][Training] 9/57 [===>..........................] - ETA: 58s  [ loss=5.8037 ][Training] 10/57 [====>.........................] - ETA: 57s  [ loss=10.7516 ][Training] 11/57 [====>.........................] - ETA: 56s  [ loss=9.3704 ][Training] 12/57 [=====>........................] - ETA: 55s  [ loss=5.9985 ][Training] 13/57 [=====>........................] - ETA: 54s  [ loss=13.3007 ][Training] 14/57 [======>.......................] - ETA: 53s  [ loss=6.7065 ][Training] 15/57 [======>.......................] - ETA: 53s  [ loss=11.0003 ][Training] 16/57 [=======>......................] - ETA: 52s  [ loss=9.8800 ][Training] 17/57 [=======>......................] - ETA: 51s  [ loss=14.8784 ][Training] 18/57 [========>.....................] - ETA: 50s  [ loss=10.3550 ][Training] 19/57 [=========>....................] - ETA: 48s  [ loss=6.6662 ][Training] 20/57 [=========>....................] - ETA: 47s  [ loss=12.9716 ][Training] 21/57 [==========>...................] - ETA: 45s  [ loss=4.4924 ][Training] 22/57 [==========>...................] - ETA: 44s  [ loss=8.7813 ][Training] 23/57 [===========>..................] - ETA: 43s  [ loss=3.7697 ][Training] 24/57 [===========>..................] - ETA: 42s  [ loss=11.0244 ][Training] 25/57 [============>.................] - ETA: 40s  [ loss=3.5596 ][Training] 26/57 [============>.................] - ETA: 39s  [ loss=3.6777 ][Training] 27/57 [=============>................] - ETA: 37s  [ loss=9.5899 ][Training] 28/57 [=============>................] - ETA: 36s  [ loss=13.1616 ][Training] 29/57 [==============>...............] - ETA: 35s  [ loss=8.2627 ][Training] 30/57 [==============>...............] - ETA: 33s  [ loss=6.8798 ][Training] 31/57 [===============>..............] - ETA: 32s  [ loss=4.5333 ][Training] 32/57 [===============>..............] - ETA: 31s  [ loss=5.4512 ][Training] 33/57 [================>.............] - ETA: 30s  [ loss=6.5094 ][Training] 34/57 [================>.............] - ETA: 29s  [ loss=7.7529 ][Training] 35/57 [=================>............] - ETA: 27s  [ loss=4.5758 ][Training] 36/57 [=================>............] - ETA: 26s  [ loss=15.7362 ][Training] 37/57 [==================>...........] - ETA: 25s  [ loss=11.2700 ][Training] 38/57 [===================>..........] - ETA: 24s  [ loss=3.4876 ][Training] 39/57 [===================>..........] - ETA: 23s  [ loss=11.2995 ][Training] 40/57 [====================>.........] - ETA: 21s  [ loss=7.5172 ][Training] 41/57 [====================>.........] - ETA: 20s  [ loss=7.4608 ][Training] 42/57 [=====================>........] - ETA: 19s  [ loss=7.3513 ][Training] 43/57 [=====================>........] - ETA: 18s  [ loss=12.8507 ][Training] 44/57 [======================>.......] - ETA: 16s  [ loss=4.3614 ][Training] 45/57 [======================>.......] - ETA: 15s  [ loss=7.5442 ][Training] 46/57 [=======================>......] - ETA: 14s  [ loss=2.8952 ][Training] 47/57 [=======================>......] - ETA: 12s  [ loss=8.6657 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=7.2786 ][Training] 49/57 [========================>.....] - ETA: 10s  [ loss=7.5844 ][Training] 50/57 [=========================>....] - ETA: 8s  [ loss=4.2764 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=7.0784 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=7.5670 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=12.8986 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=2.9480 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=2.9210 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=14.8737 ][Training] 57/57 [==============================] 1.3s/step  [ loss=2.7694 ]
01/03/2024 21:06:04 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 21:06:04 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 21:06:04 - INFO - root -     Num examples = 269
01/03/2024 21:06:04 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 6s[Evaluating] 2/12 [====>.........................] - ETA: 5s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 573.1ms/step
01/03/2024 21:06:11 - INFO - root -   

01/03/2024 21:06:11 - INFO - root -   ***** Eval results  *****
01/03/2024 21:06:11 - INFO - root -    acc: 0.6138 - recall: 0.5157 - f1: 0.5605 - loss: 7.7284 
01/03/2024 21:06:11 - INFO - root -   ***** Entity results  *****
01/03/2024 21:06:11 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 21:06:11 - INFO - root -    acc: 0.6316 - recall: 0.7660 - f1: 0.6923 
01/03/2024 21:06:11 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 21:06:11 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 21:06:11 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 21:06:11 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 21:06:11 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 21:06:11 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 21:06:11 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 21:06:11 - INFO - root -    acc: 0.2500 - recall: 0.0256 - f1: 0.0465 
01/03/2024 21:06:11 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 21:06:11 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 21:06:11 - INFO - root -   ******* PER.NAM results ********
01/03/2024 21:06:11 - INFO - root -    acc: 0.6875 - recall: 0.6000 - f1: 0.6408 
01/03/2024 21:06:11 - INFO - root -   ******* PER.NOM results ********
01/03/2024 21:06:11 - INFO - root -    acc: 0.5789 - recall: 0.6471 - f1: 0.6111 
01/03/2024 21:06:18 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-114
01/03/2024 21:06:18 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-114
01/03/2024 21:06:18 - INFO - root -   

01/03/2024 21:06:18 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 2/50
[Training] 1/57 [..............................] - ETA: 1:12  [ loss=8.4254 ][Training] 2/57 [>.............................] - ETA: 1:08  [ loss=8.8588 ][Training] 3/57 [>.............................] - ETA: 1:05  [ loss=3.8823 ][Training] 4/57 [=>............................] - ETA: 1:02  [ loss=5.5082 ][Training] 5/57 [=>............................] - ETA: 1:02  [ loss=3.1698 ][Training] 6/57 [==>...........................] - ETA: 1:02  [ loss=5.5935 ][Training] 7/57 [==>...........................] - ETA: 1:05  [ loss=8.1925 ][Training] 8/57 [===>..........................] - ETA: 1:05  [ loss=6.7945 ][Training] 9/57 [===>..........................] - ETA: 1:03  [ loss=6.6065 ][Training] 10/57 [====>.........................] - ETA: 1:01  [ loss=5.1665 ][Training] 11/57 [====>.........................] - ETA: 1:01  [ loss=8.9319 ][Training] 12/57 [=====>........................] - ETA: 1:00  [ loss=4.8843 ][Training] 13/57 [=====>........................] - ETA: 58s  [ loss=6.3445 ][Training] 14/57 [======>.......................] - ETA: 57s  [ loss=6.6485 ][Training] 15/57 [======>.......................] - ETA: 54s  [ loss=1.5071 ][Training] 16/57 [=======>......................] - ETA: 52s  [ loss=4.8224 ][Training] 17/57 [=======>......................] - ETA: 51s  [ loss=9.7599 ][Training] 18/57 [========>.....................] - ETA: 49s  [ loss=12.8867 ][Training] 19/57 [=========>....................] - ETA: 48s  [ loss=5.9637 ][Training] 20/57 [=========>....................] - ETA: 47s  [ loss=4.7651 ][Training] 21/57 [==========>...................] - ETA: 46s  [ loss=5.7373 ][Training] 22/57 [==========>...................] - ETA: 44s  [ loss=5.6223 ][Training] 23/57 [===========>..................] - ETA: 43s  [ loss=7.3667 ][Training] 24/57 [===========>..................] - ETA: 42s  [ loss=8.0902 ][Training] 25/57 [============>.................] - ETA: 40s  [ loss=5.3718 ][Training] 26/57 [============>.................] - ETA: 39s  [ loss=5.8208 ][Training] 27/57 [=============>................] - ETA: 38s  [ loss=3.6112 ][Training] 28/57 [=============>................] - ETA: 36s  [ loss=7.1162 ][Training] 29/57 [==============>...............] - ETA: 35s  [ loss=5.1126 ][Training] 30/57 [==============>...............] - ETA: 34s  [ loss=9.8490 ][Training] 31/57 [===============>..............] - ETA: 33s  [ loss=3.5482 ][Training] 32/57 [===============>..............] - ETA: 32s  [ loss=7.1305 ][Training] 33/57 [================>.............] - ETA: 30s  [ loss=2.5697 ][Training] 34/57 [================>.............] - ETA: 29s  [ loss=8.5027 ][Training] 35/57 [=================>............] - ETA: 27s  [ loss=7.3086 ][Training] 36/57 [=================>............] - ETA: 26s  [ loss=4.6536 ][Training] 37/57 [==================>...........] - ETA: 25s  [ loss=5.3338 ][Training] 38/57 [===================>..........] - ETA: 23s  [ loss=4.5584 ][Training] 39/57 [===================>..........] - ETA: 22s  [ loss=8.1419 ][Training] 40/57 [====================>.........] - ETA: 21s  [ loss=8.7079 ][Training] 41/57 [====================>.........] - ETA: 19s  [ loss=6.2715 ][Training] 42/57 [=====================>........] - ETA: 18s  [ loss=13.7897 ][Training] 43/57 [=====================>........] - ETA: 17s  [ loss=6.1837 ][Training] 44/57 [======================>.......] - ETA: 16s  [ loss=6.0361 ][Training] 45/57 [======================>.......] - ETA: 15s  [ loss=6.7771 ][Training] 46/57 [=======================>......] - ETA: 13s  [ loss=3.9988 ][Training] 47/57 [=======================>......] - ETA: 12s  [ loss=6.4474 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=4.5132 ][Training] 49/57 [========================>.....] - ETA: 10s  [ loss=7.4419 ][Training] 50/57 [=========================>....] - ETA: 8s  [ loss=7.3443 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=6.7860 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=5.1912 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=3.6470 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=6.8916 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=7.3843 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=3.2799 ][Training] 57/57 [==============================] 1.2s/step  [ loss=11.2055 ]
01/03/2024 21:07:29 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 21:07:29 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 21:07:29 - INFO - root -     Num examples = 269
01/03/2024 21:07:29 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 7s[Evaluating] 2/12 [====>.........................] - ETA: 6s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 5s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 577.8ms/step
01/03/2024 21:07:36 - INFO - root -   

01/03/2024 21:07:36 - INFO - root -   ***** Eval results  *****
01/03/2024 21:07:36 - INFO - root -    acc: 0.6044 - recall: 0.6029 - f1: 0.6036 - loss: 7.2253 
01/03/2024 21:07:36 - INFO - root -   ***** Entity results  *****
01/03/2024 21:07:36 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 21:07:36 - INFO - root -    acc: 0.6129 - recall: 0.8085 - f1: 0.6972 
01/03/2024 21:07:36 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 21:07:36 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 21:07:36 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 21:07:36 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 21:07:36 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 21:07:36 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 21:07:36 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 21:07:36 - INFO - root -    acc: 0.4167 - recall: 0.2564 - f1: 0.3175 
01/03/2024 21:07:36 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 21:07:36 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 21:07:36 - INFO - root -   ******* PER.NAM results ********
01/03/2024 21:07:36 - INFO - root -    acc: 0.6827 - recall: 0.6455 - f1: 0.6636 
01/03/2024 21:07:36 - INFO - root -   ******* PER.NOM results ********
01/03/2024 21:07:36 - INFO - root -    acc: 0.5882 - recall: 0.7647 - f1: 0.6650 
01/03/2024 21:07:45 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-171
01/03/2024 21:07:45 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-171
01/03/2024 21:07:45 - INFO - root -   

01/03/2024 21:07:45 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 3/50
[Training] 1/57 [..............................] - ETA: 57s  [ loss=7.3924 ][Training] 2/57 [>.............................] - ETA: 1:09  [ loss=10.0182 ][Training] 3/57 [>.............................] - ETA: 1:16  [ loss=5.3760 ][Training] 4/57 [=>............................] - ETA: 1:13  [ loss=8.4450 ][Training] 5/57 [=>............................] - ETA: 1:09  [ loss=5.0638 ][Training] 6/57 [==>...........................] - ETA: 1:09  [ loss=3.3520 ][Training] 7/57 [==>...........................] - ETA: 1:08  [ loss=5.0001 ][Training] 8/57 [===>..........................] - ETA: 1:05  [ loss=3.4580 ][Training] 9/57 [===>..........................] - ETA: 1:01  [ loss=5.6107 ][Training] 10/57 [====>.........................] - ETA: 59s  [ loss=5.4328 ][Training] 11/57 [====>.........................] - ETA: 56s  [ loss=5.4604 ][Training] 12/57 [=====>........................] - ETA: 54s  [ loss=4.2429 ][Training] 13/57 [=====>........................] - ETA: 54s  [ loss=7.4196 ][Training] 14/57 [======>.......................] - ETA: 54s  [ loss=6.3430 ][Training] 15/57 [======>.......................] - ETA: 53s  [ loss=6.2471 ][Training] 16/57 [=======>......................] - ETA: 52s  [ loss=2.9490 ][Training] 17/57 [=======>......................] - ETA: 51s  [ loss=2.7205 ][Training] 18/57 [========>.....................] - ETA: 50s  [ loss=6.5455 ][Training] 19/57 [=========>....................] - ETA: 49s  [ loss=5.5296 ][Training] 20/57 [=========>....................] - ETA: 48s  [ loss=6.0142 ][Training] 21/57 [==========>...................] - ETA: 47s  [ loss=5.9763 ][Training] 22/57 [==========>...................] - ETA: 45s  [ loss=4.4782 ][Training] 23/57 [===========>..................] - ETA: 43s  [ loss=6.2007 ][Training] 24/57 [===========>..................] - ETA: 42s  [ loss=5.9175 ][Training] 25/57 [============>.................] - ETA: 40s  [ loss=6.6356 ][Training] 26/57 [============>.................] - ETA: 39s  [ loss=4.5332 ][Training] 27/57 [=============>................] - ETA: 37s  [ loss=6.9355 ][Training] 28/57 [=============>................] - ETA: 36s  [ loss=7.9957 ][Training] 29/57 [==============>...............] - ETA: 34s  [ loss=3.3444 ][Training] 30/57 [==============>...............] - ETA: 33s  [ loss=4.0316 ][Training] 31/57 [===============>..............] - ETA: 32s  [ loss=5.7251 ][Training] 32/57 [===============>..............] - ETA: 30s  [ loss=5.9245 ][Training] 33/57 [================>.............] - ETA: 29s  [ loss=6.0662 ][Training] 34/57 [================>.............] - ETA: 28s  [ loss=5.6756 ][Training] 35/57 [=================>............] - ETA: 27s  [ loss=4.8602 ][Training] 36/57 [=================>............] - ETA: 26s  [ loss=7.6898 ][Training] 37/57 [==================>...........] - ETA: 25s  [ loss=4.7216 ][Training] 38/57 [===================>..........] - ETA: 23s  [ loss=4.1769 ][Training] 39/57 [===================>..........] - ETA: 22s  [ loss=5.4873 ][Training] 40/57 [====================>.........] - ETA: 21s  [ loss=5.0034 ][Training] 41/57 [====================>.........] - ETA: 20s  [ loss=6.9402 ][Training] 42/57 [=====================>........] - ETA: 18s  [ loss=7.1034 ][Training] 43/57 [=====================>........] - ETA: 17s  [ loss=7.7045 ][Training] 44/57 [======================>.......] - ETA: 16s  [ loss=4.8770 ][Training] 45/57 [======================>.......] - ETA: 15s  [ loss=6.3380 ][Training] 46/57 [=======================>......] - ETA: 13s  [ loss=3.7288 ][Training] 47/57 [=======================>......] - ETA: 12s  [ loss=5.4062 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=4.8641 ][Training] 49/57 [========================>.....] - ETA: 10s  [ loss=5.0110 ][Training] 50/57 [=========================>....] - ETA: 8s  [ loss=5.4013 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=2.6194 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=2.8896 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=3.2333 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=3.6228 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=6.3383 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=2.0948 ][Training] 57/57 [==============================] 1.2s/step  [ loss=2.8592 ]
01/03/2024 21:08:56 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 21:08:56 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 21:08:56 - INFO - root -     Num examples = 269
01/03/2024 21:08:56 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 5s[Evaluating] 2/12 [====>.........................] - ETA: 5s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 2s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 550.2ms/step
01/03/2024 21:09:02 - INFO - root -   

01/03/2024 21:09:02 - INFO - root -   ***** Eval results  *****
01/03/2024 21:09:02 - INFO - root -    acc: 0.6809 - recall: 0.6199 - f1: 0.6489 - loss: 6.3333 
01/03/2024 21:09:02 - INFO - root -   ***** Entity results  *****
01/03/2024 21:09:02 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 21:09:02 - INFO - root -    acc: 0.7091 - recall: 0.8298 - f1: 0.7647 
01/03/2024 21:09:02 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 21:09:02 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 21:09:02 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 21:09:02 - INFO - root -    acc: 0.4000 - recall: 0.1053 - f1: 0.1667 
01/03/2024 21:09:02 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 21:09:02 - INFO - root -    acc: 0.5000 - recall: 0.1111 - f1: 0.1818 
01/03/2024 21:09:02 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 21:09:02 - INFO - root -    acc: 0.4211 - recall: 0.2051 - f1: 0.2759 
01/03/2024 21:09:02 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 21:09:02 - INFO - root -    acc: 1.0000 - recall: 0.2353 - f1: 0.3810 
01/03/2024 21:09:02 - INFO - root -   ******* PER.NAM results ********
01/03/2024 21:09:02 - INFO - root -    acc: 0.7551 - recall: 0.6727 - f1: 0.7115 
01/03/2024 21:09:02 - INFO - root -   ******* PER.NOM results ********
01/03/2024 21:09:02 - INFO - root -    acc: 0.6632 - recall: 0.7529 - f1: 0.7052 
01/03/2024 21:09:17 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-228
01/03/2024 21:09:17 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-228
01/03/2024 21:09:17 - INFO - root -   

01/03/2024 21:09:17 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 4/50
[Training] 1/57 [..............................] - ETA: 1:02  [ loss=6.1660 ][Training] 2/57 [>.............................] - ETA: 1:03  [ loss=3.3851 ][Training] 3/57 [>.............................] - ETA: 1:04  [ loss=6.7477 ][Training] 4/57 [=>............................] - ETA: 1:03  [ loss=5.5766 ][Training] 5/57 [=>............................] - ETA: 1:03  [ loss=4.4012 ][Training] 6/57 [==>...........................] - ETA: 59s  [ loss=2.2908 ][Training] 7/57 [==>...........................] - ETA: 1:00  [ loss=3.0745 ][Training] 8/57 [===>..........................] - ETA: 59s  [ loss=5.2289 ][Training] 9/57 [===>..........................] - ETA: 59s  [ loss=5.2492 ][Training] 10/57 [====>.........................] - ETA: 59s  [ loss=7.9267 ][Training] 11/57 [====>.........................] - ETA: 58s  [ loss=3.7347 ][Training] 12/57 [=====>........................] - ETA: 56s  [ loss=2.9616 ][Training] 13/57 [=====>........................] - ETA: 56s  [ loss=4.4556 ][Training] 14/57 [======>.......................] - ETA: 54s  [ loss=4.5174 ][Training] 15/57 [======>.......................] - ETA: 52s  [ loss=2.5980 ][Training] 16/57 [=======>......................] - ETA: 51s  [ loss=2.9143 ][Training] 17/57 [=======>......................] - ETA: 49s  [ loss=2.1007 ][Training] 18/57 [========>.....................] - ETA: 48s  [ loss=4.9500 ][Training] 19/57 [=========>....................] - ETA: 47s  [ loss=6.5663 ][Training] 20/57 [=========>....................] - ETA: 46s  [ loss=3.9237 ][Training] 21/57 [==========>...................] - ETA: 44s  [ loss=3.2607 ][Training] 22/57 [==========>...................] - ETA: 43s  [ loss=4.8292 ][Training] 23/57 [===========>..................] - ETA: 42s  [ loss=5.5647 ][Training] 24/57 [===========>..................] - ETA: 41s  [ loss=4.8257 ][Training] 25/57 [============>.................] - ETA: 40s  [ loss=3.7196 ][Training] 26/57 [============>.................] - ETA: 38s  [ loss=2.7353 ][Training] 27/57 [=============>................] - ETA: 37s  [ loss=3.6366 ][Training] 28/57 [=============>................] - ETA: 35s  [ loss=7.7544 ][Training] 29/57 [==============>...............] - ETA: 34s  [ loss=6.0998 ][Training] 30/57 [==============>...............] - ETA: 33s  [ loss=3.1185 ][Training] 31/57 [===============>..............] - ETA: 31s  [ loss=7.1286 ][Training] 32/57 [===============>..............] - ETA: 30s  [ loss=5.4438 ][Training] 33/57 [================>.............] - ETA: 29s  [ loss=3.7673 ][Training] 34/57 [================>.............] - ETA: 27s  [ loss=6.1368 ][Training] 35/57 [=================>............] - ETA: 26s  [ loss=5.2072 ][Training] 36/57 [=================>............] - ETA: 25s  [ loss=4.0681 ][Training] 37/57 [==================>...........] - ETA: 24s  [ loss=6.6175 ][Training] 38/57 [===================>..........] - ETA: 22s  [ loss=3.6160 ][Training] 39/57 [===================>..........] - ETA: 21s  [ loss=6.0837 ][Training] 40/57 [====================>.........] - ETA: 20s  [ loss=5.1736 ][Training] 41/57 [====================>.........] - ETA: 19s  [ loss=4.4856 ][Training] 42/57 [=====================>........] - ETA: 18s  [ loss=4.7857 ][Training] 43/57 [=====================>........] - ETA: 17s  [ loss=4.8598 ][Training] 44/57 [======================>.......] - ETA: 16s  [ loss=3.1378 ][Training] 45/57 [======================>.......] - ETA: 14s  [ loss=4.8697 ][Training] 46/57 [=======================>......] - ETA: 13s  [ loss=4.8014 ][Training] 47/57 [=======================>......] - ETA: 12s  [ loss=7.5069 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=5.4009 ][Training] 49/57 [========================>.....] - ETA: 10s  [ loss=4.8738 ][Training] 50/57 [=========================>....] - ETA: 8s  [ loss=4.6664 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=3.5398 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=7.8896 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=5.5106 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=2.4433 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=7.3661 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=4.9533 ][Training] 57/57 [==============================] 1.2s/step  [ loss=0.6009 ]
01/03/2024 21:10:27 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 21:10:27 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 21:10:27 - INFO - root -     Num examples = 269
01/03/2024 21:10:27 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 6s[Evaluating] 2/12 [====>.........................] - ETA: 5s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 588.4ms/step
01/03/2024 21:10:34 - INFO - root -   

01/03/2024 21:10:34 - INFO - root -   ***** Eval results  *****
01/03/2024 21:10:34 - INFO - root -    acc: 0.6333 - recall: 0.6441 - f1: 0.6387 - loss: 6.3137 
01/03/2024 21:10:34 - INFO - root -   ***** Entity results  *****
01/03/2024 21:10:34 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 21:10:34 - INFO - root -    acc: 0.7288 - recall: 0.9149 - f1: 0.8113 
01/03/2024 21:10:34 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 21:10:34 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 21:10:34 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 21:10:34 - INFO - root -    acc: 0.3750 - recall: 0.1579 - f1: 0.2222 
01/03/2024 21:10:34 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 21:10:34 - INFO - root -    acc: 0.5000 - recall: 0.1111 - f1: 0.1818 
01/03/2024 21:10:34 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 21:10:34 - INFO - root -    acc: 0.3043 - recall: 0.1795 - f1: 0.2258 
01/03/2024 21:10:34 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 21:10:34 - INFO - root -    acc: 0.8000 - recall: 0.2353 - f1: 0.3636 
01/03/2024 21:10:34 - INFO - root -   ******* PER.NAM results ********
01/03/2024 21:10:34 - INFO - root -    acc: 0.7000 - recall: 0.7000 - f1: 0.7000 
01/03/2024 21:10:34 - INFO - root -   ******* PER.NOM results ********
01/03/2024 21:10:34 - INFO - root -    acc: 0.6150 - recall: 0.7706 - f1: 0.6841 
01/03/2024 21:10:44 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-285
01/03/2024 21:10:44 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-285
01/03/2024 21:10:44 - INFO - root -   

01/03/2024 21:10:44 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 5/50
[Training] 1/57 [..............................] - ETA: 1:01  [ loss=1.5982 ][Training] 2/57 [>.............................] - ETA: 1:00  [ loss=2.1106 ][Training] 3/57 [>.............................] - ETA: 1:03  [ loss=4.0494 ][Training] 4/57 [=>............................] - ETA: 1:02  [ loss=3.3708 ][Training] 5/57 [=>............................] - ETA: 1:02  [ loss=3.1497 ][Training] 6/57 [==>...........................] - ETA: 1:03  [ loss=8.0509 ][Training] 7/57 [==>...........................] - ETA: 1:01  [ loss=3.7231 ][Training] 8/57 [===>..........................] - ETA: 1:00  [ loss=3.0538 ][Training] 9/57 [===>..........................] - ETA: 59s  [ loss=3.1249 ][Training] 10/57 [====>.........................] - ETA: 59s  [ loss=4.8402 ][Training] 11/57 [====>.........................] - ETA: 58s  [ loss=4.3624 ][Training] 12/57 [=====>........................] - ETA: 59s  [ loss=5.1346 ][Training] 13/57 [=====>........................] - ETA: 58s  [ loss=4.1204 ][Training] 14/57 [======>.......................] - ETA: 56s  [ loss=4.7265 ][Training] 15/57 [======>.......................] - ETA: 54s  [ loss=3.1481 ][Training] 16/57 [=======>......................] - ETA: 52s  [ loss=2.6426 ][Training] 17/57 [=======>......................] - ETA: 51s  [ loss=3.5435 ][Training] 18/57 [========>.....................] - ETA: 50s  [ loss=4.7937 ][Training] 19/57 [=========>....................] - ETA: 49s  [ loss=6.5349 ][Training] 20/57 [=========>....................] - ETA: 48s  [ loss=3.4179 ][Training] 21/57 [==========>...................] - ETA: 46s  [ loss=3.6743 ][Training] 22/57 [==========>...................] - ETA: 44s  [ loss=6.1011 ][Training] 23/57 [===========>..................] - ETA: 43s  [ loss=4.1095 ][Training] 24/57 [===========>..................] - ETA: 42s  [ loss=4.0633 ][Training] 25/57 [============>.................] - ETA: 41s  [ loss=5.0948 ][Training] 26/57 [============>.................] - ETA: 40s  [ loss=6.5161 ][Training] 27/57 [=============>................] - ETA: 38s  [ loss=4.2483 ][Training] 28/57 [=============>................] - ETA: 37s  [ loss=2.1094 ][Training] 29/57 [==============>...............] - ETA: 35s  [ loss=4.0771 ][Training] 30/57 [==============>...............] - ETA: 34s  [ loss=6.7200 ][Training] 31/57 [===============>..............] - ETA: 33s  [ loss=7.1209 ][Training] 32/57 [===============>..............] - ETA: 32s  [ loss=5.7868 ][Training] 33/57 [================>.............] - ETA: 30s  [ loss=3.4400 ][Training] 34/57 [================>.............] - ETA: 29s  [ loss=6.7165 ][Training] 35/57 [=================>............] - ETA: 28s  [ loss=3.1066 ][Training] 36/57 [=================>............] - ETA: 26s  [ loss=2.1971 ][Training] 37/57 [==================>...........] - ETA: 25s  [ loss=8.2425 ][Training] 38/57 [===================>..........] - ETA: 24s  [ loss=1.8139 ][Training] 39/57 [===================>..........] - ETA: 23s  [ loss=2.9285 ][Training] 40/57 [====================>.........] - ETA: 21s  [ loss=5.0669 ][Training] 41/57 [====================>.........] - ETA: 20s  [ loss=5.6009 ][Training] 42/57 [=====================>........] - ETA: 19s  [ loss=2.5162 ][Training] 43/57 [=====================>........] - ETA: 18s  [ loss=3.6869 ][Training] 44/57 [======================>.......] - ETA: 16s  [ loss=5.2750 ][Training] 45/57 [======================>.......] - ETA: 15s  [ loss=2.5029 ][Training] 46/57 [=======================>......] - ETA: 14s  [ loss=4.7024 ][Training] 47/57 [=======================>......] - ETA: 12s  [ loss=7.5858 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=7.8194 ][Training] 49/57 [========================>.....] - ETA: 10s  [ loss=4.1399 ][Training] 50/57 [=========================>....] - ETA: 9s  [ loss=5.5901 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=3.5102 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=2.8219 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=3.2762 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=4.4119 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=3.6639 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=3.4650 ][Training] 57/57 [==============================] 1.3s/step  [ loss=3.3540 ]
01/03/2024 21:11:56 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 21:11:56 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 21:11:56 - INFO - root -     Num examples = 269
01/03/2024 21:11:56 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 6s[Evaluating] 2/12 [====>.........................] - ETA: 5s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 561.6ms/step
01/03/2024 21:12:03 - INFO - root -   

01/03/2024 21:12:03 - INFO - root -   ***** Eval results  *****
01/03/2024 21:12:03 - INFO - root -    acc: 0.6262 - recall: 0.6368 - f1: 0.6315 - loss: 6.4605 
01/03/2024 21:12:03 - INFO - root -   ***** Entity results  *****
01/03/2024 21:12:03 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 21:12:03 - INFO - root -    acc: 0.7273 - recall: 0.8511 - f1: 0.7843 
01/03/2024 21:12:03 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 21:12:03 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 21:12:03 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 21:12:03 - INFO - root -    acc: 0.3750 - recall: 0.1579 - f1: 0.2222 
01/03/2024 21:12:03 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 21:12:03 - INFO - root -    acc: 0.1667 - recall: 0.1111 - f1: 0.1333 
01/03/2024 21:12:03 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 21:12:03 - INFO - root -    acc: 0.4091 - recall: 0.2308 - f1: 0.2951 
01/03/2024 21:12:03 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 21:12:03 - INFO - root -    acc: 1.0000 - recall: 0.2353 - f1: 0.3810 
01/03/2024 21:12:03 - INFO - root -   ******* PER.NAM results ********
01/03/2024 21:12:03 - INFO - root -    acc: 0.6667 - recall: 0.7091 - f1: 0.6872 
01/03/2024 21:12:03 - INFO - root -   ******* PER.NOM results ********
01/03/2024 21:12:03 - INFO - root -    acc: 0.6154 - recall: 0.7529 - f1: 0.6772 
01/03/2024 21:12:18 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-342
01/03/2024 21:12:18 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-342
01/03/2024 21:12:18 - INFO - root -   

01/03/2024 21:12:18 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 6/50
[Training] 1/57 [..............................] - ETA: 1:04  [ loss=4.4591 ][Training] 2/57 [>.............................] - ETA: 1:05  [ loss=5.1570 ][Training] 3/57 [>.............................] - ETA: 1:02  [ loss=2.9181 ][Training] 4/57 [=>............................] - ETA: 59s  [ loss=9.6733 ][Training] 5/57 [=>............................] - ETA: 59s  [ loss=3.4306 ][Training] 6/57 [==>...........................] - ETA: 1:01  [ loss=3.7049 ][Training] 7/57 [==>...........................] - ETA: 1:01  [ loss=6.0510 ][Training] 8/57 [===>..........................] - ETA: 1:01  [ loss=4.1020 ][Training] 9/57 [===>..........................] - ETA: 59s  [ loss=2.7793 ][Training] 10/57 [====>.........................] - ETA: 58s  [ loss=3.2322 ][Training] 11/57 [====>.........................] - ETA: 58s  [ loss=4.6628 ][Training] 12/57 [=====>........................] - ETA: 56s  [ loss=3.2154 ][Training] 13/57 [=====>........................] - ETA: 54s  [ loss=4.2711 ][Training] 14/57 [======>.......................] - ETA: 53s  [ loss=2.7815 ][Training] 15/57 [======>.......................] - ETA: 52s  [ loss=5.1710 ][Training] 16/57 [=======>......................] - ETA: 52s  [ loss=5.5829 ][Training] 17/57 [=======>......................] - ETA: 50s  [ loss=2.9034 ][Training] 18/57 [========>.....................] - ETA: 49s  [ loss=1.9749 ][Training] 19/57 [=========>....................] - ETA: 48s  [ loss=4.2417 ][Training] 20/57 [=========>....................] - ETA: 47s  [ loss=5.2310 ][Training] 21/57 [==========>...................] - ETA: 47s  [ loss=3.7599 ][Training] 22/57 [==========>...................] - ETA: 46s  [ loss=3.1146 ][Training] 23/57 [===========>..................] - ETA: 45s  [ loss=2.7209 ][Training] 24/57 [===========>..................] - ETA: 44s  [ loss=2.6464 ][Training] 25/57 [============>.................] - ETA: 43s  [ loss=3.0303 ][Training] 26/57 [============>.................] - ETA: 41s  [ loss=1.6976 ][Training] 27/57 [=============>................] - ETA: 40s  [ loss=3.1955 ][Training] 28/57 [=============>................] - ETA: 38s  [ loss=6.7919 ][Training] 29/57 [==============>...............] - ETA: 37s  [ loss=2.0219 ][Training] 30/57 [==============>...............] - ETA: 35s  [ loss=5.8770 ][Training] 31/57 [===============>..............] - ETA: 34s  [ loss=4.1340 ][Training] 32/57 [===============>..............] - ETA: 32s  [ loss=5.8977 ][Training] 33/57 [================>.............] - ETA: 31s  [ loss=2.6425 ][Training] 34/57 [================>.............] - ETA: 29s  [ loss=4.5535 ][Training] 35/57 [=================>............] - ETA: 28s  [ loss=4.2441 ][Training] 36/57 [=================>............] - ETA: 27s  [ loss=2.6383 ][Training] 37/57 [==================>...........] - ETA: 26s  [ loss=3.0466 ][Training] 38/57 [===================>..........] - ETA: 24s  [ loss=2.0693 ][Training] 39/57 [===================>..........] - ETA: 23s  [ loss=2.9144 ][Training] 40/57 [====================>.........] - ETA: 21s  [ loss=5.2512 ][Training] 41/57 [====================>.........] - ETA: 20s  [ loss=6.5625 ][Training] 42/57 [=====================>........] - ETA: 19s  [ loss=2.8175 ][Training] 43/57 [=====================>........] - ETA: 18s  [ loss=3.4521 ][Training] 44/57 [======================>.......] - ETA: 16s  [ loss=3.0103 ][Training] 45/57 [======================>.......] - ETA: 15s  [ loss=3.8761 ][Training] 46/57 [=======================>......] - ETA: 14s  [ loss=3.1098 ][Training] 47/57 [=======================>......] - ETA: 13s  [ loss=5.5037 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=5.6217 ][Training] 49/57 [========================>.....] - ETA: 10s  [ loss=7.5439 ][Training] 50/57 [=========================>....] - ETA: 9s  [ loss=3.2414 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=2.3815 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=4.0921 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=3.6637 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=2.1158 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=3.2859 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=2.8838 ][Training] 57/57 [==============================] 1.3s/step  [ loss=1.5929 ]
01/03/2024 21:13:30 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 21:13:30 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 21:13:30 - INFO - root -     Num examples = 269
01/03/2024 21:13:30 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 6s[Evaluating] 2/12 [====>.........................] - ETA: 6s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 574.9ms/step
01/03/2024 21:13:37 - INFO - root -   

01/03/2024 21:13:37 - INFO - root -   ***** Eval results  *****
01/03/2024 21:13:37 - INFO - root -    acc: 0.6861 - recall: 0.6562 - f1: 0.6708 - loss: 5.8257 
01/03/2024 21:13:37 - INFO - root -   ***** Entity results  *****
01/03/2024 21:13:37 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 21:13:37 - INFO - root -    acc: 0.7636 - recall: 0.8936 - f1: 0.8235 
01/03/2024 21:13:37 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 21:13:37 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 21:13:37 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 21:13:37 - INFO - root -    acc: 0.5000 - recall: 0.3158 - f1: 0.3871 
01/03/2024 21:13:37 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 21:13:37 - INFO - root -    acc: 0.5000 - recall: 0.2222 - f1: 0.3077 
01/03/2024 21:13:37 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 21:13:37 - INFO - root -    acc: 0.3913 - recall: 0.2308 - f1: 0.2903 
01/03/2024 21:13:37 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 21:13:37 - INFO - root -    acc: 1.0000 - recall: 0.3529 - f1: 0.5217 
01/03/2024 21:13:37 - INFO - root -   ******* PER.NAM results ********
01/03/2024 21:13:37 - INFO - root -    acc: 0.7547 - recall: 0.7273 - f1: 0.7407 
01/03/2024 21:13:37 - INFO - root -   ******* PER.NOM results ********
01/03/2024 21:13:37 - INFO - root -    acc: 0.6667 - recall: 0.7412 - f1: 0.7019 
01/03/2024 21:13:47 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-399
01/03/2024 21:13:47 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-399
01/03/2024 21:13:47 - INFO - root -   

01/03/2024 21:13:47 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 7/50
[Training] 1/57 [..............................] - ETA: 1:12  [ loss=2.9459 ][Training] 2/57 [>.............................] - ETA: 1:20  [ loss=5.3632 ][Training] 3/57 [>.............................] - ETA: 1:14  [ loss=3.2081 ][Training] 4/57 [=>............................] - ETA: 1:06  [ loss=7.1487 ][Training] 5/57 [=>............................] - ETA: 1:08  [ loss=4.0060 ][Training] 6/57 [==>...........................] - ETA: 1:07  [ loss=2.4925 ][Training] 7/57 [==>...........................] - ETA: 1:04  [ loss=5.6123 ][Training] 8/57 [===>..........................] - ETA: 1:02  [ loss=2.6922 ][Training] 9/57 [===>..........................] - ETA: 1:01  [ loss=2.6357 ][Training] 10/57 [====>.........................] - ETA: 57s  [ loss=2.6746 ][Training] 11/57 [====>.........................] - ETA: 58s  [ loss=4.6588 ][Training] 12/57 [=====>........................] - ETA: 56s  [ loss=2.7113 ][Training] 13/57 [=====>........................] - ETA: 55s  [ loss=3.6960 ][Training] 14/57 [======>.......................] - ETA: 53s  [ loss=4.5404 ][Training] 15/57 [======>.......................] - ETA: 52s  [ loss=4.9919 ][Training] 16/57 [=======>......................] - ETA: 50s  [ loss=4.9172 ][Training] 17/57 [=======>......................] - ETA: 50s  [ loss=1.9737 ][Training] 18/57 [========>.....................] - ETA: 48s  [ loss=1.2181 ][Training] 19/57 [=========>....................] - ETA: 47s  [ loss=4.3243 ][Training] 20/57 [=========>....................] - ETA: 45s  [ loss=3.0338 ][Training] 21/57 [==========>...................] - ETA: 44s  [ loss=3.2448 ][Training] 22/57 [==========>...................] - ETA: 43s  [ loss=3.0793 ][Training] 23/57 [===========>..................] - ETA: 42s  [ loss=2.1740 ][Training] 24/57 [===========>..................] - ETA: 42s  [ loss=4.6940 ][Training] 25/57 [============>.................] - ETA: 40s  [ loss=4.4400 ][Training] 26/57 [============>.................] - ETA: 39s  [ loss=1.9322 ][Training] 27/57 [=============>................] - ETA: 38s  [ loss=3.3165 ][Training] 28/57 [=============>................] - ETA: 37s  [ loss=2.7247 ][Training] 29/57 [==============>...............] - ETA: 35s  [ loss=3.6059 ][Training] 30/57 [==============>...............] - ETA: 34s  [ loss=3.0251 ][Training] 31/57 [===============>..............] - ETA: 33s  [ loss=3.4566 ][Training] 32/57 [===============>..............] - ETA: 32s  [ loss=3.0590 ][Training] 33/57 [================>.............] - ETA: 30s  [ loss=3.8028 ][Training] 34/57 [================>.............] - ETA: 29s  [ loss=4.4875 ][Training] 35/57 [=================>............] - ETA: 28s  [ loss=3.0006 ][Training] 36/57 [=================>............] - ETA: 27s  [ loss=3.7823 ][Training] 37/57 [==================>...........] - ETA: 26s  [ loss=4.6245 ][Training] 38/57 [===================>..........] - ETA: 24s  [ loss=2.5781 ][Training] 39/57 [===================>..........] - ETA: 23s  [ loss=3.4545 ][Training] 40/57 [====================>.........] - ETA: 21s  [ loss=1.8068 ][Training] 41/57 [====================>.........] - ETA: 20s  [ loss=2.8128 ][Training] 42/57 [=====================>........] - ETA: 19s  [ loss=5.1438 ][Training] 43/57 [=====================>........] - ETA: 18s  [ loss=3.0871 ][Training] 44/57 [======================>.......] - ETA: 16s  [ loss=4.4245 ][Training] 45/57 [======================>.......] - ETA: 15s  [ loss=6.2452 ][Training] 46/57 [=======================>......] - ETA: 14s  [ loss=3.1767 ][Training] 47/57 [=======================>......] - ETA: 12s  [ loss=2.4858 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=4.5154 ][Training] 49/57 [========================>.....] - ETA: 10s  [ loss=3.8939 ][Training] 50/57 [=========================>....] - ETA: 9s  [ loss=5.1394 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=5.0919 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=2.1056 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=3.2916 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=4.7178 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=4.2534 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=2.9172 ][Training] 57/57 [==============================] 1.3s/step  [ loss=2.1192 ]
01/03/2024 21:14:59 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 21:15:00 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 21:15:00 - INFO - root -     Num examples = 269
01/03/2024 21:15:00 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 7s[Evaluating] 2/12 [====>.........................] - ETA: 6s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 5s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 585.0ms/step
01/03/2024 21:15:07 - INFO - root -   

01/03/2024 21:15:07 - INFO - root -   ***** Eval results  *****
01/03/2024 21:15:07 - INFO - root -    acc: 0.6683 - recall: 0.6489 - f1: 0.6585 - loss: 5.8960 
01/03/2024 21:15:07 - INFO - root -   ***** Entity results  *****
01/03/2024 21:15:07 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 21:15:07 - INFO - root -    acc: 0.7500 - recall: 0.8936 - f1: 0.8155 
01/03/2024 21:15:07 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 21:15:07 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 21:15:07 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 21:15:07 - INFO - root -    acc: 0.5385 - recall: 0.3684 - f1: 0.4375 
01/03/2024 21:15:07 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 21:15:07 - INFO - root -    acc: 0.2000 - recall: 0.1111 - f1: 0.1429 
01/03/2024 21:15:07 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 21:15:07 - INFO - root -    acc: 0.4091 - recall: 0.2308 - f1: 0.2951 
01/03/2024 21:15:07 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 21:15:07 - INFO - root -    acc: 0.8750 - recall: 0.4118 - f1: 0.5600 
01/03/2024 21:15:07 - INFO - root -   ******* PER.NAM results ********
01/03/2024 21:15:07 - INFO - root -    acc: 0.6991 - recall: 0.7182 - f1: 0.7085 
01/03/2024 21:15:07 - INFO - root -   ******* PER.NOM results ********
01/03/2024 21:15:07 - INFO - root -    acc: 0.6685 - recall: 0.7235 - f1: 0.6949 
01/03/2024 21:15:25 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-456
01/03/2024 21:15:25 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-456
01/03/2024 21:15:25 - INFO - root -   

01/03/2024 21:15:25 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 8/50
[Training] 1/57 [..............................] - ETA: 1:19  [ loss=3.1541 ][Training] 2/57 [>.............................] - ETA: 1:18  [ loss=4.2758 ][Training] 3/57 [>.............................] - ETA: 1:12  [ loss=2.7367 ][Training] 4/57 [=>............................] - ETA: 1:08  [ loss=5.6155 ][Training] 5/57 [=>............................] - ETA: 1:09  [ loss=8.8352 ][Training] 6/57 [==>...........................] - ETA: 1:05  [ loss=2.6157 ][Training] 7/57 [==>...........................] - ETA: 1:03  [ loss=5.3798 ][Training] 8/57 [===>..........................] - ETA: 1:02  [ loss=3.4936 ][Training] 9/57 [===>..........................] - ETA: 1:01  [ loss=2.5900 ][Training] 10/57 [====>.........................] - ETA: 59s  [ loss=1.4025 ][Training] 11/57 [====>.........................] - ETA: 57s  [ loss=1.6857 ][Training] 12/57 [=====>........................] - ETA: 58s  [ loss=4.1266 ][Training] 13/57 [=====>........................] - ETA: 57s  [ loss=3.5377 ][Training] 14/57 [======>.......................] - ETA: 56s  [ loss=2.8654 ][Training] 15/57 [======>.......................] - ETA: 54s  [ loss=2.9181 ][Training] 16/57 [=======>......................] - ETA: 52s  [ loss=1.5921 ][Training] 17/57 [=======>......................] - ETA: 51s  [ loss=2.3769 ][Training] 18/57 [========>.....................] - ETA: 50s  [ loss=2.7179 ][Training] 19/57 [=========>....................] - ETA: 48s  [ loss=2.9159 ][Training] 20/57 [=========>....................] - ETA: 47s  [ loss=4.5159 ][Training] 21/57 [==========>...................] - ETA: 46s  [ loss=4.4248 ][Training] 22/57 [==========>...................] - ETA: 45s  [ loss=3.9948 ][Training] 23/57 [===========>..................] - ETA: 43s  [ loss=2.1028 ][Training] 24/57 [===========>..................] - ETA: 42s  [ loss=2.8509 ][Training] 25/57 [============>.................] - ETA: 41s  [ loss=2.0323 ][Training] 26/57 [============>.................] - ETA: 39s  [ loss=1.9143 ][Training] 27/57 [=============>................] - ETA: 38s  [ loss=3.7454 ][Training] 28/57 [=============>................] - ETA: 36s  [ loss=4.0003 ][Training] 29/57 [==============>...............] - ETA: 35s  [ loss=3.5406 ][Training] 30/57 [==============>...............] - ETA: 34s  [ loss=4.3763 ][Training] 31/57 [===============>..............] - ETA: 33s  [ loss=2.9645 ][Training] 32/57 [===============>..............] - ETA: 31s  [ loss=3.5788 ][Training] 33/57 [================>.............] - ETA: 30s  [ loss=3.0190 ][Training] 34/57 [================>.............] - ETA: 29s  [ loss=2.7216 ][Training] 35/57 [=================>............] - ETA: 28s  [ loss=3.2512 ][Training] 36/57 [=================>............] - ETA: 26s  [ loss=2.1102 ][Training] 37/57 [==================>...........] - ETA: 25s  [ loss=4.2721 ][Training] 38/57 [===================>..........] - ETA: 24s  [ loss=3.3185 ][Training] 39/57 [===================>..........] - ETA: 22s  [ loss=3.3219 ][Training] 40/57 [====================>.........] - ETA: 21s  [ loss=4.8957 ][Training] 41/57 [====================>.........] - ETA: 20s  [ loss=2.4873 ][Training] 42/57 [=====================>........] - ETA: 19s  [ loss=2.8335 ][Training] 43/57 [=====================>........] - ETA: 17s  [ loss=3.0985 ][Training] 44/57 [======================>.......] - ETA: 16s  [ loss=5.2052 ][Training] 45/57 [======================>.......] - ETA: 15s  [ loss=3.0224 ][Training] 46/57 [=======================>......] - ETA: 14s  [ loss=2.1978 ][Training] 47/57 [=======================>......] - ETA: 12s  [ loss=4.7448 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=2.4417 ][Training] 49/57 [========================>.....] - ETA: 10s  [ loss=3.9392 ][Training] 50/57 [=========================>....] - ETA: 9s  [ loss=3.1548 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=4.6603 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=1.9435 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=2.4099 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=5.6637 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=5.1925 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=1.8668 ][Training] 57/57 [==============================] 1.3s/step  [ loss=2.5560 ]
01/03/2024 21:16:38 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 21:16:38 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 21:16:38 - INFO - root -     Num examples = 269
01/03/2024 21:16:38 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 5s[Evaluating] 2/12 [====>.........................] - ETA: 6s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 2s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 567.8ms/step
01/03/2024 21:16:45 - INFO - root -   

01/03/2024 21:16:45 - INFO - root -   ***** Eval results  *****
01/03/2024 21:16:45 - INFO - root -    acc: 0.6783 - recall: 0.6586 - f1: 0.6683 - loss: 5.6534 
01/03/2024 21:16:45 - INFO - root -   ***** Entity results  *****
01/03/2024 21:16:45 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 21:16:45 - INFO - root -    acc: 0.7407 - recall: 0.8511 - f1: 0.7921 
01/03/2024 21:16:45 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 21:16:45 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 21:16:45 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 21:16:45 - INFO - root -    acc: 0.4000 - recall: 0.3158 - f1: 0.3529 
01/03/2024 21:16:45 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 21:16:45 - INFO - root -    acc: 0.2222 - recall: 0.2222 - f1: 0.2222 
01/03/2024 21:16:45 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 21:16:45 - INFO - root -    acc: 0.5200 - recall: 0.3333 - f1: 0.4063 
01/03/2024 21:16:45 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 21:16:45 - INFO - root -    acc: 1.0000 - recall: 0.4118 - f1: 0.5833 
01/03/2024 21:16:45 - INFO - root -   ******* PER.NAM results ********
01/03/2024 21:16:45 - INFO - root -    acc: 0.7524 - recall: 0.7182 - f1: 0.7349 
01/03/2024 21:16:45 - INFO - root -   ******* PER.NOM results ********
01/03/2024 21:16:45 - INFO - root -    acc: 0.6720 - recall: 0.7353 - f1: 0.7022 
01/03/2024 21:16:53 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-513
01/03/2024 21:16:53 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-513
01/03/2024 21:16:53 - INFO - root -   

01/03/2024 21:16:53 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 9/50
[Training] 1/57 [..............................] - ETA: 1:15  [ loss=7.7166 ][Training] 2/57 [>.............................] - ETA: 1:14  [ loss=3.8308 ][Training] 3/57 [>.............................] - ETA: 1:13  [ loss=2.0687 ][Training] 4/57 [=>............................] - ETA: 1:12  [ loss=2.9987 ][Training] 5/57 [=>............................] - ETA: 1:09  [ loss=2.4603 ][Training] 6/57 [==>...........................] - ETA: 1:05  [ loss=2.7129 ][Training] 7/57 [==>...........................] - ETA: 1:03  [ loss=1.7590 ][Training] 8/57 [===>..........................] - ETA: 1:00  [ loss=2.0681 ][Training] 9/57 [===>..........................] - ETA: 1:00  [ loss=2.8507 ][Training] 10/57 [====>.........................] - ETA: 58s  [ loss=4.3566 ][Training] 11/57 [====>.........................] - ETA: 58s  [ loss=5.6380 ][Training] 12/57 [=====>........................] - ETA: 57s  [ loss=3.3073 ][Training] 13/57 [=====>........................] - ETA: 55s  [ loss=2.0567 ][Training] 14/57 [======>.......................] - ETA: 53s  [ loss=2.5618 ][Training] 15/57 [======>.......................] - ETA: 52s  [ loss=3.5696 ][Training] 16/57 [=======>......................] - ETA: 51s  [ loss=2.6490 ][Training] 17/57 [=======>......................] - ETA: 49s  [ loss=2.0152 ][Training] 18/57 [========>.....................] - ETA: 48s  [ loss=1.8440 ][Training] 19/57 [=========>....................] - ETA: 47s  [ loss=2.4868 ][Training] 20/57 [=========>....................] - ETA: 46s  [ loss=3.5323 ][Training] 21/57 [==========>...................] - ETA: 44s  [ loss=1.5819 ][Training] 22/57 [==========>...................] - ETA: 44s  [ loss=3.6743 ][Training] 23/57 [===========>..................] - ETA: 42s  [ loss=3.3853 ][Training] 24/57 [===========>..................] - ETA: 41s  [ loss=1.8627 ][Training] 25/57 [============>.................] - ETA: 40s  [ loss=2.5406 ][Training] 26/57 [============>.................] - ETA: 38s  [ loss=3.6919 ][Training] 27/57 [=============>................] - ETA: 36s  [ loss=5.1256 ][Training] 28/57 [=============>................] - ETA: 35s  [ loss=4.2621 ][Training] 29/57 [==============>...............] - ETA: 34s  [ loss=4.5702 ][Training] 30/57 [==============>...............] - ETA: 33s  [ loss=3.4511 ][Training] 31/57 [===============>..............] - ETA: 31s  [ loss=3.3705 ][Training] 32/57 [===============>..............] - ETA: 30s  [ loss=3.5496 ][Training] 33/57 [================>.............] - ETA: 29s  [ loss=2.2646 ][Training] 34/57 [================>.............] - ETA: 28s  [ loss=3.6742 ][Training] 35/57 [=================>............] - ETA: 27s  [ loss=2.1893 ][Training] 36/57 [=================>............] - ETA: 26s  [ loss=1.6624 ][Training] 37/57 [==================>...........] - ETA: 24s  [ loss=2.2640 ][Training] 38/57 [===================>..........] - ETA: 23s  [ loss=3.0471 ][Training] 39/57 [===================>..........] - ETA: 22s  [ loss=4.2837 ][Training] 40/57 [====================>.........] - ETA: 21s  [ loss=3.3676 ][Training] 41/57 [====================>.........] - ETA: 19s  [ loss=2.2053 ][Training] 42/57 [=====================>........] - ETA: 18s  [ loss=6.1726 ][Training] 43/57 [=====================>........] - ETA: 17s  [ loss=2.0743 ][Training] 44/57 [======================>.......] - ETA: 16s  [ loss=3.2974 ][Training] 45/57 [======================>.......] - ETA: 14s  [ loss=2.8389 ][Training] 46/57 [=======================>......] - ETA: 13s  [ loss=2.5927 ][Training] 47/57 [=======================>......] - ETA: 12s  [ loss=2.9621 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=2.4316 ][Training] 49/57 [========================>.....] - ETA: 9s  [ loss=4.7516 ][Training] 50/57 [=========================>....] - ETA: 8s  [ loss=2.7278 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=5.4394 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=1.8689 ][Training] 53/57 [==========================>...] - ETA: 4s  [ loss=5.0355 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=2.0406 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=3.3124 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=1.8152 ][Training] 57/57 [==============================] 1.2s/step  [ loss=5.5863 ]
01/03/2024 21:18:03 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 21:18:03 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 21:18:03 - INFO - root -     Num examples = 269
01/03/2024 21:18:03 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 6s[Evaluating] 2/12 [====>.........................] - ETA: 6s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 569.1ms/step
01/03/2024 21:18:10 - INFO - root -   

01/03/2024 21:18:10 - INFO - root -   ***** Eval results  *****
01/03/2024 21:18:10 - INFO - root -    acc: 0.6877 - recall: 0.6610 - f1: 0.6741 - loss: 5.5161 
01/03/2024 21:18:10 - INFO - root -   ***** Entity results  *****
01/03/2024 21:18:10 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 21:18:10 - INFO - root -    acc: 0.7636 - recall: 0.8936 - f1: 0.8235 
01/03/2024 21:18:10 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 21:18:10 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 21:18:10 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 21:18:10 - INFO - root -    acc: 0.4286 - recall: 0.3158 - f1: 0.3636 
01/03/2024 21:18:10 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 21:18:10 - INFO - root -    acc: 0.4286 - recall: 0.3333 - f1: 0.3750 
01/03/2024 21:18:10 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 21:18:10 - INFO - root -    acc: 0.5000 - recall: 0.3846 - f1: 0.4348 
01/03/2024 21:18:10 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 21:18:10 - INFO - root -    acc: 0.8750 - recall: 0.4118 - f1: 0.5600 
01/03/2024 21:18:10 - INFO - root -   ******* PER.NAM results ********
01/03/2024 21:18:10 - INFO - root -    acc: 0.7264 - recall: 0.7000 - f1: 0.7130 
01/03/2024 21:18:10 - INFO - root -   ******* PER.NOM results ********
01/03/2024 21:18:10 - INFO - root -    acc: 0.6949 - recall: 0.7235 - f1: 0.7089 
01/03/2024 21:18:25 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-570
01/03/2024 21:18:25 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-570
01/03/2024 21:18:25 - INFO - root -   

01/03/2024 21:18:25 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 10/50
[Training] 1/57 [..............................] - ETA: 1:00  [ loss=3.4113 ][Training] 2/57 [>.............................] - ETA: 59s  [ loss=1.1783 ][Training] 3/57 [>.............................] - ETA: 58s  [ loss=2.5541 ][Training] 4/57 [=>............................] - ETA: 1:00  [ loss=2.8303 ][Training] 5/57 [=>............................] - ETA: 58s  [ loss=3.0702 ][Training] 6/57 [==>...........................] - ETA: 1:00  [ loss=2.6752 ][Training] 7/57 [==>...........................] - ETA: 1:00  [ loss=2.8121 ][Training] 8/57 [===>..........................] - ETA: 58s  [ loss=1.2776 ][Training] 9/57 [===>..........................] - ETA: 57s  [ loss=2.8912 ][Training] 10/57 [====>.........................] - ETA: 56s  [ loss=2.9874 ][Training] 11/57 [====>.........................] - ETA: 55s  [ loss=2.8628 ][Training] 12/57 [=====>........................] - ETA: 54s  [ loss=2.9243 ][Training] 13/57 [=====>........................] - ETA: 54s  [ loss=3.8093 ][Training] 14/57 [======>.......................] - ETA: 52s  [ loss=2.7675 ][Training] 15/57 [======>.......................] - ETA: 52s  [ loss=2.6072 ][Training] 16/57 [=======>......................] - ETA: 51s  [ loss=4.1451 ][Training] 17/57 [=======>......................] - ETA: 50s  [ loss=4.2886 ][Training] 18/57 [========>.....................] - ETA: 49s  [ loss=2.5838 ][Training] 19/57 [=========>....................] - ETA: 47s  [ loss=3.7521 ][Training] 20/57 [=========>....................] - ETA: 47s  [ loss=3.1179 ][Training] 21/57 [==========>...................] - ETA: 45s  [ loss=2.9712 ][Training] 22/57 [==========>...................] - ETA: 44s  [ loss=3.3626 ][Training] 23/57 [===========>..................] - ETA: 43s  [ loss=5.2723 ][Training] 24/57 [===========>..................] - ETA: 41s  [ loss=1.6624 ][Training] 25/57 [============>.................] - ETA: 40s  [ loss=2.2704 ][Training] 26/57 [============>.................] - ETA: 39s  [ loss=2.3565 ][Training] 27/57 [=============>................] - ETA: 38s  [ loss=3.5608 ][Training] 28/57 [=============>................] - ETA: 36s  [ loss=2.6535 ][Training] 29/57 [==============>...............] - ETA: 35s  [ loss=4.3781 ][Training] 30/57 [==============>...............] - ETA: 34s  [ loss=3.9383 ][Training] 31/57 [===============>..............] - ETA: 33s  [ loss=3.1032 ][Training] 32/57 [===============>..............] - ETA: 31s  [ loss=2.2495 ][Training] 33/57 [================>.............] - ETA: 30s  [ loss=3.3081 ][Training] 34/57 [================>.............] - ETA: 29s  [ loss=1.9491 ][Training] 35/57 [=================>............] - ETA: 28s  [ loss=1.5855 ][Training] 36/57 [=================>............] - ETA: 26s  [ loss=1.9541 ][Training] 37/57 [==================>...........] - ETA: 25s  [ loss=2.5099 ][Training] 38/57 [===================>..........] - ETA: 24s  [ loss=6.0040 ][Training] 39/57 [===================>..........] - ETA: 23s  [ loss=4.7821 ][Training] 40/57 [====================>.........] - ETA: 21s  [ loss=3.2824 ][Training] 41/57 [====================>.........] - ETA: 20s  [ loss=2.4224 ][Training] 42/57 [=====================>........] - ETA: 19s  [ loss=3.1207 ][Training] 43/57 [=====================>........] - ETA: 18s  [ loss=3.1828 ][Training] 44/57 [======================>.......] - ETA: 16s  [ loss=2.9617 ][Training] 45/57 [======================>.......] - ETA: 15s  [ loss=2.8833 ][Training] 46/57 [=======================>......] - ETA: 14s  [ loss=1.3124 ][Training] 47/57 [=======================>......] - ETA: 12s  [ loss=3.0510 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=2.1923 ][Training] 49/57 [========================>.....] - ETA: 10s  [ loss=2.9539 ][Training] 50/57 [=========================>....] - ETA: 9s  [ loss=3.0700 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=1.2310 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=2.7432 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=4.8089 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=1.4661 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=3.0908 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=3.1828 ][Training] 57/57 [==============================] 1.3s/step  [ loss=1.8533 ]
01/03/2024 21:19:38 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 21:19:38 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 21:19:38 - INFO - root -     Num examples = 269
01/03/2024 21:19:38 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 5s[Evaluating] 2/12 [====>.........................] - ETA: 5s[Evaluating] 3/12 [======>.......................] - ETA: 4s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 563.9ms/step
01/03/2024 21:19:45 - INFO - root -   

01/03/2024 21:19:45 - INFO - root -   ***** Eval results  *****
01/03/2024 21:19:45 - INFO - root -    acc: 0.6206 - recall: 0.6852 - f1: 0.6513 - loss: 6.4938 
01/03/2024 21:19:45 - INFO - root -   ***** Entity results  *****
01/03/2024 21:19:45 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 21:19:45 - INFO - root -    acc: 0.7963 - recall: 0.9149 - f1: 0.8515 
01/03/2024 21:19:45 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 21:19:45 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 21:19:45 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 21:19:45 - INFO - root -    acc: 0.4167 - recall: 0.2632 - f1: 0.3226 
01/03/2024 21:19:45 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 21:19:45 - INFO - root -    acc: 0.3333 - recall: 0.2222 - f1: 0.2667 
01/03/2024 21:19:45 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 21:19:45 - INFO - root -    acc: 0.3659 - recall: 0.3846 - f1: 0.3750 
01/03/2024 21:19:45 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 21:19:45 - INFO - root -    acc: 1.0000 - recall: 0.4706 - f1: 0.6400 
01/03/2024 21:19:45 - INFO - root -   ******* PER.NAM results ********
01/03/2024 21:19:45 - INFO - root -    acc: 0.5804 - recall: 0.7545 - f1: 0.6561 
01/03/2024 21:19:45 - INFO - root -   ******* PER.NOM results ********
01/03/2024 21:19:45 - INFO - root -    acc: 0.6615 - recall: 0.7471 - f1: 0.7017 
01/03/2024 21:19:56 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-627
01/03/2024 21:19:56 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-627
01/03/2024 21:19:56 - INFO - root -   

01/03/2024 21:19:56 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 11/50
[Training] 1/57 [..............................] - ETA: 1:15  [ loss=3.3763 ][Training] 2/57 [>.............................] - ETA: 1:13  [ loss=2.3600 ][Training] 3/57 [>.............................] - ETA: 1:09  [ loss=2.1887 ][Training] 4/57 [=>............................] - ETA: 1:11  [ loss=2.1683 ][Training] 5/57 [=>............................] - ETA: 1:10  [ loss=3.0106 ][Training] 6/57 [==>...........................] - ETA: 1:09  [ loss=3.8624 ][Training] 7/57 [==>...........................] - ETA: 1:06  [ loss=1.4494 ][Training] 8/57 [===>..........................] - ETA: 1:05  [ loss=2.1097 ][Training] 9/57 [===>..........................] - ETA: 1:04  [ loss=1.7399 ][Training] 10/57 [====>.........................] - ETA: 1:03  [ loss=1.3004 ][Training] 11/57 [====>.........................] - ETA: 1:00  [ loss=2.0697 ][Training] 12/57 [=====>........................] - ETA: 59s  [ loss=3.1888 ][Training] 13/57 [=====>........................] - ETA: 57s  [ loss=3.6022 ][Training] 14/57 [======>.......................] - ETA: 56s  [ loss=1.7760 ][Training] 15/57 [======>.......................] - ETA: 55s  [ loss=3.4589 ][Training] 16/57 [=======>......................] - ETA: 54s  [ loss=2.8570 ][Training] 17/57 [=======>......................] - ETA: 53s  [ loss=3.7807 ][Training] 18/57 [========>.....................] - ETA: 51s  [ loss=2.0042 ][Training] 19/57 [=========>....................] - ETA: 50s  [ loss=1.6875 ][Training] 20/57 [=========>....................] - ETA: 48s  [ loss=2.1532 ][Training] 21/57 [==========>...................] - ETA: 47s  [ loss=1.9791 ][Training] 22/57 [==========>...................] - ETA: 46s  [ loss=2.4309 ][Training] 23/57 [===========>..................] - ETA: 44s  [ loss=3.9534 ][Training] 24/57 [===========>..................] - ETA: 43s  [ loss=1.9720 ][Training] 25/57 [============>.................] - ETA: 41s  [ loss=0.9470 ][Training] 26/57 [============>.................] - ETA: 40s  [ loss=2.0546 ][Training] 27/57 [=============>................] - ETA: 38s  [ loss=2.6904 ][Training] 28/57 [=============>................] - ETA: 37s  [ loss=1.7672 ][Training] 29/57 [==============>...............] - ETA: 35s  [ loss=2.4448 ][Training] 30/57 [==============>...............] - ETA: 34s  [ loss=2.9316 ][Training] 31/57 [===============>..............] - ETA: 33s  [ loss=3.7666 ][Training] 32/57 [===============>..............] - ETA: 31s  [ loss=1.7459 ][Training] 33/57 [================>.............] - ETA: 30s  [ loss=4.2394 ][Training] 34/57 [================>.............] - ETA: 29s  [ loss=4.1935 ][Training] 35/57 [=================>............] - ETA: 28s  [ loss=2.0892 ][Training] 36/57 [=================>............] - ETA: 26s  [ loss=4.0669 ][Training] 37/57 [==================>...........] - ETA: 25s  [ loss=5.2695 ][Training] 38/57 [===================>..........] - ETA: 24s  [ loss=2.7225 ][Training] 39/57 [===================>..........] - ETA: 23s  [ loss=2.9198 ][Training] 40/57 [====================>.........] - ETA: 21s  [ loss=4.0694 ][Training] 41/57 [====================>.........] - ETA: 20s  [ loss=0.7751 ][Training] 42/57 [=====================>........] - ETA: 19s  [ loss=1.6007 ][Training] 43/57 [=====================>........] - ETA: 18s  [ loss=1.9195 ][Training] 44/57 [======================>.......] - ETA: 16s  [ loss=2.9625 ][Training] 45/57 [======================>.......] - ETA: 15s  [ loss=2.2440 ][Training] 46/57 [=======================>......] - ETA: 13s  [ loss=2.0856 ][Training] 47/57 [=======================>......] - ETA: 12s  [ loss=2.5225 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=3.8166 ][Training] 49/57 [========================>.....] - ETA: 10s  [ loss=1.7429 ][Training] 50/57 [=========================>....] - ETA: 8s  [ loss=2.3033 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=4.0846 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=3.9687 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=2.6066 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=2.7633 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=1.9929 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=4.2874 ][Training] 57/57 [==============================] 1.2s/step  [ loss=1.2434 ]
01/03/2024 21:21:08 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 21:21:08 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 21:21:08 - INFO - root -     Num examples = 269
01/03/2024 21:21:08 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 5s[Evaluating] 2/12 [====>.........................] - ETA: 6s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 2s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 564.1ms/step
01/03/2024 21:21:15 - INFO - root -   

01/03/2024 21:21:15 - INFO - root -   ***** Eval results  *****
01/03/2024 21:21:15 - INFO - root -    acc: 0.6642 - recall: 0.6513 - f1: 0.6577 - loss: 5.4145 
01/03/2024 21:21:15 - INFO - root -   ***** Entity results  *****
01/03/2024 21:21:15 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 21:21:15 - INFO - root -    acc: 0.7407 - recall: 0.8511 - f1: 0.7921 
01/03/2024 21:21:15 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 21:21:15 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 21:21:15 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 21:21:15 - INFO - root -    acc: 0.5000 - recall: 0.3684 - f1: 0.4242 
01/03/2024 21:21:15 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 21:21:15 - INFO - root -    acc: 0.2500 - recall: 0.2222 - f1: 0.2353 
01/03/2024 21:21:15 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 21:21:15 - INFO - root -    acc: 0.4516 - recall: 0.3590 - f1: 0.4000 
01/03/2024 21:21:15 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 21:21:15 - INFO - root -    acc: 1.0000 - recall: 0.4706 - f1: 0.6400 
01/03/2024 21:21:15 - INFO - root -   ******* PER.NAM results ********
01/03/2024 21:21:15 - INFO - root -    acc: 0.6637 - recall: 0.6818 - f1: 0.6726 
01/03/2024 21:21:15 - INFO - root -   ******* PER.NOM results ********
01/03/2024 21:21:15 - INFO - root -    acc: 0.6949 - recall: 0.7235 - f1: 0.7089 
01/03/2024 21:21:24 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-684
01/03/2024 21:21:24 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-684
01/03/2024 21:21:24 - INFO - root -   

01/03/2024 21:21:24 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 12/50
[Training] 1/57 [..............................] - ETA: 1:02  [ loss=1.6451 ][Training] 2/57 [>.............................] - ETA: 1:03  [ loss=4.4336 ][Training] 3/57 [>.............................] - ETA: 1:03  [ loss=1.7594 ][Training] 4/57 [=>............................] - ETA: 1:03  [ loss=2.2551 ][Training] 5/57 [=>............................] - ETA: 1:06  [ loss=2.2025 ][Training] 6/57 [==>...........................] - ETA: 1:06  [ loss=4.0658 ][Training] 7/57 [==>...........................] - ETA: 1:04  [ loss=0.8403 ][Training] 8/57 [===>..........................] - ETA: 1:03  [ loss=1.9685 ][Training] 9/57 [===>..........................] - ETA: 1:03  [ loss=2.2878 ][Training] 10/57 [====>.........................] - ETA: 1:01  [ loss=2.6694 ][Training] 11/57 [====>.........................] - ETA: 1:00  [ loss=1.9187 ][Training] 12/57 [=====>........................] - ETA: 59s  [ loss=1.6861 ][Training] 13/57 [=====>........................] - ETA: 57s  [ loss=2.8782 ][Training] 14/57 [======>.......................] - ETA: 56s  [ loss=1.5337 ][Training] 15/57 [======>.......................] - ETA: 55s  [ loss=1.0160 ][Training] 16/57 [=======>......................] - ETA: 53s  [ loss=2.1915 ][Training] 17/57 [=======>......................] - ETA: 52s  [ loss=1.4852 ][Training] 18/57 [========>.....................] - ETA: 50s  [ loss=2.5282 ][Training] 19/57 [=========>....................] - ETA: 50s  [ loss=2.6126 ][Training] 20/57 [=========>....................] - ETA: 48s  [ loss=3.1955 ][Training] 21/57 [==========>...................] - ETA: 47s  [ loss=2.4682 ][Training] 22/57 [==========>...................] - ETA: 45s  [ loss=2.0110 ][Training] 23/57 [===========>..................] - ETA: 44s  [ loss=3.3455 ][Training] 24/57 [===========>..................] - ETA: 42s  [ loss=2.0318 ][Training] 25/57 [============>.................] - ETA: 41s  [ loss=2.1737 ][Training] 26/57 [============>.................] - ETA: 39s  [ loss=3.6429 ][Training] 27/57 [=============>................] - ETA: 38s  [ loss=2.9680 ][Training] 28/57 [=============>................] - ETA: 37s  [ loss=1.8676 ][Training] 29/57 [==============>...............] - ETA: 36s  [ loss=2.2671 ][Training] 30/57 [==============>...............] - ETA: 35s  [ loss=4.0929 ][Training] 31/57 [===============>..............] - ETA: 33s  [ loss=2.1071 ][Training] 32/57 [===============>..............] - ETA: 32s  [ loss=3.8792 ][Training] 33/57 [================>.............] - ETA: 31s  [ loss=2.1778 ][Training] 34/57 [================>.............] - ETA: 29s  [ loss=1.6154 ][Training] 35/57 [=================>............] - ETA: 28s  [ loss=1.2158 ][Training] 36/57 [=================>............] - ETA: 27s  [ loss=3.3107 ][Training] 37/57 [==================>...........] - ETA: 25s  [ loss=1.0161 ][Training] 38/57 [===================>..........] - ETA: 24s  [ loss=3.3542 ][Training] 39/57 [===================>..........] - ETA: 23s  [ loss=2.9742 ][Training] 40/57 [====================>.........] - ETA: 22s  [ loss=1.5494 ][Training] 41/57 [====================>.........] - ETA: 20s  [ loss=3.2993 ][Training] 42/57 [=====================>........] - ETA: 19s  [ loss=1.0338 ][Training] 43/57 [=====================>........] - ETA: 18s  [ loss=3.2864 ][Training] 44/57 [======================>.......] - ETA: 16s  [ loss=1.5854 ][Training] 45/57 [======================>.......] - ETA: 15s  [ loss=3.6825 ][Training] 46/57 [=======================>......] - ETA: 14s  [ loss=2.7809 ][Training] 47/57 [=======================>......] - ETA: 13s  [ loss=2.6257 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=4.1335 ][Training] 49/57 [========================>.....] - ETA: 10s  [ loss=2.8207 ][Training] 50/57 [=========================>....] - ETA: 9s  [ loss=3.5463 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=3.1707 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=1.9221 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=2.0216 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=2.4630 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=5.8077 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=1.8707 ][Training] 57/57 [==============================] 1.3s/step  [ loss=3.5156 ]
01/03/2024 21:22:37 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 21:22:37 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 21:22:37 - INFO - root -     Num examples = 269
01/03/2024 21:22:37 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 5s[Evaluating] 2/12 [====>.........................] - ETA: 6s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 582.3ms/step
01/03/2024 21:22:44 - INFO - root -   

01/03/2024 21:22:44 - INFO - root -   ***** Eval results  *****
01/03/2024 21:22:44 - INFO - root -    acc: 0.6519 - recall: 0.6755 - f1: 0.6635 - loss: 5.7168 
01/03/2024 21:22:44 - INFO - root -   ***** Entity results  *****
01/03/2024 21:22:44 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 21:22:44 - INFO - root -    acc: 0.8077 - recall: 0.8936 - f1: 0.8485 
01/03/2024 21:22:44 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 21:22:44 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 21:22:44 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 21:22:44 - INFO - root -    acc: 0.4706 - recall: 0.4211 - f1: 0.4444 
01/03/2024 21:22:44 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 21:22:44 - INFO - root -    acc: 0.2857 - recall: 0.2222 - f1: 0.2500 
01/03/2024 21:22:44 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 21:22:44 - INFO - root -    acc: 0.4286 - recall: 0.3846 - f1: 0.4054 
01/03/2024 21:22:44 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 21:22:44 - INFO - root -    acc: 1.0000 - recall: 0.4118 - f1: 0.5833 
01/03/2024 21:22:44 - INFO - root -   ******* PER.NAM results ********
01/03/2024 21:22:44 - INFO - root -    acc: 0.7027 - recall: 0.7091 - f1: 0.7059 
01/03/2024 21:22:44 - INFO - root -   ******* PER.NOM results ********
01/03/2024 21:22:44 - INFO - root -    acc: 0.6382 - recall: 0.7471 - f1: 0.6883 
01/03/2024 21:22:53 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-741
01/03/2024 21:22:53 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-741
01/03/2024 21:22:53 - INFO - root -   

01/03/2024 21:22:53 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 13/50
[Training] 1/57 [..............................] - ETA: 1:12  [ loss=2.9206 ][Training] 2/57 [>.............................] - ETA: 1:08  [ loss=1.0703 ][Training] 3/57 [>.............................] - ETA: 1:04  [ loss=2.6743 ][Training] 4/57 [=>............................] - ETA: 1:03  [ loss=1.9467 ][Training] 5/57 [=>............................] - ETA: 1:00  [ loss=2.3508 ][Training] 6/57 [==>...........................] - ETA: 58s  [ loss=1.9259 ][Training] 7/57 [==>...........................] - ETA: 59s  [ loss=1.0176 ][Training] 8/57 [===>..........................] - ETA: 1:00  [ loss=4.0140 ][Training] 9/57 [===>..........................] - ETA: 58s  [ loss=2.9216 ][Training] 10/57 [====>.........................] - ETA: 58s  [ loss=2.5312 ][Training] 11/57 [====>.........................] - ETA: 56s  [ loss=2.2461 ][Training] 12/57 [=====>........................] - ETA: 54s  [ loss=1.9953 ][Training] 13/57 [=====>........................] - ETA: 53s  [ loss=2.3823 ][Training] 14/57 [======>.......................] - ETA: 53s  [ loss=1.4109 ][Training] 15/57 [======>.......................] - ETA: 51s  [ loss=1.9295 ][Training] 16/57 [=======>......................] - ETA: 49s  [ loss=1.7735 ][Training] 17/57 [=======>......................] - ETA: 49s  [ loss=2.9142 ][Training] 18/57 [========>.....................] - ETA: 48s  [ loss=1.2400 ][Training] 19/57 [=========>....................] - ETA: 47s  [ loss=3.2276 ][Training] 20/57 [=========>....................] - ETA: 47s  [ loss=3.2168 ][Training] 21/57 [==========>...................] - ETA: 46s  [ loss=2.1967 ][Training] 22/57 [==========>...................] - ETA: 44s  [ loss=1.5820 ][Training] 23/57 [===========>..................] - ETA: 43s  [ loss=1.5222 ][Training] 24/57 [===========>..................] - ETA: 42s  [ loss=1.9726 ][Training] 25/57 [============>.................] - ETA: 41s  [ loss=2.2982 ][Training] 26/57 [============>.................] - ETA: 40s  [ loss=2.7041 ][Training] 27/57 [=============>................] - ETA: 38s  [ loss=2.1709 ][Training] 28/57 [=============>................] - ETA: 37s  [ loss=2.8229 ][Training] 29/57 [==============>...............] - ETA: 36s  [ loss=1.8950 ][Training] 30/57 [==============>...............] - ETA: 35s  [ loss=2.3743 ][Training] 31/57 [===============>..............] - ETA: 33s  [ loss=1.4914 ][Training] 32/57 [===============>..............] - ETA: 32s  [ loss=1.3776 ][Training] 33/57 [================>.............] - ETA: 31s  [ loss=2.6504 ][Training] 34/57 [================>.............] - ETA: 29s  [ loss=2.4772 ][Training] 35/57 [=================>............] - ETA: 28s  [ loss=1.7317 ][Training] 36/57 [=================>............] - ETA: 27s  [ loss=4.1170 ][Training] 37/57 [==================>...........] - ETA: 25s  [ loss=1.3043 ][Training] 38/57 [===================>..........] - ETA: 24s  [ loss=2.1692 ][Training] 39/57 [===================>..........] - ETA: 23s  [ loss=1.8068 ][Training] 40/57 [====================>.........] - ETA: 22s  [ loss=2.6701 ][Training] 41/57 [====================>.........] - ETA: 21s  [ loss=3.3786 ][Training] 42/57 [=====================>........] - ETA: 19s  [ loss=2.3120 ][Training] 43/57 [=====================>........] - ETA: 18s  [ loss=2.0873 ][Training] 44/57 [======================>.......] - ETA: 17s  [ loss=1.5535 ][Training] 45/57 [======================>.......] - ETA: 15s  [ loss=2.7360 ][Training] 46/57 [=======================>......] - ETA: 14s  [ loss=2.0815 ][Training] 47/57 [=======================>......] - ETA: 13s  [ loss=2.9093 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=1.7602 ][Training] 49/57 [========================>.....] - ETA: 10s  [ loss=1.3765 ][Training] 50/57 [=========================>....] - ETA: 9s  [ loss=2.2530 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=2.9154 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=3.4189 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=2.2891 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=2.0110 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=2.1429 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=3.6188 ][Training] 57/57 [==============================] 1.3s/step  [ loss=0.8028 ]
01/03/2024 21:24:07 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 21:24:07 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 21:24:07 - INFO - root -     Num examples = 269
01/03/2024 21:24:07 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 5s[Evaluating] 2/12 [====>.........................] - ETA: 5s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 3s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 2s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 549.9ms/step
01/03/2024 21:24:14 - INFO - root -   

01/03/2024 21:24:14 - INFO - root -   ***** Eval results  *****
01/03/2024 21:24:14 - INFO - root -    acc: 0.6589 - recall: 0.6828 - f1: 0.6706 - loss: 5.7353 
01/03/2024 21:24:14 - INFO - root -   ***** Entity results  *****
01/03/2024 21:24:14 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 21:24:14 - INFO - root -    acc: 0.7414 - recall: 0.9149 - f1: 0.8190 
01/03/2024 21:24:14 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 21:24:14 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 21:24:14 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 21:24:14 - INFO - root -    acc: 0.5000 - recall: 0.2632 - f1: 0.3448 
01/03/2024 21:24:14 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 21:24:14 - INFO - root -    acc: 0.3333 - recall: 0.2222 - f1: 0.2667 
01/03/2024 21:24:14 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 21:24:14 - INFO - root -    acc: 0.4828 - recall: 0.3590 - f1: 0.4118 
01/03/2024 21:24:14 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 21:24:14 - INFO - root -    acc: 0.7778 - recall: 0.4118 - f1: 0.5385 
01/03/2024 21:24:14 - INFO - root -   ******* PER.NAM results ********
01/03/2024 21:24:14 - INFO - root -    acc: 0.7273 - recall: 0.7273 - f1: 0.7273 
01/03/2024 21:24:14 - INFO - root -   ******* PER.NOM results ********
01/03/2024 21:24:14 - INFO - root -    acc: 0.6359 - recall: 0.7706 - f1: 0.6968 
01/03/2024 21:24:23 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-798
01/03/2024 21:24:23 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-798
01/03/2024 21:24:23 - INFO - root -   

01/03/2024 21:24:23 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 14/50
[Training] 1/57 [..............................] - ETA: 1:04  [ loss=1.5390 ][Training] 2/57 [>.............................] - ETA: 1:11  [ loss=1.9712 ][Training] 3/57 [>.............................] - ETA: 1:16  [ loss=4.1764 ][Training] 4/57 [=>............................] - ETA: 1:11  [ loss=0.9403 ][Training] 5/57 [=>............................] - ETA: 1:10  [ loss=1.9738 ][Training] 6/57 [==>...........................] - ETA: 1:08  [ loss=3.3448 ][Training] 7/57 [==>...........................] - ETA: 1:07  [ loss=2.1628 ][Training] 8/57 [===>..........................] - ETA: 1:04  [ loss=2.1408 ][Training] 9/57 [===>..........................] - ETA: 1:02  [ loss=1.4069 ][Training] 10/57 [====>.........................] - ETA: 1:01  [ loss=2.5592 ][Training] 11/57 [====>.........................] - ETA: 1:01  [ loss=3.2512 ][Training] 12/57 [=====>........................] - ETA: 59s  [ loss=1.2420 ][Training] 13/57 [=====>........................] - ETA: 57s  [ loss=1.3138 ][Training] 14/57 [======>.......................] - ETA: 56s  [ loss=1.9560 ][Training] 15/57 [======>.......................] - ETA: 55s  [ loss=1.4464 ][Training] 16/57 [=======>......................] - ETA: 54s  [ loss=2.2267 ][Training] 17/57 [=======>......................] - ETA: 52s  [ loss=1.2961 ][Training] 18/57 [========>.....................] - ETA: 51s  [ loss=2.2631 ][Training] 19/57 [=========>....................] - ETA: 50s  [ loss=2.7472 ][Training] 20/57 [=========>....................] - ETA: 49s  [ loss=2.7707 ][Training] 21/57 [==========>...................] - ETA: 47s  [ loss=2.0360 ][Training] 22/57 [==========>...................] - ETA: 46s  [ loss=1.8114 ][Training] 23/57 [===========>..................] - ETA: 44s  [ loss=1.8434 ][Training] 24/57 [===========>..................] - ETA: 43s  [ loss=1.9107 ][Training] 25/57 [============>.................] - ETA: 42s  [ loss=2.6526 ][Training] 26/57 [============>.................] - ETA: 40s  [ loss=1.0276 ][Training] 27/57 [=============>................] - ETA: 39s  [ loss=2.3030 ][Training] 28/57 [=============>................] - ETA: 38s  [ loss=1.7803 ][Training] 29/57 [==============>...............] - ETA: 37s  [ loss=3.1565 ][Training] 30/57 [==============>...............] - ETA: 35s  [ loss=2.2229 ][Training] 31/57 [===============>..............] - ETA: 34s  [ loss=1.2423 ][Training] 32/57 [===============>..............] - ETA: 32s  [ loss=2.2339 ][Training] 33/57 [================>.............] - ETA: 31s  [ loss=2.0807 ][Training] 34/57 [================>.............] - ETA: 29s  [ loss=1.6358 ][Training] 35/57 [=================>............] - ETA: 28s  [ loss=1.7207 ][Training] 36/57 [=================>............] - ETA: 27s  [ loss=2.0055 ][Training] 37/57 [==================>...........] - ETA: 25s  [ loss=2.1112 ][Training] 38/57 [===================>..........] - ETA: 24s  [ loss=1.8976 ][Training] 39/57 [===================>..........] - ETA: 22s  [ loss=1.6259 ][Training] 40/57 [====================>.........] - ETA: 21s  [ loss=2.7482 ][Training] 41/57 [====================>.........] - ETA: 20s  [ loss=5.1044 ][Training] 42/57 [=====================>........] - ETA: 19s  [ loss=1.1487 ][Training] 43/57 [=====================>........] - ETA: 17s  [ loss=1.9342 ][Training] 44/57 [======================>.......] - ETA: 16s  [ loss=2.3117 ][Training] 45/57 [======================>.......] - ETA: 15s  [ loss=0.8752 ][Training] 46/57 [=======================>......] - ETA: 14s  [ loss=2.7847 ][Training] 47/57 [=======================>......] - ETA: 12s  [ loss=2.6931 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=1.2495 ][Training] 49/57 [========================>.....] - ETA: 10s  [ loss=2.1598 ][Training] 50/57 [=========================>....] - ETA: 9s  [ loss=2.2712 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=1.1754 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=2.3765 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=1.9191 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=1.3153 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=3.6869 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=1.7249 ][Training] 57/57 [==============================] 1.3s/step  [ loss=0.7416 ]
01/03/2024 21:25:35 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 21:25:35 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 21:25:35 - INFO - root -     Num examples = 269
01/03/2024 21:25:35 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 6s[Evaluating] 2/12 [====>.........................] - ETA: 6s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 590.9ms/step
01/03/2024 21:25:42 - INFO - root -   

01/03/2024 21:25:42 - INFO - root -   ***** Eval results  *****
01/03/2024 21:25:42 - INFO - root -    acc: 0.6634 - recall: 0.6586 - f1: 0.6610 - loss: 5.5172 
01/03/2024 21:25:42 - INFO - root -   ***** Entity results  *****
01/03/2024 21:25:42 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 21:25:42 - INFO - root -    acc: 0.7455 - recall: 0.8723 - f1: 0.8039 
01/03/2024 21:25:42 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 21:25:42 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 21:25:42 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 21:25:42 - INFO - root -    acc: 0.5294 - recall: 0.4737 - f1: 0.5000 
01/03/2024 21:25:42 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 21:25:42 - INFO - root -    acc: 0.2000 - recall: 0.1111 - f1: 0.1429 
01/03/2024 21:25:42 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 21:25:42 - INFO - root -    acc: 0.5000 - recall: 0.3590 - f1: 0.4179 
01/03/2024 21:25:42 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 21:25:42 - INFO - root -    acc: 0.8750 - recall: 0.4118 - f1: 0.5600 
01/03/2024 21:25:42 - INFO - root -   ******* PER.NAM results ********
01/03/2024 21:25:42 - INFO - root -    acc: 0.7091 - recall: 0.7091 - f1: 0.7091 
01/03/2024 21:25:42 - INFO - root -   ******* PER.NOM results ********
01/03/2024 21:25:42 - INFO - root -    acc: 0.6524 - recall: 0.7176 - f1: 0.6835 
01/03/2024 21:25:50 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-855
01/03/2024 21:25:50 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-855
01/03/2024 21:25:50 - INFO - root -   

01/03/2024 21:25:50 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 15/50
[Training] 1/57 [..............................] - ETA: 1:14  [ loss=1.2332 ][Training] 2/57 [>.............................] - ETA: 1:15  [ loss=1.5148 ][Training] 3/57 [>.............................] - ETA: 1:11  [ loss=0.9741 ][Training] 4/57 [=>............................] - ETA: 1:02  [ loss=1.3383 ][Training] 5/57 [=>............................] - ETA: 1:08  [ loss=1.4899 ][Training] 6/57 [==>...........................] - ETA: 1:05  [ loss=1.5945 ][Training] 7/57 [==>...........................] - ETA: 1:02  [ loss=0.9872 ][Training] 8/57 [===>..........................] - ETA: 1:04  [ loss=2.4710 ][Training] 9/57 [===>..........................] - ETA: 1:02  [ loss=2.6307 ][Training] 10/57 [====>.........................] - ETA: 1:00  [ loss=2.0243 ][Training] 11/57 [====>.........................] - ETA: 58s  [ loss=1.2914 ][Training] 12/57 [=====>........................] - ETA: 59s  [ loss=3.1320 ][Training] 13/57 [=====>........................] - ETA: 57s  [ loss=1.2317 ][Training] 14/57 [======>.......................] - ETA: 55s  [ loss=2.3167 ][Training] 15/57 [======>.......................] - ETA: 54s  [ loss=1.6393 ][Training] 16/57 [=======>......................] - ETA: 53s  [ loss=1.9117 ][Training] 17/57 [=======>......................] - ETA: 52s  [ loss=2.1234 ][Training] 18/57 [========>.....................] - ETA: 51s  [ loss=3.4808 ][Training] 19/57 [=========>....................] - ETA: 50s  [ loss=2.0866 ][Training] 20/57 [=========>....................] - ETA: 49s  [ loss=2.2151 ][Training] 21/57 [==========>...................] - ETA: 48s  [ loss=2.3332 ][Training] 22/57 [==========>...................] - ETA: 46s  [ loss=1.5252 ][Training] 23/57 [===========>..................] - ETA: 45s  [ loss=2.3555 ][Training] 24/57 [===========>..................] - ETA: 44s  [ loss=2.0382 ][Training] 25/57 [============>.................] - ETA: 42s  [ loss=2.3664 ][Training] 26/57 [============>.................] - ETA: 41s  [ loss=2.1576 ][Training] 27/57 [=============>................] - ETA: 40s  [ loss=2.1664 ][Training] 28/57 [=============>................] - ETA: 38s  [ loss=3.0054 ][Training] 29/57 [==============>...............] - ETA: 37s  [ loss=1.3471 ][Training] 30/57 [==============>...............] - ETA: 36s  [ loss=2.1531 ][Training] 31/57 [===============>..............] - ETA: 34s  [ loss=1.7312 ][Training] 32/57 [===============>..............] - ETA: 33s  [ loss=0.9988 ][Training] 33/57 [================>.............] - ETA: 31s  [ loss=1.5803 ][Training] 34/57 [================>.............] - ETA: 30s  [ loss=1.5022 ][Training] 35/57 [=================>............] - ETA: 29s  [ loss=2.0796 ][Training] 36/57 [=================>............] - ETA: 27s  [ loss=4.3261 ][Training] 37/57 [==================>...........] - ETA: 26s  [ loss=3.8237 ][Training] 38/57 [===================>..........] - ETA: 25s  [ loss=2.0459 ][Training] 39/57 [===================>..........] - ETA: 23s  [ loss=1.4339 ][Training] 40/57 [====================>.........] - ETA: 22s  [ loss=2.6113 ][Training] 41/57 [====================>.........] - ETA: 21s  [ loss=0.7507 ][Training] 42/57 [=====================>........] - ETA: 19s  [ loss=1.2195 ][Training] 43/57 [=====================>........] - ETA: 18s  [ loss=2.3108 ][Training] 44/57 [======================>.......] - ETA: 17s  [ loss=1.6015 ][Training] 45/57 [======================>.......] - ETA: 15s  [ loss=2.0699 ][Training] 46/57 [=======================>......] - ETA: 14s  [ loss=1.0393 ][Training] 47/57 [=======================>......] - ETA: 13s  [ loss=1.9210 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=2.2969 ][Training] 49/57 [========================>.....] - ETA: 10s  [ loss=1.9599 ][Training] 50/57 [=========================>....] - ETA: 9s  [ loss=2.8611 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=2.2547 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=2.2719 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=2.0339 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=1.9951 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=2.3425 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=2.4502 ][Training] 57/57 [==============================] 1.3s/step  [ loss=1.3468 ]
01/03/2024 21:27:04 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 21:27:04 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 21:27:04 - INFO - root -     Num examples = 269
01/03/2024 21:27:04 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 5s[Evaluating] 2/12 [====>.........................] - ETA: 6s[Evaluating] 3/12 [======>.......................] - ETA: 6s[Evaluating] 4/12 [=========>....................] - ETA: 5s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 632.9ms/step
01/03/2024 21:27:12 - INFO - root -   

01/03/2024 21:27:12 - INFO - root -   ***** Eval results  *****
01/03/2024 21:27:12 - INFO - root -    acc: 0.6168 - recall: 0.7094 - f1: 0.6599 - loss: 6.5346 
01/03/2024 21:27:12 - INFO - root -   ***** Entity results  *****
01/03/2024 21:27:12 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 21:27:12 - INFO - root -    acc: 0.7288 - recall: 0.9149 - f1: 0.8113 
01/03/2024 21:27:12 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 21:27:12 - INFO - root -    acc: 0.6667 - recall: 1.0000 - f1: 0.8000 
01/03/2024 21:27:12 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 21:27:12 - INFO - root -    acc: 0.5625 - recall: 0.4737 - f1: 0.5143 
01/03/2024 21:27:12 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 21:27:12 - INFO - root -    acc: 0.3333 - recall: 0.3333 - f1: 0.3333 
01/03/2024 21:27:12 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 21:27:12 - INFO - root -    acc: 0.4412 - recall: 0.3846 - f1: 0.4110 
01/03/2024 21:27:12 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 21:27:12 - INFO - root -    acc: 0.6154 - recall: 0.4706 - f1: 0.5333 
01/03/2024 21:27:12 - INFO - root -   ******* PER.NAM results ********
01/03/2024 21:27:12 - INFO - root -    acc: 0.6250 - recall: 0.7273 - f1: 0.6723 
01/03/2024 21:27:12 - INFO - root -   ******* PER.NOM results ********
01/03/2024 21:27:12 - INFO - root -    acc: 0.6244 - recall: 0.7824 - f1: 0.6945 
01/03/2024 21:27:37 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-912
01/03/2024 21:27:38 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-912
01/03/2024 21:27:38 - INFO - root -   

01/03/2024 21:27:38 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 16/50
[Training] 1/57 [..............................] - ETA: 52s  [ loss=1.5644 ][Training] 2/57 [>.............................] - ETA: 49s  [ loss=2.0628 ][Training] 3/57 [>.............................] - ETA: 50s  [ loss=2.5231 ][Training] 4/57 [=>............................] - ETA: 49s  [ loss=1.7851 ][Training] 5/57 [=>............................] - ETA: 47s  [ loss=1.5148 ][Training] 6/57 [==>...........................] - ETA: 47s  [ loss=1.0695 ][Training] 7/57 [==>...........................] - ETA: 48s  [ loss=1.5631 ][Training] 8/57 [===>..........................] - ETA: 45s  [ loss=1.2380 ][Training] 9/57 [===>..........................] - ETA: 44s  [ loss=1.2992 ][Training] 10/57 [====>.........................] - ETA: 43s  [ loss=1.7983 ][Training] 11/57 [====>.........................] - ETA: 44s  [ loss=2.2296 ][Training] 12/57 [=====>........................] - ETA: 42s  [ loss=2.1825 ][Training] 13/57 [=====>........................] - ETA: 42s  [ loss=1.5430 ][Training] 14/57 [======>.......................] - ETA: 41s  [ loss=2.3578 ][Training] 15/57 [======>.......................] - ETA: 41s  [ loss=1.2366 ][Training] 16/57 [=======>......................] - ETA: 40s  [ loss=1.9796 ][Training] 17/57 [=======>......................] - ETA: 39s  [ loss=1.9783 ][Training] 18/57 [========>.....................] - ETA: 38s  [ loss=1.6119 ][Training] 19/57 [=========>....................] - ETA: 37s  [ loss=1.8930 ][Training] 20/57 [=========>....................] - ETA: 36s  [ loss=1.8923 ][Training] 21/57 [==========>...................] - ETA: 36s  [ loss=1.7881 ][Training] 22/57 [==========>...................] - ETA: 36s  [ loss=1.6211 ][Training] 23/57 [===========>..................] - ETA: 35s  [ loss=0.8541 ][Training] 24/57 [===========>..................] - ETA: 34s  [ loss=1.2257 ][Training] 25/57 [============>.................] - ETA: 33s  [ loss=1.1725 ][Training] 26/57 [============>.................] - ETA: 32s  [ loss=4.7751 ][Training] 27/57 [=============>................] - ETA: 32s  [ loss=2.5938 ][Training] 28/57 [=============>................] - ETA: 31s  [ loss=1.1130 ][Training] 29/57 [==============>...............] - ETA: 30s  [ loss=1.8513 ][Training] 30/57 [==============>...............] - ETA: 29s  [ loss=2.5617 ][Training] 31/57 [===============>..............] - ETA: 28s  [ loss=1.2026 ][Training] 32/57 [===============>..............] - ETA: 27s  [ loss=2.4077 ][Training] 33/57 [================>.............] - ETA: 27s  [ loss=2.1052 ][Training] 34/57 [================>.............] - ETA: 26s  [ loss=1.8450 ][Training] 35/57 [=================>............] - ETA: 24s  [ loss=1.0608 ][Training] 36/57 [=================>............] - ETA: 23s  [ loss=1.5197 ][Training] 37/57 [==================>...........] - ETA: 23s  [ loss=2.6846 ][Training] 38/57 [===================>..........] - ETA: 22s  [ loss=1.9532 ][Training] 39/57 [===================>..........] - ETA: 20s  [ loss=1.6957 ][Training] 40/57 [====================>.........] - ETA: 19s  [ loss=1.7884 ][Training] 41/57 [====================>.........] - ETA: 18s  [ loss=2.0990 ][Training] 42/57 [=====================>........] - ETA: 17s  [ loss=2.5402 ][Training] 43/57 [=====================>........] - ETA: 16s  [ loss=2.0929 ][Training] 44/57 [======================>.......] - ETA: 15s  [ loss=1.9209 ][Training] 45/57 [======================>.......] - ETA: 14s  [ loss=1.9002 ][Training] 46/57 [=======================>......] - ETA: 12s  [ loss=1.1965 ][Training] 47/57 [=======================>......] - ETA: 11s  [ loss=1.2475 ][Training] 48/57 [========================>.....] - ETA: 10s  [ loss=1.2663 ][Training] 49/57 [========================>.....] - ETA: 9s  [ loss=1.1284 ][Training] 50/57 [=========================>....] - ETA: 8s  [ loss=2.1218 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=2.8583 ][Training] 52/57 [==========================>...] - ETA: 5s  [ loss=3.0864 ][Training] 53/57 [==========================>...] - ETA: 4s  [ loss=1.8575 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=0.9512 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=1.4783 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=2.0210 ][Training] 57/57 [==============================] 1.2s/step  [ loss=1.3753 ]
01/03/2024 21:28:45 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 21:28:45 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 21:28:45 - INFO - root -     Num examples = 269
01/03/2024 21:28:45 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 5s[Evaluating] 2/12 [====>.........................] - ETA: 5s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 2s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 555.7ms/step
01/03/2024 21:28:52 - INFO - root -   

01/03/2024 21:28:52 - INFO - root -   ***** Eval results  *****
01/03/2024 21:28:52 - INFO - root -    acc: 0.6144 - recall: 0.7022 - f1: 0.6554 - loss: 6.3500 
01/03/2024 21:28:52 - INFO - root -   ***** Entity results  *****
01/03/2024 21:28:52 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 21:28:52 - INFO - root -    acc: 0.7963 - recall: 0.9149 - f1: 0.8515 
01/03/2024 21:28:52 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 21:28:52 - INFO - root -    acc: 1.0000 - recall: 1.0000 - f1: 1.0000 
01/03/2024 21:28:52 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 21:28:52 - INFO - root -    acc: 0.6000 - recall: 0.4737 - f1: 0.5294 
01/03/2024 21:28:52 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 21:28:52 - INFO - root -    acc: 0.3750 - recall: 0.3333 - f1: 0.3529 
01/03/2024 21:28:52 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 21:28:52 - INFO - root -    acc: 0.3571 - recall: 0.3846 - f1: 0.3704 
01/03/2024 21:28:52 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 21:28:52 - INFO - root -    acc: 1.0000 - recall: 0.4706 - f1: 0.6400 
01/03/2024 21:28:52 - INFO - root -   ******* PER.NAM results ********
01/03/2024 21:28:52 - INFO - root -    acc: 0.6031 - recall: 0.7182 - f1: 0.6556 
01/03/2024 21:28:52 - INFO - root -   ******* PER.NOM results ********
01/03/2024 21:28:52 - INFO - root -    acc: 0.6179 - recall: 0.7706 - f1: 0.6859 
01/03/2024 21:29:00 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-969
01/03/2024 21:29:00 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-969
01/03/2024 21:29:00 - INFO - root -   

01/03/2024 21:29:00 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 17/50
[Training] 1/57 [..............................] - ETA: 1:19  [ loss=2.0172 ][Training] 2/57 [>.............................] - ETA: 59s  [ loss=1.4315 ][Training] 3/57 [>.............................] - ETA: 1:01  [ loss=0.8857 ][Training] 4/57 [=>............................] - ETA: 1:02  [ loss=1.4233 ][Training] 5/57 [=>............................] - ETA: 1:03  [ loss=1.6769 ][Training] 6/57 [==>...........................] - ETA: 1:03  [ loss=1.3894 ][Training] 7/57 [==>...........................] - ETA: 1:01  [ loss=2.3377 ][Training] 8/57 [===>..........................] - ETA: 58s  [ loss=1.0077 ][Training] 9/57 [===>..........................] - ETA: 59s  [ loss=1.5604 ][Training] 10/57 [====>.........................] - ETA: 59s  [ loss=1.9577 ][Training] 11/57 [====>.........................] - ETA: 59s  [ loss=1.5936 ][Training] 12/57 [=====>........................] - ETA: 58s  [ loss=2.9600 ][Training] 13/57 [=====>........................] - ETA: 56s  [ loss=1.1044 ][Training] 14/57 [======>.......................] - ETA: 55s  [ loss=1.9692 ][Training] 15/57 [======>.......................] - ETA: 54s  [ loss=1.5275 ][Training] 16/57 [=======>......................] - ETA: 52s  [ loss=1.2982 ][Training] 17/57 [=======>......................] - ETA: 51s  [ loss=0.8322 ][Training] 18/57 [========>.....................] - ETA: 50s  [ loss=3.8824 ][Training] 19/57 [=========>....................] - ETA: 50s  [ loss=1.9996 ][Training] 20/57 [=========>....................] - ETA: 48s  [ loss=1.9730 ][Training] 21/57 [==========>...................] - ETA: 46s  [ loss=1.6863 ][Training] 22/57 [==========>...................] - ETA: 45s  [ loss=1.8414 ][Training] 23/57 [===========>..................] - ETA: 45s  [ loss=2.3641 ][Training] 24/57 [===========>..................] - ETA: 43s  [ loss=1.1297 ][Training] 25/57 [============>.................] - ETA: 42s  [ loss=1.5409 ][Training] 26/57 [============>.................] - ETA: 41s  [ loss=2.2818 ][Training] 27/57 [=============>................] - ETA: 39s  [ loss=1.7235 ][Training] 28/57 [=============>................] - ETA: 38s  [ loss=0.9845 ][Training] 29/57 [==============>...............] - ETA: 37s  [ loss=2.2133 ][Training] 30/57 [==============>...............] - ETA: 36s  [ loss=1.0026 ][Training] 31/57 [===============>..............] - ETA: 34s  [ loss=1.1952 ][Training] 32/57 [===============>..............] - ETA: 33s  [ loss=1.3656 ][Training] 33/57 [================>.............] - ETA: 32s  [ loss=1.0545 ][Training] 34/57 [================>.............] - ETA: 30s  [ loss=1.3610 ][Training] 35/57 [=================>............] - ETA: 29s  [ loss=2.6303 ][Training] 36/57 [=================>............] - ETA: 28s  [ loss=2.4659 ][Training] 37/57 [==================>...........] - ETA: 26s  [ loss=1.6050 ][Training] 38/57 [===================>..........] - ETA: 25s  [ loss=1.6286 ][Training] 39/57 [===================>..........] - ETA: 23s  [ loss=0.8910 ][Training] 40/57 [====================>.........] - ETA: 22s  [ loss=1.1292 ][Training] 41/57 [====================>.........] - ETA: 21s  [ loss=0.8684 ][Training] 42/57 [=====================>........] - ETA: 19s  [ loss=1.6928 ][Training] 43/57 [=====================>........] - ETA: 18s  [ loss=1.1627 ][Training] 44/57 [======================>.......] - ETA: 17s  [ loss=1.4281 ][Training] 45/57 [======================>.......] - ETA: 15s  [ loss=1.5588 ][Training] 46/57 [=======================>......] - ETA: 14s  [ loss=1.4378 ][Training] 47/57 [=======================>......] - ETA: 13s  [ loss=2.1200 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=1.2041 ][Training] 49/57 [========================>.....] - ETA: 10s  [ loss=2.0587 ][Training] 50/57 [=========================>....] - ETA: 9s  [ loss=1.3016 ][Training] 51/57 [=========================>....] - ETA: 8s  [ loss=2.0061 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=1.2231 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=1.7742 ][Training] 54/57 [===========================>..] - ETA: 4s  [ loss=0.9359 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=1.8787 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=2.8902 ][Training] 57/57 [==============================] 1.3s/step  [ loss=1.3161 ]
01/03/2024 21:30:16 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 21:30:16 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 21:30:16 - INFO - root -     Num examples = 269
01/03/2024 21:30:16 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 5s[Evaluating] 2/12 [====>.........................] - ETA: 6s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 567.8ms/step
01/03/2024 21:30:23 - INFO - root -   

01/03/2024 21:30:23 - INFO - root -   ***** Eval results  *****
01/03/2024 21:30:23 - INFO - root -    acc: 0.6961 - recall: 0.6489 - f1: 0.6717 - loss: 5.6886 
01/03/2024 21:30:23 - INFO - root -   ***** Entity results  *****
01/03/2024 21:30:23 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 21:30:23 - INFO - root -    acc: 0.7451 - recall: 0.8085 - f1: 0.7755 
01/03/2024 21:30:23 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 21:30:23 - INFO - root -    acc: 1.0000 - recall: 0.5000 - f1: 0.6667 
01/03/2024 21:30:23 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 21:30:23 - INFO - root -    acc: 0.3750 - recall: 0.3158 - f1: 0.3429 
01/03/2024 21:30:23 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 21:30:23 - INFO - root -    acc: 0.3333 - recall: 0.2222 - f1: 0.2667 
01/03/2024 21:30:23 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 21:30:23 - INFO - root -    acc: 0.6471 - recall: 0.2821 - f1: 0.3929 
01/03/2024 21:30:23 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 21:30:23 - INFO - root -    acc: 0.7778 - recall: 0.4118 - f1: 0.5385 
01/03/2024 21:30:23 - INFO - root -   ******* PER.NAM results ********
01/03/2024 21:30:23 - INFO - root -    acc: 0.7400 - recall: 0.6727 - f1: 0.7048 
01/03/2024 21:30:23 - INFO - root -   ******* PER.NOM results ********
01/03/2024 21:30:23 - INFO - root -    acc: 0.6973 - recall: 0.7588 - f1: 0.7268 
01/03/2024 21:30:31 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1026
01/03/2024 21:30:31 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1026
01/03/2024 21:30:31 - INFO - root -   

01/03/2024 21:30:31 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 18/50
[Training] 1/57 [..............................] - ETA: 1:01  [ loss=2.8900 ][Training] 2/57 [>.............................] - ETA: 1:09  [ loss=2.8937 ][Training] 3/57 [>.............................] - ETA: 1:13  [ loss=1.8986 ][Training] 4/57 [=>............................] - ETA: 1:11  [ loss=0.7392 ][Training] 5/57 [=>............................] - ETA: 1:06  [ loss=1.5993 ][Training] 6/57 [==>...........................] - ETA: 1:05  [ loss=1.0127 ][Training] 7/57 [==>...........................] - ETA: 1:02  [ loss=2.0825 ][Training] 8/57 [===>..........................] - ETA: 1:03  [ loss=2.7757 ][Training] 9/57 [===>..........................] - ETA: 1:00  [ loss=1.0281 ][Training] 10/57 [====>.........................] - ETA: 59s  [ loss=1.5973 ][Training] 11/57 [====>.........................] - ETA: 56s  [ loss=0.6465 ][Training] 12/57 [=====>........................] - ETA: 55s  [ loss=1.4623 ][Training] 13/57 [=====>........................] - ETA: 54s  [ loss=1.5352 ][Training] 14/57 [======>.......................] - ETA: 53s  [ loss=0.8929 ][Training] 15/57 [======>.......................] - ETA: 53s  [ loss=1.7517 ][Training] 16/57 [=======>......................] - ETA: 51s  [ loss=1.9519 ][Training] 17/57 [=======>......................] - ETA: 51s  [ loss=1.8334 ][Training] 18/57 [========>.....................] - ETA: 49s  [ loss=1.4951 ][Training] 19/57 [=========>....................] - ETA: 48s  [ loss=2.0813 ][Training] 20/57 [=========>....................] - ETA: 47s  [ loss=1.9419 ][Training] 21/57 [==========>...................] - ETA: 45s  [ loss=1.8280 ][Training] 22/57 [==========>...................] - ETA: 44s  [ loss=1.5620 ][Training] 23/57 [===========>..................] - ETA: 42s  [ loss=1.2310 ][Training] 24/57 [===========>..................] - ETA: 41s  [ loss=1.8799 ][Training] 25/57 [============>.................] - ETA: 41s  [ loss=2.2901 ][Training] 26/57 [============>.................] - ETA: 39s  [ loss=1.1425 ][Training] 27/57 [=============>................] - ETA: 38s  [ loss=1.4004 ][Training] 28/57 [=============>................] - ETA: 37s  [ loss=0.6504 ][Training] 29/57 [==============>...............] - ETA: 35s  [ loss=1.2096 ][Training] 30/57 [==============>...............] - ETA: 34s  [ loss=2.4824 ][Training] 31/57 [===============>..............] - ETA: 33s  [ loss=1.4366 ][Training] 32/57 [===============>..............] - ETA: 31s  [ loss=1.2167 ][Training] 33/57 [================>.............] - ETA: 30s  [ loss=0.9054 ][Training] 34/57 [================>.............] - ETA: 29s  [ loss=1.7553 ][Training] 35/57 [=================>............] - ETA: 27s  [ loss=1.7501 ][Training] 36/57 [=================>............] - ETA: 26s  [ loss=1.6940 ][Training] 37/57 [==================>...........] - ETA: 25s  [ loss=1.6727 ][Training] 38/57 [===================>..........] - ETA: 24s  [ loss=2.9181 ][Training] 39/57 [===================>..........] - ETA: 23s  [ loss=1.9013 ][Training] 40/57 [====================>.........] - ETA: 21s  [ loss=1.2713 ][Training] 41/57 [====================>.........] - ETA: 20s  [ loss=0.9546 ][Training] 42/57 [=====================>........] - ETA: 19s  [ loss=1.5208 ][Training] 43/57 [=====================>........] - ETA: 18s  [ loss=1.7053 ][Training] 44/57 [======================>.......] - ETA: 16s  [ loss=1.5693 ][Training] 45/57 [======================>.......] - ETA: 15s  [ loss=1.5670 ][Training] 46/57 [=======================>......] - ETA: 14s  [ loss=0.7206 ][Training] 47/57 [=======================>......] - ETA: 12s  [ loss=1.9643 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=1.4697 ][Training] 49/57 [========================>.....] - ETA: 10s  [ loss=3.3052 ][Training] 50/57 [=========================>....] - ETA: 8s  [ loss=1.5531 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=1.3315 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=0.7628 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=3.3336 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=1.5817 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=1.2031 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=1.3509 ][Training] 57/57 [==============================] 1.3s/step  [ loss=1.7689 ]
01/03/2024 21:31:43 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 21:31:43 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 21:31:43 - INFO - root -     Num examples = 269
01/03/2024 21:31:43 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 7s[Evaluating] 2/12 [====>.........................] - ETA: 6s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 577.9ms/step
01/03/2024 21:31:50 - INFO - root -   

01/03/2024 21:31:50 - INFO - root -   ***** Eval results  *****
01/03/2024 21:31:50 - INFO - root -    acc: 0.6350 - recall: 0.6949 - f1: 0.6636 - loss: 5.8260 
01/03/2024 21:31:50 - INFO - root -   ***** Entity results  *****
01/03/2024 21:31:50 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 21:31:50 - INFO - root -    acc: 0.8039 - recall: 0.8723 - f1: 0.8367 
01/03/2024 21:31:50 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 21:31:50 - INFO - root -    acc: 1.0000 - recall: 1.0000 - f1: 1.0000 
01/03/2024 21:31:50 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 21:31:50 - INFO - root -    acc: 0.5625 - recall: 0.4737 - f1: 0.5143 
01/03/2024 21:31:50 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 21:31:50 - INFO - root -    acc: 0.2500 - recall: 0.2222 - f1: 0.2353 
01/03/2024 21:31:50 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 21:31:50 - INFO - root -    acc: 0.4848 - recall: 0.4103 - f1: 0.4444 
01/03/2024 21:31:50 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 21:31:50 - INFO - root -    acc: 0.7778 - recall: 0.4118 - f1: 0.5385 
01/03/2024 21:31:50 - INFO - root -   ******* PER.NAM results ********
01/03/2024 21:31:50 - INFO - root -    acc: 0.6525 - recall: 0.7000 - f1: 0.6754 
01/03/2024 21:31:50 - INFO - root -   ******* PER.NOM results ********
01/03/2024 21:31:50 - INFO - root -    acc: 0.6186 - recall: 0.7824 - f1: 0.6909 
01/03/2024 21:31:57 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1083
01/03/2024 21:31:57 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1083
01/03/2024 21:31:57 - INFO - root -   

01/03/2024 21:31:57 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 19/50
[Training] 1/57 [..............................] - ETA: 55s  [ loss=1.4062 ][Training] 2/57 [>.............................] - ETA: 1:03  [ loss=1.1690 ][Training] 3/57 [>.............................] - ETA: 1:03  [ loss=1.2535 ][Training] 4/57 [=>............................] - ETA: 1:03  [ loss=0.8333 ][Training] 5/57 [=>............................] - ETA: 1:02  [ loss=1.3095 ][Training] 6/57 [==>...........................] - ETA: 59s  [ loss=1.0894 ][Training] 7/57 [==>...........................] - ETA: 57s  [ loss=1.2595 ][Training] 8/57 [===>..........................] - ETA: 57s  [ loss=1.3887 ][Training] 9/57 [===>..........................] - ETA: 56s  [ loss=1.1205 ][Training] 10/57 [====>.........................] - ETA: 55s  [ loss=1.4166 ][Training] 11/57 [====>.........................] - ETA: 56s  [ loss=1.5691 ][Training] 12/57 [=====>........................] - ETA: 55s  [ loss=1.2167 ][Training] 13/57 [=====>........................] - ETA: 54s  [ loss=1.6047 ][Training] 14/57 [======>.......................] - ETA: 52s  [ loss=1.5293 ][Training] 15/57 [======>.......................] - ETA: 51s  [ loss=0.7736 ][Training] 16/57 [=======>......................] - ETA: 50s  [ loss=1.2248 ][Training] 17/57 [=======>......................] - ETA: 49s  [ loss=2.2341 ][Training] 18/57 [========>.....................] - ETA: 48s  [ loss=1.3958 ][Training] 19/57 [=========>....................] - ETA: 47s  [ loss=1.7273 ][Training] 20/57 [=========>....................] - ETA: 46s  [ loss=0.5875 ][Training] 21/57 [==========>...................] - ETA: 45s  [ loss=1.9134 ][Training] 22/57 [==========>...................] - ETA: 43s  [ loss=1.2753 ][Training] 23/57 [===========>..................] - ETA: 42s  [ loss=2.1623 ][Training] 24/57 [===========>..................] - ETA: 41s  [ loss=1.9663 ][Training] 25/57 [============>.................] - ETA: 39s  [ loss=0.8861 ][Training] 26/57 [============>.................] - ETA: 38s  [ loss=2.2271 ][Training] 27/57 [=============>................] - ETA: 36s  [ loss=1.1945 ][Training] 28/57 [=============>................] - ETA: 35s  [ loss=1.6721 ][Training] 29/57 [==============>...............] - ETA: 34s  [ loss=2.3372 ][Training] 30/57 [==============>...............] - ETA: 33s  [ loss=2.0807 ][Training] 31/57 [===============>..............] - ETA: 32s  [ loss=1.2061 ][Training] 32/57 [===============>..............] - ETA: 30s  [ loss=0.8431 ][Training] 33/57 [================>.............] - ETA: 29s  [ loss=0.8996 ][Training] 34/57 [================>.............] - ETA: 28s  [ loss=1.2290 ][Training] 35/57 [=================>............] - ETA: 27s  [ loss=1.3763 ][Training] 36/57 [=================>............] - ETA: 25s  [ loss=2.4850 ][Training] 37/57 [==================>...........] - ETA: 25s  [ loss=1.0504 ][Training] 38/57 [===================>..........] - ETA: 23s  [ loss=0.7010 ][Training] 39/57 [===================>..........] - ETA: 22s  [ loss=1.6929 ][Training] 40/57 [====================>.........] - ETA: 21s  [ loss=2.1546 ][Training] 41/57 [====================>.........] - ETA: 20s  [ loss=1.2658 ][Training] 42/57 [=====================>........] - ETA: 19s  [ loss=1.4155 ][Training] 43/57 [=====================>........] - ETA: 17s  [ loss=0.8903 ][Training] 44/57 [======================>.......] - ETA: 16s  [ loss=1.4129 ][Training] 45/57 [======================>.......] - ETA: 15s  [ loss=1.3274 ][Training] 46/57 [=======================>......] - ETA: 13s  [ loss=1.1762 ][Training] 47/57 [=======================>......] - ETA: 12s  [ loss=1.8670 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=1.1877 ][Training] 49/57 [========================>.....] - ETA: 10s  [ loss=1.8141 ][Training] 50/57 [=========================>....] - ETA: 8s  [ loss=0.6340 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=2.0977 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=1.4378 ][Training] 53/57 [==========================>...] - ETA: 4s  [ loss=2.0040 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=2.9656 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=1.8550 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=1.8050 ][Training] 57/57 [==============================] 1.2s/step  [ loss=1.6024 ]
01/03/2024 21:33:07 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 21:33:07 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 21:33:07 - INFO - root -     Num examples = 269
01/03/2024 21:33:07 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 6s[Evaluating] 2/12 [====>.........................] - ETA: 5s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 563.9ms/step
01/03/2024 21:33:14 - INFO - root -   

01/03/2024 21:33:14 - INFO - root -   ***** Eval results  *****
01/03/2024 21:33:14 - INFO - root -    acc: 0.6756 - recall: 0.6707 - f1: 0.6731 - loss: 5.5233 
01/03/2024 21:33:14 - INFO - root -   ***** Entity results  *****
01/03/2024 21:33:14 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 21:33:14 - INFO - root -    acc: 0.7736 - recall: 0.8723 - f1: 0.8200 
01/03/2024 21:33:14 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 21:33:14 - INFO - root -    acc: 1.0000 - recall: 0.5000 - f1: 0.6667 
01/03/2024 21:33:14 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 21:33:14 - INFO - root -    acc: 0.6429 - recall: 0.4737 - f1: 0.5455 
01/03/2024 21:33:14 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 21:33:14 - INFO - root -    acc: 0.3333 - recall: 0.3333 - f1: 0.3333 
01/03/2024 21:33:14 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 21:33:14 - INFO - root -    acc: 0.4375 - recall: 0.3590 - f1: 0.3944 
01/03/2024 21:33:14 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 21:33:14 - INFO - root -    acc: 0.7778 - recall: 0.4118 - f1: 0.5385 
01/03/2024 21:33:14 - INFO - root -   ******* PER.NAM results ********
01/03/2024 21:33:14 - INFO - root -    acc: 0.6393 - recall: 0.7091 - f1: 0.6724 
01/03/2024 21:33:14 - INFO - root -   ******* PER.NOM results ********
01/03/2024 21:33:14 - INFO - root -    acc: 0.7294 - recall: 0.7294 - f1: 0.7294 
01/03/2024 21:33:33 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1140
01/03/2024 21:33:34 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1140
01/03/2024 21:33:34 - INFO - root -   

01/03/2024 21:33:34 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 20/50
[Training] 1/57 [..............................] - ETA: 1:05  [ loss=1.0695 ][Training] 2/57 [>.............................] - ETA: 1:07  [ loss=0.8626 ][Training] 3/57 [>.............................] - ETA: 1:07  [ loss=1.7969 ][Training] 4/57 [=>............................] - ETA: 1:04  [ loss=1.0510 ][Training] 5/57 [=>............................] - ETA: 1:06  [ loss=1.6126 ][Training] 6/57 [==>...........................] - ETA: 1:05  [ loss=1.8904 ][Training] 7/57 [==>...........................] - ETA: 1:07  [ loss=2.0654 ][Training] 8/57 [===>..........................] - ETA: 1:03  [ loss=1.1037 ][Training] 9/57 [===>..........................] - ETA: 1:02  [ loss=1.6505 ][Training] 10/57 [====>.........................] - ETA: 1:01  [ loss=1.4716 ][Training] 11/57 [====>.........................] - ETA: 1:00  [ loss=0.8145 ][Training] 12/57 [=====>........................] - ETA: 58s  [ loss=2.1384 ][Training] 13/57 [=====>........................] - ETA: 56s  [ loss=1.1607 ][Training] 14/57 [======>.......................] - ETA: 54s  [ loss=1.1812 ][Training] 15/57 [======>.......................] - ETA: 53s  [ loss=0.9546 ][Training] 16/57 [=======>......................] - ETA: 52s  [ loss=1.0976 ][Training] 17/57 [=======>......................] - ETA: 51s  [ loss=1.9114 ][Training] 18/57 [========>.....................] - ETA: 50s  [ loss=1.8213 ][Training] 19/57 [=========>....................] - ETA: 49s  [ loss=1.0000 ][Training] 20/57 [=========>....................] - ETA: 47s  [ loss=0.4535 ][Training] 21/57 [==========>...................] - ETA: 46s  [ loss=1.9550 ][Training] 22/57 [==========>...................] - ETA: 45s  [ loss=3.0525 ][Training] 23/57 [===========>..................] - ETA: 43s  [ loss=1.4030 ][Training] 24/57 [===========>..................] - ETA: 41s  [ loss=1.2434 ][Training] 25/57 [============>.................] - ETA: 40s  [ loss=1.6653 ][Training] 26/57 [============>.................] - ETA: 39s  [ loss=1.4556 ][Training] 27/57 [=============>................] - ETA: 38s  [ loss=1.1944 ][Training] 28/57 [=============>................] - ETA: 37s  [ loss=1.8797 ][Training] 29/57 [==============>...............] - ETA: 36s  [ loss=1.5997 ][Training] 30/57 [==============>...............] - ETA: 34s  [ loss=1.4766 ][Training] 31/57 [===============>..............] - ETA: 33s  [ loss=0.4111 ][Training] 32/57 [===============>..............] - ETA: 32s  [ loss=1.0965 ][Training] 33/57 [================>.............] - ETA: 31s  [ loss=2.1074 ][Training] 34/57 [================>.............] - ETA: 29s  [ loss=0.9676 ][Training] 35/57 [=================>............] - ETA: 28s  [ loss=1.7336 ][Training] 36/57 [=================>............] - ETA: 27s  [ loss=1.3117 ][Training] 37/57 [==================>...........] - ETA: 25s  [ loss=0.9492 ][Training] 38/57 [===================>..........] - ETA: 24s  [ loss=1.5363 ][Training] 39/57 [===================>..........] - ETA: 23s  [ loss=1.4557 ][Training] 40/57 [====================>.........] - ETA: 21s  [ loss=0.9235 ][Training] 41/57 [====================>.........] - ETA: 20s  [ loss=1.6359 ][Training] 42/57 [=====================>........] - ETA: 19s  [ loss=1.2471 ][Training] 43/57 [=====================>........] - ETA: 17s  [ loss=1.1531 ][Training] 44/57 [======================>.......] - ETA: 16s  [ loss=1.5611 ][Training] 45/57 [======================>.......] - ETA: 15s  [ loss=0.8849 ][Training] 46/57 [=======================>......] - ETA: 14s  [ loss=1.2194 ][Training] 47/57 [=======================>......] - ETA: 12s  [ loss=1.6945 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=1.3836 ][Training] 49/57 [========================>.....] - ETA: 10s  [ loss=1.6260 ][Training] 50/57 [=========================>....] - ETA: 8s  [ loss=0.5867 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=1.3391 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=2.0604 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=0.5461 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=1.1520 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=1.8120 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=1.7951 ][Training] 57/57 [==============================] 1.3s/step  [ loss=0.8377 ]
01/03/2024 21:34:46 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 21:34:46 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 21:34:46 - INFO - root -     Num examples = 269
01/03/2024 21:34:46 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 6s[Evaluating] 2/12 [====>.........................] - ETA: 7s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 5s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 578.2ms/step
01/03/2024 21:34:53 - INFO - root -   

01/03/2024 21:34:53 - INFO - root -   ***** Eval results  *****
01/03/2024 21:34:53 - INFO - root -    acc: 0.6374 - recall: 0.6852 - f1: 0.6604 - loss: 5.9657 
01/03/2024 21:34:53 - INFO - root -   ***** Entity results  *****
01/03/2024 21:34:53 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 21:34:53 - INFO - root -    acc: 0.7544 - recall: 0.9149 - f1: 0.8269 
01/03/2024 21:34:53 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 21:34:53 - INFO - root -    acc: 0.6667 - recall: 1.0000 - f1: 0.8000 
01/03/2024 21:34:53 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 21:34:53 - INFO - root -    acc: 0.5385 - recall: 0.3684 - f1: 0.4375 
01/03/2024 21:34:53 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 21:34:53 - INFO - root -    acc: 0.3333 - recall: 0.4444 - f1: 0.3810 
01/03/2024 21:34:53 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 21:34:53 - INFO - root -    acc: 0.4839 - recall: 0.3846 - f1: 0.4286 
01/03/2024 21:34:53 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 21:34:53 - INFO - root -    acc: 0.7273 - recall: 0.4706 - f1: 0.5714 
01/03/2024 21:34:53 - INFO - root -   ******* PER.NAM results ********
01/03/2024 21:34:53 - INFO - root -    acc: 0.6847 - recall: 0.6909 - f1: 0.6878 
01/03/2024 21:34:53 - INFO - root -   ******* PER.NOM results ********
01/03/2024 21:34:53 - INFO - root -    acc: 0.6214 - recall: 0.7529 - f1: 0.6809 
01/03/2024 21:35:01 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1197
01/03/2024 21:35:01 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1197
01/03/2024 21:35:01 - INFO - root -   

01/03/2024 21:35:01 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 21/50
[Training] 1/57 [..............................] - ETA: 57s  [ loss=0.8128 ][Training] 2/57 [>.............................] - ETA: 1:09  [ loss=2.1221 ][Training] 3/57 [>.............................] - ETA: 1:06  [ loss=2.5442 ][Training] 4/57 [=>............................] - ETA: 1:04  [ loss=0.9325 ][Training] 5/57 [=>............................] - ETA: 1:01  [ loss=1.1918 ][Training] 6/57 [==>...........................] - ETA: 1:00  [ loss=1.1889 ][Training] 7/57 [==>...........................] - ETA: 1:00  [ loss=0.8770 ][Training] 8/57 [===>..........................] - ETA: 1:00  [ loss=0.8000 ][Training] 9/57 [===>..........................] - ETA: 1:00  [ loss=0.7149 ][Training] 10/57 [====>.........................] - ETA: 58s  [ loss=1.7036 ][Training] 11/57 [====>.........................] - ETA: 58s  [ loss=2.0800 ][Training] 12/57 [=====>........................] - ETA: 55s  [ loss=0.5162 ][Training] 13/57 [=====>........................] - ETA: 55s  [ loss=1.1389 ][Training] 14/57 [======>.......................] - ETA: 53s  [ loss=1.0327 ][Training] 15/57 [======>.......................] - ETA: 51s  [ loss=1.0472 ][Training] 16/57 [=======>......................] - ETA: 51s  [ loss=0.5071 ][Training] 17/57 [=======>......................] - ETA: 49s  [ loss=1.9452 ][Training] 18/57 [========>.....................] - ETA: 48s  [ loss=1.0783 ][Training] 19/57 [=========>....................] - ETA: 47s  [ loss=1.1790 ][Training] 20/57 [=========>....................] - ETA: 46s  [ loss=0.5541 ][Training] 21/57 [==========>...................] - ETA: 45s  [ loss=1.1357 ][Training] 22/57 [==========>...................] - ETA: 44s  [ loss=1.8897 ][Training] 23/57 [===========>..................] - ETA: 42s  [ loss=1.4302 ][Training] 24/57 [===========>..................] - ETA: 41s  [ loss=0.9951 ][Training] 25/57 [============>.................] - ETA: 40s  [ loss=1.7384 ][Training] 26/57 [============>.................] - ETA: 38s  [ loss=0.9147 ][Training] 27/57 [=============>................] - ETA: 37s  [ loss=1.1222 ][Training] 28/57 [=============>................] - ETA: 36s  [ loss=1.4016 ][Training] 29/57 [==============>...............] - ETA: 35s  [ loss=1.8711 ][Training] 30/57 [==============>...............] - ETA: 33s  [ loss=1.2048 ][Training] 31/57 [===============>..............] - ETA: 32s  [ loss=1.2265 ][Training] 32/57 [===============>..............] - ETA: 31s  [ loss=2.2112 ][Training] 33/57 [================>.............] - ETA: 30s  [ loss=0.8594 ][Training] 34/57 [================>.............] - ETA: 28s  [ loss=1.8817 ][Training] 35/57 [=================>............] - ETA: 27s  [ loss=2.2650 ][Training] 36/57 [=================>............] - ETA: 26s  [ loss=0.6430 ][Training] 37/57 [==================>...........] - ETA: 25s  [ loss=1.5889 ][Training] 38/57 [===================>..........] - ETA: 24s  [ loss=1.1693 ][Training] 39/57 [===================>..........] - ETA: 22s  [ loss=1.0726 ][Training] 40/57 [====================>.........] - ETA: 21s  [ loss=1.5454 ][Training] 41/57 [====================>.........] - ETA: 20s  [ loss=0.5391 ][Training] 42/57 [=====================>........] - ETA: 19s  [ loss=1.0235 ][Training] 43/57 [=====================>........] - ETA: 17s  [ loss=0.5431 ][Training] 44/57 [======================>.......] - ETA: 16s  [ loss=0.7958 ][Training] 45/57 [======================>.......] - ETA: 15s  [ loss=1.0675 ][Training] 46/57 [=======================>......] - ETA: 14s  [ loss=1.3284 ][Training] 47/57 [=======================>......] - ETA: 12s  [ loss=0.9547 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=1.5342 ][Training] 49/57 [========================>.....] - ETA: 10s  [ loss=1.5868 ][Training] 50/57 [=========================>....] - ETA: 8s  [ loss=1.2618 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=1.3689 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=1.3343 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=0.6185 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=1.7226 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=1.4970 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.6253 ][Training] 57/57 [==============================] 1.3s/step  [ loss=3.4944 ]
01/03/2024 21:36:13 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 21:36:13 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 21:36:13 - INFO - root -     Num examples = 269
01/03/2024 21:36:13 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 6s[Evaluating] 2/12 [====>.........................] - ETA: 6s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 573.5ms/step
01/03/2024 21:36:20 - INFO - root -   

01/03/2024 21:36:20 - INFO - root -   ***** Eval results  *****
01/03/2024 21:36:20 - INFO - root -    acc: 0.6955 - recall: 0.6804 - f1: 0.6879 - loss: 5.5072 
01/03/2024 21:36:20 - INFO - root -   ***** Entity results  *****
01/03/2024 21:36:20 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 21:36:20 - INFO - root -    acc: 0.7818 - recall: 0.9149 - f1: 0.8431 
01/03/2024 21:36:20 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 21:36:20 - INFO - root -    acc: 1.0000 - recall: 0.5000 - f1: 0.6667 
01/03/2024 21:36:20 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 21:36:20 - INFO - root -    acc: 0.6364 - recall: 0.3684 - f1: 0.4667 
01/03/2024 21:36:20 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 21:36:20 - INFO - root -    acc: 0.1667 - recall: 0.1111 - f1: 0.1333 
01/03/2024 21:36:20 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 21:36:20 - INFO - root -    acc: 0.5417 - recall: 0.3333 - f1: 0.4127 
01/03/2024 21:36:20 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 21:36:20 - INFO - root -    acc: 0.8750 - recall: 0.4118 - f1: 0.5600 
01/03/2024 21:36:20 - INFO - root -   ******* PER.NAM results ********
01/03/2024 21:36:20 - INFO - root -    acc: 0.6964 - recall: 0.7091 - f1: 0.7027 
01/03/2024 21:36:20 - INFO - root -   ******* PER.NOM results ********
01/03/2024 21:36:20 - INFO - root -    acc: 0.7005 - recall: 0.7706 - f1: 0.7339 
01/03/2024 21:36:29 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1254
01/03/2024 21:36:29 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1254
01/03/2024 21:36:29 - INFO - root -   

01/03/2024 21:36:29 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 22/50
[Training] 1/57 [..............................] - ETA: 1:10  [ loss=0.9315 ][Training] 2/57 [>.............................] - ETA: 1:03  [ loss=1.6106 ][Training] 3/57 [>.............................] - ETA: 1:13  [ loss=0.9312 ][Training] 4/57 [=>............................] - ETA: 1:13  [ loss=1.3708 ][Training] 5/57 [=>............................] - ETA: 1:11  [ loss=0.8285 ][Training] 6/57 [==>...........................] - ETA: 1:05  [ loss=0.7004 ][Training] 7/57 [==>...........................] - ETA: 1:04  [ loss=1.3819 ][Training] 8/57 [===>..........................] - ETA: 1:03  [ loss=1.1215 ][Training] 9/57 [===>..........................] - ETA: 1:02  [ loss=1.4376 ][Training] 10/57 [====>.........................] - ETA: 1:00  [ loss=1.7167 ][Training] 11/57 [====>.........................] - ETA: 59s  [ loss=1.4310 ][Training] 12/57 [=====>........................] - ETA: 57s  [ loss=0.9505 ][Training] 13/57 [=====>........................] - ETA: 56s  [ loss=0.7699 ][Training] 14/57 [======>.......................] - ETA: 55s  [ loss=0.5078 ][Training] 15/57 [======>.......................] - ETA: 54s  [ loss=0.9801 ][Training] 16/57 [=======>......................] - ETA: 53s  [ loss=0.7727 ][Training] 17/57 [=======>......................] - ETA: 51s  [ loss=1.7613 ][Training] 18/57 [========>.....................] - ETA: 49s  [ loss=1.2695 ][Training] 19/57 [=========>....................] - ETA: 48s  [ loss=1.5804 ][Training] 20/57 [=========>....................] - ETA: 47s  [ loss=1.2202 ][Training] 21/57 [==========>...................] - ETA: 45s  [ loss=0.6116 ][Training] 22/57 [==========>...................] - ETA: 45s  [ loss=1.0152 ][Training] 23/57 [===========>..................] - ETA: 44s  [ loss=1.4248 ][Training] 24/57 [===========>..................] - ETA: 42s  [ loss=1.0663 ][Training] 25/57 [============>.................] - ETA: 41s  [ loss=0.6484 ][Training] 26/57 [============>.................] - ETA: 40s  [ loss=1.2903 ][Training] 27/57 [=============>................] - ETA: 39s  [ loss=1.0392 ][Training] 28/57 [=============>................] - ETA: 37s  [ loss=2.8763 ][Training] 29/57 [==============>...............] - ETA: 36s  [ loss=0.6686 ][Training] 30/57 [==============>...............] - ETA: 35s  [ loss=1.3806 ][Training] 31/57 [===============>..............] - ETA: 33s  [ loss=1.6796 ][Training] 32/57 [===============>..............] - ETA: 32s  [ loss=1.3728 ][Training] 33/57 [================>.............] - ETA: 31s  [ loss=0.9737 ][Training] 34/57 [================>.............] - ETA: 30s  [ loss=1.3513 ][Training] 35/57 [=================>............] - ETA: 28s  [ loss=0.8500 ][Training] 36/57 [=================>............] - ETA: 27s  [ loss=0.8964 ][Training] 37/57 [==================>...........] - ETA: 26s  [ loss=0.7604 ][Training] 38/57 [===================>..........] - ETA: 24s  [ loss=2.3527 ][Training] 39/57 [===================>..........] - ETA: 23s  [ loss=1.1340 ][Training] 40/57 [====================>.........] - ETA: 22s  [ loss=0.5922 ][Training] 41/57 [====================>.........] - ETA: 20s  [ loss=0.5998 ][Training] 42/57 [=====================>........] - ETA: 19s  [ loss=0.8928 ][Training] 43/57 [=====================>........] - ETA: 18s  [ loss=1.3403 ][Training] 44/57 [======================>.......] - ETA: 16s  [ loss=1.0232 ][Training] 45/57 [======================>.......] - ETA: 15s  [ loss=0.5321 ][Training] 46/57 [=======================>......] - ETA: 14s  [ loss=1.8594 ][Training] 47/57 [=======================>......] - ETA: 13s  [ loss=1.0288 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=1.1712 ][Training] 49/57 [========================>.....] - ETA: 10s  [ loss=1.0870 ][Training] 50/57 [=========================>....] - ETA: 9s  [ loss=0.8485 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=0.9113 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=1.8848 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=1.2152 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=0.8582 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=1.0967 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=1.3468 ][Training] 57/57 [==============================] 1.3s/step  [ loss=1.1718 ]
01/03/2024 21:37:42 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 21:37:43 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 21:37:43 - INFO - root -     Num examples = 269
01/03/2024 21:37:43 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 5s[Evaluating] 2/12 [====>.........................] - ETA: 5s[Evaluating] 3/12 [======>.......................] - ETA: 4s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 3s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 2s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 526.3ms/step
01/03/2024 21:37:49 - INFO - root -   

01/03/2024 21:37:49 - INFO - root -   ***** Eval results  *****
01/03/2024 21:37:49 - INFO - root -    acc: 0.6456 - recall: 0.6925 - f1: 0.6682 - loss: 5.7462 
01/03/2024 21:37:49 - INFO - root -   ***** Entity results  *****
01/03/2024 21:37:49 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 21:37:49 - INFO - root -    acc: 0.7679 - recall: 0.9149 - f1: 0.8350 
01/03/2024 21:37:49 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 21:37:49 - INFO - root -    acc: 1.0000 - recall: 0.5000 - f1: 0.6667 
01/03/2024 21:37:49 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 21:37:49 - INFO - root -    acc: 0.6429 - recall: 0.4737 - f1: 0.5455 
01/03/2024 21:37:49 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 21:37:49 - INFO - root -    acc: 0.3000 - recall: 0.3333 - f1: 0.3158 
01/03/2024 21:37:49 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 21:37:49 - INFO - root -    acc: 0.4167 - recall: 0.3846 - f1: 0.4000 
01/03/2024 21:37:49 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 21:37:49 - INFO - root -    acc: 0.8000 - recall: 0.4706 - f1: 0.5926 
01/03/2024 21:37:49 - INFO - root -   ******* PER.NAM results ********
01/03/2024 21:37:49 - INFO - root -    acc: 0.6417 - recall: 0.7000 - f1: 0.6696 
01/03/2024 21:37:49 - INFO - root -   ******* PER.NOM results ********
01/03/2024 21:37:49 - INFO - root -    acc: 0.6633 - recall: 0.7647 - f1: 0.7104 
01/03/2024 21:38:01 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1311
01/03/2024 21:38:01 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1311
01/03/2024 21:38:01 - INFO - root -   

01/03/2024 21:38:01 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 23/50
[Training] 1/57 [..............................] - ETA: 1:10  [ loss=0.6710 ][Training] 2/57 [>.............................] - ETA: 1:06  [ loss=1.3789 ][Training] 3/57 [>.............................] - ETA: 1:10  [ loss=1.5285 ][Training] 4/57 [=>............................] - ETA: 1:05  [ loss=0.9253 ][Training] 5/57 [=>............................] - ETA: 1:03  [ loss=1.1307 ][Training] 6/57 [==>...........................] - ETA: 1:01  [ loss=0.8045 ][Training] 7/57 [==>...........................] - ETA: 59s  [ loss=0.9156 ][Training] 8/57 [===>..........................] - ETA: 58s  [ loss=0.7778 ][Training] 9/57 [===>..........................] - ETA: 57s  [ loss=1.3866 ][Training] 10/57 [====>.........................] - ETA: 57s  [ loss=0.9182 ][Training] 11/57 [====>.........................] - ETA: 56s  [ loss=1.2232 ][Training] 12/57 [=====>........................] - ETA: 54s  [ loss=0.7538 ][Training] 13/57 [=====>........................] - ETA: 53s  [ loss=1.6417 ][Training] 14/57 [======>.......................] - ETA: 53s  [ loss=1.1154 ][Training] 15/57 [======>.......................] - ETA: 53s  [ loss=2.5118 ][Training] 16/57 [=======>......................] - ETA: 52s  [ loss=1.2522 ][Training] 17/57 [=======>......................] - ETA: 51s  [ loss=1.1113 ][Training] 18/57 [========>.....................] - ETA: 51s  [ loss=1.8711 ][Training] 19/57 [=========>....................] - ETA: 49s  [ loss=1.0105 ][Training] 20/57 [=========>....................] - ETA: 48s  [ loss=0.4155 ][Training] 21/57 [==========>...................] - ETA: 46s  [ loss=0.9919 ][Training] 22/57 [==========>...................] - ETA: 45s  [ loss=0.4943 ][Training] 23/57 [===========>..................] - ETA: 44s  [ loss=1.1336 ][Training] 24/57 [===========>..................] - ETA: 42s  [ loss=0.9551 ][Training] 25/57 [============>.................] - ETA: 41s  [ loss=0.4666 ][Training] 26/57 [============>.................] - ETA: 39s  [ loss=2.1888 ][Training] 27/57 [=============>................] - ETA: 39s  [ loss=1.1645 ][Training] 28/57 [=============>................] - ETA: 37s  [ loss=1.1285 ][Training] 29/57 [==============>...............] - ETA: 36s  [ loss=0.7291 ][Training] 30/57 [==============>...............] - ETA: 34s  [ loss=0.4198 ][Training] 31/57 [===============>..............] - ETA: 33s  [ loss=1.5519 ][Training] 32/57 [===============>..............] - ETA: 32s  [ loss=0.9473 ][Training] 33/57 [================>.............] - ETA: 30s  [ loss=0.8804 ][Training] 34/57 [================>.............] - ETA: 29s  [ loss=0.9344 ][Training] 35/57 [=================>............] - ETA: 28s  [ loss=1.0137 ][Training] 36/57 [=================>............] - ETA: 26s  [ loss=0.8532 ][Training] 37/57 [==================>...........] - ETA: 25s  [ loss=1.2212 ][Training] 38/57 [===================>..........] - ETA: 24s  [ loss=0.6992 ][Training] 39/57 [===================>..........] - ETA: 22s  [ loss=2.5785 ][Training] 40/57 [====================>.........] - ETA: 21s  [ loss=1.6221 ][Training] 41/57 [====================>.........] - ETA: 20s  [ loss=1.8810 ][Training] 42/57 [=====================>........] - ETA: 19s  [ loss=0.6715 ][Training] 43/57 [=====================>........] - ETA: 17s  [ loss=0.9326 ][Training] 44/57 [======================>.......] - ETA: 16s  [ loss=1.2475 ][Training] 45/57 [======================>.......] - ETA: 15s  [ loss=0.7870 ][Training] 46/57 [=======================>......] - ETA: 14s  [ loss=1.4655 ][Training] 47/57 [=======================>......] - ETA: 12s  [ loss=0.7640 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=1.8521 ][Training] 49/57 [========================>.....] - ETA: 10s  [ loss=1.0139 ][Training] 50/57 [=========================>....] - ETA: 9s  [ loss=1.5204 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=0.7633 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=1.3581 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=1.3604 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=0.6769 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=1.5566 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=1.0978 ][Training] 57/57 [==============================] 1.3s/step  [ loss=0.6153 ]
01/03/2024 21:39:13 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 21:39:13 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 21:39:13 - INFO - root -     Num examples = 269
01/03/2024 21:39:13 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 5s[Evaluating] 2/12 [====>.........................] - ETA: 6s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 574.9ms/step
01/03/2024 21:39:20 - INFO - root -   

01/03/2024 21:39:20 - INFO - root -   ***** Eval results  *****
01/03/2024 21:39:20 - INFO - root -    acc: 0.6611 - recall: 0.6755 - f1: 0.6683 - loss: 5.8374 
01/03/2024 21:39:20 - INFO - root -   ***** Entity results  *****
01/03/2024 21:39:20 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 21:39:20 - INFO - root -    acc: 0.8077 - recall: 0.8936 - f1: 0.8485 
01/03/2024 21:39:20 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 21:39:20 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 21:39:20 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 21:39:20 - INFO - root -    acc: 0.6000 - recall: 0.4737 - f1: 0.5294 
01/03/2024 21:39:20 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 21:39:20 - INFO - root -    acc: 0.2000 - recall: 0.1111 - f1: 0.1429 
01/03/2024 21:39:20 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 21:39:20 - INFO - root -    acc: 0.4688 - recall: 0.3846 - f1: 0.4225 
01/03/2024 21:39:20 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 21:39:20 - INFO - root -    acc: 0.7000 - recall: 0.4118 - f1: 0.5185 
01/03/2024 21:39:20 - INFO - root -   ******* PER.NAM results ********
01/03/2024 21:39:20 - INFO - root -    acc: 0.6029 - recall: 0.7455 - f1: 0.6667 
01/03/2024 21:39:20 - INFO - root -   ******* PER.NOM results ********
01/03/2024 21:39:20 - INFO - root -    acc: 0.7151 - recall: 0.7235 - f1: 0.7193 
01/03/2024 21:39:30 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1368
01/03/2024 21:39:30 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1368
01/03/2024 21:39:30 - INFO - root -   

01/03/2024 21:39:30 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 24/50
[Training] 1/57 [..............................] - ETA: 1:21  [ loss=1.5167 ][Training] 2/57 [>.............................] - ETA: 1:13  [ loss=1.0069 ][Training] 3/57 [>.............................] - ETA: 1:11  [ loss=1.1392 ][Training] 4/57 [=>............................] - ETA: 1:09  [ loss=0.4131 ][Training] 5/57 [=>............................] - ETA: 1:06  [ loss=0.5763 ][Training] 6/57 [==>...........................] - ETA: 1:03  [ loss=0.8013 ][Training] 7/57 [==>...........................] - ETA: 1:00  [ loss=0.4510 ][Training] 8/57 [===>..........................] - ETA: 58s  [ loss=0.5815 ][Training] 9/57 [===>..........................] - ETA: 56s  [ loss=1.1906 ][Training] 10/57 [====>.........................] - ETA: 56s  [ loss=0.7018 ][Training] 11/57 [====>.........................] - ETA: 55s  [ loss=0.7213 ][Training] 12/57 [=====>........................] - ETA: 54s  [ loss=0.9543 ][Training] 13/57 [=====>........................] - ETA: 52s  [ loss=1.5128 ][Training] 14/57 [======>.......................] - ETA: 52s  [ loss=1.3945 ][Training] 15/57 [======>.......................] - ETA: 51s  [ loss=1.6422 ][Training] 16/57 [=======>......................] - ETA: 50s  [ loss=1.3206 ][Training] 17/57 [=======>......................] - ETA: 49s  [ loss=1.6068 ][Training] 18/57 [========>.....................] - ETA: 47s  [ loss=0.7434 ][Training] 19/57 [=========>....................] - ETA: 46s  [ loss=1.2726 ][Training] 20/57 [=========>....................] - ETA: 44s  [ loss=1.3601 ][Training] 21/57 [==========>...................] - ETA: 43s  [ loss=1.1495 ][Training] 22/57 [==========>...................] - ETA: 41s  [ loss=0.8603 ][Training] 23/57 [===========>..................] - ETA: 40s  [ loss=1.4364 ][Training] 24/57 [===========>..................] - ETA: 38s  [ loss=2.0081 ][Training] 25/57 [============>.................] - ETA: 37s  [ loss=0.9029 ][Training] 26/57 [============>.................] - ETA: 36s  [ loss=1.4692 ][Training] 27/57 [=============>................] - ETA: 35s  [ loss=1.4731 ][Training] 28/57 [=============>................] - ETA: 34s  [ loss=1.1373 ][Training] 29/57 [==============>...............] - ETA: 33s  [ loss=1.3680 ][Training] 30/57 [==============>...............] - ETA: 31s  [ loss=1.0465 ][Training] 31/57 [===============>..............] - ETA: 30s  [ loss=0.5087 ][Training] 32/57 [===============>..............] - ETA: 29s  [ loss=0.8520 ][Training] 33/57 [================>.............] - ETA: 28s  [ loss=1.6206 ][Training] 34/57 [================>.............] - ETA: 27s  [ loss=0.7573 ][Training] 35/57 [=================>............] - ETA: 26s  [ loss=0.4604 ][Training] 36/57 [=================>............] - ETA: 25s  [ loss=0.6247 ][Training] 37/57 [==================>...........] - ETA: 23s  [ loss=0.9781 ][Training] 38/57 [===================>..........] - ETA: 22s  [ loss=1.1274 ][Training] 39/57 [===================>..........] - ETA: 21s  [ loss=0.8268 ][Training] 40/57 [====================>.........] - ETA: 20s  [ loss=1.3866 ][Training] 41/57 [====================>.........] - ETA: 19s  [ loss=0.9581 ][Training] 42/57 [=====================>........] - ETA: 18s  [ loss=0.5623 ][Training] 43/57 [=====================>........] - ETA: 16s  [ loss=0.6938 ][Training] 44/57 [======================>.......] - ETA: 15s  [ loss=1.4907 ][Training] 45/57 [======================>.......] - ETA: 14s  [ loss=1.3117 ][Training] 46/57 [=======================>......] - ETA: 13s  [ loss=0.7849 ][Training] 47/57 [=======================>......] - ETA: 12s  [ loss=0.5212 ][Training] 48/57 [========================>.....] - ETA: 10s  [ loss=1.7382 ][Training] 49/57 [========================>.....] - ETA: 9s  [ loss=1.1410 ][Training] 50/57 [=========================>....] - ETA: 8s  [ loss=0.4827 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=1.7915 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=0.5769 ][Training] 53/57 [==========================>...] - ETA: 4s  [ loss=0.7037 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=0.9281 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=1.2722 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.8956 ][Training] 57/57 [==============================] 1.2s/step  [ loss=0.9206 ]
01/03/2024 21:40:39 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 21:40:39 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 21:40:39 - INFO - root -     Num examples = 269
01/03/2024 21:40:39 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 5s[Evaluating] 2/12 [====>.........................] - ETA: 6s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 586.8ms/step
01/03/2024 21:40:46 - INFO - root -   

01/03/2024 21:40:46 - INFO - root -   ***** Eval results  *****
01/03/2024 21:40:46 - INFO - root -    acc: 0.6488 - recall: 0.7022 - f1: 0.6744 - loss: 5.8442 
01/03/2024 21:40:46 - INFO - root -   ***** Entity results  *****
01/03/2024 21:40:46 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 21:40:46 - INFO - root -    acc: 0.7679 - recall: 0.9149 - f1: 0.8350 
01/03/2024 21:40:46 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 21:40:46 - INFO - root -    acc: 1.0000 - recall: 1.0000 - f1: 1.0000 
01/03/2024 21:40:46 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 21:40:46 - INFO - root -    acc: 0.6923 - recall: 0.4737 - f1: 0.5625 
01/03/2024 21:40:46 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 21:40:46 - INFO - root -    acc: 0.3636 - recall: 0.4444 - f1: 0.4000 
01/03/2024 21:40:46 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 21:40:46 - INFO - root -    acc: 0.4516 - recall: 0.3590 - f1: 0.4000 
01/03/2024 21:40:46 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 21:40:46 - INFO - root -    acc: 0.8000 - recall: 0.4706 - f1: 0.5926 
01/03/2024 21:40:46 - INFO - root -   ******* PER.NAM results ********
01/03/2024 21:40:46 - INFO - root -    acc: 0.5985 - recall: 0.7455 - f1: 0.6640 
01/03/2024 21:40:46 - INFO - root -   ******* PER.NOM results ********
01/03/2024 21:40:46 - INFO - root -    acc: 0.6845 - recall: 0.7529 - f1: 0.7171 
01/03/2024 21:41:08 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1425
01/03/2024 21:41:08 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1425
01/03/2024 21:41:08 - INFO - root -   

01/03/2024 21:41:08 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 25/50
[Training] 1/57 [..............................] - ETA: 54s  [ loss=0.3954 ][Training] 2/57 [>.............................] - ETA: 59s  [ loss=1.0312 ][Training] 3/57 [>.............................] - ETA: 1:02  [ loss=0.7195 ][Training] 4/57 [=>............................] - ETA: 1:01  [ loss=0.5887 ][Training] 5/57 [=>............................] - ETA: 1:04  [ loss=1.3096 ][Training] 6/57 [==>...........................] - ETA: 1:02  [ loss=0.8408 ][Training] 7/57 [==>...........................] - ETA: 1:00  [ loss=0.6633 ][Training] 8/57 [===>..........................] - ETA: 1:01  [ loss=1.6451 ][Training] 9/57 [===>..........................] - ETA: 58s  [ loss=0.2816 ][Training] 10/57 [====>.........................] - ETA: 59s  [ loss=0.9422 ][Training] 11/57 [====>.........................] - ETA: 57s  [ loss=1.5152 ][Training] 12/57 [=====>........................] - ETA: 56s  [ loss=0.7190 ][Training] 13/57 [=====>........................] - ETA: 55s  [ loss=0.7563 ][Training] 14/57 [======>.......................] - ETA: 54s  [ loss=1.2777 ][Training] 15/57 [======>.......................] - ETA: 54s  [ loss=1.1176 ][Training] 16/57 [=======>......................] - ETA: 53s  [ loss=0.7624 ][Training] 17/57 [=======>......................] - ETA: 52s  [ loss=0.7559 ][Training] 18/57 [========>.....................] - ETA: 51s  [ loss=0.3232 ][Training] 19/57 [=========>....................] - ETA: 50s  [ loss=1.0928 ][Training] 20/57 [=========>....................] - ETA: 48s  [ loss=0.8763 ][Training] 21/57 [==========>...................] - ETA: 47s  [ loss=1.0371 ][Training] 22/57 [==========>...................] - ETA: 46s  [ loss=0.8339 ][Training] 23/57 [===========>..................] - ETA: 45s  [ loss=0.9097 ][Training] 24/57 [===========>..................] - ETA: 43s  [ loss=1.7502 ][Training] 25/57 [============>.................] - ETA: 42s  [ loss=0.5971 ][Training] 26/57 [============>.................] - ETA: 40s  [ loss=0.6459 ][Training] 27/57 [=============>................] - ETA: 40s  [ loss=0.9984 ][Training] 28/57 [=============>................] - ETA: 39s  [ loss=0.9913 ][Training] 29/57 [==============>...............] - ETA: 37s  [ loss=1.2901 ][Training] 30/57 [==============>...............] - ETA: 36s  [ loss=1.2671 ][Training] 31/57 [===============>..............] - ETA: 35s  [ loss=1.0867 ][Training] 32/57 [===============>..............] - ETA: 33s  [ loss=1.3279 ][Training] 33/57 [================>.............] - ETA: 32s  [ loss=0.6361 ][Training] 34/57 [================>.............] - ETA: 30s  [ loss=1.3177 ][Training] 35/57 [=================>............] - ETA: 29s  [ loss=1.6938 ][Training] 36/57 [=================>............] - ETA: 28s  [ loss=0.5118 ][Training] 37/57 [==================>...........] - ETA: 26s  [ loss=0.9477 ][Training] 38/57 [===================>..........] - ETA: 25s  [ loss=0.5731 ][Training] 39/57 [===================>..........] - ETA: 23s  [ loss=0.9473 ][Training] 40/57 [====================>.........] - ETA: 22s  [ loss=0.7463 ][Training] 41/57 [====================>.........] - ETA: 21s  [ loss=0.7911 ][Training] 42/57 [=====================>........] - ETA: 19s  [ loss=0.7353 ][Training] 43/57 [=====================>........] - ETA: 18s  [ loss=1.1641 ][Training] 44/57 [======================>.......] - ETA: 16s  [ loss=0.7861 ][Training] 45/57 [======================>.......] - ETA: 15s  [ loss=0.6277 ][Training] 46/57 [=======================>......] - ETA: 14s  [ loss=0.7950 ][Training] 47/57 [=======================>......] - ETA: 13s  [ loss=0.3644 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=0.9689 ][Training] 49/57 [========================>.....] - ETA: 10s  [ loss=1.3858 ][Training] 50/57 [=========================>....] - ETA: 9s  [ loss=0.9982 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=0.8172 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=0.8549 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=0.5067 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=2.4476 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=1.4650 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.9377 ][Training] 57/57 [==============================] 1.3s/step  [ loss=0.1564 ]
01/03/2024 21:42:21 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 21:42:22 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 21:42:22 - INFO - root -     Num examples = 269
01/03/2024 21:42:22 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 4s[Evaluating] 2/12 [====>.........................] - ETA: 4s[Evaluating] 3/12 [======>.......................] - ETA: 4s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 3s[Evaluating] 6/12 [==============>...............] - ETA: 2s[Evaluating] 7/12 [================>.............] - ETA: 2s[Evaluating] 8/12 [===================>..........] - ETA: 1s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 0s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 461.0ms/step
01/03/2024 21:42:27 - INFO - root -   

01/03/2024 21:42:27 - INFO - root -   ***** Eval results  *****
01/03/2024 21:42:27 - INFO - root -    acc: 0.6741 - recall: 0.6562 - f1: 0.6650 - loss: 5.7862 
01/03/2024 21:42:27 - INFO - root -   ***** Entity results  *****
01/03/2024 21:42:27 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 21:42:27 - INFO - root -    acc: 0.7818 - recall: 0.9149 - f1: 0.8431 
01/03/2024 21:42:27 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 21:42:27 - INFO - root -    acc: 1.0000 - recall: 1.0000 - f1: 1.0000 
01/03/2024 21:42:27 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 21:42:27 - INFO - root -    acc: 0.6923 - recall: 0.4737 - f1: 0.5625 
01/03/2024 21:42:27 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 21:42:27 - INFO - root -    acc: 0.3333 - recall: 0.2222 - f1: 0.2667 
01/03/2024 21:42:27 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 21:42:27 - INFO - root -    acc: 0.4412 - recall: 0.3846 - f1: 0.4110 
01/03/2024 21:42:27 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 21:42:27 - INFO - root -    acc: 1.0000 - recall: 0.4118 - f1: 0.5833 
01/03/2024 21:42:27 - INFO - root -   ******* PER.NAM results ********
01/03/2024 21:42:27 - INFO - root -    acc: 0.6220 - recall: 0.7182 - f1: 0.6667 
01/03/2024 21:42:27 - INFO - root -   ******* PER.NOM results ********
01/03/2024 21:42:27 - INFO - root -    acc: 0.7215 - recall: 0.6706 - f1: 0.6951 
01/03/2024 21:42:58 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1482
01/03/2024 21:42:58 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1482
01/03/2024 21:42:58 - INFO - root -   

01/03/2024 21:42:58 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 26/50
[Training] 1/57 [..............................] - ETA: 1:31  [ loss=1.9708 ][Training] 2/57 [>.............................] - ETA: 1:23  [ loss=1.2070 ][Training] 3/57 [>.............................] - ETA: 1:27  [ loss=2.1887 ][Training] 4/57 [=>............................] - ETA: 1:21  [ loss=0.4276 ][Training] 5/57 [=>............................] - ETA: 1:14  [ loss=0.7673 ][Training] 6/57 [==>...........................] - ETA: 1:12  [ loss=0.7580 ][Training] 7/57 [==>...........................] - ETA: 1:09  [ loss=0.2337 ][Training] 8/57 [===>..........................] - ETA: 1:07  [ loss=0.6597 ][Training] 9/57 [===>..........................] - ETA: 1:05  [ loss=0.5318 ][Training] 10/57 [====>.........................] - ETA: 1:03  [ loss=0.7293 ][Training] 11/57 [====>.........................] - ETA: 1:01  [ loss=0.4284 ][Training] 12/57 [=====>........................] - ETA: 59s  [ loss=0.6875 ][Training] 13/57 [=====>........................] - ETA: 58s  [ loss=1.3991 ][Training] 14/57 [======>.......................] - ETA: 56s  [ loss=1.3650 ][Training] 15/57 [======>.......................] - ETA: 55s  [ loss=0.5683 ][Training] 16/57 [=======>......................] - ETA: 52s  [ loss=0.7405 ][Training] 17/57 [=======>......................] - ETA: 52s  [ loss=0.8489 ][Training] 18/57 [========>.....................] - ETA: 50s  [ loss=0.5068 ][Training] 19/57 [=========>....................] - ETA: 48s  [ loss=0.9653 ][Training] 20/57 [=========>....................] - ETA: 47s  [ loss=0.7367 ][Training] 21/57 [==========>...................] - ETA: 45s  [ loss=0.7688 ][Training] 22/57 [==========>...................] - ETA: 44s  [ loss=0.5327 ][Training] 23/57 [===========>..................] - ETA: 42s  [ loss=0.5868 ][Training] 24/57 [===========>..................] - ETA: 42s  [ loss=1.0414 ][Training] 25/57 [============>.................] - ETA: 40s  [ loss=0.4329 ][Training] 26/57 [============>.................] - ETA: 39s  [ loss=1.5069 ][Training] 27/57 [=============>................] - ETA: 38s  [ loss=0.3253 ][Training] 28/57 [=============>................] - ETA: 37s  [ loss=1.1603 ][Training] 29/57 [==============>...............] - ETA: 36s  [ loss=1.2941 ][Training] 30/57 [==============>...............] - ETA: 34s  [ loss=0.7357 ][Training] 31/57 [===============>..............] - ETA: 33s  [ loss=0.6318 ][Training] 32/57 [===============>..............] - ETA: 32s  [ loss=0.9354 ][Training] 33/57 [================>.............] - ETA: 30s  [ loss=1.1708 ][Training] 34/57 [================>.............] - ETA: 29s  [ loss=0.8525 ][Training] 35/57 [=================>............] - ETA: 28s  [ loss=1.2143 ][Training] 36/57 [=================>............] - ETA: 26s  [ loss=0.9460 ][Training] 37/57 [==================>...........] - ETA: 25s  [ loss=1.0478 ][Training] 38/57 [===================>..........] - ETA: 24s  [ loss=0.6858 ][Training] 39/57 [===================>..........] - ETA: 22s  [ loss=0.6894 ][Training] 40/57 [====================>.........] - ETA: 21s  [ loss=0.9602 ][Training] 41/57 [====================>.........] - ETA: 20s  [ loss=0.7763 ][Training] 42/57 [=====================>........] - ETA: 19s  [ loss=0.8009 ][Training] 43/57 [=====================>........] - ETA: 17s  [ loss=0.9352 ][Training] 44/57 [======================>.......] - ETA: 16s  [ loss=0.9826 ][Training] 45/57 [======================>.......] - ETA: 15s  [ loss=0.6689 ][Training] 46/57 [=======================>......] - ETA: 13s  [ loss=1.7723 ][Training] 47/57 [=======================>......] - ETA: 12s  [ loss=0.5658 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=1.0041 ][Training] 49/57 [========================>.....] - ETA: 10s  [ loss=0.7275 ][Training] 50/57 [=========================>....] - ETA: 8s  [ loss=1.4402 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=0.9941 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=1.3064 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=0.9689 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=1.2449 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=1.1180 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=1.0120 ][Training] 57/57 [==============================] 1.3s/step  [ loss=0.4300 ]
01/03/2024 21:44:11 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 21:44:11 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 21:44:11 - INFO - root -     Num examples = 269
01/03/2024 21:44:11 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 6s[Evaluating] 2/12 [====>.........................] - ETA: 5s[Evaluating] 3/12 [======>.......................] - ETA: 4s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 3s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 569.1ms/step
01/03/2024 21:44:18 - INFO - root -   

01/03/2024 21:44:18 - INFO - root -   ***** Eval results  *****
01/03/2024 21:44:18 - INFO - root -    acc: 0.6524 - recall: 0.6634 - f1: 0.6579 - loss: 6.0511 
01/03/2024 21:44:18 - INFO - root -   ***** Entity results  *****
01/03/2024 21:44:18 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 21:44:18 - INFO - root -    acc: 0.7500 - recall: 0.8936 - f1: 0.8155 
01/03/2024 21:44:18 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 21:44:18 - INFO - root -    acc: 1.0000 - recall: 0.5000 - f1: 0.6667 
01/03/2024 21:44:18 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 21:44:18 - INFO - root -    acc: 0.6154 - recall: 0.4211 - f1: 0.5000 
01/03/2024 21:44:18 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 21:44:18 - INFO - root -    acc: 0.3750 - recall: 0.3333 - f1: 0.3529 
01/03/2024 21:44:18 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 21:44:18 - INFO - root -    acc: 0.5909 - recall: 0.3333 - f1: 0.4262 
01/03/2024 21:44:18 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 21:44:18 - INFO - root -    acc: 0.7778 - recall: 0.4118 - f1: 0.5385 
01/03/2024 21:44:18 - INFO - root -   ******* PER.NAM results ********
01/03/2024 21:44:18 - INFO - root -    acc: 0.6000 - recall: 0.7091 - f1: 0.6500 
01/03/2024 21:44:18 - INFO - root -   ******* PER.NOM results ********
01/03/2024 21:44:18 - INFO - root -    acc: 0.6740 - recall: 0.7176 - f1: 0.6952 
01/03/2024 21:44:27 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1539
01/03/2024 21:44:27 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1539
01/03/2024 21:44:27 - INFO - root -   

01/03/2024 21:44:27 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 27/50
[Training] 1/57 [..............................] - ETA: 1:12  [ loss=0.7645 ][Training] 2/57 [>.............................] - ETA: 1:22  [ loss=0.8357 ][Training] 3/57 [>.............................] - ETA: 1:14  [ loss=0.6934 ][Training] 4/57 [=>............................] - ETA: 1:11  [ loss=0.7299 ][Training] 5/57 [=>............................] - ETA: 1:09  [ loss=0.6178 ][Training] 6/57 [==>...........................] - ETA: 1:09  [ loss=0.5402 ][Training] 7/57 [==>...........................] - ETA: 1:08  [ loss=0.4229 ][Training] 8/57 [===>..........................] - ETA: 1:08  [ loss=1.1704 ][Training] 9/57 [===>..........................] - ETA: 1:07  [ loss=1.4951 ][Training] 10/57 [====>.........................] - ETA: 1:04  [ loss=0.6316 ][Training] 11/57 [====>.........................] - ETA: 1:02  [ loss=0.6730 ][Training] 12/57 [=====>........................] - ETA: 1:00  [ loss=0.4289 ][Training] 13/57 [=====>........................] - ETA: 59s  [ loss=0.7154 ][Training] 14/57 [======>.......................] - ETA: 57s  [ loss=0.8556 ][Training] 15/57 [======>.......................] - ETA: 55s  [ loss=0.8019 ][Training] 16/57 [=======>......................] - ETA: 54s  [ loss=0.9521 ][Training] 17/57 [=======>......................] - ETA: 52s  [ loss=1.8500 ][Training] 18/57 [========>.....................] - ETA: 50s  [ loss=0.6681 ][Training] 19/57 [=========>....................] - ETA: 48s  [ loss=0.3999 ][Training] 20/57 [=========>....................] - ETA: 48s  [ loss=1.0415 ][Training] 21/57 [==========>...................] - ETA: 47s  [ loss=0.9404 ][Training] 22/57 [==========>...................] - ETA: 45s  [ loss=0.5684 ][Training] 23/57 [===========>..................] - ETA: 44s  [ loss=0.4799 ][Training] 24/57 [===========>..................] - ETA: 43s  [ loss=1.5061 ][Training] 25/57 [============>.................] - ETA: 41s  [ loss=0.7590 ][Training] 26/57 [============>.................] - ETA: 40s  [ loss=0.5600 ][Training] 27/57 [=============>................] - ETA: 38s  [ loss=1.2358 ][Training] 28/57 [=============>................] - ETA: 37s  [ loss=0.5695 ][Training] 29/57 [==============>...............] - ETA: 36s  [ loss=0.9478 ][Training] 30/57 [==============>...............] - ETA: 35s  [ loss=0.8307 ][Training] 31/57 [===============>..............] - ETA: 33s  [ loss=1.2381 ][Training] 32/57 [===============>..............] - ETA: 32s  [ loss=0.5278 ][Training] 33/57 [================>.............] - ETA: 31s  [ loss=0.3602 ][Training] 34/57 [================>.............] - ETA: 30s  [ loss=1.0261 ][Training] 35/57 [=================>............] - ETA: 28s  [ loss=1.1899 ][Training] 36/57 [=================>............] - ETA: 27s  [ loss=0.4701 ][Training] 37/57 [==================>...........] - ETA: 26s  [ loss=0.8128 ][Training] 38/57 [===================>..........] - ETA: 24s  [ loss=0.4842 ][Training] 39/57 [===================>..........] - ETA: 23s  [ loss=0.5898 ][Training] 40/57 [====================>.........] - ETA: 22s  [ loss=0.9573 ][Training] 41/57 [====================>.........] - ETA: 21s  [ loss=1.7975 ][Training] 42/57 [=====================>........] - ETA: 19s  [ loss=1.4201 ][Training] 43/57 [=====================>........] - ETA: 18s  [ loss=0.8592 ][Training] 44/57 [======================>.......] - ETA: 17s  [ loss=1.6115 ][Training] 45/57 [======================>.......] - ETA: 15s  [ loss=0.7597 ][Training] 46/57 [=======================>......] - ETA: 14s  [ loss=1.0883 ][Training] 47/57 [=======================>......] - ETA: 13s  [ loss=1.5684 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=0.5310 ][Training] 49/57 [========================>.....] - ETA: 10s  [ loss=1.7253 ][Training] 50/57 [=========================>....] - ETA: 9s  [ loss=0.4252 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=1.6430 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=0.5580 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=0.4345 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=0.9799 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=1.2366 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=2.1900 ][Training] 57/57 [==============================] 1.3s/step  [ loss=1.8183 ]
01/03/2024 21:45:40 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 21:45:41 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 21:45:41 - INFO - root -     Num examples = 269
01/03/2024 21:45:41 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 7s[Evaluating] 2/12 [====>.........................] - ETA: 7s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 592.2ms/step
01/03/2024 21:45:48 - INFO - root -   

01/03/2024 21:45:48 - INFO - root -   ***** Eval results  *****
01/03/2024 21:45:48 - INFO - root -    acc: 0.7051 - recall: 0.6368 - f1: 0.6692 - loss: 5.9983 
01/03/2024 21:45:48 - INFO - root -   ***** Entity results  *****
01/03/2024 21:45:48 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 21:45:48 - INFO - root -    acc: 0.7547 - recall: 0.8511 - f1: 0.8000 
01/03/2024 21:45:48 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 21:45:48 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 21:45:48 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 21:45:48 - INFO - root -    acc: 0.5714 - recall: 0.4211 - f1: 0.4848 
01/03/2024 21:45:48 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 21:45:48 - INFO - root -    acc: 0.2857 - recall: 0.2222 - f1: 0.2500 
01/03/2024 21:45:48 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 21:45:48 - INFO - root -    acc: 0.5909 - recall: 0.3333 - f1: 0.4262 
01/03/2024 21:45:48 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 21:45:48 - INFO - root -    acc: 0.7778 - recall: 0.4118 - f1: 0.5385 
01/03/2024 21:45:48 - INFO - root -   ******* PER.NAM results ********
01/03/2024 21:45:48 - INFO - root -    acc: 0.7374 - recall: 0.6636 - f1: 0.6986 
01/03/2024 21:45:48 - INFO - root -   ******* PER.NOM results ********
01/03/2024 21:45:48 - INFO - root -    acc: 0.7101 - recall: 0.7059 - f1: 0.7080 
01/03/2024 21:45:56 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1596
01/03/2024 21:45:56 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1596
01/03/2024 21:45:56 - INFO - root -   

01/03/2024 21:45:56 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 28/50
[Training] 1/57 [..............................] - ETA: 1:09  [ loss=3.3737 ][Training] 2/57 [>.............................] - ETA: 1:15  [ loss=0.9009 ][Training] 3/57 [>.............................] - ETA: 1:13  [ loss=0.8016 ][Training] 4/57 [=>............................] - ETA: 1:08  [ loss=0.4724 ][Training] 5/57 [=>............................] - ETA: 1:07  [ loss=0.8211 ][Training] 6/57 [==>...........................] - ETA: 1:05  [ loss=0.6612 ][Training] 7/57 [==>...........................] - ETA: 1:07  [ loss=1.4732 ][Training] 8/57 [===>..........................] - ETA: 1:04  [ loss=0.9460 ][Training] 9/57 [===>..........................] - ETA: 1:04  [ loss=0.8291 ][Training] 10/57 [====>.........................] - ETA: 1:00  [ loss=0.2860 ][Training] 11/57 [====>.........................] - ETA: 1:00  [ loss=1.0526 ][Training] 12/57 [=====>........................] - ETA: 58s  [ loss=0.7977 ][Training] 13/57 [=====>........................] - ETA: 56s  [ loss=0.2795 ][Training] 14/57 [======>.......................] - ETA: 55s  [ loss=0.4427 ][Training] 15/57 [======>.......................] - ETA: 54s  [ loss=0.3061 ][Training] 16/57 [=======>......................] - ETA: 53s  [ loss=0.9057 ][Training] 17/57 [=======>......................] - ETA: 51s  [ loss=0.5578 ][Training] 18/57 [========>.....................] - ETA: 50s  [ loss=0.7108 ][Training] 19/57 [=========>....................] - ETA: 49s  [ loss=1.2250 ][Training] 20/57 [=========>....................] - ETA: 47s  [ loss=1.3484 ][Training] 21/57 [==========>...................] - ETA: 46s  [ loss=0.8173 ][Training] 22/57 [==========>...................] - ETA: 44s  [ loss=0.5839 ][Training] 23/57 [===========>..................] - ETA: 43s  [ loss=0.7391 ][Training] 24/57 [===========>..................] - ETA: 42s  [ loss=0.4425 ][Training] 25/57 [============>.................] - ETA: 40s  [ loss=0.8101 ][Training] 26/57 [============>.................] - ETA: 39s  [ loss=0.4144 ][Training] 27/57 [=============>................] - ETA: 38s  [ loss=0.5279 ][Training] 28/57 [=============>................] - ETA: 36s  [ loss=0.6540 ][Training] 29/57 [==============>...............] - ETA: 35s  [ loss=1.0752 ][Training] 30/57 [==============>...............] - ETA: 34s  [ loss=0.3065 ][Training] 31/57 [===============>..............] - ETA: 32s  [ loss=0.5903 ][Training] 32/57 [===============>..............] - ETA: 31s  [ loss=0.6425 ][Training] 33/57 [================>.............] - ETA: 30s  [ loss=1.3682 ][Training] 34/57 [================>.............] - ETA: 29s  [ loss=0.8801 ][Training] 35/57 [=================>............] - ETA: 27s  [ loss=0.6089 ][Training] 36/57 [=================>............] - ETA: 26s  [ loss=0.4745 ][Training] 37/57 [==================>...........] - ETA: 25s  [ loss=0.6935 ][Training] 38/57 [===================>..........] - ETA: 24s  [ loss=0.9673 ][Training] 39/57 [===================>..........] - ETA: 22s  [ loss=0.7601 ][Training] 40/57 [====================>.........] - ETA: 21s  [ loss=0.8730 ][Training] 41/57 [====================>.........] - ETA: 20s  [ loss=0.4955 ][Training] 42/57 [=====================>........] - ETA: 18s  [ loss=0.8235 ][Training] 43/57 [=====================>........] - ETA: 17s  [ loss=0.7988 ][Training] 44/57 [======================>.......] - ETA: 16s  [ loss=0.7674 ][Training] 45/57 [======================>.......] - ETA: 15s  [ loss=0.9378 ][Training] 46/57 [=======================>......] - ETA: 13s  [ loss=0.8844 ][Training] 47/57 [=======================>......] - ETA: 12s  [ loss=0.9500 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=1.5816 ][Training] 49/57 [========================>.....] - ETA: 10s  [ loss=0.4351 ][Training] 50/57 [=========================>....] - ETA: 8s  [ loss=1.5489 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=0.8455 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=0.8534 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=1.0428 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=0.8367 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=0.8403 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.9753 ][Training] 57/57 [==============================] 1.3s/step  [ loss=0.3723 ]
01/03/2024 21:47:10 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 21:47:10 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 21:47:10 - INFO - root -     Num examples = 269
01/03/2024 21:47:10 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 5s[Evaluating] 2/12 [====>.........................] - ETA: 5s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 3s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 2s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 515.1ms/step
01/03/2024 21:47:16 - INFO - root -   

01/03/2024 21:47:16 - INFO - root -   ***** Eval results  *****
01/03/2024 21:47:16 - INFO - root -    acc: 0.6651 - recall: 0.6731 - f1: 0.6691 - loss: 5.9022 
01/03/2024 21:47:16 - INFO - root -   ***** Entity results  *****
01/03/2024 21:47:16 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 21:47:16 - INFO - root -    acc: 0.7818 - recall: 0.9149 - f1: 0.8431 
01/03/2024 21:47:16 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 21:47:16 - INFO - root -    acc: 1.0000 - recall: 1.0000 - f1: 1.0000 
01/03/2024 21:47:16 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 21:47:16 - INFO - root -    acc: 0.6667 - recall: 0.4211 - f1: 0.5161 
01/03/2024 21:47:16 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 21:47:16 - INFO - root -    acc: 0.3333 - recall: 0.3333 - f1: 0.3333 
01/03/2024 21:47:16 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 21:47:16 - INFO - root -    acc: 0.4828 - recall: 0.3590 - f1: 0.4118 
01/03/2024 21:47:16 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 21:47:16 - INFO - root -    acc: 0.8000 - recall: 0.4706 - f1: 0.5926 
01/03/2024 21:47:16 - INFO - root -   ******* PER.NAM results ********
01/03/2024 21:47:16 - INFO - root -    acc: 0.6250 - recall: 0.6818 - f1: 0.6522 
01/03/2024 21:47:16 - INFO - root -   ******* PER.NOM results ********
01/03/2024 21:47:16 - INFO - root -    acc: 0.6906 - recall: 0.7353 - f1: 0.7123 
01/03/2024 21:47:39 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1653
01/03/2024 21:47:39 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1653
01/03/2024 21:47:39 - INFO - root -   

01/03/2024 21:47:39 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 29/50
[Training] 1/57 [..............................] - ETA: 58s  [ loss=0.6281 ][Training] 2/57 [>.............................] - ETA: 57s  [ loss=0.5927 ][Training] 3/57 [>.............................] - ETA: 56s  [ loss=0.7810 ][Training] 4/57 [=>............................] - ETA: 58s  [ loss=1.1683 ][Training] 5/57 [=>............................] - ETA: 1:00  [ loss=0.4835 ][Training] 6/57 [==>...........................] - ETA: 59s  [ loss=0.6864 ][Training] 7/57 [==>...........................] - ETA: 59s  [ loss=0.8216 ][Training] 8/57 [===>..........................] - ETA: 58s  [ loss=0.5110 ][Training] 9/57 [===>..........................] - ETA: 58s  [ loss=0.8092 ][Training] 10/57 [====>.........................] - ETA: 59s  [ loss=0.6189 ][Training] 11/57 [====>.........................] - ETA: 57s  [ loss=0.9672 ][Training] 12/57 [=====>........................] - ETA: 56s  [ loss=0.5798 ][Training] 13/57 [=====>........................] - ETA: 55s  [ loss=0.3681 ][Training] 14/57 [======>.......................] - ETA: 54s  [ loss=0.7089 ][Training] 15/57 [======>.......................] - ETA: 52s  [ loss=0.4966 ][Training] 16/57 [=======>......................] - ETA: 50s  [ loss=0.4443 ][Training] 17/57 [=======>......................] - ETA: 50s  [ loss=0.7180 ][Training] 18/57 [========>.....................] - ETA: 48s  [ loss=0.4854 ][Training] 19/57 [=========>....................] - ETA: 47s  [ loss=0.7887 ][Training] 20/57 [=========>....................] - ETA: 46s  [ loss=0.2967 ][Training] 21/57 [==========>...................] - ETA: 45s  [ loss=0.9299 ][Training] 22/57 [==========>...................] - ETA: 44s  [ loss=0.9427 ][Training] 23/57 [===========>..................] - ETA: 43s  [ loss=1.1484 ][Training] 24/57 [===========>..................] - ETA: 42s  [ loss=1.3316 ][Training] 25/57 [============>.................] - ETA: 41s  [ loss=0.8010 ][Training] 26/57 [============>.................] - ETA: 40s  [ loss=0.3719 ][Training] 27/57 [=============>................] - ETA: 38s  [ loss=0.6865 ][Training] 28/57 [=============>................] - ETA: 37s  [ loss=1.0431 ][Training] 29/57 [==============>...............] - ETA: 36s  [ loss=1.5506 ][Training] 30/57 [==============>...............] - ETA: 35s  [ loss=0.7256 ][Training] 31/57 [===============>..............] - ETA: 33s  [ loss=0.5769 ][Training] 32/57 [===============>..............] - ETA: 32s  [ loss=1.2725 ][Training] 33/57 [================>.............] - ETA: 30s  [ loss=0.2529 ][Training] 34/57 [================>.............] - ETA: 29s  [ loss=0.7033 ][Training] 35/57 [=================>............] - ETA: 28s  [ loss=0.3302 ][Training] 36/57 [=================>............] - ETA: 26s  [ loss=1.0165 ][Training] 37/57 [==================>...........] - ETA: 25s  [ loss=0.5517 ][Training] 38/57 [===================>..........] - ETA: 24s  [ loss=1.1640 ][Training] 39/57 [===================>..........] - ETA: 23s  [ loss=0.9855 ][Training] 40/57 [====================>.........] - ETA: 21s  [ loss=1.1579 ][Training] 41/57 [====================>.........] - ETA: 20s  [ loss=0.8972 ][Training] 42/57 [=====================>........] - ETA: 19s  [ loss=1.0142 ][Training] 43/57 [=====================>........] - ETA: 17s  [ loss=0.6273 ][Training] 44/57 [======================>.......] - ETA: 16s  [ loss=0.9213 ][Training] 45/57 [======================>.......] - ETA: 15s  [ loss=0.8843 ][Training] 46/57 [=======================>......] - ETA: 14s  [ loss=0.9780 ][Training] 47/57 [=======================>......] - ETA: 12s  [ loss=0.6692 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=0.9934 ][Training] 49/57 [========================>.....] - ETA: 10s  [ loss=0.5820 ][Training] 50/57 [=========================>....] - ETA: 9s  [ loss=0.4607 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=0.3864 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=0.4057 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=0.4235 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=0.7589 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=0.9632 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.6955 ][Training] 57/57 [==============================] 1.3s/step  [ loss=5.3092 ]
01/03/2024 21:48:51 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 21:48:52 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 21:48:52 - INFO - root -     Num examples = 269
01/03/2024 21:48:52 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 5s[Evaluating] 2/12 [====>.........................] - ETA: 6s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 605.8ms/step
01/03/2024 21:48:59 - INFO - root -   

01/03/2024 21:48:59 - INFO - root -   ***** Eval results  *****
01/03/2024 21:48:59 - INFO - root -    acc: 0.7029 - recall: 0.6416 - f1: 0.6709 - loss: 5.7502 
01/03/2024 21:48:59 - INFO - root -   ***** Entity results  *****
01/03/2024 21:48:59 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 21:48:59 - INFO - root -    acc: 0.7818 - recall: 0.9149 - f1: 0.8431 
01/03/2024 21:48:59 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 21:48:59 - INFO - root -    acc: 1.0000 - recall: 0.5000 - f1: 0.6667 
01/03/2024 21:48:59 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 21:48:59 - INFO - root -    acc: 0.6667 - recall: 0.4211 - f1: 0.5161 
01/03/2024 21:48:59 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 21:48:59 - INFO - root -    acc: 0.2500 - recall: 0.2222 - f1: 0.2353 
01/03/2024 21:48:59 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 21:48:59 - INFO - root -    acc: 0.4444 - recall: 0.3077 - f1: 0.3636 
01/03/2024 21:48:59 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 21:48:59 - INFO - root -    acc: 0.8000 - recall: 0.4706 - f1: 0.5926 
01/03/2024 21:48:59 - INFO - root -   ******* PER.NAM results ********
01/03/2024 21:48:59 - INFO - root -    acc: 0.7426 - recall: 0.6818 - f1: 0.7109 
01/03/2024 21:48:59 - INFO - root -   ******* PER.NOM results ********
01/03/2024 21:48:59 - INFO - root -    acc: 0.7117 - recall: 0.6824 - f1: 0.6967 
01/03/2024 21:49:18 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1710
01/03/2024 21:49:18 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1710
01/03/2024 21:49:18 - INFO - root -   

01/03/2024 21:49:18 - INFO - root -   Backbone bert_estor_crf param is not freeze

Epoch: 30/50
[Training] 1/57 [..............................] - ETA: 1:57  [ loss=0.6581 ][Training] 2/57 [>.............................] - ETA: 1:39  [ loss=0.4614 ][Training] 3/57 [>.............................] - ETA: 1:33  [ loss=0.4965 ][Training] 4/57 [=>............................] - ETA: 1:33  [ loss=0.8130 ][Training] 5/57 [=>............................] - ETA: 1:32  [ loss=0.6759 ][Training] 6/57 [==>...........................] - ETA: 1:30  [ loss=0.6394 ][Training] 7/57 [==>...........................] - ETA: 1:28  [ loss=0.5136 ][Training] 8/57 [===>..........................] - ETA: 1:27  [ loss=0.4341 ][Training] 9/57 [===>..........................] - ETA: 1:25  [ loss=0.7939 ][Training] 10/57 [====>.........................] - ETA: 1:23  [ loss=0.3363 ][Training] 11/57 [====>.........................] - ETA: 1:22  [ loss=0.8216 ][Training] 12/57 [=====>........................] - ETA: 1:20  [ loss=1.0090 ][Training] 13/57 [=====>........................] - ETA: 1:19  [ loss=0.6188 ][Training] 14/57 [======>.......................] - ETA: 1:17  [ loss=0.3502 ][Training] 15/57 [======>.......................] - ETA: 1:16  [ loss=0.8588 ][Training] 16/57 [=======>......................] - ETA: 1:14  [ loss=0.5609 ][Training] 17/57 [=======>......................] - ETA: 1:12  [ loss=0.3180 ][Training] 18/57 [========>.....................] - ETA: 1:10  [ loss=1.1996 ][Training] 19/57 [=========>....................] - ETA: 1:09  [ loss=0.5435 ][Training] 20/57 [=========>....................] - ETA: 1:07  [ loss=0.6672 ][Training] 21/57 [==========>...................] - ETA: 1:05  [ loss=0.5367 ][Training] 22/57 [==========>...................] - ETA: 1:03  [ loss=0.3431 ][Training] 23/57 [===========>..................] - ETA: 1:01  [ loss=1.0323 ][Training] 24/57 [===========>..................] - ETA: 1:00  [ loss=0.9606 ][Training] 25/57 [============>.................] - ETA: 58s  [ loss=0.4817 ][Training] 26/57 [============>.................] - ETA: 56s  [ loss=0.6658 ][Training] 27/57 [=============>................] - ETA: 55s  [ loss=0.3955 ][Training] 28/57 [=============>................] - ETA: 53s  [ loss=0.4285 ][Training] 29/57 [==============>...............] - ETA: 51s  [ loss=0.6024 ][Training] 30/57 [==============>...............] - ETA: 50s  [ loss=0.5876 ][Training] 31/57 [===============>..............] - ETA: 48s  [ loss=0.8342 ][Training] 32/57 [===============>..............] - ETA: 46s  [ loss=1.9218 ][Training] 33/57 [================>.............] - ETA: 44s  [ loss=1.1050 ][Training] 34/57 [================>.............] - ETA: 43s  [ loss=2.9784 ][Training] 35/57 [=================>............] - ETA: 41s  [ loss=0.8052 ][Training] 36/57 [=================>............] - ETA: 39s  [ loss=0.9103 ][Training] 37/57 [==================>...........] - ETA: 37s  [ loss=0.8836 ][Training] 38/57 [===================>..........] - ETA: 35s  [ loss=0.6684 ][Training] 39/57 [===================>..........] - ETA: 33s  [ loss=0.4188 ][Training] 40/57 [====================>.........] - ETA: 31s  [ loss=0.7290 ][Training] 41/57 [====================>.........] - ETA: 29s  [ loss=0.5709 ][Training] 42/57 [=====================>........] - ETA: 27s  [ loss=0.4590 ][Training] 43/57 [=====================>........] - ETA: 26s  [ loss=0.7729 ][Training] 44/57 [======================>.......] - ETA: 24s  [ loss=1.3069 ][Training] 45/57 [======================>.......] - ETA: 22s  [ loss=1.2586 ][Training] 46/57 [=======================>......] - ETA: 20s  [ loss=1.2713 ][Training] 47/57 [=======================>......] - ETA: 18s  [ loss=0.8631 ][Training] 48/57 [========================>.....] - ETA: 16s  [ loss=1.2215 ][Training] 49/57 [========================>.....] - ETA: 14s  [ loss=0.5348 ][Training] 50/57 [=========================>....] - ETA: 13s  [ loss=1.1976 ][Training] 51/57 [=========================>....] - ETA: 11s  [ loss=1.2279 ][Training] 52/57 [==========================>...] - ETA: 9s  [ loss=0.3941 ][Training] 53/57 [==========================>...] - ETA: 7s  [ loss=0.3894 ][Training] 54/57 [===========================>..] - ETA: 5s  [ loss=0.1899 ][Training] 55/57 [===========================>..] - ETA: 3s  [ loss=0.4219 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.8236 ][Training] 57/57 [==============================] 1.8s/step  [ loss=0.0707 ]
01/03/2024 21:51:03 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 21:51:03 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 21:51:03 - INFO - root -     Num examples = 269
01/03/2024 21:51:03 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 5s[Evaluating] 2/12 [====>.........................] - ETA: 5s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 590.2ms/step
01/03/2024 21:51:10 - INFO - root -   

01/03/2024 21:51:10 - INFO - root -   ***** Eval results  *****
01/03/2024 21:51:10 - INFO - root -    acc: 0.6851 - recall: 0.6586 - f1: 0.6716 - loss: 5.8773 
01/03/2024 21:51:10 - INFO - root -   ***** Entity results  *****
01/03/2024 21:51:10 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 21:51:10 - INFO - root -    acc: 0.7636 - recall: 0.8936 - f1: 0.8235 
01/03/2024 21:51:10 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 21:51:10 - INFO - root -    acc: 1.0000 - recall: 0.5000 - f1: 0.6667 
01/03/2024 21:51:10 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 21:51:10 - INFO - root -    acc: 0.6923 - recall: 0.4737 - f1: 0.5625 
01/03/2024 21:51:10 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 21:51:10 - INFO - root -    acc: 0.3333 - recall: 0.2222 - f1: 0.2667 
01/03/2024 21:51:10 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 21:51:10 - INFO - root -    acc: 0.5417 - recall: 0.3333 - f1: 0.4127 
01/03/2024 21:51:10 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 21:51:10 - INFO - root -    acc: 0.8750 - recall: 0.4118 - f1: 0.5600 
01/03/2024 21:51:10 - INFO - root -   ******* PER.NAM results ********
01/03/2024 21:51:10 - INFO - root -    acc: 0.6757 - recall: 0.6818 - f1: 0.6787 
01/03/2024 21:51:10 - INFO - root -   ******* PER.NOM results ********
01/03/2024 21:51:10 - INFO - root -    acc: 0.6872 - recall: 0.7235 - f1: 0.7049 
01/03/2024 21:51:20 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1767
01/03/2024 21:51:20 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1767
01/03/2024 21:51:20 - INFO - root -   

01/03/2024 21:51:20 - INFO - root -   Backbone bert_estor_crf param is not freeze

Epoch: 31/50
[Training] 1/57 [..............................] - ETA: 1:44  [ loss=0.4088 ][Training] 2/57 [>.............................] - ETA: 1:37  [ loss=0.4462 ][Training] 3/57 [>.............................] - ETA: 1:40  [ loss=0.4057 ][Training] 4/57 [=>............................] - ETA: 1:35  [ loss=0.8226 ][Training] 5/57 [=>............................] - ETA: 1:32  [ loss=0.7256 ][Training] 6/57 [==>...........................] - ETA: 1:31  [ loss=0.4756 ][Training] 7/57 [==>...........................] - ETA: 1:29  [ loss=0.5920 ][Training] 8/57 [===>..........................] - ETA: 1:29  [ loss=1.0262 ][Training] 9/57 [===>..........................] - ETA: 1:26  [ loss=0.4891 ][Training] 10/57 [====>.........................] - ETA: 1:25  [ loss=0.4793 ][Training] 11/57 [====>.........................] - ETA: 1:23  [ loss=0.1871 ][Training] 12/57 [=====>........................] - ETA: 1:20  [ loss=0.5116 ][Training] 13/57 [=====>........................] - ETA: 1:17  [ loss=0.7114 ][Training] 14/57 [======>.......................] - ETA: 1:16  [ loss=2.2504 ][Training] 15/57 [======>.......................] - ETA: 1:14  [ loss=0.4067 ][Training] 16/57 [=======>......................] - ETA: 1:13  [ loss=0.6765 ][Training] 17/57 [=======>......................] - ETA: 1:10  [ loss=0.6312 ][Training] 18/57 [========>.....................] - ETA: 1:09  [ loss=0.5992 ][Training] 19/57 [=========>....................] - ETA: 1:07  [ loss=0.4922 ][Training] 20/57 [=========>....................] - ETA: 1:06  [ loss=0.5143 ][Training] 21/57 [==========>...................] - ETA: 1:05  [ loss=0.8153 ][Training] 22/57 [==========>...................] - ETA: 1:03  [ loss=0.6317 ][Training] 23/57 [===========>..................] - ETA: 1:01  [ loss=0.4334 ][Training] 24/57 [===========>..................] - ETA: 1:00  [ loss=0.9088 ][Training] 25/57 [============>.................] - ETA: 58s  [ loss=0.2681 ][Training] 26/57 [============>.................] - ETA: 56s  [ loss=1.0295 ][Training] 27/57 [=============>................] - ETA: 54s  [ loss=0.7609 ][Training] 28/57 [=============>................] - ETA: 53s  [ loss=0.9916 ][Training] 29/57 [==============>...............] - ETA: 51s  [ loss=1.9185 ][Training] 30/57 [==============>...............] - ETA: 49s  [ loss=1.3650 ][Training] 31/57 [===============>..............] - ETA: 47s  [ loss=0.5098 ][Training] 32/57 [===============>..............] - ETA: 45s  [ loss=0.4824 ][Training] 33/57 [================>.............] - ETA: 43s  [ loss=0.9587 ][Training] 34/57 [================>.............] - ETA: 41s  [ loss=0.2085 ][Training] 35/57 [=================>............] - ETA: 40s  [ loss=1.1842 ][Training] 36/57 [=================>............] - ETA: 38s  [ loss=0.4841 ][Training] 37/57 [==================>...........] - ETA: 36s  [ loss=0.8711 ][Training] 38/57 [===================>..........] - ETA: 34s  [ loss=0.7905 ][Training] 39/57 [===================>..........] - ETA: 32s  [ loss=0.7388 ][Training] 40/57 [====================>.........] - ETA: 31s  [ loss=1.0536 ][Training] 41/57 [====================>.........] - ETA: 29s  [ loss=2.2111 ][Training] 42/57 [=====================>........] - ETA: 27s  [ loss=0.9424 ][Training] 43/57 [=====================>........] - ETA: 25s  [ loss=2.1074 ][Training] 44/57 [======================>.......] - ETA: 23s  [ loss=1.4781 ][Training] 45/57 [======================>.......] - ETA: 21s  [ loss=0.7869 ][Training] 46/57 [=======================>......] - ETA: 20s  [ loss=0.4765 ][Training] 47/57 [=======================>......] - ETA: 18s  [ loss=0.8337 ][Training] 48/57 [========================>.....] - ETA: 16s  [ loss=1.6375 ][Training] 49/57 [========================>.....] - ETA: 14s  [ loss=0.8797 ][Training] 50/57 [=========================>....] - ETA: 12s  [ loss=1.4532 ][Training] 51/57 [=========================>....] - ETA: 11s  [ loss=1.3974 ][Training] 52/57 [==========================>...] - ETA: 9s  [ loss=2.4064 ][Training] 53/57 [==========================>...] - ETA: 7s  [ loss=0.4264 ][Training] 54/57 [===========================>..] - ETA: 5s  [ loss=2.2231 ][Training] 55/57 [===========================>..] - ETA: 3s  [ loss=2.1829 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=1.6517 ][Training] 57/57 [==============================] 1.8s/step  [ loss=3.8735 ]
01/03/2024 21:53:03 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 21:53:04 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 21:53:04 - INFO - root -     Num examples = 269
01/03/2024 21:53:04 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 5s[Evaluating] 2/12 [====>.........................] - ETA: 5s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 616.8ms/step
01/03/2024 21:53:11 - INFO - root -   

01/03/2024 21:53:11 - INFO - root -   ***** Eval results  *****
01/03/2024 21:53:11 - INFO - root -    acc: 0.6987 - recall: 0.6513 - f1: 0.6742 - loss: 6.0767 
01/03/2024 21:53:11 - INFO - root -   ***** Entity results  *****
01/03/2024 21:53:11 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 21:53:11 - INFO - root -    acc: 0.8269 - recall: 0.9149 - f1: 0.8687 
01/03/2024 21:53:11 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 21:53:11 - INFO - root -    acc: 1.0000 - recall: 0.5000 - f1: 0.6667 
01/03/2024 21:53:11 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 21:53:11 - INFO - root -    acc: 0.6429 - recall: 0.4737 - f1: 0.5455 
01/03/2024 21:53:11 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 21:53:11 - INFO - root -    acc: 0.3333 - recall: 0.3333 - f1: 0.3333 
01/03/2024 21:53:11 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 21:53:11 - INFO - root -    acc: 0.4000 - recall: 0.4103 - f1: 0.4051 
01/03/2024 21:53:11 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 21:53:11 - INFO - root -    acc: 0.7500 - recall: 0.3529 - f1: 0.4800 
01/03/2024 21:53:11 - INFO - root -   ******* PER.NAM results ********
01/03/2024 21:53:11 - INFO - root -    acc: 0.7103 - recall: 0.6909 - f1: 0.7005 
01/03/2024 21:53:11 - INFO - root -   ******* PER.NOM results ********
01/03/2024 21:53:11 - INFO - root -    acc: 0.7468 - recall: 0.6765 - f1: 0.7099 
01/03/2024 21:53:36 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1824
01/03/2024 21:53:36 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1824
01/03/2024 21:53:36 - INFO - root -   

01/03/2024 21:53:37 - INFO - root -   Backbone bert_estor_crf param is not freeze

Epoch: 32/50
[Training] 1/57 [..............................] - ETA: 1:51  [ loss=0.3340 ][Training] 2/57 [>.............................] - ETA: 1:38  [ loss=0.7176 ][Training] 3/57 [>.............................] - ETA: 1:44  [ loss=1.0935 ][Training] 4/57 [=>............................] - ETA: 1:44  [ loss=1.3498 ][Training] 5/57 [=>............................] - ETA: 1:39  [ loss=0.2341 ][Training] 6/57 [==>...........................] - ETA: 1:38  [ loss=1.3517 ][Training] 7/57 [==>...........................] - ETA: 1:37  [ loss=0.2478 ][Training] 8/57 [===>..........................] - ETA: 1:35  [ loss=3.2961 ][Training] 9/57 [===>..........................] - ETA: 1:31  [ loss=1.8854 ][Training] 10/57 [====>.........................] - ETA: 1:28  [ loss=2.1255 ][Training] 11/57 [====>.........................] - ETA: 1:26  [ loss=1.2844 ][Training] 12/57 [=====>........................] - ETA: 1:24  [ loss=0.2215 ][Training] 13/57 [=====>........................] - ETA: 1:22  [ loss=0.8054 ][Training] 14/57 [======>.......................] - ETA: 1:20  [ loss=0.4176 ][Training] 15/57 [======>.......................] - ETA: 1:17  [ loss=0.1852 ][Training] 16/57 [=======>......................] - ETA: 1:16  [ loss=0.5835 ][Training] 17/57 [=======>......................] - ETA: 1:14  [ loss=0.8846 ][Training] 18/57 [========>.....................] - ETA: 1:12  [ loss=0.6136 ][Training] 19/57 [=========>....................] - ETA: 1:11  [ loss=0.2958 ][Training] 20/57 [=========>....................] - ETA: 1:09  [ loss=0.9734 ][Training] 21/57 [==========>...................] - ETA: 1:07  [ loss=0.5876 ][Training] 22/57 [==========>...................] - ETA: 1:06  [ loss=1.0876 ][Training] 23/57 [===========>..................] - ETA: 1:04  [ loss=1.1500 ][Training] 24/57 [===========>..................] - ETA: 1:02  [ loss=0.4850 ][Training] 25/57 [============>.................] - ETA: 1:00  [ loss=0.7662 ][Training] 26/57 [============>.................] - ETA: 58s  [ loss=0.9337 ][Training] 27/57 [=============>................] - ETA: 56s  [ loss=2.3828 ][Training] 28/57 [=============>................] - ETA: 54s  [ loss=1.0392 ][Training] 29/57 [==============>...............] - ETA: 52s  [ loss=0.6618 ][Training] 30/57 [==============>...............] - ETA: 51s  [ loss=1.2602 ][Training] 31/57 [===============>..............] - ETA: 49s  [ loss=0.9912 ][Training] 32/57 [===============>..............] - ETA: 47s  [ loss=1.2359 ][Training] 33/57 [================>.............] - ETA: 45s  [ loss=0.4109 ][Training] 34/57 [================>.............] - ETA: 43s  [ loss=0.9643 ][Training] 35/57 [=================>............] - ETA: 41s  [ loss=1.1851 ][Training] 36/57 [=================>............] - ETA: 39s  [ loss=1.0787 ][Training] 37/57 [==================>...........] - ETA: 37s  [ loss=1.0034 ][Training] 38/57 [===================>..........] - ETA: 35s  [ loss=0.8966 ][Training] 39/57 [===================>..........] - ETA: 34s  [ loss=2.0521 ][Training] 40/57 [====================>.........] - ETA: 32s  [ loss=1.1733 ][Training] 41/57 [====================>.........] - ETA: 30s  [ loss=1.1960 ][Training] 42/57 [=====================>........] - ETA: 28s  [ loss=0.5312 ][Training] 43/57 [=====================>........] - ETA: 26s  [ loss=0.4837 ][Training] 44/57 [======================>.......] - ETA: 24s  [ loss=0.5028 ][Training] 45/57 [======================>.......] - ETA: 22s  [ loss=1.1826 ][Training] 46/57 [=======================>......] - ETA: 20s  [ loss=1.0126 ][Training] 47/57 [=======================>......] - ETA: 18s  [ loss=0.3835 ][Training] 48/57 [========================>.....] - ETA: 16s  [ loss=2.1110 ][Training] 49/57 [========================>.....] - ETA: 15s  [ loss=1.6571 ][Training] 50/57 [=========================>....] - ETA: 13s  [ loss=0.5677 ][Training] 51/57 [=========================>....] - ETA: 11s  [ loss=0.5429 ][Training] 52/57 [==========================>...] - ETA: 9s  [ loss=0.4809 ][Training] 53/57 [==========================>...] - ETA: 7s  [ loss=0.4130 ][Training] 54/57 [===========================>..] - ETA: 5s  [ loss=0.4263 ][Training] 55/57 [===========================>..] - ETA: 3s  [ loss=2.0817 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=1.4144 ][Training] 57/57 [==============================] 1.9s/step  [ loss=2.9166 ]
01/03/2024 21:55:23 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 21:55:24 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 21:55:24 - INFO - root -     Num examples = 269
01/03/2024 21:55:24 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 7s[Evaluating] 2/12 [====>.........................] - ETA: 6s[Evaluating] 3/12 [======>.......................] - ETA: 6s[Evaluating] 4/12 [=========>....................] - ETA: 5s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 595.9ms/step
01/03/2024 21:55:31 - INFO - root -   

01/03/2024 21:55:31 - INFO - root -   ***** Eval results  *****
01/03/2024 21:55:31 - INFO - root -    acc: 0.6949 - recall: 0.6562 - f1: 0.6750 - loss: 6.7652 
01/03/2024 21:55:31 - INFO - root -   ***** Entity results  *****
01/03/2024 21:55:31 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 21:55:31 - INFO - root -    acc: 0.8077 - recall: 0.8936 - f1: 0.8485 
01/03/2024 21:55:31 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 21:55:31 - INFO - root -    acc: 1.0000 - recall: 0.5000 - f1: 0.6667 
01/03/2024 21:55:31 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 21:55:31 - INFO - root -    acc: 0.5000 - recall: 0.3684 - f1: 0.4242 
01/03/2024 21:55:31 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 21:55:31 - INFO - root -    acc: 0.2500 - recall: 0.2222 - f1: 0.2353 
01/03/2024 21:55:31 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 21:55:31 - INFO - root -    acc: 0.4444 - recall: 0.4103 - f1: 0.4267 
01/03/2024 21:55:31 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 21:55:31 - INFO - root -    acc: 0.8750 - recall: 0.4118 - f1: 0.5600 
01/03/2024 21:55:31 - INFO - root -   ******* PER.NAM results ********
01/03/2024 21:55:31 - INFO - root -    acc: 0.7624 - recall: 0.7000 - f1: 0.7299 
01/03/2024 21:55:31 - INFO - root -   ******* PER.NOM results ********
01/03/2024 21:55:31 - INFO - root -    acc: 0.7000 - recall: 0.7000 - f1: 0.7000 
01/03/2024 21:55:47 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1881
01/03/2024 21:55:47 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1881
01/03/2024 21:55:47 - INFO - root -   

01/03/2024 21:55:48 - INFO - root -   Backbone bert_estor_crf param is not freeze

Epoch: 33/50
[Training] 1/57 [..............................] - ETA: 1:50  [ loss=0.2570 ][Training] 2/57 [>.............................] - ETA: 1:46  [ loss=0.1644 ][Training] 3/57 [>.............................] - ETA: 1:43  [ loss=0.5347 ][Training] 4/57 [=>............................] - ETA: 1:40  [ loss=0.6207 ][Training] 5/57 [=>............................] - ETA: 1:37  [ loss=0.4537 ][Training] 6/57 [==>...........................] - ETA: 1:41  [ loss=0.7101 ][Training] 7/57 [==>...........................] - ETA: 1:39  [ loss=2.1459 ][Training] 8/57 [===>..........................] - ETA: 1:32  [ loss=0.3973 ][Training] 9/57 [===>..........................] - ETA: 1:30  [ loss=0.2284 ][Training] 10/57 [====>.........................] - ETA: 1:27  [ loss=0.5184 ][Training] 11/57 [====>.........................] - ETA: 1:25  [ loss=0.4084 ][Training] 12/57 [=====>........................] - ETA: 1:24  [ loss=0.8150 ][Training] 13/57 [=====>........................] - ETA: 1:22  [ loss=0.7768 ][Training] 14/57 [======>.......................] - ETA: 1:19  [ loss=0.5486 ][Training] 15/57 [======>.......................] - ETA: 1:16  [ loss=0.4882 ][Training] 16/57 [=======>......................] - ETA: 1:15  [ loss=1.1852 ][Training] 17/57 [=======>......................] - ETA: 1:13  [ loss=0.9236 ][Training] 18/57 [========>.....................] - ETA: 1:11  [ loss=1.7052 ][Training] 19/57 [=========>....................] - ETA: 1:09  [ loss=0.2936 ][Training] 20/57 [=========>....................] - ETA: 1:08  [ loss=0.6487 ][Training] 21/57 [==========>...................] - ETA: 1:05  [ loss=1.1662 ][Training] 22/57 [==========>...................] - ETA: 1:03  [ loss=0.0887 ][Training] 23/57 [===========>..................] - ETA: 1:01  [ loss=0.8055 ][Training] 24/57 [===========>..................] - ETA: 1:00  [ loss=0.3372 ][Training] 25/57 [============>.................] - ETA: 58s  [ loss=1.5579 ][Training] 26/57 [============>.................] - ETA: 56s  [ loss=0.6824 ][Training] 27/57 [=============>................] - ETA: 54s  [ loss=0.7376 ][Training] 28/57 [=============>................] - ETA: 52s  [ loss=2.3234 ][Training] 29/57 [==============>...............] - ETA: 51s  [ loss=3.1574 ][Training] 30/57 [==============>...............] - ETA: 49s  [ loss=1.8106 ][Training] 31/57 [===============>..............] - ETA: 47s  [ loss=0.1361 ][Training] 32/57 [===============>..............] - ETA: 45s  [ loss=0.4481 ][Training] 33/57 [================>.............] - ETA: 43s  [ loss=0.9632 ][Training] 34/57 [================>.............] - ETA: 42s  [ loss=1.0912 ][Training] 35/57 [=================>............] - ETA: 40s  [ loss=1.2955 ][Training] 36/57 [=================>............] - ETA: 38s  [ loss=0.5845 ][Training] 37/57 [==================>...........] - ETA: 36s  [ loss=0.7222 ][Training] 38/57 [===================>..........] - ETA: 34s  [ loss=0.6334 ][Training] 39/57 [===================>..........] - ETA: 33s  [ loss=2.0619 ][Training] 40/57 [====================>.........] - ETA: 31s  [ loss=0.6186 ][Training] 41/57 [====================>.........] - ETA: 29s  [ loss=0.3346 ][Training] 42/57 [=====================>........] - ETA: 27s  [ loss=0.6243 ][Training] 43/57 [=====================>........] - ETA: 25s  [ loss=2.4508 ][Training] 44/57 [======================>.......] - ETA: 23s  [ loss=0.5044 ][Training] 45/57 [======================>.......] - ETA: 22s  [ loss=1.7020 ][Training] 46/57 [=======================>......] - ETA: 20s  [ loss=1.9281 ][Training] 47/57 [=======================>......] - ETA: 18s  [ loss=0.3082 ][Training] 48/57 [========================>.....] - ETA: 16s  [ loss=2.7553 ][Training] 49/57 [========================>.....] - ETA: 14s  [ loss=0.5833 ][Training] 50/57 [=========================>....] - ETA: 12s  [ loss=0.2728 ][Training] 51/57 [=========================>....] - ETA: 11s  [ loss=1.0807 ][Training] 52/57 [==========================>...] - ETA: 9s  [ loss=0.8214 ][Training] 53/57 [==========================>...] - ETA: 7s  [ loss=1.9241 ][Training] 54/57 [===========================>..] - ETA: 5s  [ loss=0.2349 ][Training] 55/57 [===========================>..] - ETA: 3s  [ loss=0.9222 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.4421 ][Training] 57/57 [==============================] 1.8s/step  [ loss=2.2037 ]
01/03/2024 21:57:32 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 21:57:32 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 21:57:32 - INFO - root -     Num examples = 269
01/03/2024 21:57:32 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 5s[Evaluating] 2/12 [====>.........................] - ETA: 6s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 578.7ms/step
01/03/2024 21:57:39 - INFO - root -   

01/03/2024 21:57:39 - INFO - root -   ***** Eval results  *****
01/03/2024 21:57:39 - INFO - root -    acc: 0.7143 - recall: 0.6538 - f1: 0.6827 - loss: 6.7110 
01/03/2024 21:57:39 - INFO - root -   ***** Entity results  *****
01/03/2024 21:57:39 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 21:57:39 - INFO - root -    acc: 0.7414 - recall: 0.9149 - f1: 0.8190 
01/03/2024 21:57:39 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 21:57:39 - INFO - root -    acc: 1.0000 - recall: 0.5000 - f1: 0.6667 
01/03/2024 21:57:39 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 21:57:39 - INFO - root -    acc: 0.6000 - recall: 0.3158 - f1: 0.4138 
01/03/2024 21:57:39 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 21:57:39 - INFO - root -    acc: 0.4000 - recall: 0.2222 - f1: 0.2857 
01/03/2024 21:57:39 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 21:57:39 - INFO - root -    acc: 0.4815 - recall: 0.3333 - f1: 0.3939 
01/03/2024 21:57:39 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 21:57:39 - INFO - root -    acc: 0.7000 - recall: 0.4118 - f1: 0.5185 
01/03/2024 21:57:39 - INFO - root -   ******* PER.NAM results ********
01/03/2024 21:57:39 - INFO - root -    acc: 0.7812 - recall: 0.6818 - f1: 0.7282 
01/03/2024 21:57:39 - INFO - root -   ******* PER.NOM results ********
01/03/2024 21:57:39 - INFO - root -    acc: 0.7193 - recall: 0.7235 - f1: 0.7214 
01/03/2024 21:57:48 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1938
01/03/2024 21:57:48 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1938
01/03/2024 21:57:48 - INFO - root -   

01/03/2024 21:57:48 - INFO - root -   Backbone bert_estor_crf param is not freeze

Epoch: 34/50
[Training] 1/57 [..............................] - ETA: 2:17  [ loss=0.9925 ][Training] 2/57 [>.............................] - ETA: 1:56  [ loss=0.3951 ][Training] 3/57 [>.............................] - ETA: 1:56  [ loss=1.2946 ][Training] 4/57 [=>............................] - ETA: 1:46  [ loss=0.1872 ][Training] 5/57 [=>............................] - ETA: 1:45  [ loss=1.1332 ][Training] 6/57 [==>...........................] - ETA: 1:42  [ loss=0.6096 ][Training] 7/57 [==>...........................] - ETA: 1:40  [ loss=0.2931 ][Training] 8/57 [===>..........................] - ETA: 1:37  [ loss=0.2432 ][Training] 9/57 [===>..........................] - ETA: 1:35  [ loss=0.2249 ][Training] 10/57 [====>.........................] - ETA: 1:35  [ loss=0.4995 ][Training] 11/57 [====>.........................] - ETA: 1:34  [ loss=0.2030 ][Training] 12/57 [=====>........................] - ETA: 1:30  [ loss=0.1657 ][Training] 13/57 [=====>........................] - ETA: 1:27  [ loss=0.1674 ][Training] 14/57 [======>.......................] - ETA: 1:23  [ loss=0.9583 ][Training] 15/57 [======>.......................] - ETA: 1:20  [ loss=0.3897 ][Training] 16/57 [=======>......................] - ETA: 1:17  [ loss=1.0919 ][Training] 17/57 [=======>......................] - ETA: 1:14  [ loss=0.3183 ][Training] 18/57 [========>.....................] - ETA: 1:11  [ loss=1.4810 ][Training] 19/57 [=========>....................] - ETA: 1:08  [ loss=0.3472 ][Training] 20/57 [=========>....................] - ETA: 1:06  [ loss=1.1425 ][Training] 21/57 [==========>...................] - ETA: 1:04  [ loss=0.6892 ][Training] 22/57 [==========>...................] - ETA: 1:02  [ loss=0.2997 ][Training] 23/57 [===========>..................] - ETA: 1:00  [ loss=0.8049 ][Training] 24/57 [===========>..................] - ETA: 59s  [ loss=1.4169 ][Training] 25/57 [============>.................] - ETA: 57s  [ loss=0.4606 ][Training] 26/57 [============>.................] - ETA: 54s  [ loss=0.5670 ][Training] 27/57 [=============>................] - ETA: 53s  [ loss=0.2717 ][Training] 28/57 [=============>................] - ETA: 51s  [ loss=0.2961 ][Training] 29/57 [==============>...............] - ETA: 49s  [ loss=0.1272 ][Training] 30/57 [==============>...............] - ETA: 47s  [ loss=0.3865 ][Training] 31/57 [===============>..............] - ETA: 45s  [ loss=0.6301 ][Training] 32/57 [===============>..............] - ETA: 44s  [ loss=0.7293 ][Training] 33/57 [================>.............] - ETA: 42s  [ loss=0.4837 ][Training] 34/57 [================>.............] - ETA: 40s  [ loss=0.2912 ][Training] 35/57 [=================>............] - ETA: 38s  [ loss=0.3466 ][Training] 36/57 [=================>............] - ETA: 37s  [ loss=1.2177 ][Training] 37/57 [==================>...........] - ETA: 35s  [ loss=0.2840 ][Training] 38/57 [===================>..........] - ETA: 33s  [ loss=0.3422 ][Training] 39/57 [===================>..........] - ETA: 32s  [ loss=1.2088 ][Training] 40/57 [====================>.........] - ETA: 30s  [ loss=0.2607 ][Training] 41/57 [====================>.........] - ETA: 28s  [ loss=1.7574 ][Training] 42/57 [=====================>........] - ETA: 26s  [ loss=0.8002 ][Training] 43/57 [=====================>........] - ETA: 25s  [ loss=0.6656 ][Training] 44/57 [======================>.......] - ETA: 23s  [ loss=1.5432 ][Training] 45/57 [======================>.......] - ETA: 21s  [ loss=0.3965 ][Training] 46/57 [=======================>......] - ETA: 19s  [ loss=0.2737 ][Training] 47/57 [=======================>......] - ETA: 17s  [ loss=0.3836 ][Training] 48/57 [========================>.....] - ETA: 16s  [ loss=0.8669 ][Training] 49/57 [========================>.....] - ETA: 14s  [ loss=0.3593 ][Training] 50/57 [=========================>....] - ETA: 12s  [ loss=0.9245 ][Training] 51/57 [=========================>....] - ETA: 10s  [ loss=0.5306 ][Training] 52/57 [==========================>...] - ETA: 8s  [ loss=0.8034 ][Training] 53/57 [==========================>...] - ETA: 7s  [ loss=2.0268 ][Training] 54/57 [===========================>..] - ETA: 5s  [ loss=2.4716 ][Training] 55/57 [===========================>..] - ETA: 3s  [ loss=0.7496 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.3174 ][Training] 57/57 [==============================] 1.8s/step  [ loss=1.2198 ]
01/03/2024 21:59:30 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 21:59:30 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 21:59:30 - INFO - root -     Num examples = 269
01/03/2024 21:59:30 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 5s[Evaluating] 2/12 [====>.........................] - ETA: 4s[Evaluating] 3/12 [======>.......................] - ETA: 4s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 2s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 549.2ms/step
01/03/2024 21:59:36 - INFO - root -   

01/03/2024 21:59:36 - INFO - root -   ***** Eval results  *****
01/03/2024 21:59:36 - INFO - root -    acc: 0.6706 - recall: 0.6852 - f1: 0.6778 - loss: 6.7738 
01/03/2024 21:59:36 - INFO - root -   ***** Entity results  *****
01/03/2024 21:59:36 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 21:59:36 - INFO - root -    acc: 0.6615 - recall: 0.9149 - f1: 0.7679 
01/03/2024 21:59:36 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 21:59:36 - INFO - root -    acc: 1.0000 - recall: 0.5000 - f1: 0.6667 
01/03/2024 21:59:36 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 21:59:36 - INFO - root -    acc: 0.6429 - recall: 0.4737 - f1: 0.5455 
01/03/2024 21:59:36 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 21:59:36 - INFO - root -    acc: 0.3333 - recall: 0.3333 - f1: 0.3333 
01/03/2024 21:59:36 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 21:59:36 - INFO - root -    acc: 0.5333 - recall: 0.4103 - f1: 0.4638 
01/03/2024 21:59:36 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 21:59:36 - INFO - root -    acc: 0.7000 - recall: 0.4118 - f1: 0.5185 
01/03/2024 21:59:36 - INFO - root -   ******* PER.NAM results ********
01/03/2024 21:59:36 - INFO - root -    acc: 0.7374 - recall: 0.6636 - f1: 0.6986 
01/03/2024 21:59:36 - INFO - root -   ******* PER.NOM results ********
01/03/2024 21:59:36 - INFO - root -    acc: 0.6753 - recall: 0.7706 - f1: 0.7198 
01/03/2024 21:59:59 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1995
01/03/2024 21:59:59 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1995
01/03/2024 21:59:59 - INFO - root -   

01/03/2024 21:59:59 - INFO - root -   Backbone bert_estor_crf param is not freeze

Epoch: 35/50
[Training] 1/57 [..............................] - ETA: 1:43  [ loss=0.7907 ][Training] 2/57 [>.............................] - ETA: 1:37  [ loss=1.0037 ][Training] 3/57 [>.............................] - ETA: 1:35  [ loss=0.4394 ][Training] 4/57 [=>............................] - ETA: 1:33  [ loss=0.4819 ][Training] 5/57 [=>............................] - ETA: 1:31  [ loss=0.1649 ][Training] 6/57 [==>...........................] - ETA: 1:29  [ loss=0.4994 ][Training] 7/57 [==>...........................] - ETA: 1:28  [ loss=0.1529 ][Training] 8/57 [===>..........................] - ETA: 1:29  [ loss=0.3344 ][Training] 9/57 [===>..........................] - ETA: 1:27  [ loss=0.2203 ][Training] 10/57 [====>.........................] - ETA: 1:25  [ loss=0.5620 ][Training] 11/57 [====>.........................] - ETA: 1:22  [ loss=0.2360 ][Training] 12/57 [=====>........................] - ETA: 1:21  [ loss=0.7270 ][Training] 13/57 [=====>........................] - ETA: 1:19  [ loss=0.2007 ][Training] 14/57 [======>.......................] - ETA: 1:17  [ loss=0.5246 ][Training] 15/57 [======>.......................] - ETA: 1:16  [ loss=0.6713 ][Training] 16/57 [=======>......................] - ETA: 1:13  [ loss=0.0764 ][Training] 17/57 [=======>......................] - ETA: 1:12  [ loss=1.0228 ][Training] 18/57 [========>.....................] - ETA: 1:10  [ loss=0.8818 ][Training] 19/57 [=========>....................] - ETA: 1:09  [ loss=0.4337 ][Training] 20/57 [=========>....................] - ETA: 1:08  [ loss=0.1371 ][Training] 21/57 [==========>...................] - ETA: 1:06  [ loss=0.2764 ][Training] 22/57 [==========>...................] - ETA: 1:04  [ loss=0.3584 ][Training] 23/57 [===========>..................] - ETA: 1:03  [ loss=0.9217 ][Training] 24/57 [===========>..................] - ETA: 1:01  [ loss=0.8567 ][Training] 25/57 [============>.................] - ETA: 58s  [ loss=0.4988 ][Training] 26/57 [============>.................] - ETA: 57s  [ loss=0.0783 ][Training] 27/57 [=============>................] - ETA: 54s  [ loss=0.1036 ][Training] 28/57 [=============>................] - ETA: 52s  [ loss=0.8612 ][Training] 29/57 [==============>...............] - ETA: 51s  [ loss=0.8205 ][Training] 30/57 [==============>...............] - ETA: 49s  [ loss=1.1647 ][Training] 31/57 [===============>..............] - ETA: 47s  [ loss=0.1074 ][Training] 32/57 [===============>..............] - ETA: 46s  [ loss=0.3866 ][Training] 33/57 [================>.............] - ETA: 44s  [ loss=0.1261 ][Training] 34/57 [================>.............] - ETA: 42s  [ loss=2.9702 ][Training] 35/57 [=================>............] - ETA: 40s  [ loss=0.3344 ][Training] 36/57 [=================>............] - ETA: 38s  [ loss=0.3932 ][Training] 37/57 [==================>...........] - ETA: 36s  [ loss=0.8738 ][Training] 38/57 [===================>..........] - ETA: 34s  [ loss=0.9719 ][Training] 39/57 [===================>..........] - ETA: 33s  [ loss=0.7119 ][Training] 40/57 [====================>.........] - ETA: 31s  [ loss=0.5802 ][Training] 41/57 [====================>.........] - ETA: 29s  [ loss=0.4348 ][Training] 42/57 [=====================>........] - ETA: 27s  [ loss=0.1399 ][Training] 43/57 [=====================>........] - ETA: 25s  [ loss=1.4898 ][Training] 44/57 [======================>.......] - ETA: 24s  [ loss=0.5940 ][Training] 45/57 [======================>.......] - ETA: 22s  [ loss=1.4017 ][Training] 46/57 [=======================>......] - ETA: 20s  [ loss=0.1330 ][Training] 47/57 [=======================>......] - ETA: 18s  [ loss=0.3477 ][Training] 48/57 [========================>.....] - ETA: 16s  [ loss=0.0660 ][Training] 49/57 [========================>.....] - ETA: 14s  [ loss=1.7138 ][Training] 50/57 [=========================>....] - ETA: 12s  [ loss=1.4000 ][Training] 51/57 [=========================>....] - ETA: 11s  [ loss=0.1073 ][Training] 52/57 [==========================>...] - ETA: 9s  [ loss=0.5764 ][Training] 53/57 [==========================>...] - ETA: 7s  [ loss=0.0884 ][Training] 54/57 [===========================>..] - ETA: 5s  [ loss=0.4930 ][Training] 55/57 [===========================>..] - ETA: 3s  [ loss=1.3158 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=1.8996 ][Training] 57/57 [==============================] 1.8s/step  [ loss=0.7095 ]
01/03/2024 22:01:43 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 22:01:43 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 22:01:43 - INFO - root -     Num examples = 269
01/03/2024 22:01:43 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 6s[Evaluating] 2/12 [====>.........................] - ETA: 5s[Evaluating] 3/12 [======>.......................] - ETA: 4s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 567.6ms/step
01/03/2024 22:01:50 - INFO - root -   

01/03/2024 22:01:50 - INFO - root -   ***** Eval results  *****
01/03/2024 22:01:50 - INFO - root -    acc: 0.7057 - recall: 0.6852 - f1: 0.6953 - loss: 6.6018 
01/03/2024 22:01:50 - INFO - root -   ***** Entity results  *****
01/03/2024 22:01:50 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 22:01:50 - INFO - root -    acc: 0.8235 - recall: 0.8936 - f1: 0.8571 
01/03/2024 22:01:50 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 22:01:50 - INFO - root -    acc: 1.0000 - recall: 0.5000 - f1: 0.6667 
01/03/2024 22:01:50 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 22:01:50 - INFO - root -    acc: 0.5833 - recall: 0.3684 - f1: 0.4516 
01/03/2024 22:01:50 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 22:01:50 - INFO - root -    acc: 0.3636 - recall: 0.4444 - f1: 0.4000 
01/03/2024 22:01:50 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 22:01:50 - INFO - root -    acc: 0.5143 - recall: 0.4615 - f1: 0.4865 
01/03/2024 22:01:50 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 22:01:50 - INFO - root -    acc: 0.8000 - recall: 0.4706 - f1: 0.5926 
01/03/2024 22:01:50 - INFO - root -   ******* PER.NAM results ********
01/03/2024 22:01:50 - INFO - root -    acc: 0.7596 - recall: 0.7182 - f1: 0.7383 
01/03/2024 22:01:50 - INFO - root -   ******* PER.NOM results ********
01/03/2024 22:01:50 - INFO - root -    acc: 0.7006 - recall: 0.7294 - f1: 0.7147 
01/03/2024 22:01:57 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2052
01/03/2024 22:01:57 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2052
01/03/2024 22:01:57 - INFO - root -   

01/03/2024 22:01:57 - INFO - root -   Backbone bert_estor_crf param is not freeze

Epoch: 36/50
[Training] 1/57 [..............................] - ETA: 1:28  [ loss=0.1989 ][Training] 2/57 [>.............................] - ETA: 1:42  [ loss=0.7070 ][Training] 3/57 [>.............................] - ETA: 1:36  [ loss=0.2119 ][Training] 4/57 [=>............................] - ETA: 1:35  [ loss=0.1066 ][Training] 5/57 [=>............................] - ETA: 1:33  [ loss=0.0859 ][Training] 6/57 [==>...........................] - ETA: 1:32  [ loss=0.1552 ][Training] 7/57 [==>...........................] - ETA: 1:32  [ loss=0.1651 ][Training] 8/57 [===>..........................] - ETA: 1:30  [ loss=0.1616 ][Training] 9/57 [===>..........................] - ETA: 1:29  [ loss=0.5283 ][Training] 10/57 [====>.........................] - ETA: 1:26  [ loss=0.0320 ][Training] 11/57 [====>.........................] - ETA: 1:25  [ loss=0.1771 ][Training] 12/57 [=====>........................] - ETA: 1:21  [ loss=0.2095 ][Training] 13/57 [=====>........................] - ETA: 1:20  [ loss=0.0878 ][Training] 14/57 [======>.......................] - ETA: 1:18  [ loss=0.1206 ][Training] 15/57 [======>.......................] - ETA: 1:15  [ loss=0.1366 ][Training] 16/57 [=======>......................] - ETA: 1:13  [ loss=0.0964 ][Training] 17/57 [=======>......................] - ETA: 1:11  [ loss=0.6241 ][Training] 18/57 [========>.....................] - ETA: 1:09  [ loss=0.5908 ][Training] 19/57 [=========>....................] - ETA: 1:08  [ loss=0.8799 ][Training] 20/57 [=========>....................] - ETA: 1:07  [ loss=0.5316 ][Training] 21/57 [==========>...................] - ETA: 1:05  [ loss=0.4753 ][Training] 22/57 [==========>...................] - ETA: 1:03  [ loss=0.4963 ][Training] 23/57 [===========>..................] - ETA: 1:02  [ loss=0.5445 ][Training] 24/57 [===========>..................] - ETA: 1:00  [ loss=0.0646 ][Training] 25/57 [============>.................] - ETA: 58s  [ loss=1.3598 ][Training] 26/57 [============>.................] - ETA: 56s  [ loss=0.0663 ][Training] 27/57 [=============>................] - ETA: 55s  [ loss=0.4791 ][Training] 28/57 [=============>................] - ETA: 53s  [ loss=1.1416 ][Training] 29/57 [==============>...............] - ETA: 51s  [ loss=0.7596 ][Training] 30/57 [==============>...............] - ETA: 49s  [ loss=0.7450 ][Training] 31/57 [===============>..............] - ETA: 47s  [ loss=0.3659 ][Training] 32/57 [===============>..............] - ETA: 45s  [ loss=0.2139 ][Training] 33/57 [================>.............] - ETA: 43s  [ loss=0.7455 ][Training] 34/57 [================>.............] - ETA: 42s  [ loss=1.2877 ][Training] 35/57 [=================>............] - ETA: 40s  [ loss=1.7167 ][Training] 36/57 [=================>............] - ETA: 38s  [ loss=0.6492 ][Training] 37/57 [==================>...........] - ETA: 36s  [ loss=1.3053 ][Training] 38/57 [===================>..........] - ETA: 34s  [ loss=0.1864 ][Training] 39/57 [===================>..........] - ETA: 32s  [ loss=0.0492 ][Training] 40/57 [====================>.........] - ETA: 30s  [ loss=0.4989 ][Training] 41/57 [====================>.........] - ETA: 29s  [ loss=0.6521 ][Training] 42/57 [=====================>........] - ETA: 27s  [ loss=0.0851 ][Training] 43/57 [=====================>........] - ETA: 25s  [ loss=1.3599 ][Training] 44/57 [======================>.......] - ETA: 23s  [ loss=0.0958 ][Training] 45/57 [======================>.......] - ETA: 22s  [ loss=0.5358 ][Training] 46/57 [=======================>......] - ETA: 20s  [ loss=1.0291 ][Training] 47/57 [=======================>......] - ETA: 18s  [ loss=0.7519 ][Training] 48/57 [========================>.....] - ETA: 16s  [ loss=0.6766 ][Training] 49/57 [========================>.....] - ETA: 14s  [ loss=0.8151 ][Training] 50/57 [=========================>....] - ETA: 12s  [ loss=0.3531 ][Training] 51/57 [=========================>....] - ETA: 11s  [ loss=1.4657 ][Training] 52/57 [==========================>...] - ETA: 9s  [ loss=0.1459 ][Training] 53/57 [==========================>...] - ETA: 7s  [ loss=0.1932 ][Training] 54/57 [===========================>..] - ETA: 5s  [ loss=0.3848 ][Training] 55/57 [===========================>..] - ETA: 3s  [ loss=0.1385 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.5059 ][Training] 57/57 [==============================] 1.8s/step  [ loss=0.0760 ]
01/03/2024 22:03:42 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 22:03:42 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 22:03:42 - INFO - root -     Num examples = 269
01/03/2024 22:03:42 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 7s[Evaluating] 2/12 [====>.........................] - ETA: 7s[Evaluating] 3/12 [======>.......................] - ETA: 6s[Evaluating] 4/12 [=========>....................] - ETA: 6s[Evaluating] 5/12 [===========>..................] - ETA: 5s[Evaluating] 6/12 [==============>...............] - ETA: 4s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 2s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 649.0ms/step
01/03/2024 22:03:50 - INFO - root -   

01/03/2024 22:03:50 - INFO - root -   ***** Eval results  *****
01/03/2024 22:03:50 - INFO - root -    acc: 0.7302 - recall: 0.6683 - f1: 0.6979 - loss: 7.1170 
01/03/2024 22:03:50 - INFO - root -   ***** Entity results  *****
01/03/2024 22:03:50 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 22:03:50 - INFO - root -    acc: 0.8039 - recall: 0.8723 - f1: 0.8367 
01/03/2024 22:03:50 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 22:03:50 - INFO - root -    acc: 1.0000 - recall: 1.0000 - f1: 1.0000 
01/03/2024 22:03:50 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 22:03:50 - INFO - root -    acc: 0.4737 - recall: 0.4737 - f1: 0.4737 
01/03/2024 22:03:50 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 22:03:50 - INFO - root -    acc: 0.3333 - recall: 0.3333 - f1: 0.3333 
01/03/2024 22:03:50 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 22:03:50 - INFO - root -    acc: 0.6500 - recall: 0.3333 - f1: 0.4407 
01/03/2024 22:03:50 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 22:03:50 - INFO - root -    acc: 0.7273 - recall: 0.4706 - f1: 0.5714 
01/03/2024 22:03:50 - INFO - root -   ******* PER.NAM results ********
01/03/2024 22:03:50 - INFO - root -    acc: 0.7941 - recall: 0.7364 - f1: 0.7642 
01/03/2024 22:03:50 - INFO - root -   ******* PER.NOM results ********
01/03/2024 22:03:50 - INFO - root -    acc: 0.7256 - recall: 0.7000 - f1: 0.7126 
01/03/2024 22:04:02 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2109
01/03/2024 22:04:02 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2109
01/03/2024 22:04:02 - INFO - root -   

01/03/2024 22:04:02 - INFO - root -   Backbone bert_estor_crf param is not freeze

Epoch: 37/50
[Training] 1/57 [..............................] - ETA: 1:22  [ loss=0.0352 ][Training] 2/57 [>.............................] - ETA: 1:37  [ loss=0.4467 ][Training] 3/57 [>.............................] - ETA: 1:39  [ loss=0.2026 ][Training] 4/57 [=>............................] - ETA: 1:38  [ loss=0.5662 ][Training] 5/57 [=>............................] - ETA: 1:40  [ loss=0.3617 ][Training] 6/57 [==>...........................] - ETA: 1:40  [ loss=0.7775 ][Training] 7/57 [==>...........................] - ETA: 1:35  [ loss=0.0675 ][Training] 8/57 [===>..........................] - ETA: 1:31  [ loss=0.3048 ][Training] 9/57 [===>..........................] - ETA: 1:30  [ loss=0.6782 ][Training] 10/57 [====>.........................] - ETA: 1:29  [ loss=0.0950 ][Training] 11/57 [====>.........................] - ETA: 1:26  [ loss=1.0504 ][Training] 12/57 [=====>........................] - ETA: 1:24  [ loss=0.0685 ][Training] 13/57 [=====>........................] - ETA: 1:22  [ loss=0.3068 ][Training] 14/57 [======>.......................] - ETA: 1:20  [ loss=0.5730 ][Training] 15/57 [======>.......................] - ETA: 1:17  [ loss=0.0884 ][Training] 16/57 [=======>......................] - ETA: 1:15  [ loss=0.1629 ][Training] 17/57 [=======>......................] - ETA: 1:13  [ loss=0.4490 ][Training] 18/57 [========>.....................] - ETA: 1:11  [ loss=0.2064 ][Training] 19/57 [=========>....................] - ETA: 1:10  [ loss=1.7600 ][Training] 20/57 [=========>....................] - ETA: 1:08  [ loss=0.3454 ][Training] 21/57 [==========>...................] - ETA: 1:06  [ loss=0.4524 ][Training] 22/57 [==========>...................] - ETA: 1:04  [ loss=0.2822 ][Training] 23/57 [===========>..................] - ETA: 1:01  [ loss=0.5643 ][Training] 24/57 [===========>..................] - ETA: 1:00  [ loss=0.3523 ][Training] 25/57 [============>.................] - ETA: 59s  [ loss=0.1975 ][Training] 26/57 [============>.................] - ETA: 57s  [ loss=1.2294 ][Training] 27/57 [=============>................] - ETA: 55s  [ loss=0.0854 ][Training] 28/57 [=============>................] - ETA: 53s  [ loss=0.3552 ][Training] 29/57 [==============>...............] - ETA: 51s  [ loss=0.0581 ][Training] 30/57 [==============>...............] - ETA: 49s  [ loss=0.1428 ][Training] 31/57 [===============>..............] - ETA: 47s  [ loss=0.4340 ][Training] 32/57 [===============>..............] - ETA: 45s  [ loss=0.1024 ][Training] 33/57 [================>.............] - ETA: 44s  [ loss=0.1671 ][Training] 34/57 [================>.............] - ETA: 42s  [ loss=0.1146 ][Training] 35/57 [=================>............] - ETA: 40s  [ loss=0.2649 ][Training] 36/57 [=================>............] - ETA: 38s  [ loss=0.0698 ][Training] 37/57 [==================>...........] - ETA: 36s  [ loss=0.0466 ][Training] 38/57 [===================>..........] - ETA: 34s  [ loss=0.2499 ][Training] 39/57 [===================>..........] - ETA: 33s  [ loss=0.6061 ][Training] 40/57 [====================>.........] - ETA: 31s  [ loss=1.0148 ][Training] 41/57 [====================>.........] - ETA: 29s  [ loss=0.8201 ][Training] 42/57 [=====================>........] - ETA: 27s  [ loss=0.3509 ][Training] 43/57 [=====================>........] - ETA: 25s  [ loss=0.2356 ][Training] 44/57 [======================>.......] - ETA: 23s  [ loss=0.0449 ][Training] 45/57 [======================>.......] - ETA: 21s  [ loss=0.8026 ][Training] 46/57 [=======================>......] - ETA: 19s  [ loss=0.1558 ][Training] 47/57 [=======================>......] - ETA: 18s  [ loss=0.0992 ][Training] 48/57 [========================>.....] - ETA: 16s  [ loss=0.4704 ][Training] 49/57 [========================>.....] - ETA: 14s  [ loss=0.2810 ][Training] 50/57 [=========================>....] - ETA: 12s  [ loss=0.5789 ][Training] 51/57 [=========================>....] - ETA: 10s  [ loss=0.5631 ][Training] 52/57 [==========================>...] - ETA: 9s  [ loss=0.4828 ][Training] 53/57 [==========================>...] - ETA: 7s  [ loss=0.5864 ][Training] 54/57 [===========================>..] - ETA: 5s  [ loss=1.4299 ][Training] 55/57 [===========================>..] - ETA: 3s  [ loss=0.9223 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.1574 ][Training] 57/57 [==============================] 1.8s/step  [ loss=0.0525 ]
01/03/2024 22:05:44 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 22:05:44 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 22:05:44 - INFO - root -     Num examples = 269
01/03/2024 22:05:44 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 6s[Evaluating] 2/12 [====>.........................] - ETA: 7s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 599.6ms/step
01/03/2024 22:05:52 - INFO - root -   

01/03/2024 22:05:52 - INFO - root -   ***** Eval results  *****
01/03/2024 22:05:52 - INFO - root -    acc: 0.7075 - recall: 0.6852 - f1: 0.6962 - loss: 8.0562 
01/03/2024 22:05:52 - INFO - root -   ***** Entity results  *****
01/03/2024 22:05:52 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 22:05:52 - INFO - root -    acc: 0.7414 - recall: 0.9149 - f1: 0.8190 
01/03/2024 22:05:52 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 22:05:52 - INFO - root -    acc: 1.0000 - recall: 0.5000 - f1: 0.6667 
01/03/2024 22:05:52 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 22:05:52 - INFO - root -    acc: 0.6667 - recall: 0.5263 - f1: 0.5882 
01/03/2024 22:05:52 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 22:05:52 - INFO - root -    acc: 0.2857 - recall: 0.2222 - f1: 0.2500 
01/03/2024 22:05:52 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 22:05:52 - INFO - root -    acc: 0.6842 - recall: 0.3333 - f1: 0.4483 
01/03/2024 22:05:52 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 22:05:52 - INFO - root -    acc: 0.6667 - recall: 0.3529 - f1: 0.4615 
01/03/2024 22:05:52 - INFO - root -   ******* PER.NAM results ********
01/03/2024 22:05:52 - INFO - root -    acc: 0.7049 - recall: 0.7818 - f1: 0.7414 
01/03/2024 22:05:52 - INFO - root -   ******* PER.NOM results ********
01/03/2024 22:05:52 - INFO - root -    acc: 0.7219 - recall: 0.7176 - f1: 0.7198 
01/03/2024 22:06:01 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2166
01/03/2024 22:06:01 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2166
01/03/2024 22:06:01 - INFO - root -   

01/03/2024 22:06:01 - INFO - root -   Backbone bert_estor_crf param is not freeze

Epoch: 38/50
[Training] 1/57 [..............................] - ETA: 1:43  [ loss=0.4549 ][Training] 2/57 [>.............................] - ETA: 1:47  [ loss=0.2342 ][Training] 3/57 [>.............................] - ETA: 1:43  [ loss=0.7070 ][Training] 4/57 [=>............................] - ETA: 1:42  [ loss=0.0894 ][Training] 5/57 [=>............................] - ETA: 1:42  [ loss=0.0501 ][Training] 6/57 [==>...........................] - ETA: 1:36  [ loss=0.0423 ][Training] 7/57 [==>...........................] - ETA: 1:34  [ loss=0.5949 ][Training] 8/57 [===>..........................] - ETA: 1:34  [ loss=0.2272 ][Training] 9/57 [===>..........................] - ETA: 1:31  [ loss=0.2794 ][Training] 10/57 [====>.........................] - ETA: 1:26  [ loss=0.0226 ][Training] 11/57 [====>.........................] - ETA: 1:24  [ loss=0.0589 ][Training] 12/57 [=====>........................] - ETA: 1:22  [ loss=0.8500 ][Training] 13/57 [=====>........................] - ETA: 1:20  [ loss=0.1829 ][Training] 14/57 [======>.......................] - ETA: 1:18  [ loss=0.6014 ][Training] 15/57 [======>.......................] - ETA: 1:17  [ loss=0.1864 ][Training] 16/57 [=======>......................] - ETA: 1:15  [ loss=0.0693 ][Training] 17/57 [=======>......................] - ETA: 1:14  [ loss=2.1476 ][Training] 18/57 [========>.....................] - ETA: 1:12  [ loss=0.2478 ][Training] 19/57 [=========>....................] - ETA: 1:10  [ loss=0.0244 ][Training] 20/57 [=========>....................] - ETA: 1:09  [ loss=0.6690 ][Training] 21/57 [==========>...................] - ETA: 1:07  [ loss=0.2708 ][Training] 22/57 [==========>...................] - ETA: 1:05  [ loss=0.0608 ][Training] 23/57 [===========>..................] - ETA: 1:03  [ loss=1.3937 ][Training] 24/57 [===========>..................] - ETA: 1:01  [ loss=0.0324 ][Training] 25/57 [============>.................] - ETA: 59s  [ loss=0.9027 ][Training] 26/57 [============>.................] - ETA: 56s  [ loss=0.0165 ][Training] 27/57 [=============>................] - ETA: 55s  [ loss=0.2923 ][Training] 28/57 [=============>................] - ETA: 53s  [ loss=0.0432 ][Training] 29/57 [==============>...............] - ETA: 51s  [ loss=0.1289 ][Training] 30/57 [==============>...............] - ETA: 49s  [ loss=0.9094 ][Training] 31/57 [===============>..............] - ETA: 47s  [ loss=0.0794 ][Training] 32/57 [===============>..............] - ETA: 45s  [ loss=0.2699 ][Training] 33/57 [================>.............] - ETA: 43s  [ loss=0.4504 ][Training] 34/57 [================>.............] - ETA: 41s  [ loss=1.2066 ][Training] 35/57 [=================>............] - ETA: 39s  [ loss=0.5087 ][Training] 36/57 [=================>............] - ETA: 38s  [ loss=0.0490 ][Training] 37/57 [==================>...........] - ETA: 36s  [ loss=1.7206 ][Training] 38/57 [===================>..........] - ETA: 34s  [ loss=0.2708 ][Training] 39/57 [===================>..........] - ETA: 32s  [ loss=0.8565 ][Training] 40/57 [====================>.........] - ETA: 30s  [ loss=0.0826 ][Training] 41/57 [====================>.........] - ETA: 29s  [ loss=0.0655 ][Training] 42/57 [=====================>........] - ETA: 27s  [ loss=0.7778 ][Training] 43/57 [=====================>........] - ETA: 25s  [ loss=0.1846 ][Training] 44/57 [======================>.......] - ETA: 23s  [ loss=0.2782 ][Training] 45/57 [======================>.......] - ETA: 21s  [ loss=0.2889 ][Training] 46/57 [=======================>......] - ETA: 20s  [ loss=0.0662 ][Training] 47/57 [=======================>......] - ETA: 18s  [ loss=0.4326 ][Training] 48/57 [========================>.....] - ETA: 16s  [ loss=0.0673 ][Training] 49/57 [========================>.....] - ETA: 14s  [ loss=0.4135 ][Training] 50/57 [=========================>....] - ETA: 12s  [ loss=0.0315 ][Training] 51/57 [=========================>....] - ETA: 10s  [ loss=0.0449 ][Training] 52/57 [==========================>...] - ETA: 9s  [ loss=0.1069 ][Training] 53/57 [==========================>...] - ETA: 7s  [ loss=0.9458 ][Training] 54/57 [===========================>..] - ETA: 5s  [ loss=0.1831 ][Training] 55/57 [===========================>..] - ETA: 3s  [ loss=0.9885 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.0374 ][Training] 57/57 [==============================] 1.8s/step  [ loss=1.1929 ]
01/03/2024 22:07:45 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 22:07:45 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 22:07:45 - INFO - root -     Num examples = 269
01/03/2024 22:07:45 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 5s[Evaluating] 2/12 [====>.........................] - ETA: 6s[Evaluating] 3/12 [======>.......................] - ETA: 6s[Evaluating] 4/12 [=========>....................] - ETA: 5s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 631.7ms/step
01/03/2024 22:07:52 - INFO - root -   

01/03/2024 22:07:52 - INFO - root -   ***** Eval results  *****
01/03/2024 22:07:52 - INFO - root -    acc: 0.7333 - recall: 0.6925 - f1: 0.7123 - loss: 7.5113 
01/03/2024 22:07:52 - INFO - root -   ***** Entity results  *****
01/03/2024 22:07:52 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 22:07:52 - INFO - root -    acc: 0.7963 - recall: 0.9149 - f1: 0.8515 
01/03/2024 22:07:52 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 22:07:52 - INFO - root -    acc: 1.0000 - recall: 0.5000 - f1: 0.6667 
01/03/2024 22:07:52 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 22:07:52 - INFO - root -    acc: 0.7273 - recall: 0.4211 - f1: 0.5333 
01/03/2024 22:07:52 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 22:07:52 - INFO - root -    acc: 0.5000 - recall: 0.3333 - f1: 0.4000 
01/03/2024 22:07:52 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 22:07:52 - INFO - root -    acc: 0.6000 - recall: 0.3846 - f1: 0.4688 
01/03/2024 22:07:52 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 22:07:52 - INFO - root -    acc: 0.8000 - recall: 0.4706 - f1: 0.5926 
01/03/2024 22:07:52 - INFO - root -   ******* PER.NAM results ********
01/03/2024 22:07:52 - INFO - root -    acc: 0.7885 - recall: 0.7455 - f1: 0.7664 
01/03/2024 22:07:52 - INFO - root -   ******* PER.NOM results ********
01/03/2024 22:07:52 - INFO - root -    acc: 0.7039 - recall: 0.7412 - f1: 0.7221 
01/03/2024 22:08:02 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2223
01/03/2024 22:08:02 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2223
01/03/2024 22:08:02 - INFO - root -   

01/03/2024 22:08:02 - INFO - root -   Backbone bert_estor_crf param is not freeze

Epoch: 39/50
[Training] 1/57 [..............................] - ETA: 1:43  [ loss=0.0589 ][Training] 2/57 [>.............................] - ETA: 1:42  [ loss=0.1599 ][Training] 3/57 [>.............................] - ETA: 1:34  [ loss=0.0623 ][Training] 4/57 [=>............................] - ETA: 1:30  [ loss=0.0286 ][Training] 5/57 [=>............................] - ETA: 1:30  [ loss=0.0573 ][Training] 6/57 [==>...........................] - ETA: 1:29  [ loss=0.0432 ][Training] 7/57 [==>...........................] - ETA: 1:26  [ loss=0.0710 ][Training] 8/57 [===>..........................] - ETA: 1:25  [ loss=0.1713 ][Training] 9/57 [===>..........................] - ETA: 1:24  [ loss=0.0677 ][Training] 10/57 [====>.........................] - ETA: 1:21  [ loss=0.1269 ][Training] 11/57 [====>.........................] - ETA: 1:19  [ loss=0.5868 ][Training] 12/57 [=====>........................] - ETA: 1:18  [ loss=0.0436 ][Training] 13/57 [=====>........................] - ETA: 1:16  [ loss=0.4560 ][Training] 14/57 [======>.......................] - ETA: 1:15  [ loss=0.1681 ][Training] 15/57 [======>.......................] - ETA: 1:14  [ loss=0.3662 ][Training] 16/57 [=======>......................] - ETA: 1:13  [ loss=0.0377 ][Training] 17/57 [=======>......................] - ETA: 1:10  [ loss=0.0734 ][Training] 18/57 [========>.....................] - ETA: 1:09  [ loss=0.0314 ][Training] 19/57 [=========>....................] - ETA: 1:08  [ loss=0.6771 ][Training] 20/57 [=========>....................] - ETA: 1:06  [ loss=0.0305 ][Training] 21/57 [==========>...................] - ETA: 1:04  [ loss=0.0459 ][Training] 22/57 [==========>...................] - ETA: 1:02  [ loss=0.8591 ][Training] 23/57 [===========>..................] - ETA: 1:01  [ loss=0.0362 ][Training] 24/57 [===========>..................] - ETA: 59s  [ loss=0.1875 ][Training] 25/57 [============>.................] - ETA: 57s  [ loss=0.0512 ][Training] 26/57 [============>.................] - ETA: 55s  [ loss=0.8653 ][Training] 27/57 [=============>................] - ETA: 54s  [ loss=1.0557 ][Training] 28/57 [=============>................] - ETA: 52s  [ loss=0.7228 ][Training] 29/57 [==============>...............] - ETA: 50s  [ loss=0.6086 ][Training] 30/57 [==============>...............] - ETA: 48s  [ loss=0.4585 ][Training] 31/57 [===============>..............] - ETA: 47s  [ loss=1.2869 ][Training] 32/57 [===============>..............] - ETA: 45s  [ loss=0.0242 ][Training] 33/57 [================>.............] - ETA: 44s  [ loss=0.8935 ][Training] 34/57 [================>.............] - ETA: 42s  [ loss=0.4787 ][Training] 35/57 [=================>............] - ETA: 40s  [ loss=0.0742 ][Training] 36/57 [=================>............] - ETA: 38s  [ loss=1.1055 ][Training] 37/57 [==================>...........] - ETA: 36s  [ loss=0.0621 ][Training] 38/57 [===================>..........] - ETA: 34s  [ loss=0.2566 ][Training] 39/57 [===================>..........] - ETA: 33s  [ loss=0.0211 ][Training] 40/57 [====================>.........] - ETA: 31s  [ loss=0.4621 ][Training] 41/57 [====================>.........] - ETA: 29s  [ loss=0.8691 ][Training] 42/57 [=====================>........] - ETA: 27s  [ loss=0.2904 ][Training] 43/57 [=====================>........] - ETA: 25s  [ loss=1.5206 ][Training] 44/57 [======================>.......] - ETA: 23s  [ loss=0.0271 ][Training] 45/57 [======================>.......] - ETA: 21s  [ loss=0.3608 ][Training] 46/57 [=======================>......] - ETA: 20s  [ loss=0.2210 ][Training] 47/57 [=======================>......] - ETA: 18s  [ loss=0.0435 ][Training] 48/57 [========================>.....] - ETA: 16s  [ loss=0.0581 ][Training] 49/57 [========================>.....] - ETA: 14s  [ loss=0.0569 ][Training] 50/57 [=========================>....] - ETA: 12s  [ loss=0.5068 ][Training] 51/57 [=========================>....] - ETA: 10s  [ loss=1.5056 ][Training] 52/57 [==========================>...] - ETA: 9s  [ loss=0.0414 ][Training] 53/57 [==========================>...] - ETA: 7s  [ loss=0.3887 ][Training] 54/57 [===========================>..] - ETA: 5s  [ loss=0.3321 ][Training] 55/57 [===========================>..] - ETA: 3s  [ loss=0.8378 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=1.2164 ][Training] 57/57 [==============================] 1.8s/step  [ loss=2.5143 ]
01/03/2024 22:09:43 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 22:09:44 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 22:09:44 - INFO - root -     Num examples = 269
01/03/2024 22:09:44 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 7s[Evaluating] 2/12 [====>.........................] - ETA: 7s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 606.2ms/step
01/03/2024 22:09:51 - INFO - root -   

01/03/2024 22:09:51 - INFO - root -   ***** Eval results  *****
01/03/2024 22:09:51 - INFO - root -    acc: 0.7157 - recall: 0.7070 - f1: 0.7113 - loss: 7.9693 
01/03/2024 22:09:51 - INFO - root -   ***** Entity results  *****
01/03/2024 22:09:51 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 22:09:51 - INFO - root -    acc: 0.7679 - recall: 0.9149 - f1: 0.8350 
01/03/2024 22:09:51 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 22:09:51 - INFO - root -    acc: 1.0000 - recall: 0.5000 - f1: 0.6667 
01/03/2024 22:09:51 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 22:09:51 - INFO - root -    acc: 0.6667 - recall: 0.4211 - f1: 0.5161 
01/03/2024 22:09:51 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 22:09:51 - INFO - root -    acc: 0.3000 - recall: 0.3333 - f1: 0.3158 
01/03/2024 22:09:51 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 22:09:51 - INFO - root -    acc: 0.6071 - recall: 0.4359 - f1: 0.5075 
01/03/2024 22:09:51 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 22:09:51 - INFO - root -    acc: 0.7778 - recall: 0.4118 - f1: 0.5385 
01/03/2024 22:09:51 - INFO - root -   ******* PER.NAM results ********
01/03/2024 22:09:51 - INFO - root -    acc: 0.7961 - recall: 0.7455 - f1: 0.7700 
01/03/2024 22:09:51 - INFO - root -   ******* PER.NOM results ********
01/03/2024 22:09:51 - INFO - root -    acc: 0.6931 - recall: 0.7706 - f1: 0.7298 
01/03/2024 22:10:15 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2280
01/03/2024 22:10:16 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2280
01/03/2024 22:10:16 - INFO - root -   

01/03/2024 22:10:16 - INFO - root -   Backbone bert_estor_crf param is not freeze

Epoch: 40/50
[Training] 1/57 [..............................] - ETA: 1:43  [ loss=0.1136 ][Training] 2/57 [>.............................] - ETA: 1:44  [ loss=0.4237 ][Training] 3/57 [>.............................] - ETA: 1:43  [ loss=0.2318 ][Training] 4/57 [=>............................] - ETA: 1:40  [ loss=0.0317 ][Training] 5/57 [=>............................] - ETA: 1:38  [ loss=0.1502 ][Training] 6/57 [==>...........................] - ETA: 1:37  [ loss=1.0128 ][Training] 7/57 [==>...........................] - ETA: 1:35  [ loss=0.0197 ][Training] 8/57 [===>..........................] - ETA: 1:31  [ loss=0.4409 ][Training] 9/57 [===>..........................] - ETA: 1:28  [ loss=0.0684 ][Training] 10/57 [====>.........................] - ETA: 1:27  [ loss=0.0565 ][Training] 11/57 [====>.........................] - ETA: 1:25  [ loss=0.2117 ][Training] 12/57 [=====>........................] - ETA: 1:26  [ loss=0.2913 ][Training] 13/57 [=====>........................] - ETA: 1:24  [ loss=0.1229 ][Training] 14/57 [======>.......................] - ETA: 1:21  [ loss=0.4376 ][Training] 15/57 [======>.......................] - ETA: 1:19  [ loss=0.0884 ][Training] 16/57 [=======>......................] - ETA: 1:17  [ loss=0.1063 ][Training] 17/57 [=======>......................] - ETA: 1:16  [ loss=0.0720 ][Training] 18/57 [========>.....................] - ETA: 1:14  [ loss=0.7323 ][Training] 19/57 [=========>....................] - ETA: 1:13  [ loss=0.1582 ][Training] 20/57 [=========>....................] - ETA: 1:10  [ loss=0.5135 ][Training] 21/57 [==========>...................] - ETA: 1:08  [ loss=0.7851 ][Training] 22/57 [==========>...................] - ETA: 1:06  [ loss=0.1890 ][Training] 23/57 [===========>..................] - ETA: 1:04  [ loss=0.0440 ][Training] 24/57 [===========>..................] - ETA: 1:01  [ loss=0.0214 ][Training] 25/57 [============>.................] - ETA: 59s  [ loss=0.0177 ][Training] 26/57 [============>.................] - ETA: 57s  [ loss=0.8072 ][Training] 27/57 [=============>................] - ETA: 56s  [ loss=0.5389 ][Training] 28/57 [=============>................] - ETA: 54s  [ loss=0.8550 ][Training] 29/57 [==============>...............] - ETA: 52s  [ loss=0.0235 ][Training] 30/57 [==============>...............] - ETA: 50s  [ loss=0.0164 ][Training] 31/57 [===============>..............] - ETA: 48s  [ loss=0.2719 ][Training] 32/57 [===============>..............] - ETA: 47s  [ loss=0.1062 ][Training] 33/57 [================>.............] - ETA: 45s  [ loss=0.6931 ][Training] 34/57 [================>.............] - ETA: 43s  [ loss=0.3967 ][Training] 35/57 [=================>............] - ETA: 41s  [ loss=0.4673 ][Training] 36/57 [=================>............] - ETA: 39s  [ loss=0.8366 ][Training] 37/57 [==================>...........] - ETA: 37s  [ loss=0.5440 ][Training] 38/57 [===================>..........] - ETA: 35s  [ loss=0.2506 ][Training] 39/57 [===================>..........] - ETA: 33s  [ loss=0.2487 ][Training] 40/57 [====================>.........] - ETA: 31s  [ loss=0.0405 ][Training] 41/57 [====================>.........] - ETA: 29s  [ loss=0.4746 ][Training] 42/57 [=====================>........] - ETA: 28s  [ loss=0.1521 ][Training] 43/57 [=====================>........] - ETA: 26s  [ loss=0.3914 ][Training] 44/57 [======================>.......] - ETA: 24s  [ loss=0.3382 ][Training] 45/57 [======================>.......] - ETA: 22s  [ loss=0.4950 ][Training] 46/57 [=======================>......] - ETA: 20s  [ loss=0.5292 ][Training] 47/57 [=======================>......] - ETA: 18s  [ loss=0.6035 ][Training] 48/57 [========================>.....] - ETA: 16s  [ loss=0.6339 ][Training] 49/57 [========================>.....] - ETA: 14s  [ loss=0.1769 ][Training] 50/57 [=========================>....] - ETA: 13s  [ loss=1.3987 ][Training] 51/57 [=========================>....] - ETA: 11s  [ loss=0.1230 ][Training] 52/57 [==========================>...] - ETA: 9s  [ loss=0.1606 ][Training] 53/57 [==========================>...] - ETA: 7s  [ loss=0.3847 ][Training] 54/57 [===========================>..] - ETA: 5s  [ loss=0.0319 ][Training] 55/57 [===========================>..] - ETA: 3s  [ loss=0.0223 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.0530 ][Training] 57/57 [==============================] 1.8s/step  [ loss=0.0396 ]
01/03/2024 22:12:01 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 22:12:01 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 22:12:01 - INFO - root -     Num examples = 269
01/03/2024 22:12:01 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 5s[Evaluating] 2/12 [====>.........................] - ETA: 6s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 605.3ms/step
01/03/2024 22:12:09 - INFO - root -   

01/03/2024 22:12:09 - INFO - root -   ***** Eval results  *****
01/03/2024 22:12:09 - INFO - root -    acc: 0.7347 - recall: 0.6707 - f1: 0.7013 - loss: 7.9595 
01/03/2024 22:12:09 - INFO - root -   ***** Entity results  *****
01/03/2024 22:12:09 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 22:12:09 - INFO - root -    acc: 0.7679 - recall: 0.9149 - f1: 0.8350 
01/03/2024 22:12:09 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 22:12:09 - INFO - root -    acc: 1.0000 - recall: 0.5000 - f1: 0.6667 
01/03/2024 22:12:09 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 22:12:09 - INFO - root -    acc: 0.6364 - recall: 0.3684 - f1: 0.4667 
01/03/2024 22:12:09 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 22:12:09 - INFO - root -    acc: 0.5000 - recall: 0.2222 - f1: 0.3077 
01/03/2024 22:12:09 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 22:12:09 - INFO - root -    acc: 0.6000 - recall: 0.3846 - f1: 0.4688 
01/03/2024 22:12:09 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 22:12:09 - INFO - root -    acc: 0.6667 - recall: 0.3529 - f1: 0.4615 
01/03/2024 22:12:09 - INFO - root -   ******* PER.NAM results ********
01/03/2024 22:12:09 - INFO - root -    acc: 0.7736 - recall: 0.7455 - f1: 0.7593 
01/03/2024 22:12:09 - INFO - root -   ******* PER.NOM results ********
01/03/2024 22:12:09 - INFO - root -    acc: 0.7333 - recall: 0.7118 - f1: 0.7224 
01/03/2024 22:12:18 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2337
01/03/2024 22:12:18 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2337
01/03/2024 22:12:18 - INFO - root -   

01/03/2024 22:12:18 - INFO - root -   Backbone bert_estor_crf param is not freeze

Epoch: 41/50
[Training] 1/57 [..............................] - ETA: 1:42  [ loss=0.0538 ][Training] 2/57 [>.............................] - ETA: 1:36  [ loss=0.0813 ][Training] 3/57 [>.............................] - ETA: 1:45  [ loss=0.2565 ][Training] 4/57 [=>............................] - ETA: 1:45  [ loss=1.4284 ][Training] 5/57 [=>............................] - ETA: 1:40  [ loss=0.0570 ][Training] 6/57 [==>...........................] - ETA: 1:35  [ loss=0.1859 ][Training] 7/57 [==>...........................] - ETA: 1:34  [ loss=0.0363 ][Training] 8/57 [===>..........................] - ETA: 1:31  [ loss=0.2404 ][Training] 9/57 [===>..........................] - ETA: 1:28  [ loss=0.9573 ][Training] 10/57 [====>.........................] - ETA: 1:27  [ loss=0.0237 ][Training] 11/57 [====>.........................] - ETA: 1:23  [ loss=0.3465 ][Training] 12/57 [=====>........................] - ETA: 1:21  [ loss=0.1140 ][Training] 13/57 [=====>........................] - ETA: 1:19  [ loss=0.3013 ][Training] 14/57 [======>.......................] - ETA: 1:17  [ loss=0.0919 ][Training] 15/57 [======>.......................] - ETA: 1:15  [ loss=0.2160 ][Training] 16/57 [=======>......................] - ETA: 1:12  [ loss=0.1702 ][Training] 17/57 [=======>......................] - ETA: 1:10  [ loss=0.0964 ][Training] 18/57 [========>.....................] - ETA: 1:08  [ loss=0.0400 ][Training] 19/57 [=========>....................] - ETA: 1:08  [ loss=0.0450 ][Training] 20/57 [=========>....................] - ETA: 1:06  [ loss=0.7063 ][Training] 21/57 [==========>...................] - ETA: 1:05  [ loss=0.3555 ][Training] 22/57 [==========>...................] - ETA: 1:03  [ loss=1.3703 ][Training] 23/57 [===========>..................] - ETA: 1:02  [ loss=0.0454 ][Training] 24/57 [===========>..................] - ETA: 1:00  [ loss=0.6419 ][Training] 25/57 [============>.................] - ETA: 58s  [ loss=0.0459 ][Training] 26/57 [============>.................] - ETA: 56s  [ loss=0.3339 ][Training] 27/57 [=============>................] - ETA: 54s  [ loss=0.7060 ][Training] 28/57 [=============>................] - ETA: 53s  [ loss=0.0647 ][Training] 29/57 [==============>...............] - ETA: 50s  [ loss=0.1537 ][Training] 30/57 [==============>...............] - ETA: 49s  [ loss=0.6989 ][Training] 31/57 [===============>..............] - ETA: 47s  [ loss=0.3019 ][Training] 32/57 [===============>..............] - ETA: 45s  [ loss=0.1695 ][Training] 33/57 [================>.............] - ETA: 43s  [ loss=0.1106 ][Training] 34/57 [================>.............] - ETA: 41s  [ loss=0.2865 ][Training] 35/57 [=================>............] - ETA: 39s  [ loss=0.0291 ][Training] 36/57 [=================>............] - ETA: 37s  [ loss=0.0172 ][Training] 37/57 [==================>...........] - ETA: 36s  [ loss=0.3610 ][Training] 38/57 [===================>..........] - ETA: 34s  [ loss=0.1279 ][Training] 39/57 [===================>..........] - ETA: 32s  [ loss=0.0660 ][Training] 40/57 [====================>.........] - ETA: 30s  [ loss=0.2722 ][Training] 41/57 [====================>.........] - ETA: 29s  [ loss=0.7057 ][Training] 42/57 [=====================>........] - ETA: 27s  [ loss=0.0184 ][Training] 43/57 [=====================>........] - ETA: 25s  [ loss=0.5030 ][Training] 44/57 [======================>.......] - ETA: 23s  [ loss=0.7071 ][Training] 45/57 [======================>.......] - ETA: 21s  [ loss=0.3822 ][Training] 46/57 [=======================>......] - ETA: 19s  [ loss=0.6572 ][Training] 47/57 [=======================>......] - ETA: 18s  [ loss=0.0155 ][Training] 48/57 [========================>.....] - ETA: 16s  [ loss=0.0220 ][Training] 49/57 [========================>.....] - ETA: 14s  [ loss=1.2679 ][Training] 50/57 [=========================>....] - ETA: 12s  [ loss=0.0404 ][Training] 51/57 [=========================>....] - ETA: 11s  [ loss=0.8750 ][Training] 52/57 [==========================>...] - ETA: 9s  [ loss=0.0150 ][Training] 53/57 [==========================>...] - ETA: 7s  [ loss=0.1385 ][Training] 54/57 [===========================>..] - ETA: 5s  [ loss=0.8072 ][Training] 55/57 [===========================>..] - ETA: 3s  [ loss=0.0171 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.3975 ][Training] 57/57 [==============================] 1.8s/step  [ loss=0.0179 ]
01/03/2024 22:14:01 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 22:14:02 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 22:14:02 - INFO - root -     Num examples = 269
01/03/2024 22:14:02 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 5s[Evaluating] 2/12 [====>.........................] - ETA: 5s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 2s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 573.7ms/step
01/03/2024 22:14:08 - INFO - root -   

01/03/2024 22:14:08 - INFO - root -   ***** Eval results  *****
01/03/2024 22:14:08 - INFO - root -    acc: 0.7069 - recall: 0.6949 - f1: 0.7009 - loss: 8.2436 
01/03/2024 22:14:08 - INFO - root -   ***** Entity results  *****
01/03/2024 22:14:08 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 22:14:08 - INFO - root -    acc: 0.7963 - recall: 0.9149 - f1: 0.8515 
01/03/2024 22:14:08 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 22:14:08 - INFO - root -    acc: 1.0000 - recall: 0.5000 - f1: 0.6667 
01/03/2024 22:14:08 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 22:14:08 - INFO - root -    acc: 0.6154 - recall: 0.4211 - f1: 0.5000 
01/03/2024 22:14:08 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 22:14:08 - INFO - root -    acc: 0.3750 - recall: 0.3333 - f1: 0.3529 
01/03/2024 22:14:08 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 22:14:08 - INFO - root -    acc: 0.6296 - recall: 0.4359 - f1: 0.5152 
01/03/2024 22:14:08 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 22:14:08 - INFO - root -    acc: 0.7273 - recall: 0.4706 - f1: 0.5714 
01/03/2024 22:14:08 - INFO - root -   ******* PER.NAM results ********
01/03/2024 22:14:08 - INFO - root -    acc: 0.7217 - recall: 0.7545 - f1: 0.7378 
01/03/2024 22:14:08 - INFO - root -   ******* PER.NOM results ********
01/03/2024 22:14:08 - INFO - root -    acc: 0.7006 - recall: 0.7294 - f1: 0.7147 
01/03/2024 22:14:26 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2394
01/03/2024 22:14:26 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2394
01/03/2024 22:14:26 - INFO - root -   

01/03/2024 22:14:26 - INFO - root -   Backbone bert_estor_crf param is not freeze

Epoch: 42/50
[Training] 1/57 [..............................] - ETA: 1:37  [ loss=0.1540 ][Training] 2/57 [>.............................] - ETA: 1:37  [ loss=0.1097 ][Training] 3/57 [>.............................] - ETA: 1:42  [ loss=0.3099 ][Training] 4/57 [=>............................] - ETA: 1:47  [ loss=0.1374 ][Training] 5/57 [=>............................] - ETA: 1:41  [ loss=0.0111 ][Training] 6/57 [==>...........................] - ETA: 1:40  [ loss=0.3311 ][Training] 7/57 [==>...........................] - ETA: 1:38  [ loss=0.1691 ][Training] 8/57 [===>..........................] - ETA: 1:35  [ loss=0.0289 ][Training] 9/57 [===>..........................] - ETA: 1:35  [ loss=0.0820 ][Training] 10/57 [====>.........................] - ETA: 1:32  [ loss=0.3302 ][Training] 11/57 [====>.........................] - ETA: 1:30  [ loss=0.1362 ][Training] 12/57 [=====>........................] - ETA: 1:27  [ loss=0.0103 ][Training] 13/57 [=====>........................] - ETA: 1:24  [ loss=0.7693 ][Training] 14/57 [======>.......................] - ETA: 1:21  [ loss=0.0157 ][Training] 15/57 [======>.......................] - ETA: 1:18  [ loss=0.0251 ][Training] 16/57 [=======>......................] - ETA: 1:15  [ loss=0.1853 ][Training] 17/57 [=======>......................] - ETA: 1:12  [ loss=0.0416 ][Training] 18/57 [========>.....................] - ETA: 1:10  [ loss=0.0164 ][Training] 19/57 [=========>....................] - ETA: 1:07  [ loss=0.1509 ][Training] 20/57 [=========>....................] - ETA: 1:05  [ loss=0.2329 ][Training] 21/57 [==========>...................] - ETA: 1:03  [ loss=0.3657 ][Training] 22/57 [==========>...................] - ETA: 1:01  [ loss=0.2190 ][Training] 23/57 [===========>..................] - ETA: 59s  [ loss=0.0459 ][Training] 24/57 [===========>..................] - ETA: 58s  [ loss=0.0802 ][Training] 25/57 [============>.................] - ETA: 56s  [ loss=0.1113 ][Training] 26/57 [============>.................] - ETA: 55s  [ loss=0.0150 ][Training] 27/57 [=============>................] - ETA: 53s  [ loss=0.0275 ][Training] 28/57 [=============>................] - ETA: 51s  [ loss=0.0288 ][Training] 29/57 [==============>...............] - ETA: 50s  [ loss=0.0886 ][Training] 30/57 [==============>...............] - ETA: 48s  [ loss=0.0173 ][Training] 31/57 [===============>..............] - ETA: 46s  [ loss=0.0354 ][Training] 32/57 [===============>..............] - ETA: 44s  [ loss=0.0402 ][Training] 33/57 [================>.............] - ETA: 42s  [ loss=0.0176 ][Training] 34/57 [================>.............] - ETA: 41s  [ loss=0.3145 ][Training] 35/57 [=================>............] - ETA: 39s  [ loss=0.2741 ][Training] 36/57 [=================>............] - ETA: 37s  [ loss=0.1885 ][Training] 37/57 [==================>...........] - ETA: 35s  [ loss=0.0296 ][Training] 38/57 [===================>..........] - ETA: 34s  [ loss=0.1113 ][Training] 39/57 [===================>..........] - ETA: 32s  [ loss=0.9089 ][Training] 40/57 [====================>.........] - ETA: 30s  [ loss=0.6280 ][Training] 41/57 [====================>.........] - ETA: 28s  [ loss=0.4198 ][Training] 42/57 [=====================>........] - ETA: 27s  [ loss=0.0668 ][Training] 43/57 [=====================>........] - ETA: 25s  [ loss=0.4150 ][Training] 44/57 [======================>.......] - ETA: 23s  [ loss=0.2479 ][Training] 45/57 [======================>.......] - ETA: 21s  [ loss=2.4536 ][Training] 46/57 [=======================>......] - ETA: 20s  [ loss=1.3636 ][Training] 47/57 [=======================>......] - ETA: 18s  [ loss=0.7113 ][Training] 48/57 [========================>.....] - ETA: 16s  [ loss=0.1849 ][Training] 49/57 [========================>.....] - ETA: 14s  [ loss=0.1240 ][Training] 50/57 [=========================>....] - ETA: 12s  [ loss=0.3891 ][Training] 51/57 [=========================>....] - ETA: 10s  [ loss=0.0139 ][Training] 52/57 [==========================>...] - ETA: 9s  [ loss=0.0241 ][Training] 53/57 [==========================>...] - ETA: 7s  [ loss=0.0223 ][Training] 54/57 [===========================>..] - ETA: 5s  [ loss=0.0691 ][Training] 55/57 [===========================>..] - ETA: 3s  [ loss=0.3529 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.8567 ][Training] 57/57 [==============================] 1.8s/step  [ loss=1.0170 ]
01/03/2024 22:16:09 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 22:16:09 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 22:16:09 - INFO - root -     Num examples = 269
01/03/2024 22:16:09 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 6s[Evaluating] 2/12 [====>.........................] - ETA: 5s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 5s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 590.0ms/step
01/03/2024 22:16:16 - INFO - root -   

01/03/2024 22:16:16 - INFO - root -   ***** Eval results  *****
01/03/2024 22:16:16 - INFO - root -    acc: 0.7160 - recall: 0.7143 - f1: 0.7152 - loss: 8.2926 
01/03/2024 22:16:16 - INFO - root -   ***** Entity results  *****
01/03/2024 22:16:16 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 22:16:16 - INFO - root -    acc: 0.8113 - recall: 0.9149 - f1: 0.8600 
01/03/2024 22:16:16 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 22:16:16 - INFO - root -    acc: 1.0000 - recall: 0.5000 - f1: 0.6667 
01/03/2024 22:16:16 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 22:16:16 - INFO - root -    acc: 0.6154 - recall: 0.4211 - f1: 0.5000 
01/03/2024 22:16:16 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 22:16:16 - INFO - root -    acc: 0.3000 - recall: 0.3333 - f1: 0.3158 
01/03/2024 22:16:16 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 22:16:16 - INFO - root -    acc: 0.5625 - recall: 0.4615 - f1: 0.5070 
01/03/2024 22:16:16 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 22:16:16 - INFO - root -    acc: 0.7273 - recall: 0.4706 - f1: 0.5714 
01/03/2024 22:16:16 - INFO - root -   ******* PER.NAM results ********
01/03/2024 22:16:16 - INFO - root -    acc: 0.7615 - recall: 0.7545 - f1: 0.7580 
01/03/2024 22:16:16 - INFO - root -   ******* PER.NOM results ********
01/03/2024 22:16:16 - INFO - root -    acc: 0.7158 - recall: 0.7706 - f1: 0.7422 
01/03/2024 22:16:27 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2451
01/03/2024 22:16:27 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2451
01/03/2024 22:16:27 - INFO - root -   

01/03/2024 22:16:27 - INFO - root -   Backbone bert_estor_crf param is not freeze

Epoch: 43/50
[Training] 1/57 [..............................] - ETA: 1:38  [ loss=0.4389 ][Training] 2/57 [>.............................] - ETA: 1:39  [ loss=0.0309 ][Training] 3/57 [>.............................] - ETA: 1:34  [ loss=0.0137 ][Training] 4/57 [=>............................] - ETA: 1:35  [ loss=0.3577 ][Training] 5/57 [=>............................] - ETA: 1:37  [ loss=0.0347 ][Training] 6/57 [==>...........................] - ETA: 1:37  [ loss=0.3503 ][Training] 7/57 [==>...........................] - ETA: 1:34  [ loss=0.0115 ][Training] 8/57 [===>..........................] - ETA: 1:34  [ loss=0.2707 ][Training] 9/57 [===>..........................] - ETA: 1:31  [ loss=0.0171 ][Training] 10/57 [====>.........................] - ETA: 1:28  [ loss=0.0197 ][Training] 11/57 [====>.........................] - ETA: 1:26  [ loss=0.0823 ][Training] 12/57 [=====>........................] - ETA: 1:24  [ loss=0.0116 ][Training] 13/57 [=====>........................] - ETA: 1:22  [ loss=0.1520 ][Training] 14/57 [======>.......................] - ETA: 1:21  [ loss=0.0193 ][Training] 15/57 [======>.......................] - ETA: 1:19  [ loss=0.0132 ][Training] 16/57 [=======>......................] - ETA: 1:17  [ loss=0.1168 ][Training] 17/57 [=======>......................] - ETA: 1:14  [ loss=0.0149 ][Training] 18/57 [========>.....................] - ETA: 1:12  [ loss=0.4966 ][Training] 19/57 [=========>....................] - ETA: 1:11  [ loss=0.1659 ][Training] 20/57 [=========>....................] - ETA: 1:09  [ loss=0.0169 ][Training] 21/57 [==========>...................] - ETA: 1:07  [ loss=0.4651 ][Training] 22/57 [==========>...................] - ETA: 1:05  [ loss=0.9093 ][Training] 23/57 [===========>..................] - ETA: 1:03  [ loss=0.1007 ][Training] 24/57 [===========>..................] - ETA: 1:01  [ loss=0.0208 ][Training] 25/57 [============>.................] - ETA: 1:00  [ loss=0.0848 ][Training] 26/57 [============>.................] - ETA: 58s  [ loss=0.3047 ][Training] 27/57 [=============>................] - ETA: 56s  [ loss=0.3238 ][Training] 28/57 [=============>................] - ETA: 54s  [ loss=0.1828 ][Training] 29/57 [==============>...............] - ETA: 52s  [ loss=0.2236 ][Training] 30/57 [==============>...............] - ETA: 51s  [ loss=0.1828 ][Training] 31/57 [===============>..............] - ETA: 49s  [ loss=0.0208 ][Training] 32/57 [===============>..............] - ETA: 47s  [ loss=0.2831 ][Training] 33/57 [================>.............] - ETA: 45s  [ loss=0.0679 ][Training] 34/57 [================>.............] - ETA: 43s  [ loss=0.8817 ][Training] 35/57 [=================>............] - ETA: 41s  [ loss=0.0354 ][Training] 36/57 [=================>............] - ETA: 39s  [ loss=0.3820 ][Training] 37/57 [==================>...........] - ETA: 37s  [ loss=0.6417 ][Training] 38/57 [===================>..........] - ETA: 36s  [ loss=0.6481 ][Training] 39/57 [===================>..........] - ETA: 34s  [ loss=0.0201 ][Training] 40/57 [====================>.........] - ETA: 31s  [ loss=0.4550 ][Training] 41/57 [====================>.........] - ETA: 29s  [ loss=0.1373 ][Training] 42/57 [=====================>........] - ETA: 28s  [ loss=1.6211 ][Training] 43/57 [=====================>........] - ETA: 26s  [ loss=0.1009 ][Training] 44/57 [======================>.......] - ETA: 24s  [ loss=0.3909 ][Training] 45/57 [======================>.......] - ETA: 22s  [ loss=0.3629 ][Training] 46/57 [=======================>......] - ETA: 20s  [ loss=0.0224 ][Training] 47/57 [=======================>......] - ETA: 18s  [ loss=0.0213 ][Training] 48/57 [========================>.....] - ETA: 16s  [ loss=0.0268 ][Training] 49/57 [========================>.....] - ETA: 14s  [ loss=0.0306 ][Training] 50/57 [=========================>....] - ETA: 13s  [ loss=0.6946 ][Training] 51/57 [=========================>....] - ETA: 11s  [ loss=0.6012 ][Training] 52/57 [==========================>...] - ETA: 9s  [ loss=0.0091 ][Training] 53/57 [==========================>...] - ETA: 7s  [ loss=0.4056 ][Training] 54/57 [===========================>..] - ETA: 5s  [ loss=0.8652 ][Training] 55/57 [===========================>..] - ETA: 3s  [ loss=0.3113 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.0129 ][Training] 57/57 [==============================] 1.9s/step  [ loss=0.0078 ]
01/03/2024 22:18:13 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 22:18:13 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 22:18:13 - INFO - root -     Num examples = 269
01/03/2024 22:18:13 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 6s[Evaluating] 2/12 [====>.........................] - ETA: 6s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 582.1ms/step
01/03/2024 22:18:20 - INFO - root -   

01/03/2024 22:18:20 - INFO - root -   ***** Eval results  *****
01/03/2024 22:18:20 - INFO - root -    acc: 0.7284 - recall: 0.6949 - f1: 0.7113 - loss: 8.4476 
01/03/2024 22:18:20 - INFO - root -   ***** Entity results  *****
01/03/2024 22:18:20 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 22:18:20 - INFO - root -    acc: 0.8113 - recall: 0.9149 - f1: 0.8600 
01/03/2024 22:18:20 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 22:18:20 - INFO - root -    acc: 1.0000 - recall: 0.5000 - f1: 0.6667 
01/03/2024 22:18:20 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 22:18:20 - INFO - root -    acc: 0.6923 - recall: 0.4737 - f1: 0.5625 
01/03/2024 22:18:20 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 22:18:20 - INFO - root -    acc: 0.3000 - recall: 0.3333 - f1: 0.3158 
01/03/2024 22:18:20 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 22:18:20 - INFO - root -    acc: 0.5806 - recall: 0.4615 - f1: 0.5143 
01/03/2024 22:18:20 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 22:18:20 - INFO - root -    acc: 0.7000 - recall: 0.4118 - f1: 0.5185 
01/03/2024 22:18:20 - INFO - root -   ******* PER.NAM results ********
01/03/2024 22:18:20 - INFO - root -    acc: 0.7642 - recall: 0.7364 - f1: 0.7500 
01/03/2024 22:18:20 - INFO - root -   ******* PER.NOM results ********
01/03/2024 22:18:20 - INFO - root -    acc: 0.7353 - recall: 0.7353 - f1: 0.7353 
01/03/2024 22:18:28 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2508
01/03/2024 22:18:28 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2508
01/03/2024 22:18:28 - INFO - root -   

01/03/2024 22:18:28 - INFO - root -   Backbone bert_estor_crf param is not freeze

Epoch: 44/50
[Training] 1/57 [..............................] - ETA: 1:29  [ loss=0.1340 ][Training] 2/57 [>.............................] - ETA: 1:35  [ loss=0.0122 ][Training] 3/57 [>.............................] - ETA: 1:37  [ loss=0.0959 ][Training] 4/57 [=>............................] - ETA: 1:37  [ loss=0.2403 ][Training] 5/57 [=>............................] - ETA: 1:34  [ loss=0.2849 ][Training] 6/57 [==>...........................] - ETA: 1:32  [ loss=0.0189 ][Training] 7/57 [==>...........................] - ETA: 1:30  [ loss=0.2074 ][Training] 8/57 [===>..........................] - ETA: 1:29  [ loss=0.3804 ][Training] 9/57 [===>..........................] - ETA: 1:27  [ loss=0.0139 ][Training] 10/57 [====>.........................] - ETA: 1:25  [ loss=0.0149 ][Training] 11/57 [====>.........................] - ETA: 1:23  [ loss=0.0948 ][Training] 12/57 [=====>........................] - ETA: 1:22  [ loss=0.3341 ][Training] 13/57 [=====>........................] - ETA: 1:21  [ loss=0.0579 ][Training] 14/57 [======>.......................] - ETA: 1:18  [ loss=0.0127 ][Training] 15/57 [======>.......................] - ETA: 1:16  [ loss=0.4417 ][Training] 16/57 [=======>......................] - ETA: 1:14  [ loss=0.0186 ][Training] 17/57 [=======>......................] - ETA: 1:12  [ loss=0.5229 ][Training] 18/57 [========>.....................] - ETA: 1:10  [ loss=0.0155 ][Training] 19/57 [=========>....................] - ETA: 1:09  [ loss=0.1016 ][Training] 20/57 [=========>....................] - ETA: 1:07  [ loss=0.0286 ][Training] 21/57 [==========>...................] - ETA: 1:05  [ loss=0.2783 ][Training] 22/57 [==========>...................] - ETA: 1:04  [ loss=0.0556 ][Training] 23/57 [===========>..................] - ETA: 1:01  [ loss=0.2344 ][Training] 24/57 [===========>..................] - ETA: 1:00  [ loss=0.1194 ][Training] 25/57 [============>.................] - ETA: 58s  [ loss=0.0118 ][Training] 26/57 [============>.................] - ETA: 57s  [ loss=0.0224 ][Training] 27/57 [=============>................] - ETA: 55s  [ loss=0.6642 ][Training] 28/57 [=============>................] - ETA: 53s  [ loss=0.3714 ][Training] 29/57 [==============>...............] - ETA: 52s  [ loss=0.1922 ][Training] 30/57 [==============>...............] - ETA: 50s  [ loss=0.2247 ][Training] 31/57 [===============>..............] - ETA: 48s  [ loss=0.4572 ][Training] 32/57 [===============>..............] - ETA: 47s  [ loss=0.0406 ][Training] 33/57 [================>.............] - ETA: 44s  [ loss=0.1511 ][Training] 34/57 [================>.............] - ETA: 42s  [ loss=0.2477 ][Training] 35/57 [=================>............] - ETA: 40s  [ loss=0.4845 ][Training] 36/57 [=================>............] - ETA: 38s  [ loss=0.0127 ][Training] 37/57 [==================>...........] - ETA: 36s  [ loss=0.0136 ][Training] 38/57 [===================>..........] - ETA: 34s  [ loss=1.0743 ][Training] 39/57 [===================>..........] - ETA: 33s  [ loss=0.0313 ][Training] 40/57 [====================>.........] - ETA: 31s  [ loss=0.1980 ][Training] 41/57 [====================>.........] - ETA: 29s  [ loss=0.8165 ][Training] 42/57 [=====================>........] - ETA: 27s  [ loss=0.0213 ][Training] 43/57 [=====================>........] - ETA: 25s  [ loss=0.5044 ][Training] 44/57 [======================>.......] - ETA: 24s  [ loss=0.1426 ][Training] 45/57 [======================>.......] - ETA: 22s  [ loss=0.0267 ][Training] 46/57 [=======================>......] - ETA: 20s  [ loss=0.5352 ][Training] 47/57 [=======================>......] - ETA: 18s  [ loss=0.1845 ][Training] 48/57 [========================>.....] - ETA: 16s  [ loss=0.1758 ][Training] 49/57 [========================>.....] - ETA: 14s  [ loss=0.0195 ][Training] 50/57 [=========================>....] - ETA: 12s  [ loss=0.3526 ][Training] 51/57 [=========================>....] - ETA: 11s  [ loss=0.0144 ][Training] 52/57 [==========================>...] - ETA: 9s  [ loss=0.0126 ][Training] 53/57 [==========================>...] - ETA: 7s  [ loss=0.4761 ][Training] 54/57 [===========================>..] - ETA: 5s  [ loss=0.7118 ][Training] 55/57 [===========================>..] - ETA: 3s  [ loss=0.0548 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.0129 ][Training] 57/57 [==============================] 1.8s/step  [ loss=0.0081 ]
01/03/2024 22:20:13 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 22:20:13 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 22:20:13 - INFO - root -     Num examples = 269
01/03/2024 22:20:13 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 5s[Evaluating] 2/12 [====>.........................] - ETA: 5s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 563.1ms/step
01/03/2024 22:20:20 - INFO - root -   

01/03/2024 22:20:20 - INFO - root -   ***** Eval results  *****
01/03/2024 22:20:20 - INFO - root -    acc: 0.7087 - recall: 0.7070 - f1: 0.7079 - loss: 8.5030 
01/03/2024 22:20:20 - INFO - root -   ***** Entity results  *****
01/03/2024 22:20:20 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 22:20:20 - INFO - root -    acc: 0.8113 - recall: 0.9149 - f1: 0.8600 
01/03/2024 22:20:20 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 22:20:20 - INFO - root -    acc: 1.0000 - recall: 0.5000 - f1: 0.6667 
01/03/2024 22:20:20 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 22:20:20 - INFO - root -    acc: 0.6000 - recall: 0.4737 - f1: 0.5294 
01/03/2024 22:20:20 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 22:20:20 - INFO - root -    acc: 0.3333 - recall: 0.3333 - f1: 0.3333 
01/03/2024 22:20:20 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 22:20:20 - INFO - root -    acc: 0.5294 - recall: 0.4615 - f1: 0.4932 
01/03/2024 22:20:20 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 22:20:20 - INFO - root -    acc: 0.7778 - recall: 0.4118 - f1: 0.5385 
01/03/2024 22:20:20 - INFO - root -   ******* PER.NAM results ********
01/03/2024 22:20:20 - INFO - root -    acc: 0.7523 - recall: 0.7455 - f1: 0.7489 
01/03/2024 22:20:20 - INFO - root -   ******* PER.NOM results ********
01/03/2024 22:20:20 - INFO - root -    acc: 0.7088 - recall: 0.7588 - f1: 0.7330 
01/03/2024 22:20:31 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2565
01/03/2024 22:20:31 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2565
01/03/2024 22:20:31 - INFO - root -   

01/03/2024 22:20:31 - INFO - root -   Backbone bert_estor_crf param is not freeze

Epoch: 45/50
[Training] 1/57 [..............................] - ETA: 1:38  [ loss=0.0196 ][Training] 2/57 [>.............................] - ETA: 1:29  [ loss=0.0288 ][Training] 3/57 [>.............................] - ETA: 1:23  [ loss=0.0557 ][Training] 4/57 [=>............................] - ETA: 1:18  [ loss=0.1636 ][Training] 5/57 [=>............................] - ETA: 1:20  [ loss=0.2744 ][Training] 6/57 [==>...........................] - ETA: 1:19  [ loss=0.0828 ][Training] 7/57 [==>...........................] - ETA: 1:21  [ loss=0.0631 ][Training] 8/57 [===>..........................] - ETA: 1:22  [ loss=0.1361 ][Training] 9/57 [===>..........................] - ETA: 1:21  [ loss=0.1226 ][Training] 10/57 [====>.........................] - ETA: 1:20  [ loss=0.0506 ][Training] 11/57 [====>.........................] - ETA: 1:17  [ loss=0.0073 ][Training] 12/57 [=====>........................] - ETA: 1:16  [ loss=0.0219 ][Training] 13/57 [=====>........................] - ETA: 1:15  [ loss=0.0139 ][Training] 14/57 [======>.......................] - ETA: 1:14  [ loss=0.0369 ][Training] 15/57 [======>.......................] - ETA: 1:12  [ loss=0.0654 ][Training] 16/57 [=======>......................] - ETA: 1:11  [ loss=0.0418 ][Training] 17/57 [=======>......................] - ETA: 1:08  [ loss=0.3076 ][Training] 18/57 [========>.....................] - ETA: 1:07  [ loss=0.0148 ][Training] 19/57 [=========>....................] - ETA: 1:05  [ loss=0.2957 ][Training] 20/57 [=========>....................] - ETA: 1:04  [ loss=0.0516 ][Training] 21/57 [==========>...................] - ETA: 1:03  [ loss=0.4454 ][Training] 22/57 [==========>...................] - ETA: 1:01  [ loss=0.1354 ][Training] 23/57 [===========>..................] - ETA: 1:00  [ loss=0.0110 ][Training] 24/57 [===========>..................] - ETA: 58s  [ loss=0.0343 ][Training] 25/57 [============>.................] - ETA: 56s  [ loss=0.0099 ][Training] 26/57 [============>.................] - ETA: 55s  [ loss=0.2925 ][Training] 27/57 [=============>................] - ETA: 53s  [ loss=0.0110 ][Training] 28/57 [=============>................] - ETA: 51s  [ loss=0.0378 ][Training] 29/57 [==============>...............] - ETA: 49s  [ loss=0.0086 ][Training] 30/57 [==============>...............] - ETA: 48s  [ loss=0.0448 ][Training] 31/57 [===============>..............] - ETA: 46s  [ loss=0.1463 ][Training] 32/57 [===============>..............] - ETA: 44s  [ loss=0.9709 ][Training] 33/57 [================>.............] - ETA: 43s  [ loss=0.3655 ][Training] 34/57 [================>.............] - ETA: 41s  [ loss=0.1333 ][Training] 35/57 [=================>............] - ETA: 39s  [ loss=0.2208 ][Training] 36/57 [=================>............] - ETA: 38s  [ loss=0.2671 ][Training] 37/57 [==================>...........] - ETA: 36s  [ loss=0.1212 ][Training] 38/57 [===================>..........] - ETA: 34s  [ loss=0.8401 ][Training] 39/57 [===================>..........] - ETA: 32s  [ loss=0.3262 ][Training] 40/57 [====================>.........] - ETA: 30s  [ loss=0.2469 ][Training] 41/57 [====================>.........] - ETA: 28s  [ loss=0.0248 ][Training] 42/57 [=====================>........] - ETA: 26s  [ loss=0.0098 ][Training] 43/57 [=====================>........] - ETA: 25s  [ loss=0.7892 ][Training] 44/57 [======================>.......] - ETA: 23s  [ loss=0.2678 ][Training] 45/57 [======================>.......] - ETA: 21s  [ loss=0.2541 ][Training] 46/57 [=======================>......] - ETA: 19s  [ loss=0.2633 ][Training] 47/57 [=======================>......] - ETA: 18s  [ loss=0.5244 ][Training] 48/57 [========================>.....] - ETA: 16s  [ loss=0.2836 ][Training] 49/57 [========================>.....] - ETA: 14s  [ loss=0.7120 ][Training] 50/57 [=========================>....] - ETA: 12s  [ loss=0.0978 ][Training] 51/57 [=========================>....] - ETA: 10s  [ loss=0.1857 ][Training] 52/57 [==========================>...] - ETA: 9s  [ loss=0.2468 ][Training] 53/57 [==========================>...] - ETA: 7s  [ loss=0.0108 ][Training] 54/57 [===========================>..] - ETA: 5s  [ loss=0.2846 ][Training] 55/57 [===========================>..] - ETA: 3s  [ loss=0.5379 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.4617 ][Training] 57/57 [==============================] 1.8s/step  [ loss=0.0113 ]
01/03/2024 22:22:14 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 22:22:14 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 22:22:14 - INFO - root -     Num examples = 269
01/03/2024 22:22:14 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 8s[Evaluating] 2/12 [====>.........................] - ETA: 6s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 5s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 577.3ms/step
01/03/2024 22:22:21 - INFO - root -   

01/03/2024 22:22:21 - INFO - root -   ***** Eval results  *****
01/03/2024 22:22:21 - INFO - root -    acc: 0.7226 - recall: 0.6877 - f1: 0.7047 - loss: 8.7729 
01/03/2024 22:22:21 - INFO - root -   ***** Entity results  *****
01/03/2024 22:22:21 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 22:22:21 - INFO - root -    acc: 0.7679 - recall: 0.9149 - f1: 0.8350 
01/03/2024 22:22:21 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 22:22:21 - INFO - root -    acc: 1.0000 - recall: 0.5000 - f1: 0.6667 
01/03/2024 22:22:21 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 22:22:21 - INFO - root -    acc: 0.7000 - recall: 0.3684 - f1: 0.4828 
01/03/2024 22:22:21 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 22:22:21 - INFO - root -    acc: 0.3333 - recall: 0.3333 - f1: 0.3333 
01/03/2024 22:22:21 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 22:22:21 - INFO - root -    acc: 0.6296 - recall: 0.4359 - f1: 0.5152 
01/03/2024 22:22:21 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 22:22:21 - INFO - root -    acc: 0.7778 - recall: 0.4118 - f1: 0.5385 
01/03/2024 22:22:21 - INFO - root -   ******* PER.NAM results ********
01/03/2024 22:22:21 - INFO - root -    acc: 0.7788 - recall: 0.7364 - f1: 0.7570 
01/03/2024 22:22:21 - INFO - root -   ******* PER.NOM results ********
01/03/2024 22:22:21 - INFO - root -    acc: 0.7062 - recall: 0.7353 - f1: 0.7205 
01/03/2024 22:22:28 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2622
01/03/2024 22:22:28 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2622
01/03/2024 22:22:28 - INFO - root -   

01/03/2024 22:22:29 - INFO - root -   Backbone bert_estor_crf param is not freeze

Epoch: 46/50
[Training] 1/57 [..............................] - ETA: 1:28  [ loss=0.0320 ][Training] 2/57 [>.............................] - ETA: 1:22  [ loss=0.0126 ][Training] 3/57 [>.............................] - ETA: 1:27  [ loss=0.0121 ][Training] 4/57 [=>............................] - ETA: 1:32  [ loss=0.0180 ][Training] 5/57 [=>............................] - ETA: 1:30  [ loss=0.3096 ][Training] 6/57 [==>...........................] - ETA: 1:32  [ loss=0.1087 ][Training] 7/57 [==>...........................] - ETA: 1:31  [ loss=0.0730 ][Training] 8/57 [===>..........................] - ETA: 1:29  [ loss=0.1036 ][Training] 9/57 [===>..........................] - ETA: 1:29  [ loss=0.1468 ][Training] 10/57 [====>.........................] - ETA: 1:26  [ loss=0.0107 ][Training] 11/57 [====>.........................] - ETA: 1:24  [ loss=0.2050 ][Training] 12/57 [=====>........................] - ETA: 1:22  [ loss=0.2149 ][Training] 13/57 [=====>........................] - ETA: 1:18  [ loss=0.2137 ][Training] 14/57 [======>.......................] - ETA: 1:16  [ loss=0.4398 ][Training] 15/57 [======>.......................] - ETA: 1:14  [ loss=0.0531 ][Training] 16/57 [=======>......................] - ETA: 1:13  [ loss=0.4295 ][Training] 17/57 [=======>......................] - ETA: 1:11  [ loss=0.0172 ][Training] 18/57 [========>.....................] - ETA: 1:09  [ loss=0.1921 ][Training] 19/57 [=========>....................] - ETA: 1:07  [ loss=0.0122 ][Training] 20/57 [=========>....................] - ETA: 1:05  [ loss=0.0805 ][Training] 21/57 [==========>...................] - ETA: 1:03  [ loss=0.0776 ][Training] 22/57 [==========>...................] - ETA: 1:02  [ loss=0.2059 ][Training] 23/57 [===========>..................] - ETA: 1:00  [ loss=0.2924 ][Training] 24/57 [===========>..................] - ETA: 59s  [ loss=0.1694 ][Training] 25/57 [============>.................] - ETA: 57s  [ loss=0.6249 ][Training] 26/57 [============>.................] - ETA: 56s  [ loss=0.0700 ][Training] 27/57 [=============>................] - ETA: 54s  [ loss=0.7068 ][Training] 28/57 [=============>................] - ETA: 52s  [ loss=0.0202 ][Training] 29/57 [==============>...............] - ETA: 50s  [ loss=0.3021 ][Training] 30/57 [==============>...............] - ETA: 49s  [ loss=0.0160 ][Training] 31/57 [===============>..............] - ETA: 47s  [ loss=0.1013 ][Training] 32/57 [===============>..............] - ETA: 45s  [ loss=0.3824 ][Training] 33/57 [================>.............] - ETA: 43s  [ loss=0.1325 ][Training] 34/57 [================>.............] - ETA: 41s  [ loss=0.2266 ][Training] 35/57 [=================>............] - ETA: 40s  [ loss=0.0269 ][Training] 36/57 [=================>............] - ETA: 38s  [ loss=0.1307 ][Training] 37/57 [==================>...........] - ETA: 36s  [ loss=0.3744 ][Training] 38/57 [===================>..........] - ETA: 34s  [ loss=0.0938 ][Training] 39/57 [===================>..........] - ETA: 32s  [ loss=0.0068 ][Training] 40/57 [====================>.........] - ETA: 30s  [ loss=0.0108 ][Training] 41/57 [====================>.........] - ETA: 28s  [ loss=0.0067 ][Training] 42/57 [=====================>........] - ETA: 27s  [ loss=0.0082 ][Training] 43/57 [=====================>........] - ETA: 25s  [ loss=0.0146 ][Training] 44/57 [======================>.......] - ETA: 23s  [ loss=0.1829 ][Training] 45/57 [======================>.......] - ETA: 21s  [ loss=0.5540 ][Training] 46/57 [=======================>......] - ETA: 19s  [ loss=0.1951 ][Training] 47/57 [=======================>......] - ETA: 18s  [ loss=0.2637 ][Training] 48/57 [========================>.....] - ETA: 16s  [ loss=0.5107 ][Training] 49/57 [========================>.....] - ETA: 14s  [ loss=1.3426 ][Training] 50/57 [=========================>....] - ETA: 12s  [ loss=0.0463 ][Training] 51/57 [=========================>....] - ETA: 10s  [ loss=0.0114 ][Training] 52/57 [==========================>...] - ETA: 9s  [ loss=0.2584 ][Training] 53/57 [==========================>...] - ETA: 7s  [ loss=0.1547 ][Training] 54/57 [===========================>..] - ETA: 5s  [ loss=0.1480 ][Training] 55/57 [===========================>..] - ETA: 3s  [ loss=0.3332 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.5317 ][Training] 57/57 [==============================] 1.8s/step  [ loss=0.0042 ]
01/03/2024 22:24:10 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 22:24:11 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 22:24:11 - INFO - root -     Num examples = 269
01/03/2024 22:24:11 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 8s[Evaluating] 2/12 [====>.........................] - ETA: 6s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 578.6ms/step
01/03/2024 22:24:17 - INFO - root -   

01/03/2024 22:24:17 - INFO - root -   ***** Eval results  *****
01/03/2024 22:24:17 - INFO - root -    acc: 0.7308 - recall: 0.6901 - f1: 0.7098 - loss: 8.8387 
01/03/2024 22:24:17 - INFO - root -   ***** Entity results  *****
01/03/2024 22:24:17 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 22:24:17 - INFO - root -    acc: 0.7818 - recall: 0.9149 - f1: 0.8431 
01/03/2024 22:24:17 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 22:24:17 - INFO - root -    acc: 1.0000 - recall: 0.5000 - f1: 0.6667 
01/03/2024 22:24:17 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 22:24:17 - INFO - root -    acc: 0.5455 - recall: 0.3158 - f1: 0.4000 
01/03/2024 22:24:17 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 22:24:17 - INFO - root -    acc: 0.4286 - recall: 0.3333 - f1: 0.3750 
01/03/2024 22:24:17 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 22:24:17 - INFO - root -    acc: 0.6429 - recall: 0.4615 - f1: 0.5373 
01/03/2024 22:24:17 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 22:24:17 - INFO - root -    acc: 0.7778 - recall: 0.4118 - f1: 0.5385 
01/03/2024 22:24:17 - INFO - root -   ******* PER.NAM results ********
01/03/2024 22:24:17 - INFO - root -    acc: 0.7714 - recall: 0.7364 - f1: 0.7535 
01/03/2024 22:24:17 - INFO - root -   ******* PER.NOM results ********
01/03/2024 22:24:17 - INFO - root -    acc: 0.7241 - recall: 0.7412 - f1: 0.7326 
01/03/2024 22:24:36 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2679
01/03/2024 22:24:36 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2679
01/03/2024 22:24:36 - INFO - root -   

01/03/2024 22:24:36 - INFO - root -   Backbone bert_estor_crf param is not freeze

Epoch: 47/50
[Training] 1/57 [..............................] - ETA: 1:39  [ loss=0.2202 ][Training] 2/57 [>.............................] - ETA: 1:42  [ loss=0.0831 ][Training] 3/57 [>.............................] - ETA: 1:33  [ loss=0.0116 ][Training] 4/57 [=>............................] - ETA: 1:32  [ loss=0.0085 ][Training] 5/57 [=>............................] - ETA: 1:33  [ loss=0.1352 ][Training] 6/57 [==>...........................] - ETA: 1:33  [ loss=0.5506 ][Training] 7/57 [==>...........................] - ETA: 1:31  [ loss=0.0060 ][Training] 8/57 [===>..........................] - ETA: 1:32  [ loss=0.1432 ][Training] 9/57 [===>..........................] - ETA: 1:29  [ loss=0.0099 ][Training] 10/57 [====>.........................] - ETA: 1:27  [ loss=0.1810 ][Training] 11/57 [====>.........................] - ETA: 1:25  [ loss=0.1527 ][Training] 12/57 [=====>........................] - ETA: 1:22  [ loss=0.0663 ][Training] 13/57 [=====>........................] - ETA: 1:19  [ loss=0.0332 ][Training] 14/57 [======>.......................] - ETA: 1:18  [ loss=0.0568 ][Training] 15/57 [======>.......................] - ETA: 1:16  [ loss=0.1917 ][Training] 16/57 [=======>......................] - ETA: 1:14  [ loss=0.1623 ][Training] 17/57 [=======>......................] - ETA: 1:12  [ loss=0.0632 ][Training] 18/57 [========>.....................] - ETA: 1:10  [ loss=0.1472 ][Training] 19/57 [=========>....................] - ETA: 1:08  [ loss=0.0462 ][Training] 20/57 [=========>....................] - ETA: 1:07  [ loss=0.2122 ][Training] 21/57 [==========>...................] - ETA: 1:05  [ loss=0.2898 ][Training] 22/57 [==========>...................] - ETA: 1:03  [ loss=0.5136 ][Training] 23/57 [===========>..................] - ETA: 1:01  [ loss=0.0167 ][Training] 24/57 [===========>..................] - ETA: 1:00  [ loss=0.1460 ][Training] 25/57 [============>.................] - ETA: 58s  [ loss=0.2082 ][Training] 26/57 [============>.................] - ETA: 56s  [ loss=0.1611 ][Training] 27/57 [=============>................] - ETA: 54s  [ loss=0.1900 ][Training] 28/57 [=============>................] - ETA: 53s  [ loss=0.2051 ][Training] 29/57 [==============>...............] - ETA: 51s  [ loss=0.2123 ][Training] 30/57 [==============>...............] - ETA: 49s  [ loss=0.5135 ][Training] 31/57 [===============>..............] - ETA: 47s  [ loss=0.1434 ][Training] 32/57 [===============>..............] - ETA: 45s  [ loss=0.0121 ][Training] 33/57 [================>.............] - ETA: 44s  [ loss=0.0729 ][Training] 34/57 [================>.............] - ETA: 41s  [ loss=0.1974 ][Training] 35/57 [=================>............] - ETA: 40s  [ loss=0.0179 ][Training] 36/57 [=================>............] - ETA: 38s  [ loss=0.5720 ][Training] 37/57 [==================>...........] - ETA: 36s  [ loss=0.0707 ][Training] 38/57 [===================>..........] - ETA: 34s  [ loss=0.0078 ][Training] 39/57 [===================>..........] - ETA: 32s  [ loss=0.1879 ][Training] 40/57 [====================>.........] - ETA: 31s  [ loss=0.0181 ][Training] 41/57 [====================>.........] - ETA: 29s  [ loss=0.1070 ][Training] 42/57 [=====================>........] - ETA: 27s  [ loss=0.1239 ][Training] 43/57 [=====================>........] - ETA: 25s  [ loss=0.2268 ][Training] 44/57 [======================>.......] - ETA: 24s  [ loss=0.2047 ][Training] 45/57 [======================>.......] - ETA: 22s  [ loss=0.1609 ][Training] 46/57 [=======================>......] - ETA: 20s  [ loss=0.2894 ][Training] 47/57 [=======================>......] - ETA: 18s  [ loss=0.2306 ][Training] 48/57 [========================>.....] - ETA: 16s  [ loss=0.0135 ][Training] 49/57 [========================>.....] - ETA: 14s  [ loss=0.0860 ][Training] 50/57 [=========================>....] - ETA: 12s  [ loss=0.1415 ][Training] 51/57 [=========================>....] - ETA: 11s  [ loss=0.1773 ][Training] 52/57 [==========================>...] - ETA: 9s  [ loss=0.4108 ][Training] 53/57 [==========================>...] - ETA: 7s  [ loss=0.0575 ][Training] 54/57 [===========================>..] - ETA: 5s  [ loss=0.3413 ][Training] 55/57 [===========================>..] - ETA: 3s  [ loss=0.0178 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.0149 ][Training] 57/57 [==============================] 1.8s/step  [ loss=0.0157 ]
01/03/2024 22:26:18 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 22:26:18 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 22:26:18 - INFO - root -     Num examples = 269
01/03/2024 22:26:18 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 6s[Evaluating] 2/12 [====>.........................] - ETA: 6s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 2s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 571.3ms/step
01/03/2024 22:26:25 - INFO - root -   

01/03/2024 22:26:25 - INFO - root -   ***** Eval results  *****
01/03/2024 22:26:25 - INFO - root -    acc: 0.7263 - recall: 0.6877 - f1: 0.7065 - loss: 8.9421 
01/03/2024 22:26:25 - INFO - root -   ***** Entity results  *****
01/03/2024 22:26:25 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 22:26:25 - INFO - root -    acc: 0.7818 - recall: 0.9149 - f1: 0.8431 
01/03/2024 22:26:25 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 22:26:25 - INFO - root -    acc: 1.0000 - recall: 0.5000 - f1: 0.6667 
01/03/2024 22:26:25 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 22:26:25 - INFO - root -    acc: 0.5455 - recall: 0.3158 - f1: 0.4000 
01/03/2024 22:26:25 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 22:26:25 - INFO - root -    acc: 0.4286 - recall: 0.3333 - f1: 0.3750 
01/03/2024 22:26:25 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 22:26:25 - INFO - root -    acc: 0.6154 - recall: 0.4103 - f1: 0.4923 
01/03/2024 22:26:25 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 22:26:25 - INFO - root -    acc: 0.7778 - recall: 0.4118 - f1: 0.5385 
01/03/2024 22:26:25 - INFO - root -   ******* PER.NAM results ********
01/03/2024 22:26:25 - INFO - root -    acc: 0.7941 - recall: 0.7364 - f1: 0.7642 
01/03/2024 22:26:25 - INFO - root -   ******* PER.NOM results ********
01/03/2024 22:26:25 - INFO - root -    acc: 0.7056 - recall: 0.7471 - f1: 0.7257 
01/03/2024 22:26:34 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2736
01/03/2024 22:26:34 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2736
01/03/2024 22:26:34 - INFO - root -   

01/03/2024 22:26:34 - INFO - root -   Backbone bert_estor_crf param is not freeze

Epoch: 48/50
[Training] 1/57 [..............................] - ETA: 1:40  [ loss=0.0568 ][Training] 2/57 [>.............................] - ETA: 1:36  [ loss=0.4415 ][Training] 3/57 [>.............................] - ETA: 1:36  [ loss=0.0650 ][Training] 4/57 [=>............................] - ETA: 1:37  [ loss=0.0366 ][Training] 5/57 [=>............................] - ETA: 1:32  [ loss=0.1032 ][Training] 6/57 [==>...........................] - ETA: 1:28  [ loss=0.0814 ][Training] 7/57 [==>...........................] - ETA: 1:30  [ loss=0.1199 ][Training] 8/57 [===>..........................] - ETA: 1:29  [ loss=0.0759 ][Training] 9/57 [===>..........................] - ETA: 1:28  [ loss=0.0119 ][Training] 10/57 [====>.........................] - ETA: 1:26  [ loss=0.2017 ][Training] 11/57 [====>.........................] - ETA: 1:24  [ loss=0.0917 ][Training] 12/57 [=====>........................] - ETA: 1:23  [ loss=0.2334 ][Training] 13/57 [=====>........................] - ETA: 1:22  [ loss=0.1335 ][Training] 14/57 [======>.......................] - ETA: 1:20  [ loss=0.2396 ][Training] 15/57 [======>.......................] - ETA: 1:18  [ loss=0.0462 ][Training] 16/57 [=======>......................] - ETA: 1:16  [ loss=0.0136 ][Training] 17/57 [=======>......................] - ETA: 1:15  [ loss=0.3348 ][Training] 18/57 [========>.....................] - ETA: 1:12  [ loss=0.0842 ][Training] 19/57 [=========>....................] - ETA: 1:09  [ loss=0.1579 ][Training] 20/57 [=========>....................] - ETA: 1:07  [ loss=0.0118 ][Training] 21/57 [==========>...................] - ETA: 1:06  [ loss=0.2749 ][Training] 22/57 [==========>...................] - ETA: 1:04  [ loss=0.1171 ][Training] 23/57 [===========>..................] - ETA: 1:02  [ loss=0.3806 ][Training] 24/57 [===========>..................] - ETA: 1:00  [ loss=0.4790 ][Training] 25/57 [============>.................] - ETA: 59s  [ loss=0.0161 ][Training] 26/57 [============>.................] - ETA: 57s  [ loss=0.3539 ][Training] 27/57 [=============>................] - ETA: 55s  [ loss=0.1500 ][Training] 28/57 [=============>................] - ETA: 53s  [ loss=0.0122 ][Training] 29/57 [==============>...............] - ETA: 51s  [ loss=0.1920 ][Training] 30/57 [==============>...............] - ETA: 50s  [ loss=0.0471 ][Training] 31/57 [===============>..............] - ETA: 48s  [ loss=0.0093 ][Training] 32/57 [===============>..............] - ETA: 46s  [ loss=0.3141 ][Training] 33/57 [================>.............] - ETA: 44s  [ loss=0.0110 ][Training] 34/57 [================>.............] - ETA: 42s  [ loss=0.2096 ][Training] 35/57 [=================>............] - ETA: 40s  [ loss=0.0907 ][Training] 36/57 [=================>............] - ETA: 39s  [ loss=0.1867 ][Training] 37/57 [==================>...........] - ETA: 37s  [ loss=0.0838 ][Training] 38/57 [===================>..........] - ETA: 35s  [ loss=0.5187 ][Training] 39/57 [===================>..........] - ETA: 33s  [ loss=0.1592 ][Training] 40/57 [====================>.........] - ETA: 31s  [ loss=0.0137 ][Training] 41/57 [====================>.........] - ETA: 29s  [ loss=0.0129 ][Training] 42/57 [=====================>........] - ETA: 27s  [ loss=0.0076 ][Training] 43/57 [=====================>........] - ETA: 26s  [ loss=0.0125 ][Training] 44/57 [======================>.......] - ETA: 24s  [ loss=0.0527 ][Training] 45/57 [======================>.......] - ETA: 22s  [ loss=0.0158 ][Training] 46/57 [=======================>......] - ETA: 20s  [ loss=0.0802 ][Training] 47/57 [=======================>......] - ETA: 18s  [ loss=0.1808 ][Training] 48/57 [========================>.....] - ETA: 16s  [ loss=0.3811 ][Training] 49/57 [========================>.....] - ETA: 14s  [ loss=0.1728 ][Training] 50/57 [=========================>....] - ETA: 12s  [ loss=0.0065 ][Training] 51/57 [=========================>....] - ETA: 11s  [ loss=0.0540 ][Training] 52/57 [==========================>...] - ETA: 9s  [ loss=0.3112 ][Training] 53/57 [==========================>...] - ETA: 7s  [ loss=0.0752 ][Training] 54/57 [===========================>..] - ETA: 5s  [ loss=0.0105 ][Training] 55/57 [===========================>..] - ETA: 3s  [ loss=0.1915 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.0091 ][Training] 57/57 [==============================] 1.8s/step  [ loss=0.1095 ]
01/03/2024 22:28:19 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 22:28:19 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 22:28:19 - INFO - root -     Num examples = 269
01/03/2024 22:28:19 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 6s[Evaluating] 2/12 [====>.........................] - ETA: 5s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 588.2ms/step
01/03/2024 22:28:26 - INFO - root -   

01/03/2024 22:28:26 - INFO - root -   ***** Eval results  *****
01/03/2024 22:28:26 - INFO - root -    acc: 0.7193 - recall: 0.6949 - f1: 0.7069 - loss: 8.8346 
01/03/2024 22:28:26 - INFO - root -   ***** Entity results  *****
01/03/2024 22:28:26 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 22:28:26 - INFO - root -    acc: 0.7818 - recall: 0.9149 - f1: 0.8431 
01/03/2024 22:28:26 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 22:28:26 - INFO - root -    acc: 1.0000 - recall: 0.5000 - f1: 0.6667 
01/03/2024 22:28:26 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 22:28:26 - INFO - root -    acc: 0.5833 - recall: 0.3684 - f1: 0.4516 
01/03/2024 22:28:26 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 22:28:26 - INFO - root -    acc: 0.3333 - recall: 0.3333 - f1: 0.3333 
01/03/2024 22:28:26 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 22:28:26 - INFO - root -    acc: 0.6207 - recall: 0.4615 - f1: 0.5294 
01/03/2024 22:28:26 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 22:28:26 - INFO - root -    acc: 0.7000 - recall: 0.4118 - f1: 0.5185 
01/03/2024 22:28:26 - INFO - root -   ******* PER.NAM results ********
01/03/2024 22:28:26 - INFO - root -    acc: 0.7593 - recall: 0.7455 - f1: 0.7523 
01/03/2024 22:28:26 - INFO - root -   ******* PER.NOM results ********
01/03/2024 22:28:26 - INFO - root -    acc: 0.7200 - recall: 0.7412 - f1: 0.7304 
01/03/2024 22:28:38 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2793
01/03/2024 22:28:38 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2793
01/03/2024 22:28:38 - INFO - root -   

01/03/2024 22:28:38 - INFO - root -   Backbone bert_estor_crf param is not freeze

Epoch: 49/50
[Training] 1/57 [..............................] - ETA: 1:38  [ loss=0.0104 ][Training] 2/57 [>.............................] - ETA: 1:33  [ loss=0.0298 ][Training] 3/57 [>.............................] - ETA: 1:33  [ loss=0.0587 ][Training] 4/57 [=>............................] - ETA: 1:32  [ loss=0.0959 ][Training] 5/57 [=>............................] - ETA: 1:31  [ loss=0.1693 ][Training] 6/57 [==>...........................] - ETA: 1:29  [ loss=0.1060 ][Training] 7/57 [==>...........................] - ETA: 1:27  [ loss=0.1237 ][Training] 8/57 [===>..........................] - ETA: 1:26  [ loss=0.1633 ][Training] 9/57 [===>..........................] - ETA: 1:23  [ loss=0.4227 ][Training] 10/57 [====>.........................] - ETA: 1:23  [ loss=0.2641 ][Training] 11/57 [====>.........................] - ETA: 1:21  [ loss=0.0150 ][Training] 12/57 [=====>........................] - ETA: 1:21  [ loss=0.0130 ][Training] 13/57 [=====>........................] - ETA: 1:19  [ loss=0.2706 ][Training] 14/57 [======>.......................] - ETA: 1:18  [ loss=0.1398 ][Training] 15/57 [======>.......................] - ETA: 1:16  [ loss=0.1165 ][Training] 16/57 [=======>......................] - ETA: 1:15  [ loss=0.1358 ][Training] 17/57 [=======>......................] - ETA: 1:14  [ loss=0.0705 ][Training] 18/57 [========>.....................] - ETA: 1:12  [ loss=0.0894 ][Training] 19/57 [=========>....................] - ETA: 1:10  [ loss=0.4031 ][Training] 20/57 [=========>....................] - ETA: 1:07  [ loss=0.1260 ][Training] 21/57 [==========>...................] - ETA: 1:06  [ loss=0.0823 ][Training] 22/57 [==========>...................] - ETA: 1:05  [ loss=0.1385 ][Training] 23/57 [===========>..................] - ETA: 1:03  [ loss=0.0072 ][Training] 24/57 [===========>..................] - ETA: 1:01  [ loss=0.1826 ][Training] 25/57 [============>.................] - ETA: 58s  [ loss=0.0609 ][Training] 26/57 [============>.................] - ETA: 56s  [ loss=0.0120 ][Training] 27/57 [=============>................] - ETA: 54s  [ loss=0.4232 ][Training] 28/57 [=============>................] - ETA: 52s  [ loss=0.0093 ][Training] 29/57 [==============>...............] - ETA: 51s  [ loss=0.1600 ][Training] 30/57 [==============>...............] - ETA: 49s  [ loss=0.2903 ][Training] 31/57 [===============>..............] - ETA: 48s  [ loss=0.4273 ][Training] 32/57 [===============>..............] - ETA: 46s  [ loss=0.0133 ][Training] 33/57 [================>.............] - ETA: 44s  [ loss=0.0082 ][Training] 34/57 [================>.............] - ETA: 42s  [ loss=0.0105 ][Training] 35/57 [=================>............] - ETA: 40s  [ loss=0.1759 ][Training] 36/57 [=================>............] - ETA: 38s  [ loss=0.0193 ][Training] 37/57 [==================>...........] - ETA: 36s  [ loss=0.0717 ][Training] 38/57 [===================>..........] - ETA: 35s  [ loss=0.0331 ][Training] 39/57 [===================>..........] - ETA: 33s  [ loss=0.3111 ][Training] 40/57 [====================>.........] - ETA: 31s  [ loss=0.0143 ][Training] 41/57 [====================>.........] - ETA: 29s  [ loss=0.0796 ][Training] 42/57 [=====================>........] - ETA: 27s  [ loss=0.0761 ][Training] 43/57 [=====================>........] - ETA: 25s  [ loss=0.1366 ][Training] 44/57 [======================>.......] - ETA: 24s  [ loss=0.3045 ][Training] 45/57 [======================>.......] - ETA: 22s  [ loss=0.0551 ][Training] 46/57 [=======================>......] - ETA: 20s  [ loss=0.2237 ][Training] 47/57 [=======================>......] - ETA: 18s  [ loss=0.0102 ][Training] 48/57 [========================>.....] - ETA: 16s  [ loss=0.0181 ][Training] 49/57 [========================>.....] - ETA: 14s  [ loss=0.0502 ][Training] 50/57 [=========================>....] - ETA: 13s  [ loss=0.1356 ][Training] 51/57 [=========================>....] - ETA: 11s  [ loss=0.0077 ][Training] 52/57 [==========================>...] - ETA: 9s  [ loss=0.0100 ][Training] 53/57 [==========================>...] - ETA: 7s  [ loss=0.1694 ][Training] 54/57 [===========================>..] - ETA: 5s  [ loss=0.3353 ][Training] 55/57 [===========================>..] - ETA: 3s  [ loss=0.0933 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.0146 ][Training] 57/57 [==============================] 1.8s/step  [ loss=0.0211 ]
01/03/2024 22:30:22 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 22:30:22 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 22:30:22 - INFO - root -     Num examples = 269
01/03/2024 22:30:22 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 5s[Evaluating] 2/12 [====>.........................] - ETA: 5s[Evaluating] 3/12 [======>.......................] - ETA: 4s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 3s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 2s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 500.3ms/step
01/03/2024 22:30:28 - INFO - root -   

01/03/2024 22:30:28 - INFO - root -   ***** Eval results  *****
01/03/2024 22:30:28 - INFO - root -    acc: 0.7236 - recall: 0.6973 - f1: 0.7102 - loss: 8.8679 
01/03/2024 22:30:28 - INFO - root -   ***** Entity results  *****
01/03/2024 22:30:28 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 22:30:28 - INFO - root -    acc: 0.7818 - recall: 0.9149 - f1: 0.8431 
01/03/2024 22:30:28 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 22:30:28 - INFO - root -    acc: 1.0000 - recall: 0.5000 - f1: 0.6667 
01/03/2024 22:30:28 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 22:30:28 - INFO - root -    acc: 0.6667 - recall: 0.4211 - f1: 0.5161 
01/03/2024 22:30:28 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 22:30:28 - INFO - root -    acc: 0.3333 - recall: 0.3333 - f1: 0.3333 
01/03/2024 22:30:28 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 22:30:28 - INFO - root -    acc: 0.6429 - recall: 0.4615 - f1: 0.5373 
01/03/2024 22:30:28 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 22:30:28 - INFO - root -    acc: 0.7000 - recall: 0.4118 - f1: 0.5185 
01/03/2024 22:30:28 - INFO - root -   ******* PER.NAM results ********
01/03/2024 22:30:28 - INFO - root -    acc: 0.7593 - recall: 0.7455 - f1: 0.7523 
01/03/2024 22:30:28 - INFO - root -   ******* PER.NOM results ********
01/03/2024 22:30:28 - INFO - root -    acc: 0.7200 - recall: 0.7412 - f1: 0.7304 
01/03/2024 22:30:47 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2850
01/03/2024 22:30:47 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2850
01/03/2024 22:30:47 - INFO - root -   

01/03/2024 22:30:47 - INFO - root -    global_step = 2850, average loss = 2.1030991973030266
01/03/2024 22:30:47 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf
