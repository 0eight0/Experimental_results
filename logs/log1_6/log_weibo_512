nohup: ignoring input
01/06/2024 08:04:41 - WARNING - root -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
Some weights of BertEstorCrf were not initialized from the model checkpoint at /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/prev_trained_model/roberta-large-chinese and are newly initialized: ['estor.gate_linear.weight', 'estor.encoder.linear2.bias', 'crf.start_transitions', 'estor.encoder.self_attn.out_proj.bias', 'classifier.bias', 'estor.positional_embedding.embeddings', 'estor.self_attention.out_proj.weight', 'crf.end_transitions', 'estor.self_attention.in_proj_bias', 'estor.attention.out_proj.bias', 'estor.reshape_linear.weight', 'estor.encoder.linear2.weight', 'estor.encoder.norm2.bias', 'crf.transitions', 'estor.attention.in_proj_weight', 'estor.reshape_linear.bias', 'estor.self_attention.in_proj_weight', 'estor.att_norm.weight', 'estor.tag_embedding_layer.weight', 'estor.encoder.self_attn.out_proj.weight', 'estor.encoder.self_attn.in_proj_bias', 'estor.attention.in_proj_bias', 'estor.encoder.norm2.weight', 'estor.encoder.self_attn.in_proj_weight', 'estor.attention.out_proj.weight', 'classifier.weight', 'estor.att_norm.bias', 'estor.encoder.norm1.bias', 'estor.gate_linear.bias', 'estor.encoder.linear1.weight', 'estor.hidden_size_to_tag_hidden_size.weight', 'estor.encoder.linear1.bias', 'estor.encoder.norm1.weight', 'estor.self_attention.out_proj.bias', 'estor.hidden_size_to_tag_hidden_size.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/06/2024 08:04:52 - INFO - root -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, adv_epsilon=1.0, adv_name='word_embeddings', backbone='bert_estor_crf', cache_dir='', config_name='', contrastive_alpha=0.1, crf_learning_rate=0.001, data_dir='/mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/', device=device(type='cuda'), do_adv=False, do_eval=False, do_lower_case=True, do_predict=False, do_train=True, enumerate_mode='attention', eval_all_checkpoints=False, eval_max_seq_length=512, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', freeze_backbone_epoch=30, gate_dropout_rate=0.5, gate_scaling_rate=0.6, gradient_accumulation_steps=1, id2label={0: 'X', 1: 'O', 2: '[START]', 3: '[END]', 4: 'B-PER.NAM', 5: 'I-PER.NAM', 6: 'B-PER.NOM', 7: 'I-PER.NOM', 8: 'B-LOC.NAM', 9: 'I-LOC.NAM', 10: 'B-LOC.NOM', 11: 'I-LOC.NOM', 12: 'B-GPE.NAM', 13: 'I-GPE.NAM', 14: 'B-GPE.NOM', 15: 'I-GPE.NOM', 16: 'B-ORG.NAM', 17: 'I-ORG.NAM', 18: 'B-ORG.NOM', 19: 'I-ORG.NOM'}, id2tag={0: 'ORG.NAM', 1: 'GPE.NOM', 2: 'LOC.NOM', 3: 'PER.NOM', 4: 'ORG.NOM', 5: 'LOC.NAM', 6: 'PER.NAM', 7: 'GPE.NAM'}, if_add_a_self_attention=True, if_contrastive_learn=True, if_merge_by_add=True, label2id={'X': 0, 'O': 1, '[START]': 2, '[END]': 3, 'B-PER.NAM': 4, 'I-PER.NAM': 5, 'B-PER.NOM': 6, 'I-PER.NOM': 7, 'B-LOC.NAM': 8, 'I-LOC.NAM': 9, 'B-LOC.NOM': 10, 'I-LOC.NOM': 11, 'B-GPE.NAM': 12, 'I-GPE.NAM': 13, 'B-GPE.NOM': 14, 'I-GPE.NOM': 15, 'B-ORG.NAM': 16, 'I-ORG.NAM': 17, 'B-ORG.NOM': 18, 'I-ORG.NOM': 19}, learning_rate=3e-05, local_rank=-1, logging_steps=-1, loss_type='ce', markup='bio', max_grad_norm=1.0, max_steps=-1, model_name_or_path='/mnt/storage/wubinghong.wbh/deepl/torch_ner_new/prev_trained_model/roberta-large-chinese', n_gpu=1, no_cuda=False, num_train_epochs=50.0, output_dir='/mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=24, per_gpu_train_batch_size=24, pos_learning_rate=5e-05, predict_checkpoints=0, save_steps=-1, seed=42, tag2id={'ORG.NAM': 0, 'GPE.NOM': 1, 'LOC.NOM': 2, 'PER.NOM': 3, 'ORG.NOM': 4, 'LOC.NAM': 5, 'PER.NAM': 6, 'GPE.NAM': 7}, tagging_rate=1.0, task_name='weibo', tokenizer_name='', train_max_seq_length=512, warmup_proportion=0.1, weight_decay=0.01)
01/06/2024 08:04:52 - INFO - root -   Creating features from dataset file at /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/
['X', 'O', '[START]', '[END]', 'B-PER.NAM', 'I-PER.NAM', 'B-PER.NOM', 'I-PER.NOM', 'B-LOC.NAM', 'I-LOC.NAM', 'B-LOC.NOM', 'I-LOC.NOM', 'B-GPE.NAM', 'I-GPE.NAM', 'B-GPE.NOM', 'I-GPE.NOM', 'B-ORG.NAM', 'I-ORG.NAM', 'B-ORG.NOM', 'I-ORG.NOM'] ['ORG.NAM', 'GPE.NOM', 'LOC.NOM', 'PER.NOM', 'ORG.NOM', 'LOC.NAM', 'PER.NAM', 'GPE.NAM']
  0%|          | 0/8 [00:00<?, ?it/s]100%|██████████| 8/8 [00:00<00:00, 4249.01it/s]
  0%|          | 0/8 [00:00<?, ?it/s]100%|██████████| 8/8 [00:00<00:00, 7166.69it/s]
['ORG.NAM', 'GPE.NOM', 'LOC.NOM', 'PER.NOM', 'ORG.NOM', 'LOC.NAM', 'PER.NAM', 'GPE.NAM']
  0%|          | 0/1349 [00:00<?, ?it/s]01/06/2024 08:04:53 - INFO - processors.ner_seq -   Writing example 0 of 1349
01/06/2024 08:04:53 - INFO - processors.ner_seq -   *** Example ***
01/06/2024 08:04:53 - INFO - processors.ner_seq -   guid: train-1
01/06/2024 08:04:53 - INFO - processors.ner_seq -   tokens: [CLS] 对 ， 输 给 一 个 女 人 ， 的 成 绩 。 失 望 [SEP]
01/06/2024 08:04:53 - INFO - processors.ner_seq -   input_ids: 101 2190 8024 6783 5314 671 702 1957 782 8024 4638 2768 5327 511 1927 3307 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/06/2024 08:04:53 - INFO - processors.ner_seq -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/06/2024 08:04:53 - INFO - processors.ner_seq -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/06/2024 08:04:53 - INFO - processors.ner_seq -   label_ids: 1 1 1 1 1 1 1 6 7 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/06/2024 08:04:53 - INFO - processors.ner_seq -   idx: 0
01/06/2024 08:04:53 - INFO - processors.ner_seq -   tag_to_spans: defaultdict(<class 'list'>, {3: [[7, 8], [7, 9]], 6: [[18, 19]]})
01/06/2024 08:04:53 - INFO - processors.ner_seq -   *** Example ***
01/06/2024 08:04:53 - INFO - processors.ner_seq -   guid: train-2
01/06/2024 08:04:53 - INFO - processors.ner_seq -   tokens: [CLS] 今 天 下 午 起 来 看 到 外 面 的 太 阳 。 。 。 。 我 第 一 反 应 竟 然 是 强 烈 的 想 回 家 泪 想 我 们 一 起 在 嘉 鱼 个 时 候 了 。 。 。 。 有 好 多 好 多 的 话 想 对 你 说 李 巾 凡 想 要 瘦 瘦 瘦 成 李 帆 我 是 想 切 开 云 朵 的 心 [SEP]
01/06/2024 08:04:53 - INFO - processors.ner_seq -   input_ids: 101 791 1921 678 1286 6629 3341 4692 1168 1912 7481 4638 1922 7345 511 511 511 511 2769 5018 671 1353 2418 4994 4197 3221 2487 4164 4638 2682 1726 2157 3801 2682 2769 812 671 6629 1762 1649 7824 702 3198 952 749 511 511 511 511 3300 1962 1914 1962 1914 4638 6413 2682 2190 872 6432 3330 2353 1127 2682 6206 4607 4607 4607 2768 3330 2359 2769 3221 2682 1147 2458 756 3321 4638 2552 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/06/2024 08:04:53 - INFO - processors.ner_seq -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/06/2024 08:04:53 - INFO - processors.ner_seq -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/06/2024 08:04:53 - INFO - processors.ner_seq -   label_ids: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 8 9 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 5 5 1 1 1 1 1 1 4 5 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/06/2024 08:04:53 - INFO - processors.ner_seq -   idx: 1
01/06/2024 08:04:53 - INFO - processors.ner_seq -   tag_to_spans: defaultdict(<class 'list'>, {2: [[31, 32]], 6: [[76, 77], [82, 83], [69, 71], [60, 63]], 5: [[39, 41]]})
01/06/2024 08:04:53 - INFO - processors.ner_seq -   *** Example ***
01/06/2024 08:04:53 - INFO - processors.ner_seq -   guid: train-3
01/06/2024 08:04:53 - INFO - processors.ner_seq -   tokens: [CLS] 今 年 拜 年 不 短 信 ， 就 在 微 博 拜 大 年 寻 龙 记 [SEP]
01/06/2024 08:04:53 - INFO - processors.ner_seq -   input_ids: 101 791 2399 2876 2399 679 4764 928 8024 2218 1762 2544 1300 2876 1920 2399 2192 7987 6381 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/06/2024 08:04:53 - INFO - processors.ner_seq -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/06/2024 08:04:53 - INFO - processors.ner_seq -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/06/2024 08:04:53 - INFO - processors.ner_seq -   label_ids: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/06/2024 08:04:53 - INFO - processors.ner_seq -   idx: 2
01/06/2024 08:04:53 - INFO - processors.ner_seq -   tag_to_spans: defaultdict(<class 'list'>, {6: [[21, 22]]})
01/06/2024 08:04:53 - INFO - processors.ner_seq -   *** Example ***
01/06/2024 08:04:53 - INFO - processors.ner_seq -   guid: train-4
01/06/2024 08:04:53 - INFO - processors.ner_seq -   tokens: [CLS] 浑 身 酸 疼 ， 两 腿 无 力 ， 眼 神 呆 滞 ， 怎 么 了 [SEP]
01/06/2024 08:04:53 - INFO - processors.ner_seq -   input_ids: 101 3847 6716 7000 4563 8024 697 5597 3187 1213 8024 4706 4868 1438 4005 8024 2582 720 749 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/06/2024 08:04:53 - INFO - processors.ner_seq -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/06/2024 08:04:53 - INFO - processors.ner_seq -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/06/2024 08:04:53 - INFO - processors.ner_seq -   label_ids: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/06/2024 08:04:53 - INFO - processors.ner_seq -   idx: 3
01/06/2024 08:04:53 - INFO - processors.ner_seq -   tag_to_spans: defaultdict(<class 'list'>, {6: [[21, 22]]})
01/06/2024 08:04:53 - INFO - processors.ner_seq -   *** Example ***
01/06/2024 08:04:53 - INFO - processors.ner_seq -   guid: train-5
01/06/2024 08:04:53 - INFO - processors.ner_seq -   tokens: [CLS] 明 显 紧 张 状 态 没 出 来 ， 失 误 多 。 [SEP]
01/06/2024 08:04:53 - INFO - processors.ner_seq -   input_ids: 101 3209 3227 5165 2476 4307 2578 3766 1139 3341 8024 1927 6428 1914 511 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/06/2024 08:04:53 - INFO - processors.ner_seq -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/06/2024 08:04:53 - INFO - processors.ner_seq -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/06/2024 08:04:53 - INFO - processors.ner_seq -   label_ids: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/06/2024 08:04:53 - INFO - processors.ner_seq -   idx: 4
01/06/2024 08:04:53 - INFO - processors.ner_seq -   tag_to_spans: defaultdict(<class 'list'>, {6: [[17, 18]]})
 34%|███▍      | 463/1349 [00:00<00:00, 4623.32it/s] 69%|██████▊   | 926/1349 [00:00<00:00, 3486.86it/s] 96%|█████████▌| 1292/1349 [00:00<00:00, 2086.02it/s]100%|██████████| 1349/1349 [00:00<00:00, 2438.12it/s]
01/06/2024 08:04:53 - INFO - root -   Saving features into cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-train_roberta-large-chinese_512_weibo
01/06/2024 08:04:55 - INFO - root -   The model with entity_enumerator
/mnt/storage/wubinghong.wbh/project/pytorch-3.8/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
01/06/2024 08:04:55 - INFO - root -   ***** Running training *****
01/06/2024 08:04:55 - INFO - root -     Num examples = 1349
01/06/2024 08:04:55 - INFO - root -     Num Epochs = 50
01/06/2024 08:04:55 - INFO - root -     Instantaneous batch size per GPU = 24
01/06/2024 08:04:55 - INFO - root -     Total train batch size (w. parallel, distributed & accumulation) = 24
01/06/2024 08:04:55 - INFO - root -     Gradient Accumulation steps = 1
01/06/2024 08:04:55 - INFO - root -     Total optimization steps = 2850
01/06/2024 08:04:55 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 0/50
[Training] 1/57 [..............................] - ETA: 2:09  [ loss=239.4379 ][Training] 2/57 [>.............................] - ETA: 1:43  [ loss=183.2946 ][Training] 3/57 [>.............................] - ETA: 1:33  [ loss=123.4720 ][Training] 4/57 [=>............................] - ETA: 1:25  [ loss=57.1923 ][Training] 5/57 [=>............................] - ETA: 1:20  [ loss=49.5168 ][Training] 6/57 [==>...........................] - ETA: 1:18  [ loss=29.6996 ][Training] 7/57 [==>...........................] - ETA: 1:18  [ loss=35.9530 ][Training] 8/57 [===>..........................] - ETA: 1:14  [ loss=40.6213 ][Training] 9/57 [===>..........................] - ETA: 1:14  [ loss=33.1302 ][Training] 10/57 [====>.........................] - ETA: 1:10  [ loss=21.4588 ][Training] 11/57 [====>.........................] - ETA: 1:09  [ loss=40.4875 ][Training] 12/57 [=====>........................] - ETA: 1:07  [ loss=11.2557 ][Training] 13/57 [=====>........................] - ETA: 1:04  [ loss=27.9764 ][Training] 14/57 [======>.......................] - ETA: 1:01  [ loss=20.2817 ][Training] 15/57 [======>.......................] - ETA: 59s  [ loss=21.8183 ][Training] 16/57 [=======>......................] - ETA: 57s  [ loss=27.3083 ][Training] 17/57 [=======>......................] - ETA: 55s  [ loss=19.1861 ][Training] 18/57 [========>.....................] - ETA: 54s  [ loss=13.5022 ][Training] 19/57 [=========>....................] - ETA: 52s  [ loss=25.1731 ][Training] 20/57 [=========>....................] - ETA: 50s  [ loss=16.8527 ][Training] 21/57 [==========>...................] - ETA: 48s  [ loss=16.3885 ][Training] 22/57 [==========>...................] - ETA: 47s  [ loss=30.0623 ][Training] 23/57 [===========>..................] - ETA: 46s  [ loss=18.9087 ][Training] 24/57 [===========>..................] - ETA: 44s  [ loss=18.4488 ][Training] 25/57 [============>.................] - ETA: 43s  [ loss=14.1602 ][Training] 26/57 [============>.................] - ETA: 42s  [ loss=21.3850 ][Training] 27/57 [=============>................] - ETA: 40s  [ loss=12.5213 ][Training] 28/57 [=============>................] - ETA: 39s  [ loss=17.7033 ][Training] 29/57 [==============>...............] - ETA: 38s  [ loss=18.8399 ][Training] 30/57 [==============>...............] - ETA: 36s  [ loss=18.0530 ][Training] 31/57 [===============>..............] - ETA: 35s  [ loss=7.1497 ][Training] 32/57 [===============>..............] - ETA: 33s  [ loss=11.3276 ][Training] 33/57 [================>.............] - ETA: 32s  [ loss=11.9203 ][Training] 34/57 [================>.............] - ETA: 30s  [ loss=18.5230 ][Training] 35/57 [=================>............] - ETA: 29s  [ loss=14.8219 ][Training] 36/57 [=================>............] - ETA: 28s  [ loss=7.6847 ][Training] 37/57 [==================>...........] - ETA: 26s  [ loss=7.2947 ][Training] 38/57 [===================>..........] - ETA: 25s  [ loss=23.2685 ][Training] 39/57 [===================>..........] - ETA: 23s  [ loss=9.4989 ][Training] 40/57 [====================>.........] - ETA: 22s  [ loss=13.3176 ][Training] 41/57 [====================>.........] - ETA: 21s  [ loss=9.1770 ][Training] 42/57 [=====================>........] - ETA: 19s  [ loss=4.9384 ][Training] 43/57 [=====================>........] - ETA: 18s  [ loss=12.3122 ][Training] 44/57 [======================>.......] - ETA: 17s  [ loss=7.7166 ][Training] 45/57 [======================>.......] - ETA: 15s  [ loss=10.2054 ][Training] 46/57 [=======================>......] - ETA: 14s  [ loss=10.2822 ][Training] 47/57 [=======================>......] - ETA: 13s  [ loss=10.1203 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=7.8671 ][Training] 49/57 [========================>.....] - ETA: 10s  [ loss=14.2603 ][Training] 50/57 [=========================>....] - ETA: 9s  [ loss=9.1704 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=7.2131 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=10.6373 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=13.7575 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=11.0270 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=6.6064 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=7.2538 ][Training] 57/57 [==============================] 1.3s/step  [ loss=5.8679 ]
/mnt/storage/wubinghong.wbh/deepl/torch_ner_new/models/layers/crf.py:233: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at ../aten/src/ATen/native/TensorCompare.cpp:493.)
  score = torch.where(mask[i].unsqueeze(1), next_score, score)
01/06/2024 08:06:08 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/06/2024 08:06:08 - INFO - root -   ***** Running evaluation on test dataset  *****
01/06/2024 08:06:08 - INFO - root -     Num examples = 269
01/06/2024 08:06:08 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 4s[Evaluating] 2/12 [====>.........................] - ETA: 8s[Evaluating] 3/12 [======>.......................] - ETA: 6s[Evaluating] 4/12 [=========>....................] - ETA: 5s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 4s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 615.8ms/step
/mnt/storage/wubinghong.wbh/project/pytorch-3.8/lib/python3.8/site-packages/torch/nn/modules/transformer.py:562: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)
  return torch._transformer_encoder_layer_fwd(
01/06/2024 08:06:16 - INFO - root -   

01/06/2024 08:06:16 - INFO - root -   ***** Eval results  *****
01/06/2024 08:06:16 - INFO - root -    acc: 0.6570 - recall: 0.3850 - f1: 0.4855 - loss: 9.3033 
01/06/2024 08:06:16 - INFO - root -   ***** Entity results  *****
01/06/2024 08:06:16 - INFO - root -   ******* GPE.NAM results ********
01/06/2024 08:06:16 - INFO - root -    acc: 0.3750 - recall: 0.0638 - f1: 0.1091 
01/06/2024 08:06:16 - INFO - root -   ******* GPE.NOM results ********
01/06/2024 08:06:16 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/06/2024 08:06:16 - INFO - root -   ******* LOC.NAM results ********
01/06/2024 08:06:16 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/06/2024 08:06:16 - INFO - root -   ******* LOC.NOM results ********
01/06/2024 08:06:16 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/06/2024 08:06:16 - INFO - root -   ******* ORG.NAM results ********
01/06/2024 08:06:16 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/06/2024 08:06:16 - INFO - root -   ******* ORG.NOM results ********
01/06/2024 08:06:16 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/06/2024 08:06:16 - INFO - root -   ******* PER.NAM results ********
01/06/2024 08:06:16 - INFO - root -    acc: 0.8143 - recall: 0.5182 - f1: 0.6333 
01/06/2024 08:06:16 - INFO - root -   ******* PER.NOM results ********
01/06/2024 08:06:16 - INFO - root -    acc: 0.6074 - recall: 0.5824 - f1: 0.5946 
01/06/2024 08:06:21 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-57
01/06/2024 08:06:22 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-57
01/06/2024 08:06:22 - INFO - root -   

01/06/2024 08:06:22 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 1/50
[Training] 1/57 [..............................] - ETA: 52s  [ loss=8.5141 ][Training] 2/57 [>.............................] - ETA: 1:09  [ loss=7.8998 ][Training] 3/57 [>.............................] - ETA: 1:15  [ loss=12.9945 ][Training] 4/57 [=>............................] - ETA: 1:05  [ loss=3.1869 ][Training] 5/57 [=>............................] - ETA: 1:05  [ loss=7.1142 ][Training] 6/57 [==>...........................] - ETA: 1:00  [ loss=6.2130 ][Training] 7/57 [==>...........................] - ETA: 1:01  [ loss=7.3740 ][Training] 8/57 [===>..........................] - ETA: 1:02  [ loss=5.3697 ][Training] 9/57 [===>..........................] - ETA: 1:00  [ loss=3.9417 ][Training] 10/57 [====>.........................] - ETA: 59s  [ loss=10.2448 ][Training] 11/57 [====>.........................] - ETA: 57s  [ loss=6.3350 ][Training] 12/57 [=====>........................] - ETA: 55s  [ loss=5.8263 ][Training] 13/57 [=====>........................] - ETA: 54s  [ loss=10.1479 ][Training] 14/57 [======>.......................] - ETA: 52s  [ loss=4.3994 ][Training] 15/57 [======>.......................] - ETA: 52s  [ loss=9.4613 ][Training] 16/57 [=======>......................] - ETA: 51s  [ loss=7.8050 ][Training] 17/57 [=======>......................] - ETA: 50s  [ loss=12.9823 ][Training] 18/57 [========>.....................] - ETA: 49s  [ loss=7.9033 ][Training] 19/57 [=========>....................] - ETA: 48s  [ loss=4.7935 ][Training] 20/57 [=========>....................] - ETA: 47s  [ loss=8.9799 ][Training] 21/57 [==========>...................] - ETA: 45s  [ loss=2.5133 ][Training] 22/57 [==========>...................] - ETA: 45s  [ loss=5.5715 ][Training] 23/57 [===========>..................] - ETA: 43s  [ loss=3.0532 ][Training] 24/57 [===========>..................] - ETA: 42s  [ loss=7.9870 ][Training] 25/57 [============>.................] - ETA: 40s  [ loss=2.9640 ][Training] 26/57 [============>.................] - ETA: 39s  [ loss=2.9323 ][Training] 27/57 [=============>................] - ETA: 38s  [ loss=6.7551 ][Training] 28/57 [=============>................] - ETA: 37s  [ loss=8.8821 ][Training] 29/57 [==============>...............] - ETA: 36s  [ loss=5.4597 ][Training] 30/57 [==============>...............] - ETA: 34s  [ loss=5.4476 ][Training] 31/57 [===============>..............] - ETA: 33s  [ loss=3.1576 ][Training] 32/57 [===============>..............] - ETA: 32s  [ loss=5.4424 ][Training] 33/57 [================>.............] - ETA: 31s  [ loss=4.5785 ][Training] 34/57 [================>.............] - ETA: 29s  [ loss=5.1710 ][Training] 35/57 [=================>............] - ETA: 28s  [ loss=3.3922 ][Training] 36/57 [=================>............] - ETA: 26s  [ loss=14.6411 ][Training] 37/57 [==================>...........] - ETA: 25s  [ loss=7.7052 ][Training] 38/57 [===================>..........] - ETA: 24s  [ loss=1.7014 ][Training] 39/57 [===================>..........] - ETA: 22s  [ loss=8.5624 ][Training] 40/57 [====================>.........] - ETA: 21s  [ loss=6.1951 ][Training] 41/57 [====================>.........] - ETA: 20s  [ loss=4.5735 ][Training] 42/57 [=====================>........] - ETA: 19s  [ loss=5.0621 ][Training] 43/57 [=====================>........] - ETA: 17s  [ loss=10.6747 ][Training] 44/57 [======================>.......] - ETA: 16s  [ loss=2.0936 ][Training] 45/57 [======================>.......] - ETA: 15s  [ loss=6.5315 ][Training] 46/57 [=======================>......] - ETA: 14s  [ loss=2.7155 ][Training] 47/57 [=======================>......] - ETA: 12s  [ loss=5.2305 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=7.0070 ][Training] 49/57 [========================>.....] - ETA: 10s  [ loss=6.6826 ][Training] 50/57 [=========================>....] - ETA: 8s  [ loss=2.9021 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=3.7397 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=6.3596 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=10.1130 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=3.5227 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=2.2759 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=10.5960 ][Training] 57/57 [==============================] 1.3s/step  [ loss=2.5339 ]
01/06/2024 08:07:34 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/06/2024 08:07:34 - INFO - root -   ***** Running evaluation on test dataset  *****
01/06/2024 08:07:34 - INFO - root -     Num examples = 269
01/06/2024 08:07:34 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 7s[Evaluating] 2/12 [====>.........................] - ETA: 5s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 2s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 556.9ms/step
01/06/2024 08:07:40 - INFO - root -   

01/06/2024 08:07:40 - INFO - root -   ***** Eval results  *****
01/06/2024 08:07:40 - INFO - root -    acc: 0.6667 - recall: 0.5908 - f1: 0.6264 - loss: 5.6509 
01/06/2024 08:07:40 - INFO - root -   ***** Entity results  *****
01/06/2024 08:07:40 - INFO - root -   ******* GPE.NAM results ********
01/06/2024 08:07:40 - INFO - root -    acc: 0.6809 - recall: 0.6809 - f1: 0.6809 
01/06/2024 08:07:40 - INFO - root -   ******* GPE.NOM results ********
01/06/2024 08:07:40 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/06/2024 08:07:40 - INFO - root -   ******* LOC.NAM results ********
01/06/2024 08:07:40 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/06/2024 08:07:40 - INFO - root -   ******* LOC.NOM results ********
01/06/2024 08:07:40 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/06/2024 08:07:40 - INFO - root -   ******* ORG.NAM results ********
01/06/2024 08:07:40 - INFO - root -    acc: 0.4074 - recall: 0.2821 - f1: 0.3333 
01/06/2024 08:07:40 - INFO - root -   ******* ORG.NOM results ********
01/06/2024 08:07:40 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/06/2024 08:07:40 - INFO - root -   ******* PER.NAM results ********
01/06/2024 08:07:40 - INFO - root -    acc: 0.7714 - recall: 0.7364 - f1: 0.7535 
01/06/2024 08:07:40 - INFO - root -   ******* PER.NOM results ********
01/06/2024 08:07:40 - INFO - root -    acc: 0.6417 - recall: 0.7059 - f1: 0.6723 
01/06/2024 08:07:46 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-114
01/06/2024 08:07:46 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-114
01/06/2024 08:07:46 - INFO - root -   

01/06/2024 08:07:46 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 2/50
[Training] 1/57 [..............................] - ETA: 1:09  [ loss=7.4388 ][Training] 2/57 [>.............................] - ETA: 1:10  [ loss=3.3674 ][Training] 3/57 [>.............................] - ETA: 58s  [ loss=3.1818 ][Training] 4/57 [=>............................] - ETA: 1:02  [ loss=3.8201 ][Training] 5/57 [=>............................] - ETA: 1:03  [ loss=2.4820 ][Training] 6/57 [==>...........................] - ETA: 1:01  [ loss=3.5033 ][Training] 7/57 [==>...........................] - ETA: 1:01  [ loss=6.8370 ][Training] 8/57 [===>..........................] - ETA: 1:03  [ loss=3.7196 ][Training] 9/57 [===>..........................] - ETA: 1:02  [ loss=3.8063 ][Training] 10/57 [====>.........................] - ETA: 59s  [ loss=3.2257 ][Training] 11/57 [====>.........................] - ETA: 59s  [ loss=5.6874 ][Training] 12/57 [=====>........................] - ETA: 57s  [ loss=4.1482 ][Training] 13/57 [=====>........................] - ETA: 56s  [ loss=4.9175 ][Training] 14/57 [======>.......................] - ETA: 54s  [ loss=6.4984 ][Training] 15/57 [======>.......................] - ETA: 51s  [ loss=0.5588 ][Training] 16/57 [=======>......................] - ETA: 50s  [ loss=3.8787 ][Training] 17/57 [=======>......................] - ETA: 49s  [ loss=5.6125 ][Training] 18/57 [========>.....................] - ETA: 47s  [ loss=9.4622 ][Training] 19/57 [=========>....................] - ETA: 46s  [ loss=5.0132 ][Training] 20/57 [=========>....................] - ETA: 44s  [ loss=3.4554 ][Training] 21/57 [==========>...................] - ETA: 43s  [ loss=3.5019 ][Training] 22/57 [==========>...................] - ETA: 41s  [ loss=2.8376 ][Training] 23/57 [===========>..................] - ETA: 41s  [ loss=3.7406 ][Training] 24/57 [===========>..................] - ETA: 40s  [ loss=7.5227 ][Training] 25/57 [============>.................] - ETA: 38s  [ loss=3.2537 ][Training] 26/57 [============>.................] - ETA: 37s  [ loss=3.0980 ][Training] 27/57 [=============>................] - ETA: 35s  [ loss=2.5304 ][Training] 28/57 [=============>................] - ETA: 34s  [ loss=5.3397 ][Training] 29/57 [==============>...............] - ETA: 33s  [ loss=2.3288 ][Training] 30/57 [==============>...............] - ETA: 32s  [ loss=9.6171 ][Training] 31/57 [===============>..............] - ETA: 31s  [ loss=2.3337 ][Training] 32/57 [===============>..............] - ETA: 30s  [ loss=5.4870 ][Training] 33/57 [================>.............] - ETA: 28s  [ loss=1.3844 ][Training] 34/57 [================>.............] - ETA: 28s  [ loss=5.0667 ][Training] 35/57 [=================>............] - ETA: 27s  [ loss=5.4836 ][Training] 36/57 [=================>............] - ETA: 25s  [ loss=2.8215 ][Training] 37/57 [==================>...........] - ETA: 24s  [ loss=3.3917 ][Training] 38/57 [===================>..........] - ETA: 23s  [ loss=2.6626 ][Training] 39/57 [===================>..........] - ETA: 22s  [ loss=6.0030 ][Training] 40/57 [====================>.........] - ETA: 21s  [ loss=5.5579 ][Training] 41/57 [====================>.........] - ETA: 19s  [ loss=5.2828 ][Training] 42/57 [=====================>........] - ETA: 18s  [ loss=8.5364 ][Training] 43/57 [=====================>........] - ETA: 17s  [ loss=4.1259 ][Training] 44/57 [======================>.......] - ETA: 16s  [ loss=4.9655 ][Training] 45/57 [======================>.......] - ETA: 15s  [ loss=3.6781 ][Training] 46/57 [=======================>......] - ETA: 13s  [ loss=3.3582 ][Training] 47/57 [=======================>......] - ETA: 12s  [ loss=4.1438 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=3.6339 ][Training] 49/57 [========================>.....] - ETA: 10s  [ loss=6.4784 ][Training] 50/57 [=========================>....] - ETA: 8s  [ loss=5.7533 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=4.1968 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=1.8387 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=1.5946 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=6.4873 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=5.0936 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=1.5441 ][Training] 57/57 [==============================] 1.3s/step  [ loss=5.0100 ]
01/06/2024 08:08:57 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/06/2024 08:08:57 - INFO - root -   ***** Running evaluation on test dataset  *****
01/06/2024 08:08:57 - INFO - root -     Num examples = 269
01/06/2024 08:08:57 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 9s[Evaluating] 2/12 [====>.........................] - ETA: 6s[Evaluating] 3/12 [======>.......................] - ETA: 6s[Evaluating] 4/12 [=========>....................] - ETA: 5s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 619.4ms/step
01/06/2024 08:09:05 - INFO - root -   

01/06/2024 08:09:05 - INFO - root -   ***** Eval results  *****
01/06/2024 08:09:05 - INFO - root -    acc: 0.6917 - recall: 0.6901 - f1: 0.6909 - loss: 5.0501 
01/06/2024 08:09:05 - INFO - root -   ***** Entity results  *****
01/06/2024 08:09:05 - INFO - root -   ******* GPE.NAM results ********
01/06/2024 08:09:05 - INFO - root -    acc: 0.7872 - recall: 0.7872 - f1: 0.7872 
01/06/2024 08:09:05 - INFO - root -   ******* GPE.NOM results ********
01/06/2024 08:09:05 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/06/2024 08:09:05 - INFO - root -   ******* LOC.NAM results ********
01/06/2024 08:09:05 - INFO - root -    acc: 0.2857 - recall: 0.1053 - f1: 0.1538 
01/06/2024 08:09:05 - INFO - root -   ******* LOC.NOM results ********
01/06/2024 08:09:05 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/06/2024 08:09:05 - INFO - root -   ******* ORG.NAM results ********
01/06/2024 08:09:05 - INFO - root -    acc: 0.5455 - recall: 0.6154 - f1: 0.5783 
01/06/2024 08:09:05 - INFO - root -   ******* ORG.NOM results ********
01/06/2024 08:09:05 - INFO - root -    acc: 0.7143 - recall: 0.2941 - f1: 0.4167 
01/06/2024 08:09:05 - INFO - root -   ******* PER.NAM results ********
01/06/2024 08:09:05 - INFO - root -    acc: 0.7807 - recall: 0.8091 - f1: 0.7946 
01/06/2024 08:09:05 - INFO - root -   ******* PER.NOM results ********
01/06/2024 08:09:05 - INFO - root -    acc: 0.6632 - recall: 0.7529 - f1: 0.7052 
01/06/2024 08:09:10 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-171
01/06/2024 08:09:10 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-171
01/06/2024 08:09:10 - INFO - root -   

01/06/2024 08:09:10 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 3/50
[Training] 1/57 [..............................] - ETA: 1:14  [ loss=5.3208 ][Training] 2/57 [>.............................] - ETA: 1:17  [ loss=9.1653 ][Training] 3/57 [>.............................] - ETA: 1:15  [ loss=2.6977 ][Training] 4/57 [=>............................] - ETA: 1:14  [ loss=3.3404 ][Training] 5/57 [=>............................] - ETA: 1:11  [ loss=1.9071 ][Training] 6/57 [==>...........................] - ETA: 1:07  [ loss=2.1987 ][Training] 7/57 [==>...........................] - ETA: 1:06  [ loss=3.3929 ][Training] 8/57 [===>..........................] - ETA: 1:02  [ loss=2.0995 ][Training] 9/57 [===>..........................] - ETA: 1:01  [ loss=3.3891 ][Training] 10/57 [====>.........................] - ETA: 59s  [ loss=4.1918 ][Training] 11/57 [====>.........................] - ETA: 58s  [ loss=3.0663 ][Training] 12/57 [=====>........................] - ETA: 56s  [ loss=3.2219 ][Training] 13/57 [=====>........................] - ETA: 55s  [ loss=7.8864 ][Training] 14/57 [======>.......................] - ETA: 54s  [ loss=5.8434 ][Training] 15/57 [======>.......................] - ETA: 53s  [ loss=4.5633 ][Training] 16/57 [=======>......................] - ETA: 51s  [ loss=2.4422 ][Training] 17/57 [=======>......................] - ETA: 49s  [ loss=1.5502 ][Training] 18/57 [========>.....................] - ETA: 49s  [ loss=6.6402 ][Training] 19/57 [=========>....................] - ETA: 47s  [ loss=4.5882 ][Training] 20/57 [=========>....................] - ETA: 46s  [ loss=5.1735 ][Training] 21/57 [==========>...................] - ETA: 45s  [ loss=3.6848 ][Training] 22/57 [==========>...................] - ETA: 44s  [ loss=2.1688 ][Training] 23/57 [===========>..................] - ETA: 42s  [ loss=3.8855 ][Training] 24/57 [===========>..................] - ETA: 41s  [ loss=3.5862 ][Training] 25/57 [============>.................] - ETA: 40s  [ loss=4.7876 ][Training] 26/57 [============>.................] - ETA: 39s  [ loss=1.7808 ][Training] 27/57 [=============>................] - ETA: 38s  [ loss=4.2995 ][Training] 28/57 [=============>................] - ETA: 36s  [ loss=4.4782 ][Training] 29/57 [==============>...............] - ETA: 35s  [ loss=1.3197 ][Training] 30/57 [==============>...............] - ETA: 34s  [ loss=3.5850 ][Training] 31/57 [===============>..............] - ETA: 33s  [ loss=3.8390 ][Training] 32/57 [===============>..............] - ETA: 32s  [ loss=3.2706 ][Training] 33/57 [================>.............] - ETA: 30s  [ loss=3.9731 ][Training] 34/57 [================>.............] - ETA: 29s  [ loss=2.0219 ][Training] 35/57 [=================>............] - ETA: 28s  [ loss=3.6419 ][Training] 36/57 [=================>............] - ETA: 26s  [ loss=3.5443 ][Training] 37/57 [==================>...........] - ETA: 25s  [ loss=3.4210 ][Training] 38/57 [===================>..........] - ETA: 24s  [ loss=2.7459 ][Training] 39/57 [===================>..........] - ETA: 23s  [ loss=3.2147 ][Training] 40/57 [====================>.........] - ETA: 21s  [ loss=3.9920 ][Training] 41/57 [====================>.........] - ETA: 20s  [ loss=4.1347 ][Training] 42/57 [=====================>........] - ETA: 19s  [ loss=3.4221 ][Training] 43/57 [=====================>........] - ETA: 18s  [ loss=5.0203 ][Training] 44/57 [======================>.......] - ETA: 16s  [ loss=3.6113 ][Training] 45/57 [======================>.......] - ETA: 15s  [ loss=2.8020 ][Training] 46/57 [=======================>......] - ETA: 14s  [ loss=3.5323 ][Training] 47/57 [=======================>......] - ETA: 13s  [ loss=1.9654 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=5.2753 ][Training] 49/57 [========================>.....] - ETA: 10s  [ loss=2.6262 ][Training] 50/57 [=========================>....] - ETA: 9s  [ loss=2.8226 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=1.8328 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=2.2440 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=1.5709 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=2.2952 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=3.6157 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=2.1651 ][Training] 57/57 [==============================] 1.3s/step  [ loss=1.9351 ]
01/06/2024 08:10:24 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/06/2024 08:10:24 - INFO - root -   ***** Running evaluation on test dataset  *****
01/06/2024 08:10:24 - INFO - root -     Num examples = 269
01/06/2024 08:10:24 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 4s[Evaluating] 2/12 [====>.........................] - ETA: 5s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 577.0ms/step
01/06/2024 08:10:31 - INFO - root -   

01/06/2024 08:10:31 - INFO - root -   ***** Eval results  *****
01/06/2024 08:10:31 - INFO - root -    acc: 0.6993 - recall: 0.7094 - f1: 0.7043 - loss: 4.2576 
01/06/2024 08:10:31 - INFO - root -   ***** Entity results  *****
01/06/2024 08:10:31 - INFO - root -   ******* GPE.NAM results ********
01/06/2024 08:10:31 - INFO - root -    acc: 0.8478 - recall: 0.8298 - f1: 0.8387 
01/06/2024 08:10:31 - INFO - root -   ******* GPE.NOM results ********
01/06/2024 08:10:31 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/06/2024 08:10:31 - INFO - root -   ******* LOC.NAM results ********
01/06/2024 08:10:31 - INFO - root -    acc: 0.6000 - recall: 0.3158 - f1: 0.4138 
01/06/2024 08:10:31 - INFO - root -   ******* LOC.NOM results ********
01/06/2024 08:10:31 - INFO - root -    acc: 0.5000 - recall: 0.1111 - f1: 0.1818 
01/06/2024 08:10:31 - INFO - root -   ******* ORG.NAM results ********
01/06/2024 08:10:31 - INFO - root -    acc: 0.5610 - recall: 0.5897 - f1: 0.5750 
01/06/2024 08:10:31 - INFO - root -   ******* ORG.NOM results ********
01/06/2024 08:10:31 - INFO - root -    acc: 1.0000 - recall: 0.4118 - f1: 0.5833 
01/06/2024 08:10:31 - INFO - root -   ******* PER.NAM results ********
01/06/2024 08:10:31 - INFO - root -    acc: 0.8125 - recall: 0.8273 - f1: 0.8198 
01/06/2024 08:10:31 - INFO - root -   ******* PER.NOM results ********
01/06/2024 08:10:31 - INFO - root -    acc: 0.6269 - recall: 0.7412 - f1: 0.6792 
01/06/2024 08:10:35 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-228
01/06/2024 08:10:35 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-228
01/06/2024 08:10:35 - INFO - root -   

01/06/2024 08:10:35 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 4/50
[Training] 1/57 [..............................] - ETA: 1:29  [ loss=5.2974 ][Training] 2/57 [>.............................] - ETA: 1:08  [ loss=1.2251 ][Training] 3/57 [>.............................] - ETA: 1:16  [ loss=3.3838 ][Training] 4/57 [=>............................] - ETA: 1:13  [ loss=4.0049 ][Training] 5/57 [=>............................] - ETA: 1:09  [ loss=2.6230 ][Training] 6/57 [==>...........................] - ETA: 1:07  [ loss=1.2024 ][Training] 7/57 [==>...........................] - ETA: 1:05  [ loss=1.6435 ][Training] 8/57 [===>..........................] - ETA: 1:03  [ loss=3.8241 ][Training] 9/57 [===>..........................] - ETA: 1:01  [ loss=3.9435 ][Training] 10/57 [====>.........................] - ETA: 1:01  [ loss=5.3294 ][Training] 11/57 [====>.........................] - ETA: 1:00  [ loss=1.5374 ][Training] 12/57 [=====>........................] - ETA: 58s  [ loss=1.5629 ][Training] 13/57 [=====>........................] - ETA: 56s  [ loss=4.0485 ][Training] 14/57 [======>.......................] - ETA: 55s  [ loss=2.4926 ][Training] 15/57 [======>.......................] - ETA: 54s  [ loss=0.9420 ][Training] 16/57 [=======>......................] - ETA: 52s  [ loss=1.0039 ][Training] 17/57 [=======>......................] - ETA: 51s  [ loss=1.2301 ][Training] 18/57 [========>.....................] - ETA: 49s  [ loss=2.2901 ][Training] 19/57 [=========>....................] - ETA: 48s  [ loss=4.0558 ][Training] 20/57 [=========>....................] - ETA: 46s  [ loss=2.3166 ][Training] 21/57 [==========>...................] - ETA: 45s  [ loss=1.5861 ][Training] 22/57 [==========>...................] - ETA: 44s  [ loss=2.7864 ][Training] 23/57 [===========>..................] - ETA: 42s  [ loss=2.5013 ][Training] 24/57 [===========>..................] - ETA: 42s  [ loss=3.8835 ][Training] 25/57 [============>.................] - ETA: 40s  [ loss=2.6035 ][Training] 26/57 [============>.................] - ETA: 38s  [ loss=2.5872 ][Training] 27/57 [=============>................] - ETA: 37s  [ loss=3.0089 ][Training] 28/57 [=============>................] - ETA: 35s  [ loss=3.3028 ][Training] 29/57 [==============>...............] - ETA: 34s  [ loss=2.8015 ][Training] 30/57 [==============>...............] - ETA: 33s  [ loss=1.5201 ][Training] 31/57 [===============>..............] - ETA: 32s  [ loss=5.3189 ][Training] 32/57 [===============>..............] - ETA: 31s  [ loss=4.4850 ][Training] 33/57 [================>.............] - ETA: 30s  [ loss=2.4972 ][Training] 34/57 [================>.............] - ETA: 29s  [ loss=4.4907 ][Training] 35/57 [=================>............] - ETA: 27s  [ loss=3.5778 ][Training] 36/57 [=================>............] - ETA: 26s  [ loss=1.9668 ][Training] 37/57 [==================>...........] - ETA: 25s  [ loss=2.5073 ][Training] 38/57 [===================>..........] - ETA: 24s  [ loss=2.0494 ][Training] 39/57 [===================>..........] - ETA: 22s  [ loss=4.4429 ][Training] 40/57 [====================>.........] - ETA: 21s  [ loss=2.4402 ][Training] 41/57 [====================>.........] - ETA: 20s  [ loss=3.3850 ][Training] 42/57 [=====================>........] - ETA: 19s  [ loss=3.2574 ][Training] 43/57 [=====================>........] - ETA: 17s  [ loss=2.1250 ][Training] 44/57 [======================>.......] - ETA: 16s  [ loss=1.5916 ][Training] 45/57 [======================>.......] - ETA: 15s  [ loss=2.1020 ][Training] 46/57 [=======================>......] - ETA: 14s  [ loss=3.3970 ][Training] 47/57 [=======================>......] - ETA: 13s  [ loss=5.0397 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=3.0185 ][Training] 49/57 [========================>.....] - ETA: 10s  [ loss=1.7907 ][Training] 50/57 [=========================>....] - ETA: 9s  [ loss=3.3998 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=1.2107 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=5.5243 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=4.5282 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=0.9694 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=3.3228 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=3.1606 ][Training] 57/57 [==============================] 1.3s/step  [ loss=0.1653 ]
01/06/2024 08:11:48 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/06/2024 08:11:49 - INFO - root -   ***** Running evaluation on test dataset  *****
01/06/2024 08:11:49 - INFO - root -     Num examples = 269
01/06/2024 08:11:49 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 6s[Evaluating] 2/12 [====>.........................] - ETA: 6s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 5s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 608.3ms/step
01/06/2024 08:11:56 - INFO - root -   

01/06/2024 08:11:56 - INFO - root -   ***** Eval results  *****
01/06/2024 08:11:56 - INFO - root -    acc: 0.7382 - recall: 0.7167 - f1: 0.7273 - loss: 4.1500 
01/06/2024 08:11:56 - INFO - root -   ***** Entity results  *****
01/06/2024 08:11:56 - INFO - root -   ******* GPE.NAM results ********
01/06/2024 08:11:56 - INFO - root -    acc: 0.8163 - recall: 0.8511 - f1: 0.8333 
01/06/2024 08:11:56 - INFO - root -   ******* GPE.NOM results ********
01/06/2024 08:11:56 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/06/2024 08:11:56 - INFO - root -   ******* LOC.NAM results ********
01/06/2024 08:11:56 - INFO - root -    acc: 0.5385 - recall: 0.3684 - f1: 0.4375 
01/06/2024 08:11:56 - INFO - root -   ******* LOC.NOM results ********
01/06/2024 08:11:56 - INFO - root -    acc: 0.5000 - recall: 0.2222 - f1: 0.3077 
01/06/2024 08:11:56 - INFO - root -   ******* ORG.NAM results ********
01/06/2024 08:11:56 - INFO - root -    acc: 0.6316 - recall: 0.6154 - f1: 0.6234 
01/06/2024 08:11:56 - INFO - root -   ******* ORG.NOM results ********
01/06/2024 08:11:56 - INFO - root -    acc: 0.8000 - recall: 0.4706 - f1: 0.5926 
01/06/2024 08:11:56 - INFO - root -   ******* PER.NAM results ********
01/06/2024 08:11:56 - INFO - root -    acc: 0.7909 - recall: 0.7909 - f1: 0.7909 
01/06/2024 08:11:56 - INFO - root -   ******* PER.NOM results ********
01/06/2024 08:11:56 - INFO - root -    acc: 0.7232 - recall: 0.7529 - f1: 0.7378 
01/06/2024 08:12:01 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-285
01/06/2024 08:12:01 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-285
01/06/2024 08:12:01 - INFO - root -   

01/06/2024 08:12:01 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 5/50
[Training] 1/57 [..............................] - ETA: 1:20  [ loss=0.5722 ][Training] 2/57 [>.............................] - ETA: 1:06  [ loss=1.4991 ][Training] 3/57 [>.............................] - ETA: 1:09  [ loss=2.9260 ][Training] 4/57 [=>............................] - ETA: 1:05  [ loss=1.1167 ][Training] 5/57 [=>............................] - ETA: 1:07  [ loss=1.8658 ][Training] 6/57 [==>...........................] - ETA: 1:04  [ loss=3.2877 ][Training] 7/57 [==>...........................] - ETA: 1:03  [ loss=2.0854 ][Training] 8/57 [===>..........................] - ETA: 1:02  [ loss=1.0372 ][Training] 9/57 [===>..........................] - ETA: 1:00  [ loss=2.0029 ][Training] 10/57 [====>.........................] - ETA: 1:00  [ loss=2.6543 ][Training] 11/57 [====>.........................] - ETA: 1:00  [ loss=2.6879 ][Training] 12/57 [=====>........................] - ETA: 58s  [ loss=2.9895 ][Training] 13/57 [=====>........................] - ETA: 57s  [ loss=1.8608 ][Training] 14/57 [======>.......................] - ETA: 57s  [ loss=3.1740 ][Training] 15/57 [======>.......................] - ETA: 54s  [ loss=2.2176 ][Training] 16/57 [=======>......................] - ETA: 53s  [ loss=1.4346 ][Training] 17/57 [=======>......................] - ETA: 51s  [ loss=1.3860 ][Training] 18/57 [========>.....................] - ETA: 51s  [ loss=4.6525 ][Training] 19/57 [=========>....................] - ETA: 49s  [ loss=3.0498 ][Training] 20/57 [=========>....................] - ETA: 48s  [ loss=1.5795 ][Training] 21/57 [==========>...................] - ETA: 46s  [ loss=2.0759 ][Training] 22/57 [==========>...................] - ETA: 45s  [ loss=3.9953 ][Training] 23/57 [===========>..................] - ETA: 44s  [ loss=1.5358 ][Training] 24/57 [===========>..................] - ETA: 43s  [ loss=1.8182 ][Training] 25/57 [============>.................] - ETA: 42s  [ loss=2.3546 ][Training] 26/57 [============>.................] - ETA: 40s  [ loss=3.6779 ][Training] 27/57 [=============>................] - ETA: 38s  [ loss=2.6925 ][Training] 28/57 [=============>................] - ETA: 37s  [ loss=1.6002 ][Training] 29/57 [==============>...............] - ETA: 35s  [ loss=2.3803 ][Training] 30/57 [==============>...............] - ETA: 34s  [ loss=2.3499 ][Training] 31/57 [===============>..............] - ETA: 33s  [ loss=3.8485 ][Training] 32/57 [===============>..............] - ETA: 31s  [ loss=4.0402 ][Training] 33/57 [================>.............] - ETA: 30s  [ loss=2.3561 ][Training] 34/57 [================>.............] - ETA: 29s  [ loss=5.4676 ][Training] 35/57 [=================>............] - ETA: 27s  [ loss=1.3028 ][Training] 36/57 [=================>............] - ETA: 26s  [ loss=1.1597 ][Training] 37/57 [==================>...........] - ETA: 25s  [ loss=7.9719 ][Training] 38/57 [===================>..........] - ETA: 23s  [ loss=1.4218 ][Training] 39/57 [===================>..........] - ETA: 22s  [ loss=1.4364 ][Training] 40/57 [====================>.........] - ETA: 21s  [ loss=4.1532 ][Training] 41/57 [====================>.........] - ETA: 20s  [ loss=2.6050 ][Training] 42/57 [=====================>........] - ETA: 18s  [ loss=1.8559 ][Training] 43/57 [=====================>........] - ETA: 17s  [ loss=1.7538 ][Training] 44/57 [======================>.......] - ETA: 16s  [ loss=2.8062 ][Training] 45/57 [======================>.......] - ETA: 14s  [ loss=1.3516 ][Training] 46/57 [=======================>......] - ETA: 13s  [ loss=2.4432 ][Training] 47/57 [=======================>......] - ETA: 12s  [ loss=4.9509 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=2.8966 ][Training] 49/57 [========================>.....] - ETA: 9s  [ loss=2.0396 ][Training] 50/57 [=========================>....] - ETA: 8s  [ loss=3.5453 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=1.6681 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=1.3893 ][Training] 53/57 [==========================>...] - ETA: 4s  [ loss=1.5800 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=2.6051 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=2.1753 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=2.4130 ][Training] 57/57 [==============================] 1.2s/step  [ loss=1.8419 ]
01/06/2024 08:13:11 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/06/2024 08:13:11 - INFO - root -   ***** Running evaluation on test dataset  *****
01/06/2024 08:13:11 - INFO - root -     Num examples = 269
01/06/2024 08:13:11 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 10s[Evaluating] 2/12 [====>.........................] - ETA: 7s[Evaluating] 3/12 [======>.......................] - ETA: 6s[Evaluating] 4/12 [=========>....................] - ETA: 5s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 4s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 631.2ms/step
01/06/2024 08:13:18 - INFO - root -   

01/06/2024 08:13:18 - INFO - root -   ***** Eval results  *****
01/06/2024 08:13:18 - INFO - root -    acc: 0.7176 - recall: 0.7385 - f1: 0.7279 - loss: 4.3385 
01/06/2024 08:13:18 - INFO - root -   ***** Entity results  *****
01/06/2024 08:13:18 - INFO - root -   ******* GPE.NAM results ********
01/06/2024 08:13:18 - INFO - root -    acc: 0.8478 - recall: 0.8298 - f1: 0.8387 
01/06/2024 08:13:18 - INFO - root -   ******* GPE.NOM results ********
01/06/2024 08:13:18 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/06/2024 08:13:18 - INFO - root -   ******* LOC.NAM results ********
01/06/2024 08:13:18 - INFO - root -    acc: 0.5556 - recall: 0.5263 - f1: 0.5405 
01/06/2024 08:13:18 - INFO - root -   ******* LOC.NOM results ********
01/06/2024 08:13:18 - INFO - root -    acc: 0.5000 - recall: 0.2222 - f1: 0.3077 
01/06/2024 08:13:18 - INFO - root -   ******* ORG.NAM results ********
01/06/2024 08:13:18 - INFO - root -    acc: 0.6216 - recall: 0.5897 - f1: 0.6053 
01/06/2024 08:13:18 - INFO - root -   ******* ORG.NOM results ********
01/06/2024 08:13:18 - INFO - root -    acc: 0.8889 - recall: 0.4706 - f1: 0.6154 
01/06/2024 08:13:18 - INFO - root -   ******* PER.NAM results ********
01/06/2024 08:13:18 - INFO - root -    acc: 0.7647 - recall: 0.8273 - f1: 0.7948 
01/06/2024 08:13:18 - INFO - root -   ******* PER.NOM results ********
01/06/2024 08:13:18 - INFO - root -    acc: 0.6875 - recall: 0.7765 - f1: 0.7293 
01/06/2024 08:13:23 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-342
01/06/2024 08:13:23 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-342
01/06/2024 08:13:23 - INFO - root -   

01/06/2024 08:13:23 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 6/50
[Training] 1/57 [..............................] - ETA: 51s  [ loss=4.1077 ][Training] 2/57 [>.............................] - ETA: 1:06  [ loss=2.7956 ][Training] 3/57 [>.............................] - ETA: 1:04  [ loss=1.5247 ][Training] 4/57 [=>............................] - ETA: 1:09  [ loss=3.3488 ][Training] 5/57 [=>............................] - ETA: 1:03  [ loss=2.0458 ][Training] 6/57 [==>...........................] - ETA: 1:04  [ loss=1.8956 ][Training] 7/57 [==>...........................] - ETA: 1:04  [ loss=2.7263 ][Training] 8/57 [===>..........................] - ETA: 1:01  [ loss=1.7332 ][Training] 9/57 [===>..........................] - ETA: 1:00  [ loss=1.8927 ][Training] 10/57 [====>.........................] - ETA: 56s  [ loss=0.9268 ][Training] 11/57 [====>.........................] - ETA: 58s  [ loss=4.9547 ][Training] 12/57 [=====>........................] - ETA: 57s  [ loss=2.5048 ][Training] 13/57 [=====>........................] - ETA: 55s  [ loss=2.3507 ][Training] 14/57 [======>.......................] - ETA: 54s  [ loss=1.8468 ][Training] 15/57 [======>.......................] - ETA: 53s  [ loss=2.8763 ][Training] 16/57 [=======>......................] - ETA: 51s  [ loss=1.8576 ][Training] 17/57 [=======>......................] - ETA: 50s  [ loss=1.9291 ][Training] 18/57 [========>.....................] - ETA: 48s  [ loss=1.2328 ][Training] 19/57 [=========>....................] - ETA: 48s  [ loss=2.2144 ][Training] 20/57 [=========>....................] - ETA: 46s  [ loss=1.8578 ][Training] 21/57 [==========>...................] - ETA: 45s  [ loss=1.9320 ][Training] 22/57 [==========>...................] - ETA: 44s  [ loss=2.3940 ][Training] 23/57 [===========>..................] - ETA: 43s  [ loss=1.2431 ][Training] 24/57 [===========>..................] - ETA: 41s  [ loss=1.1229 ][Training] 25/57 [============>.................] - ETA: 40s  [ loss=1.5006 ][Training] 26/57 [============>.................] - ETA: 39s  [ loss=0.6488 ][Training] 27/57 [=============>................] - ETA: 38s  [ loss=2.3122 ][Training] 28/57 [=============>................] - ETA: 36s  [ loss=3.4868 ][Training] 29/57 [==============>...............] - ETA: 35s  [ loss=0.9577 ][Training] 30/57 [==============>...............] - ETA: 34s  [ loss=2.5451 ][Training] 31/57 [===============>..............] - ETA: 33s  [ loss=2.9304 ][Training] 32/57 [===============>..............] - ETA: 31s  [ loss=3.1136 ][Training] 33/57 [================>.............] - ETA: 30s  [ loss=2.1502 ][Training] 34/57 [================>.............] - ETA: 29s  [ loss=2.8439 ][Training] 35/57 [=================>............] - ETA: 28s  [ loss=3.0010 ][Training] 36/57 [=================>............] - ETA: 26s  [ loss=1.3852 ][Training] 37/57 [==================>...........] - ETA: 25s  [ loss=0.9235 ][Training] 38/57 [===================>..........] - ETA: 24s  [ loss=1.9480 ][Training] 39/57 [===================>..........] - ETA: 22s  [ loss=1.9357 ][Training] 40/57 [====================>.........] - ETA: 21s  [ loss=2.6735 ][Training] 41/57 [====================>.........] - ETA: 20s  [ loss=2.8730 ][Training] 42/57 [=====================>........] - ETA: 19s  [ loss=2.2365 ][Training] 43/57 [=====================>........] - ETA: 17s  [ loss=2.0104 ][Training] 44/57 [======================>.......] - ETA: 16s  [ loss=2.7112 ][Training] 45/57 [======================>.......] - ETA: 15s  [ loss=2.3810 ][Training] 46/57 [=======================>......] - ETA: 13s  [ loss=1.7892 ][Training] 47/57 [=======================>......] - ETA: 12s  [ loss=3.0913 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=2.1015 ][Training] 49/57 [========================>.....] - ETA: 10s  [ loss=4.2135 ][Training] 50/57 [=========================>....] - ETA: 8s  [ loss=0.8963 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=1.1197 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=2.3221 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=2.2106 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=1.4678 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=1.3676 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=2.1986 ][Training] 57/57 [==============================] 1.3s/step  [ loss=1.1086 ]
01/06/2024 08:14:35 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/06/2024 08:14:35 - INFO - root -   ***** Running evaluation on test dataset  *****
01/06/2024 08:14:35 - INFO - root -     Num examples = 269
01/06/2024 08:14:35 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 4s[Evaluating] 2/12 [====>.........................] - ETA: 5s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 2s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 560.0ms/step
01/06/2024 08:14:42 - INFO - root -   

01/06/2024 08:14:42 - INFO - root -   ***** Eval results  *****
01/06/2024 08:14:42 - INFO - root -    acc: 0.6943 - recall: 0.7700 - f1: 0.7302 - loss: 4.1273 
01/06/2024 08:14:42 - INFO - root -   ***** Entity results  *****
01/06/2024 08:14:42 - INFO - root -   ******* GPE.NAM results ********
01/06/2024 08:14:42 - INFO - root -    acc: 0.7692 - recall: 0.8511 - f1: 0.8081 
01/06/2024 08:14:42 - INFO - root -   ******* GPE.NOM results ********
01/06/2024 08:14:42 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/06/2024 08:14:42 - INFO - root -   ******* LOC.NAM results ********
01/06/2024 08:14:42 - INFO - root -    acc: 0.6500 - recall: 0.6842 - f1: 0.6667 
01/06/2024 08:14:42 - INFO - root -   ******* LOC.NOM results ********
01/06/2024 08:14:42 - INFO - root -    acc: 0.3333 - recall: 0.3333 - f1: 0.3333 
01/06/2024 08:14:42 - INFO - root -   ******* ORG.NAM results ********
01/06/2024 08:14:42 - INFO - root -    acc: 0.6047 - recall: 0.6667 - f1: 0.6341 
01/06/2024 08:14:42 - INFO - root -   ******* ORG.NOM results ********
01/06/2024 08:14:42 - INFO - root -    acc: 0.8000 - recall: 0.4706 - f1: 0.5926 
01/06/2024 08:14:42 - INFO - root -   ******* PER.NAM results ********
01/06/2024 08:14:42 - INFO - root -    acc: 0.7542 - recall: 0.8091 - f1: 0.7807 
01/06/2024 08:14:42 - INFO - root -   ******* PER.NOM results ********
01/06/2024 08:14:42 - INFO - root -    acc: 0.6748 - recall: 0.8176 - f1: 0.7394 
01/06/2024 08:14:46 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-399
01/06/2024 08:14:46 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-399
01/06/2024 08:14:46 - INFO - root -   

01/06/2024 08:14:46 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 7/50
[Training] 1/57 [..............................] - ETA: 1:15  [ loss=1.7885 ][Training] 2/57 [>.............................] - ETA: 1:08  [ loss=3.8480 ][Training] 3/57 [>.............................] - ETA: 1:01  [ loss=1.0128 ][Training] 4/57 [=>............................] - ETA: 1:01  [ loss=2.1225 ][Training] 5/57 [=>............................] - ETA: 1:02  [ loss=1.8933 ][Training] 6/57 [==>...........................] - ETA: 59s  [ loss=0.9074 ][Training] 7/57 [==>...........................] - ETA: 1:01  [ loss=2.5528 ][Training] 8/57 [===>..........................] - ETA: 58s  [ loss=1.5127 ][Training] 9/57 [===>..........................] - ETA: 58s  [ loss=1.5122 ][Training] 10/57 [====>.........................] - ETA: 56s  [ loss=1.1990 ][Training] 11/57 [====>.........................] - ETA: 56s  [ loss=4.2951 ][Training] 12/57 [=====>........................] - ETA: 55s  [ loss=1.1953 ][Training] 13/57 [=====>........................] - ETA: 55s  [ loss=2.1551 ][Training] 14/57 [======>.......................] - ETA: 54s  [ loss=1.6167 ][Training] 15/57 [======>.......................] - ETA: 52s  [ loss=2.2832 ][Training] 16/57 [=======>......................] - ETA: 51s  [ loss=2.3315 ][Training] 17/57 [=======>......................] - ETA: 50s  [ loss=1.1588 ][Training] 18/57 [========>.....................] - ETA: 48s  [ loss=0.8511 ][Training] 19/57 [=========>....................] - ETA: 46s  [ loss=1.5364 ][Training] 20/57 [=========>....................] - ETA: 45s  [ loss=1.2874 ][Training] 21/57 [==========>...................] - ETA: 44s  [ loss=2.6896 ][Training] 22/57 [==========>...................] - ETA: 44s  [ loss=0.9908 ][Training] 23/57 [===========>..................] - ETA: 42s  [ loss=1.3966 ][Training] 24/57 [===========>..................] - ETA: 41s  [ loss=1.5593 ][Training] 25/57 [============>.................] - ETA: 40s  [ loss=2.8052 ][Training] 26/57 [============>.................] - ETA: 39s  [ loss=0.9477 ][Training] 27/57 [=============>................] - ETA: 38s  [ loss=1.5626 ][Training] 28/57 [=============>................] - ETA: 37s  [ loss=0.8837 ][Training] 29/57 [==============>...............] - ETA: 35s  [ loss=1.9107 ][Training] 30/57 [==============>...............] - ETA: 34s  [ loss=1.0009 ][Training] 31/57 [===============>..............] - ETA: 32s  [ loss=1.7583 ][Training] 32/57 [===============>..............] - ETA: 31s  [ loss=2.3642 ][Training] 33/57 [================>.............] - ETA: 30s  [ loss=1.6806 ][Training] 34/57 [================>.............] - ETA: 28s  [ loss=2.4332 ][Training] 35/57 [=================>............] - ETA: 27s  [ loss=1.3584 ][Training] 36/57 [=================>............] - ETA: 26s  [ loss=1.3869 ][Training] 37/57 [==================>...........] - ETA: 24s  [ loss=3.6472 ][Training] 38/57 [===================>..........] - ETA: 23s  [ loss=1.7728 ][Training] 39/57 [===================>..........] - ETA: 22s  [ loss=1.0827 ][Training] 40/57 [====================>.........] - ETA: 21s  [ loss=0.4664 ][Training] 41/57 [====================>.........] - ETA: 19s  [ loss=1.4285 ][Training] 42/57 [=====================>........] - ETA: 18s  [ loss=2.8271 ][Training] 43/57 [=====================>........] - ETA: 17s  [ loss=1.5858 ][Training] 44/57 [======================>.......] - ETA: 16s  [ loss=3.3082 ][Training] 45/57 [======================>.......] - ETA: 14s  [ loss=2.3403 ][Training] 46/57 [=======================>......] - ETA: 13s  [ loss=2.1785 ][Training] 47/57 [=======================>......] - ETA: 12s  [ loss=1.1456 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=2.4051 ][Training] 49/57 [========================>.....] - ETA: 10s  [ loss=1.8835 ][Training] 50/57 [=========================>....] - ETA: 8s  [ loss=3.3826 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=2.3970 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=0.7489 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=0.8100 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=2.7113 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=4.3815 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=1.5728 ][Training] 57/57 [==============================] 1.3s/step  [ loss=2.5673 ]
01/06/2024 08:15:58 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/06/2024 08:15:58 - INFO - root -   ***** Running evaluation on test dataset  *****
01/06/2024 08:15:58 - INFO - root -     Num examples = 269
01/06/2024 08:15:58 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 7s[Evaluating] 2/12 [====>.........................] - ETA: 5s[Evaluating] 3/12 [======>.......................] - ETA: 4s[Evaluating] 4/12 [=========>....................] - ETA: 5s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 609.4ms/step
01/06/2024 08:16:05 - INFO - root -   

01/06/2024 08:16:05 - INFO - root -   ***** Eval results  *****
01/06/2024 08:16:05 - INFO - root -    acc: 0.7662 - recall: 0.7458 - f1: 0.7558 - loss: 3.8244 
01/06/2024 08:16:05 - INFO - root -   ***** Entity results  *****
01/06/2024 08:16:05 - INFO - root -   ******* GPE.NAM results ********
01/06/2024 08:16:05 - INFO - root -    acc: 0.8696 - recall: 0.8511 - f1: 0.8602 
01/06/2024 08:16:05 - INFO - root -   ******* GPE.NOM results ********
01/06/2024 08:16:05 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/06/2024 08:16:05 - INFO - root -   ******* LOC.NAM results ********
01/06/2024 08:16:05 - INFO - root -    acc: 0.5833 - recall: 0.7368 - f1: 0.6512 
01/06/2024 08:16:05 - INFO - root -   ******* LOC.NOM results ********
01/06/2024 08:16:05 - INFO - root -    acc: 0.6667 - recall: 0.2222 - f1: 0.3333 
01/06/2024 08:16:05 - INFO - root -   ******* ORG.NAM results ********
01/06/2024 08:16:05 - INFO - root -    acc: 0.6667 - recall: 0.6667 - f1: 0.6667 
01/06/2024 08:16:05 - INFO - root -   ******* ORG.NOM results ********
01/06/2024 08:16:05 - INFO - root -    acc: 0.7500 - recall: 0.5294 - f1: 0.6207 
01/06/2024 08:16:05 - INFO - root -   ******* PER.NAM results ********
01/06/2024 08:16:05 - INFO - root -    acc: 0.8108 - recall: 0.8182 - f1: 0.8145 
01/06/2024 08:16:05 - INFO - root -   ******* PER.NOM results ********
01/06/2024 08:16:05 - INFO - root -    acc: 0.7651 - recall: 0.7471 - f1: 0.7560 
01/06/2024 08:16:18 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-456
01/06/2024 08:16:18 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-456
01/06/2024 08:16:18 - INFO - root -   

01/06/2024 08:16:18 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 8/50
[Training] 1/57 [..............................] - ETA: 1:02  [ loss=1.1958 ][Training] 2/57 [>.............................] - ETA: 59s  [ loss=1.8643 ][Training] 3/57 [>.............................] - ETA: 1:05  [ loss=0.8367 ][Training] 4/57 [=>............................] - ETA: 1:02  [ loss=3.3515 ][Training] 5/57 [=>............................] - ETA: 1:06  [ loss=2.5932 ][Training] 6/57 [==>...........................] - ETA: 1:03  [ loss=1.0731 ][Training] 7/57 [==>...........................] - ETA: 1:01  [ loss=1.3209 ][Training] 8/57 [===>..........................] - ETA: 58s  [ loss=1.9018 ][Training] 9/57 [===>..........................] - ETA: 1:00  [ loss=1.4244 ][Training] 10/57 [====>.........................] - ETA: 57s  [ loss=0.6738 ][Training] 11/57 [====>.........................] - ETA: 57s  [ loss=0.8676 ][Training] 12/57 [=====>........................] - ETA: 55s  [ loss=3.6737 ][Training] 13/57 [=====>........................] - ETA: 54s  [ loss=1.3134 ][Training] 14/57 [======>.......................] - ETA: 52s  [ loss=0.7639 ][Training] 15/57 [======>.......................] - ETA: 51s  [ loss=2.7977 ][Training] 16/57 [=======>......................] - ETA: 49s  [ loss=1.3022 ][Training] 17/57 [=======>......................] - ETA: 48s  [ loss=0.6977 ][Training] 18/57 [========>.....................] - ETA: 47s  [ loss=1.3157 ][Training] 19/57 [=========>....................] - ETA: 45s  [ loss=1.4753 ][Training] 20/57 [=========>....................] - ETA: 44s  [ loss=1.8351 ][Training] 21/57 [==========>...................] - ETA: 44s  [ loss=1.3959 ][Training] 22/57 [==========>...................] - ETA: 43s  [ loss=1.7037 ][Training] 23/57 [===========>..................] - ETA: 42s  [ loss=0.6156 ][Training] 24/57 [===========>..................] - ETA: 40s  [ loss=1.0568 ][Training] 25/57 [============>.................] - ETA: 39s  [ loss=1.2213 ][Training] 26/57 [============>.................] - ETA: 38s  [ loss=2.0120 ][Training] 27/57 [=============>................] - ETA: 36s  [ loss=2.9485 ][Training] 28/57 [=============>................] - ETA: 35s  [ loss=1.8215 ][Training] 29/57 [==============>...............] - ETA: 34s  [ loss=1.0757 ][Training] 30/57 [==============>...............] - ETA: 33s  [ loss=2.3840 ][Training] 31/57 [===============>..............] - ETA: 31s  [ loss=1.1542 ][Training] 32/57 [===============>..............] - ETA: 30s  [ loss=2.3049 ][Training] 33/57 [================>.............] - ETA: 29s  [ loss=1.5790 ][Training] 34/57 [================>.............] - ETA: 28s  [ loss=1.1854 ][Training] 35/57 [=================>............] - ETA: 27s  [ loss=1.4223 ][Training] 36/57 [=================>............] - ETA: 25s  [ loss=0.9872 ][Training] 37/57 [==================>...........] - ETA: 24s  [ loss=2.0137 ][Training] 38/57 [===================>..........] - ETA: 23s  [ loss=1.3411 ][Training] 39/57 [===================>..........] - ETA: 22s  [ loss=1.2968 ][Training] 40/57 [====================>.........] - ETA: 21s  [ loss=2.5553 ][Training] 41/57 [====================>.........] - ETA: 19s  [ loss=2.3089 ][Training] 42/57 [=====================>........] - ETA: 18s  [ loss=1.1283 ][Training] 43/57 [=====================>........] - ETA: 17s  [ loss=1.9781 ][Training] 44/57 [======================>.......] - ETA: 16s  [ loss=1.7439 ][Training] 45/57 [======================>.......] - ETA: 14s  [ loss=1.8712 ][Training] 46/57 [=======================>......] - ETA: 13s  [ loss=0.7207 ][Training] 47/57 [=======================>......] - ETA: 12s  [ loss=2.3413 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=1.4387 ][Training] 49/57 [========================>.....] - ETA: 9s  [ loss=1.8660 ][Training] 50/57 [=========================>....] - ETA: 8s  [ loss=1.7722 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=2.2104 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=1.2487 ][Training] 53/57 [==========================>...] - ETA: 4s  [ loss=1.5939 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=4.6953 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=1.9628 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=1.0414 ][Training] 57/57 [==============================] 1.2s/step  [ loss=2.0155 ]
01/06/2024 08:17:28 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/06/2024 08:17:28 - INFO - root -   ***** Running evaluation on test dataset  *****
01/06/2024 08:17:28 - INFO - root -     Num examples = 269
01/06/2024 08:17:28 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 5s[Evaluating] 2/12 [====>.........................] - ETA: 6s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 597.8ms/step
01/06/2024 08:17:35 - INFO - root -   

01/06/2024 08:17:35 - INFO - root -   ***** Eval results  *****
01/06/2024 08:17:35 - INFO - root -    acc: 0.7470 - recall: 0.7651 - f1: 0.7560 - loss: 4.0267 
01/06/2024 08:17:35 - INFO - root -   ***** Entity results  *****
01/06/2024 08:17:35 - INFO - root -   ******* GPE.NAM results ********
01/06/2024 08:17:35 - INFO - root -    acc: 0.8542 - recall: 0.8723 - f1: 0.8632 
01/06/2024 08:17:35 - INFO - root -   ******* GPE.NOM results ********
01/06/2024 08:17:35 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/06/2024 08:17:35 - INFO - root -   ******* LOC.NAM results ********
01/06/2024 08:17:35 - INFO - root -    acc: 0.6364 - recall: 0.7368 - f1: 0.6829 
01/06/2024 08:17:35 - INFO - root -   ******* LOC.NOM results ********
01/06/2024 08:17:35 - INFO - root -    acc: 0.3636 - recall: 0.4444 - f1: 0.4000 
01/06/2024 08:17:35 - INFO - root -   ******* ORG.NAM results ********
01/06/2024 08:17:35 - INFO - root -    acc: 0.6571 - recall: 0.5897 - f1: 0.6216 
01/06/2024 08:17:35 - INFO - root -   ******* ORG.NOM results ********
01/06/2024 08:17:35 - INFO - root -    acc: 0.7500 - recall: 0.5294 - f1: 0.6207 
01/06/2024 08:17:35 - INFO - root -   ******* PER.NAM results ********
01/06/2024 08:17:35 - INFO - root -    acc: 0.7807 - recall: 0.8091 - f1: 0.7946 
01/06/2024 08:17:35 - INFO - root -   ******* PER.NOM results ********
01/06/2024 08:17:35 - INFO - root -    acc: 0.7514 - recall: 0.8000 - f1: 0.7749 
01/06/2024 08:17:41 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-513
01/06/2024 08:17:41 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-513
01/06/2024 08:17:41 - INFO - root -   

01/06/2024 08:17:41 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 9/50
[Training] 1/57 [..............................] - ETA: 1:23  [ loss=2.5139 ][Training] 2/57 [>.............................] - ETA: 1:13  [ loss=0.8648 ][Training] 3/57 [>.............................] - ETA: 1:11  [ loss=0.8711 ][Training] 4/57 [=>............................] - ETA: 1:07  [ loss=1.8256 ][Training] 5/57 [=>............................] - ETA: 1:06  [ loss=1.9112 ][Training] 6/57 [==>...........................] - ETA: 1:01  [ loss=0.7959 ][Training] 7/57 [==>...........................] - ETA: 1:00  [ loss=0.5126 ][Training] 8/57 [===>..........................] - ETA: 58s  [ loss=0.6291 ][Training] 9/57 [===>..........................] - ETA: 58s  [ loss=2.3614 ][Training] 10/57 [====>.........................] - ETA: 56s  [ loss=1.3391 ][Training] 11/57 [====>.........................] - ETA: 58s  [ loss=2.0545 ][Training] 12/57 [=====>........................] - ETA: 56s  [ loss=1.3892 ][Training] 13/57 [=====>........................] - ETA: 54s  [ loss=1.1255 ][Training] 14/57 [======>.......................] - ETA: 52s  [ loss=1.8008 ][Training] 15/57 [======>.......................] - ETA: 51s  [ loss=1.3796 ][Training] 16/57 [=======>......................] - ETA: 49s  [ loss=1.1584 ][Training] 17/57 [=======>......................] - ETA: 48s  [ loss=0.5700 ][Training] 18/57 [========>.....................] - ETA: 46s  [ loss=1.4606 ][Training] 19/57 [=========>....................] - ETA: 45s  [ loss=0.8113 ][Training] 20/57 [=========>....................] - ETA: 44s  [ loss=1.1951 ][Training] 21/57 [==========>...................] - ETA: 43s  [ loss=0.5621 ][Training] 22/57 [==========>...................] - ETA: 42s  [ loss=1.2987 ][Training] 23/57 [===========>..................] - ETA: 41s  [ loss=1.4510 ][Training] 24/57 [===========>..................] - ETA: 40s  [ loss=0.6919 ][Training] 25/57 [============>.................] - ETA: 38s  [ loss=1.3098 ][Training] 26/57 [============>.................] - ETA: 37s  [ loss=1.9417 ][Training] 27/57 [=============>................] - ETA: 36s  [ loss=2.5258 ][Training] 28/57 [=============>................] - ETA: 35s  [ loss=1.8780 ][Training] 29/57 [==============>...............] - ETA: 34s  [ loss=3.6894 ][Training] 30/57 [==============>...............] - ETA: 33s  [ loss=1.7539 ][Training] 31/57 [===============>..............] - ETA: 31s  [ loss=1.4683 ][Training] 32/57 [===============>..............] - ETA: 30s  [ loss=1.3288 ][Training] 33/57 [================>.............] - ETA: 29s  [ loss=0.6968 ][Training] 34/57 [================>.............] - ETA: 28s  [ loss=1.5815 ][Training] 35/57 [=================>............] - ETA: 26s  [ loss=0.9550 ][Training] 36/57 [=================>............] - ETA: 26s  [ loss=1.0962 ][Training] 37/57 [==================>...........] - ETA: 24s  [ loss=1.2490 ][Training] 38/57 [===================>..........] - ETA: 23s  [ loss=1.2192 ][Training] 39/57 [===================>..........] - ETA: 22s  [ loss=3.0566 ][Training] 40/57 [====================>.........] - ETA: 21s  [ loss=1.6527 ][Training] 41/57 [====================>.........] - ETA: 19s  [ loss=1.0807 ][Training] 42/57 [=====================>........] - ETA: 18s  [ loss=1.2285 ][Training] 43/57 [=====================>........] - ETA: 17s  [ loss=1.4959 ][Training] 44/57 [======================>.......] - ETA: 16s  [ loss=1.0411 ][Training] 45/57 [======================>.......] - ETA: 15s  [ loss=0.9710 ][Training] 46/57 [=======================>......] - ETA: 13s  [ loss=1.0365 ][Training] 47/57 [=======================>......] - ETA: 12s  [ loss=1.4789 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=1.2850 ][Training] 49/57 [========================>.....] - ETA: 10s  [ loss=2.3186 ][Training] 50/57 [=========================>....] - ETA: 8s  [ loss=0.6984 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=2.4016 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=1.0164 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=2.8905 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=1.1166 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=1.4021 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.8211 ][Training] 57/57 [==============================] 1.3s/step  [ loss=4.6652 ]
01/06/2024 08:18:53 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/06/2024 08:18:53 - INFO - root -   ***** Running evaluation on test dataset  *****
01/06/2024 08:18:53 - INFO - root -     Num examples = 269
01/06/2024 08:18:53 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 9s[Evaluating] 2/12 [====>.........................] - ETA: 7s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 5s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 4s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 2s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 615.8ms/step
01/06/2024 08:19:00 - INFO - root -   

01/06/2024 08:19:00 - INFO - root -   ***** Eval results  *****
01/06/2024 08:19:00 - INFO - root -    acc: 0.7373 - recall: 0.7748 - f1: 0.7556 - loss: 4.2139 
01/06/2024 08:19:00 - INFO - root -   ***** Entity results  *****
01/06/2024 08:19:00 - INFO - root -   ******* GPE.NAM results ********
01/06/2024 08:19:00 - INFO - root -    acc: 0.8269 - recall: 0.9149 - f1: 0.8687 
01/06/2024 08:19:00 - INFO - root -   ******* GPE.NOM results ********
01/06/2024 08:19:00 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/06/2024 08:19:00 - INFO - root -   ******* LOC.NAM results ********
01/06/2024 08:19:00 - INFO - root -    acc: 0.6667 - recall: 0.7368 - f1: 0.7000 
01/06/2024 08:19:00 - INFO - root -   ******* LOC.NOM results ********
01/06/2024 08:19:00 - INFO - root -    acc: 0.2857 - recall: 0.4444 - f1: 0.3478 
01/06/2024 08:19:00 - INFO - root -   ******* ORG.NAM results ********
01/06/2024 08:19:00 - INFO - root -    acc: 0.7000 - recall: 0.7179 - f1: 0.7089 
01/06/2024 08:19:00 - INFO - root -   ******* ORG.NOM results ********
01/06/2024 08:19:00 - INFO - root -    acc: 0.7059 - recall: 0.7059 - f1: 0.7059 
01/06/2024 08:19:00 - INFO - root -   ******* PER.NAM results ********
01/06/2024 08:19:00 - INFO - root -    acc: 0.7797 - recall: 0.8364 - f1: 0.8070 
01/06/2024 08:19:00 - INFO - root -   ******* PER.NOM results ********
01/06/2024 08:19:00 - INFO - root -    acc: 0.7384 - recall: 0.7471 - f1: 0.7427 
01/06/2024 08:19:09 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-570
01/06/2024 08:19:09 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-570
01/06/2024 08:19:09 - INFO - root -   

01/06/2024 08:19:09 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 10/50
[Training] 1/57 [..............................] - ETA: 57s  [ loss=1.1662 ][Training] 2/57 [>.............................] - ETA: 50s  [ loss=0.3857 ][Training] 3/57 [>.............................] - ETA: 57s  [ loss=1.0032 ][Training] 4/57 [=>............................] - ETA: 1:02  [ loss=2.5545 ][Training] 5/57 [=>............................] - ETA: 1:00  [ loss=1.1034 ][Training] 6/57 [==>...........................] - ETA: 1:01  [ loss=1.2917 ][Training] 7/57 [==>...........................] - ETA: 1:01  [ loss=1.0151 ][Training] 8/57 [===>..........................] - ETA: 59s  [ loss=0.8282 ][Training] 9/57 [===>..........................] - ETA: 59s  [ loss=0.7595 ][Training] 10/57 [====>.........................] - ETA: 57s  [ loss=1.5352 ][Training] 11/57 [====>.........................] - ETA: 57s  [ loss=1.0435 ][Training] 12/57 [=====>........................] - ETA: 57s  [ loss=1.8718 ][Training] 13/57 [=====>........................] - ETA: 55s  [ loss=1.4167 ][Training] 14/57 [======>.......................] - ETA: 57s  [ loss=0.9939 ][Training] 15/57 [======>.......................] - ETA: 55s  [ loss=1.0969 ][Training] 16/57 [=======>......................] - ETA: 54s  [ loss=2.4145 ][Training] 17/57 [=======>......................] - ETA: 53s  [ loss=1.2162 ][Training] 18/57 [========>.....................] - ETA: 51s  [ loss=0.9917 ][Training] 19/57 [=========>....................] - ETA: 50s  [ loss=1.2952 ][Training] 20/57 [=========>....................] - ETA: 49s  [ loss=1.5888 ][Training] 21/57 [==========>...................] - ETA: 48s  [ loss=1.6125 ][Training] 22/57 [==========>...................] - ETA: 46s  [ loss=0.9585 ][Training] 23/57 [===========>..................] - ETA: 45s  [ loss=1.1480 ][Training] 24/57 [===========>..................] - ETA: 44s  [ loss=0.6295 ][Training] 25/57 [============>.................] - ETA: 42s  [ loss=1.0396 ][Training] 26/57 [============>.................] - ETA: 40s  [ loss=1.6284 ][Training] 27/57 [=============>................] - ETA: 39s  [ loss=2.4090 ][Training] 28/57 [=============>................] - ETA: 38s  [ loss=0.7904 ][Training] 29/57 [==============>...............] - ETA: 37s  [ loss=1.8074 ][Training] 30/57 [==============>...............] - ETA: 35s  [ loss=1.6780 ][Training] 31/57 [===============>..............] - ETA: 34s  [ loss=1.1302 ][Training] 32/57 [===============>..............] - ETA: 32s  [ loss=1.5083 ][Training] 33/57 [================>.............] - ETA: 31s  [ loss=1.8472 ][Training] 34/57 [================>.............] - ETA: 30s  [ loss=0.6783 ][Training] 35/57 [=================>............] - ETA: 28s  [ loss=0.3284 ][Training] 36/57 [=================>............] - ETA: 27s  [ loss=1.0161 ][Training] 37/57 [==================>...........] - ETA: 26s  [ loss=2.1437 ][Training] 38/57 [===================>..........] - ETA: 24s  [ loss=3.0711 ][Training] 39/57 [===================>..........] - ETA: 23s  [ loss=2.3204 ][Training] 40/57 [====================>.........] - ETA: 22s  [ loss=1.6268 ][Training] 41/57 [====================>.........] - ETA: 20s  [ loss=1.3034 ][Training] 42/57 [=====================>........] - ETA: 19s  [ loss=1.3838 ][Training] 43/57 [=====================>........] - ETA: 18s  [ loss=2.9824 ][Training] 44/57 [======================>.......] - ETA: 16s  [ loss=0.8666 ][Training] 45/57 [======================>.......] - ETA: 15s  [ loss=0.8785 ][Training] 46/57 [=======================>......] - ETA: 14s  [ loss=0.3978 ][Training] 47/57 [=======================>......] - ETA: 12s  [ loss=1.4108 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=2.8777 ][Training] 49/57 [========================>.....] - ETA: 10s  [ loss=0.8087 ][Training] 50/57 [=========================>....] - ETA: 9s  [ loss=1.2022 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=0.3805 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=1.5621 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=1.9786 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=0.8553 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=1.5475 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=1.1777 ][Training] 57/57 [==============================] 1.3s/step  [ loss=1.3475 ]
01/06/2024 08:20:22 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/06/2024 08:20:22 - INFO - root -   ***** Running evaluation on test dataset  *****
01/06/2024 08:20:22 - INFO - root -     Num examples = 269
01/06/2024 08:20:22 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 4s[Evaluating] 2/12 [====>.........................] - ETA: 5s[Evaluating] 3/12 [======>.......................] - ETA: 4s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 2s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 580.2ms/step
01/06/2024 08:20:29 - INFO - root -   

01/06/2024 08:20:29 - INFO - root -   ***** Eval results  *****
01/06/2024 08:20:29 - INFO - root -    acc: 0.6896 - recall: 0.8015 - f1: 0.7413 - loss: 5.3761 
01/06/2024 08:20:29 - INFO - root -   ***** Entity results  *****
01/06/2024 08:20:29 - INFO - root -   ******* GPE.NAM results ********
01/06/2024 08:20:29 - INFO - root -    acc: 0.8400 - recall: 0.8936 - f1: 0.8660 
01/06/2024 08:20:29 - INFO - root -   ******* GPE.NOM results ********
01/06/2024 08:20:29 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/06/2024 08:20:29 - INFO - root -   ******* LOC.NAM results ********
01/06/2024 08:20:29 - INFO - root -    acc: 0.7000 - recall: 0.7368 - f1: 0.7179 
01/06/2024 08:20:29 - INFO - root -   ******* LOC.NOM results ********
01/06/2024 08:20:29 - INFO - root -    acc: 0.4000 - recall: 0.4444 - f1: 0.4211 
01/06/2024 08:20:29 - INFO - root -   ******* ORG.NAM results ********
01/06/2024 08:20:29 - INFO - root -    acc: 0.6170 - recall: 0.7436 - f1: 0.6744 
01/06/2024 08:20:29 - INFO - root -   ******* ORG.NOM results ********
01/06/2024 08:20:29 - INFO - root -    acc: 0.7059 - recall: 0.7059 - f1: 0.7059 
01/06/2024 08:20:29 - INFO - root -   ******* PER.NAM results ********
01/06/2024 08:20:29 - INFO - root -    acc: 0.6985 - recall: 0.8636 - f1: 0.7724 
01/06/2024 08:20:29 - INFO - root -   ******* PER.NOM results ********
01/06/2024 08:20:29 - INFO - root -    acc: 0.6784 - recall: 0.7941 - f1: 0.7317 
01/06/2024 08:20:33 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-627
01/06/2024 08:20:33 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-627
01/06/2024 08:20:33 - INFO - root -   

01/06/2024 08:20:33 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 11/50
[Training] 1/57 [..............................] - ETA: 1:07  [ loss=2.1028 ][Training] 2/57 [>.............................] - ETA: 1:02  [ loss=2.1408 ][Training] 3/57 [>.............................] - ETA: 1:05  [ loss=0.8676 ][Training] 4/57 [=>............................] - ETA: 1:01  [ loss=1.8383 ][Training] 5/57 [=>............................] - ETA: 1:04  [ loss=1.2670 ][Training] 6/57 [==>...........................] - ETA: 1:04  [ loss=2.4086 ][Training] 7/57 [==>...........................] - ETA: 1:00  [ loss=0.4538 ][Training] 8/57 [===>..........................] - ETA: 57s  [ loss=0.9039 ][Training] 9/57 [===>..........................] - ETA: 58s  [ loss=0.8336 ][Training] 10/57 [====>.........................] - ETA: 58s  [ loss=1.1954 ][Training] 11/57 [====>.........................] - ETA: 55s  [ loss=0.8115 ][Training] 12/57 [=====>........................] - ETA: 55s  [ loss=1.2089 ][Training] 13/57 [=====>........................] - ETA: 52s  [ loss=2.1399 ][Training] 14/57 [======>.......................] - ETA: 50s  [ loss=0.9637 ][Training] 15/57 [======>.......................] - ETA: 50s  [ loss=1.6566 ][Training] 16/57 [=======>......................] - ETA: 49s  [ loss=1.0414 ][Training] 17/57 [=======>......................] - ETA: 48s  [ loss=1.4748 ][Training] 18/57 [========>.....................] - ETA: 47s  [ loss=0.6077 ][Training] 19/57 [=========>....................] - ETA: 45s  [ loss=0.7207 ][Training] 20/57 [=========>....................] - ETA: 44s  [ loss=1.4171 ][Training] 21/57 [==========>...................] - ETA: 43s  [ loss=0.9047 ][Training] 22/57 [==========>...................] - ETA: 42s  [ loss=0.6361 ][Training] 23/57 [===========>..................] - ETA: 41s  [ loss=2.9476 ][Training] 24/57 [===========>..................] - ETA: 39s  [ loss=0.6969 ][Training] 25/57 [============>.................] - ETA: 37s  [ loss=0.1639 ][Training] 26/57 [============>.................] - ETA: 37s  [ loss=0.9474 ][Training] 27/57 [=============>................] - ETA: 35s  [ loss=1.3375 ][Training] 28/57 [=============>................] - ETA: 34s  [ loss=0.7022 ][Training] 29/57 [==============>...............] - ETA: 33s  [ loss=1.2044 ][Training] 30/57 [==============>...............] - ETA: 32s  [ loss=1.1953 ][Training] 31/57 [===============>..............] - ETA: 31s  [ loss=2.4893 ][Training] 32/57 [===============>..............] - ETA: 30s  [ loss=0.7805 ][Training] 33/57 [================>.............] - ETA: 28s  [ loss=1.3316 ][Training] 34/57 [================>.............] - ETA: 28s  [ loss=2.1816 ][Training] 35/57 [=================>............] - ETA: 26s  [ loss=1.1620 ][Training] 36/57 [=================>............] - ETA: 25s  [ loss=1.5380 ][Training] 37/57 [==================>...........] - ETA: 24s  [ loss=1.8292 ][Training] 38/57 [===================>..........] - ETA: 23s  [ loss=1.1220 ][Training] 39/57 [===================>..........] - ETA: 22s  [ loss=1.0553 ][Training] 40/57 [====================>.........] - ETA: 21s  [ loss=1.3042 ][Training] 41/57 [====================>.........] - ETA: 20s  [ loss=0.3330 ][Training] 42/57 [=====================>........] - ETA: 18s  [ loss=1.4564 ][Training] 43/57 [=====================>........] - ETA: 17s  [ loss=0.6125 ][Training] 44/57 [======================>.......] - ETA: 16s  [ loss=1.0695 ][Training] 45/57 [======================>.......] - ETA: 14s  [ loss=0.5027 ][Training] 46/57 [=======================>......] - ETA: 13s  [ loss=1.2789 ][Training] 47/57 [=======================>......] - ETA: 12s  [ loss=0.8077 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=3.4428 ][Training] 49/57 [========================>.....] - ETA: 9s  [ loss=0.5297 ][Training] 50/57 [=========================>....] - ETA: 8s  [ loss=0.8709 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=1.3449 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=0.6963 ][Training] 53/57 [==========================>...] - ETA: 4s  [ loss=1.5656 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=1.1137 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=0.9617 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=2.8636 ][Training] 57/57 [==============================] 1.2s/step  [ loss=0.9230 ]
01/06/2024 08:21:43 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/06/2024 08:21:43 - INFO - root -   ***** Running evaluation on test dataset  *****
01/06/2024 08:21:43 - INFO - root -     Num examples = 269
01/06/2024 08:21:43 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 4s[Evaluating] 2/12 [====>.........................] - ETA: 5s[Evaluating] 3/12 [======>.......................] - ETA: 4s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 576.8ms/step
01/06/2024 08:21:50 - INFO - root -   

01/06/2024 08:21:50 - INFO - root -   ***** Eval results  *****
01/06/2024 08:21:50 - INFO - root -    acc: 0.7427 - recall: 0.7409 - f1: 0.7418 - loss: 4.2901 
01/06/2024 08:21:50 - INFO - root -   ***** Entity results  *****
01/06/2024 08:21:50 - INFO - root -   ******* GPE.NAM results ********
01/06/2024 08:21:50 - INFO - root -    acc: 0.8269 - recall: 0.9149 - f1: 0.8687 
01/06/2024 08:21:50 - INFO - root -   ******* GPE.NOM results ********
01/06/2024 08:21:50 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/06/2024 08:21:50 - INFO - root -   ******* LOC.NAM results ********
01/06/2024 08:21:50 - INFO - root -    acc: 0.6087 - recall: 0.7368 - f1: 0.6667 
01/06/2024 08:21:50 - INFO - root -   ******* LOC.NOM results ********
01/06/2024 08:21:50 - INFO - root -    acc: 0.5000 - recall: 0.4444 - f1: 0.4706 
01/06/2024 08:21:50 - INFO - root -   ******* ORG.NAM results ********
01/06/2024 08:21:50 - INFO - root -    acc: 0.6410 - recall: 0.6410 - f1: 0.6410 
01/06/2024 08:21:50 - INFO - root -   ******* ORG.NOM results ********
01/06/2024 08:21:50 - INFO - root -    acc: 0.7143 - recall: 0.5882 - f1: 0.6452 
01/06/2024 08:21:50 - INFO - root -   ******* PER.NAM results ********
01/06/2024 08:21:50 - INFO - root -    acc: 0.7459 - recall: 0.8273 - f1: 0.7845 
01/06/2024 08:21:50 - INFO - root -   ******* PER.NOM results ********
01/06/2024 08:21:50 - INFO - root -    acc: 0.7778 - recall: 0.7000 - f1: 0.7368 
01/06/2024 08:21:55 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-684
01/06/2024 08:21:55 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-684
01/06/2024 08:21:55 - INFO - root -   

01/06/2024 08:21:55 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 12/50
[Training] 1/57 [..............................] - ETA: 1:06  [ loss=0.6694 ][Training] 2/57 [>.............................] - ETA: 1:08  [ loss=1.3382 ][Training] 3/57 [>.............................] - ETA: 58s  [ loss=0.6459 ][Training] 4/57 [=>............................] - ETA: 1:05  [ loss=1.0112 ][Training] 5/57 [=>............................] - ETA: 1:02  [ loss=1.5591 ][Training] 6/57 [==>...........................] - ETA: 1:04  [ loss=2.4878 ][Training] 7/57 [==>...........................] - ETA: 1:00  [ loss=0.3660 ][Training] 8/57 [===>..........................] - ETA: 1:01  [ loss=0.7111 ][Training] 9/57 [===>..........................] - ETA: 58s  [ loss=0.9737 ][Training] 10/57 [====>.........................] - ETA: 1:00  [ loss=1.1705 ][Training] 11/57 [====>.........................] - ETA: 59s  [ loss=0.8772 ][Training] 12/57 [=====>........................] - ETA: 57s  [ loss=0.6457 ][Training] 13/57 [=====>........................] - ETA: 57s  [ loss=1.6611 ][Training] 14/57 [======>.......................] - ETA: 55s  [ loss=0.9969 ][Training] 15/57 [======>.......................] - ETA: 54s  [ loss=0.3052 ][Training] 16/57 [=======>......................] - ETA: 51s  [ loss=0.7452 ][Training] 17/57 [=======>......................] - ETA: 50s  [ loss=0.7464 ][Training] 18/57 [========>.....................] - ETA: 48s  [ loss=0.5789 ][Training] 19/57 [=========>....................] - ETA: 47s  [ loss=1.4938 ][Training] 20/57 [=========>....................] - ETA: 45s  [ loss=1.6833 ][Training] 21/57 [==========>...................] - ETA: 45s  [ loss=0.7122 ][Training] 22/57 [==========>...................] - ETA: 43s  [ loss=1.0592 ][Training] 23/57 [===========>..................] - ETA: 42s  [ loss=1.0875 ][Training] 24/57 [===========>..................] - ETA: 40s  [ loss=0.7378 ][Training] 25/57 [============>.................] - ETA: 39s  [ loss=0.6182 ][Training] 26/57 [============>.................] - ETA: 38s  [ loss=2.3403 ][Training] 27/57 [=============>................] - ETA: 37s  [ loss=1.4709 ][Training] 28/57 [=============>................] - ETA: 36s  [ loss=0.7131 ][Training] 29/57 [==============>...............] - ETA: 34s  [ loss=0.9932 ][Training] 30/57 [==============>...............] - ETA: 33s  [ loss=1.3145 ][Training] 31/57 [===============>..............] - ETA: 32s  [ loss=0.4701 ][Training] 32/57 [===============>..............] - ETA: 31s  [ loss=1.0024 ][Training] 33/57 [================>.............] - ETA: 30s  [ loss=0.6510 ][Training] 34/57 [================>.............] - ETA: 28s  [ loss=0.3650 ][Training] 35/57 [=================>............] - ETA: 27s  [ loss=0.2536 ][Training] 36/57 [=================>............] - ETA: 26s  [ loss=1.3736 ][Training] 37/57 [==================>...........] - ETA: 25s  [ loss=0.4214 ][Training] 38/57 [===================>..........] - ETA: 23s  [ loss=1.6505 ][Training] 39/57 [===================>..........] - ETA: 22s  [ loss=2.7649 ][Training] 40/57 [====================>.........] - ETA: 21s  [ loss=0.9396 ][Training] 41/57 [====================>.........] - ETA: 20s  [ loss=0.8162 ][Training] 42/57 [=====================>........] - ETA: 18s  [ loss=0.3880 ][Training] 43/57 [=====================>........] - ETA: 17s  [ loss=1.0997 ][Training] 44/57 [======================>.......] - ETA: 16s  [ loss=1.3303 ][Training] 45/57 [======================>.......] - ETA: 15s  [ loss=2.2050 ][Training] 46/57 [=======================>......] - ETA: 13s  [ loss=1.3196 ][Training] 47/57 [=======================>......] - ETA: 12s  [ loss=1.1919 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=2.2056 ][Training] 49/57 [========================>.....] - ETA: 10s  [ loss=0.6944 ][Training] 50/57 [=========================>....] - ETA: 8s  [ loss=1.7386 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=0.7784 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=0.8688 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=0.6395 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=0.7865 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=2.7623 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=1.4863 ][Training] 57/57 [==============================] 1.3s/step  [ loss=1.6346 ]
01/06/2024 08:23:07 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/06/2024 08:23:07 - INFO - root -   ***** Running evaluation on test dataset  *****
01/06/2024 08:23:07 - INFO - root -     Num examples = 269
01/06/2024 08:23:07 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 4s[Evaluating] 2/12 [====>.........................] - ETA: 5s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 3s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 575.7ms/step
01/06/2024 08:23:14 - INFO - root -   

01/06/2024 08:23:14 - INFO - root -   ***** Eval results  *****
01/06/2024 08:23:14 - INFO - root -    acc: 0.7536 - recall: 0.7554 - f1: 0.7545 - loss: 4.3544 
01/06/2024 08:23:14 - INFO - root -   ***** Entity results  *****
01/06/2024 08:23:14 - INFO - root -   ******* GPE.NAM results ********
01/06/2024 08:23:14 - INFO - root -    acc: 0.8431 - recall: 0.9149 - f1: 0.8776 
01/06/2024 08:23:14 - INFO - root -   ******* GPE.NOM results ********
01/06/2024 08:23:14 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/06/2024 08:23:14 - INFO - root -   ******* LOC.NAM results ********
01/06/2024 08:23:14 - INFO - root -    acc: 0.6667 - recall: 0.7368 - f1: 0.7000 
01/06/2024 08:23:14 - INFO - root -   ******* LOC.NOM results ********
01/06/2024 08:23:14 - INFO - root -    acc: 0.5000 - recall: 0.3333 - f1: 0.4000 
01/06/2024 08:23:14 - INFO - root -   ******* ORG.NAM results ********
01/06/2024 08:23:14 - INFO - root -    acc: 0.6170 - recall: 0.7436 - f1: 0.6744 
01/06/2024 08:23:14 - INFO - root -   ******* ORG.NOM results ********
01/06/2024 08:23:14 - INFO - root -    acc: 0.7692 - recall: 0.5882 - f1: 0.6667 
01/06/2024 08:23:14 - INFO - root -   ******* PER.NAM results ********
01/06/2024 08:23:14 - INFO - root -    acc: 0.8241 - recall: 0.8091 - f1: 0.8165 
01/06/2024 08:23:14 - INFO - root -   ******* PER.NOM results ********
01/06/2024 08:23:14 - INFO - root -    acc: 0.7425 - recall: 0.7294 - f1: 0.7359 
01/06/2024 08:23:18 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-741
01/06/2024 08:23:18 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-741
01/06/2024 08:23:18 - INFO - root -   

01/06/2024 08:23:19 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 13/50
[Training] 1/57 [..............................] - ETA: 55s  [ loss=1.1098 ][Training] 2/57 [>.............................] - ETA: 1:01  [ loss=0.4067 ][Training] 3/57 [>.............................] - ETA: 1:01  [ loss=0.6296 ][Training] 4/57 [=>............................] - ETA: 1:04  [ loss=0.7003 ][Training] 5/57 [=>............................] - ETA: 58s  [ loss=0.3359 ][Training] 6/57 [==>...........................] - ETA: 54s  [ loss=1.2531 ][Training] 7/57 [==>...........................] - ETA: 56s  [ loss=0.4318 ][Training] 8/57 [===>..........................] - ETA: 56s  [ loss=1.9634 ][Training] 9/57 [===>..........................] - ETA: 55s  [ loss=1.6098 ][Training] 10/57 [====>.........................] - ETA: 53s  [ loss=1.2833 ][Training] 11/57 [====>.........................] - ETA: 54s  [ loss=1.1766 ][Training] 12/57 [=====>........................] - ETA: 52s  [ loss=0.8201 ][Training] 13/57 [=====>........................] - ETA: 52s  [ loss=1.0621 ][Training] 14/57 [======>.......................] - ETA: 51s  [ loss=0.5302 ][Training] 15/57 [======>.......................] - ETA: 49s  [ loss=0.6309 ][Training] 16/57 [=======>......................] - ETA: 49s  [ loss=0.8405 ][Training] 17/57 [=======>......................] - ETA: 48s  [ loss=0.7056 ][Training] 18/57 [========>.....................] - ETA: 48s  [ loss=0.6338 ][Training] 19/57 [=========>....................] - ETA: 47s  [ loss=2.5717 ][Training] 20/57 [=========>....................] - ETA: 45s  [ loss=1.0603 ][Training] 21/57 [==========>...................] - ETA: 44s  [ loss=1.0728 ][Training] 22/57 [==========>...................] - ETA: 43s  [ loss=0.5399 ][Training] 23/57 [===========>..................] - ETA: 42s  [ loss=0.8674 ][Training] 24/57 [===========>..................] - ETA: 41s  [ loss=0.9338 ][Training] 25/57 [============>.................] - ETA: 39s  [ loss=1.1561 ][Training] 26/57 [============>.................] - ETA: 39s  [ loss=0.9102 ][Training] 27/57 [=============>................] - ETA: 38s  [ loss=1.0849 ][Training] 28/57 [=============>................] - ETA: 36s  [ loss=1.1827 ][Training] 29/57 [==============>...............] - ETA: 35s  [ loss=1.3447 ][Training] 30/57 [==============>...............] - ETA: 34s  [ loss=0.9950 ][Training] 31/57 [===============>..............] - ETA: 32s  [ loss=0.6463 ][Training] 32/57 [===============>..............] - ETA: 31s  [ loss=0.6566 ][Training] 33/57 [================>.............] - ETA: 30s  [ loss=1.0853 ][Training] 34/57 [================>.............] - ETA: 28s  [ loss=0.5146 ][Training] 35/57 [=================>............] - ETA: 27s  [ loss=0.3109 ][Training] 36/57 [=================>............] - ETA: 26s  [ loss=1.3675 ][Training] 37/57 [==================>...........] - ETA: 24s  [ loss=0.7067 ][Training] 38/57 [===================>..........] - ETA: 23s  [ loss=0.7720 ][Training] 39/57 [===================>..........] - ETA: 22s  [ loss=0.9913 ][Training] 40/57 [====================>.........] - ETA: 21s  [ loss=0.8136 ][Training] 41/57 [====================>.........] - ETA: 20s  [ loss=1.2697 ][Training] 42/57 [=====================>........] - ETA: 19s  [ loss=0.5291 ][Training] 43/57 [=====================>........] - ETA: 17s  [ loss=0.8545 ][Training] 44/57 [======================>.......] - ETA: 16s  [ loss=0.5163 ][Training] 45/57 [======================>.......] - ETA: 15s  [ loss=0.8752 ][Training] 46/57 [=======================>......] - ETA: 14s  [ loss=0.8472 ][Training] 47/57 [=======================>......] - ETA: 12s  [ loss=1.4820 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=0.8789 ][Training] 49/57 [========================>.....] - ETA: 10s  [ loss=1.0642 ][Training] 50/57 [=========================>....] - ETA: 8s  [ loss=1.1502 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=0.7726 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=1.0507 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=0.8623 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=1.9068 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=2.0697 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=1.7037 ][Training] 57/57 [==============================] 1.3s/step  [ loss=0.1560 ]
01/06/2024 08:24:30 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/06/2024 08:24:30 - INFO - root -   ***** Running evaluation on test dataset  *****
01/06/2024 08:24:30 - INFO - root -     Num examples = 269
01/06/2024 08:24:30 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 5s[Evaluating] 2/12 [====>.........................] - ETA: 5s[Evaluating] 3/12 [======>.......................] - ETA: 4s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 2s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 569.5ms/step
01/06/2024 08:24:37 - INFO - root -   

01/06/2024 08:24:37 - INFO - root -   ***** Eval results  *****
01/06/2024 08:24:37 - INFO - root -    acc: 0.7293 - recall: 0.7893 - f1: 0.7581 - loss: 4.7808 
01/06/2024 08:24:37 - INFO - root -   ***** Entity results  *****
01/06/2024 08:24:37 - INFO - root -   ******* GPE.NAM results ********
01/06/2024 08:24:37 - INFO - root -    acc: 0.8542 - recall: 0.8723 - f1: 0.8632 
01/06/2024 08:24:37 - INFO - root -   ******* GPE.NOM results ********
01/06/2024 08:24:37 - INFO - root -    acc: 0.5000 - recall: 0.5000 - f1: 0.5000 
01/06/2024 08:24:37 - INFO - root -   ******* LOC.NAM results ********
01/06/2024 08:24:37 - INFO - root -    acc: 0.6087 - recall: 0.7368 - f1: 0.6667 
01/06/2024 08:24:37 - INFO - root -   ******* LOC.NOM results ********
01/06/2024 08:24:37 - INFO - root -    acc: 0.4286 - recall: 0.3333 - f1: 0.3750 
01/06/2024 08:24:37 - INFO - root -   ******* ORG.NAM results ********
01/06/2024 08:24:37 - INFO - root -    acc: 0.6316 - recall: 0.6154 - f1: 0.6234 
01/06/2024 08:24:37 - INFO - root -   ******* ORG.NOM results ********
01/06/2024 08:24:37 - INFO - root -    acc: 0.7857 - recall: 0.6471 - f1: 0.7097 
01/06/2024 08:24:37 - INFO - root -   ******* PER.NAM results ********
01/06/2024 08:24:37 - INFO - root -    acc: 0.7807 - recall: 0.8091 - f1: 0.7946 
01/06/2024 08:24:37 - INFO - root -   ******* PER.NOM results ********
01/06/2024 08:24:37 - INFO - root -    acc: 0.7114 - recall: 0.8412 - f1: 0.7709 
01/06/2024 08:24:41 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-798
01/06/2024 08:24:41 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-798
01/06/2024 08:24:41 - INFO - root -   

01/06/2024 08:24:41 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 14/50
[Training] 1/57 [..............................] - ETA: 1:25  [ loss=0.4178 ][Training] 2/57 [>.............................] - ETA: 1:02  [ loss=0.9166 ][Training] 3/57 [>.............................] - ETA: 1:17  [ loss=2.0428 ][Training] 4/57 [=>............................] - ETA: 1:09  [ loss=1.1472 ][Training] 5/57 [=>............................] - ETA: 1:13  [ loss=0.8986 ][Training] 6/57 [==>...........................] - ETA: 1:12  [ loss=1.5384 ][Training] 7/57 [==>...........................] - ETA: 1:10  [ loss=0.7681 ][Training] 8/57 [===>..........................] - ETA: 1:09  [ loss=1.1612 ][Training] 9/57 [===>..........................] - ETA: 1:06  [ loss=0.6712 ][Training] 10/57 [====>.........................] - ETA: 1:06  [ loss=1.3834 ][Training] 11/57 [====>.........................] - ETA: 1:05  [ loss=1.0984 ][Training] 12/57 [=====>........................] - ETA: 1:03  [ loss=0.1803 ][Training] 13/57 [=====>........................] - ETA: 1:00  [ loss=0.4465 ][Training] 14/57 [======>.......................] - ETA: 59s  [ loss=1.0931 ][Training] 15/57 [======>.......................] - ETA: 57s  [ loss=0.8982 ][Training] 16/57 [=======>......................] - ETA: 56s  [ loss=1.3408 ][Training] 17/57 [=======>......................] - ETA: 54s  [ loss=0.7781 ][Training] 18/57 [========>.....................] - ETA: 52s  [ loss=0.8117 ][Training] 19/57 [=========>....................] - ETA: 52s  [ loss=1.8550 ][Training] 20/57 [=========>....................] - ETA: 51s  [ loss=2.1192 ][Training] 21/57 [==========>...................] - ETA: 48s  [ loss=1.7027 ][Training] 22/57 [==========>...................] - ETA: 47s  [ loss=0.8741 ][Training] 23/57 [===========>..................] - ETA: 46s  [ loss=0.9173 ][Training] 24/57 [===========>..................] - ETA: 44s  [ loss=0.6540 ][Training] 25/57 [============>.................] - ETA: 43s  [ loss=1.3220 ][Training] 26/57 [============>.................] - ETA: 41s  [ loss=0.4228 ][Training] 27/57 [=============>................] - ETA: 40s  [ loss=0.9206 ][Training] 28/57 [=============>................] - ETA: 38s  [ loss=0.7274 ][Training] 29/57 [==============>...............] - ETA: 37s  [ loss=1.0669 ][Training] 30/57 [==============>...............] - ETA: 35s  [ loss=0.8269 ][Training] 31/57 [===============>..............] - ETA: 34s  [ loss=0.3136 ][Training] 32/57 [===============>..............] - ETA: 32s  [ loss=0.6440 ][Training] 33/57 [================>.............] - ETA: 31s  [ loss=0.4838 ][Training] 34/57 [================>.............] - ETA: 29s  [ loss=0.5319 ][Training] 35/57 [=================>............] - ETA: 28s  [ loss=0.7641 ][Training] 36/57 [=================>............] - ETA: 27s  [ loss=0.6842 ][Training] 37/57 [==================>...........] - ETA: 25s  [ loss=0.6660 ][Training] 38/57 [===================>..........] - ETA: 24s  [ loss=0.9841 ][Training] 39/57 [===================>..........] - ETA: 23s  [ loss=0.8624 ][Training] 40/57 [====================>.........] - ETA: 21s  [ loss=0.9383 ][Training] 41/57 [====================>.........] - ETA: 20s  [ loss=1.4677 ][Training] 42/57 [=====================>........] - ETA: 19s  [ loss=0.5717 ][Training] 43/57 [=====================>........] - ETA: 18s  [ loss=0.8842 ][Training] 44/57 [======================>.......] - ETA: 16s  [ loss=0.6373 ][Training] 45/57 [======================>.......] - ETA: 15s  [ loss=0.3463 ][Training] 46/57 [=======================>......] - ETA: 14s  [ loss=0.8147 ][Training] 47/57 [=======================>......] - ETA: 12s  [ loss=1.4643 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=0.4323 ][Training] 49/57 [========================>.....] - ETA: 10s  [ loss=0.6512 ][Training] 50/57 [=========================>....] - ETA: 9s  [ loss=0.8147 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=0.3245 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=1.0425 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=0.5984 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=0.8027 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=0.6272 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.9355 ][Training] 57/57 [==============================] 1.3s/step  [ loss=0.1820 ]
01/06/2024 08:25:55 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/06/2024 08:25:55 - INFO - root -   ***** Running evaluation on test dataset  *****
01/06/2024 08:25:55 - INFO - root -     Num examples = 269
01/06/2024 08:25:55 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 6s[Evaluating] 2/12 [====>.........................] - ETA: 5s[Evaluating] 3/12 [======>.......................] - ETA: 4s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 2s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 593.3ms/step
01/06/2024 08:26:02 - INFO - root -   

01/06/2024 08:26:02 - INFO - root -   ***** Eval results  *****
01/06/2024 08:26:02 - INFO - root -    acc: 0.7568 - recall: 0.7458 - f1: 0.7512 - loss: 4.4019 
01/06/2024 08:26:02 - INFO - root -   ***** Entity results  *****
01/06/2024 08:26:02 - INFO - root -   ******* GPE.NAM results ********
01/06/2024 08:26:02 - INFO - root -    acc: 0.8600 - recall: 0.9149 - f1: 0.8866 
01/06/2024 08:26:02 - INFO - root -   ******* GPE.NOM results ********
01/06/2024 08:26:02 - INFO - root -    acc: 0.5000 - recall: 0.5000 - f1: 0.5000 
01/06/2024 08:26:02 - INFO - root -   ******* LOC.NAM results ********
01/06/2024 08:26:02 - INFO - root -    acc: 0.6667 - recall: 0.7368 - f1: 0.7000 
01/06/2024 08:26:02 - INFO - root -   ******* LOC.NOM results ********
01/06/2024 08:26:02 - INFO - root -    acc: 0.5000 - recall: 0.4444 - f1: 0.4706 
01/06/2024 08:26:02 - INFO - root -   ******* ORG.NAM results ********
01/06/2024 08:26:02 - INFO - root -    acc: 0.6250 - recall: 0.6410 - f1: 0.6329 
01/06/2024 08:26:02 - INFO - root -   ******* ORG.NOM results ********
01/06/2024 08:26:02 - INFO - root -    acc: 0.7059 - recall: 0.7059 - f1: 0.7059 
01/06/2024 08:26:02 - INFO - root -   ******* PER.NAM results ********
01/06/2024 08:26:02 - INFO - root -    acc: 0.7826 - recall: 0.8182 - f1: 0.8000 
01/06/2024 08:26:02 - INFO - root -   ******* PER.NOM results ********
01/06/2024 08:26:02 - INFO - root -    acc: 0.7727 - recall: 0.7000 - f1: 0.7346 
01/06/2024 08:26:10 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-855
01/06/2024 08:26:10 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-855
01/06/2024 08:26:10 - INFO - root -   

01/06/2024 08:26:10 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 15/50
[Training] 1/57 [..............................] - ETA: 1:14  [ loss=0.4567 ][Training] 2/57 [>.............................] - ETA: 1:06  [ loss=0.4123 ][Training] 3/57 [>.............................] - ETA: 1:08  [ loss=0.2434 ][Training] 4/57 [=>............................] - ETA: 1:02  [ loss=0.8129 ][Training] 5/57 [=>............................] - ETA: 1:04  [ loss=0.3481 ][Training] 6/57 [==>...........................] - ETA: 59s  [ loss=0.6712 ][Training] 7/57 [==>...........................] - ETA: 1:00  [ loss=0.1123 ][Training] 8/57 [===>..........................] - ETA: 1:00  [ loss=1.7891 ][Training] 9/57 [===>..........................] - ETA: 1:01  [ loss=0.5451 ][Training] 10/57 [====>.........................] - ETA: 1:00  [ loss=0.4736 ][Training] 11/57 [====>.........................] - ETA: 58s  [ loss=0.3114 ][Training] 12/57 [=====>........................] - ETA: 58s  [ loss=1.3912 ][Training] 13/57 [=====>........................] - ETA: 57s  [ loss=0.2752 ][Training] 14/57 [======>.......................] - ETA: 56s  [ loss=0.5264 ][Training] 15/57 [======>.......................] - ETA: 55s  [ loss=0.6113 ][Training] 16/57 [=======>......................] - ETA: 53s  [ loss=0.6757 ][Training] 17/57 [=======>......................] - ETA: 52s  [ loss=0.6030 ][Training] 18/57 [========>.....................] - ETA: 50s  [ loss=1.1890 ][Training] 19/57 [=========>....................] - ETA: 48s  [ loss=0.6278 ][Training] 20/57 [=========>....................] - ETA: 47s  [ loss=0.9636 ][Training] 21/57 [==========>...................] - ETA: 46s  [ loss=1.9698 ][Training] 22/57 [==========>...................] - ETA: 44s  [ loss=1.5713 ][Training] 23/57 [===========>..................] - ETA: 43s  [ loss=0.6835 ][Training] 24/57 [===========>..................] - ETA: 42s  [ loss=0.6352 ][Training] 25/57 [============>.................] - ETA: 40s  [ loss=0.8198 ][Training] 26/57 [============>.................] - ETA: 39s  [ loss=0.6609 ][Training] 27/57 [=============>................] - ETA: 38s  [ loss=1.5540 ][Training] 28/57 [=============>................] - ETA: 37s  [ loss=2.3172 ][Training] 29/57 [==============>...............] - ETA: 36s  [ loss=0.7140 ][Training] 30/57 [==============>...............] - ETA: 35s  [ loss=0.8684 ][Training] 31/57 [===============>..............] - ETA: 33s  [ loss=0.7537 ][Training] 32/57 [===============>..............] - ETA: 32s  [ loss=0.8316 ][Training] 33/57 [================>.............] - ETA: 31s  [ loss=0.6861 ][Training] 34/57 [================>.............] - ETA: 29s  [ loss=0.1536 ][Training] 35/57 [=================>............] - ETA: 28s  [ loss=1.0247 ][Training] 36/57 [=================>............] - ETA: 27s  [ loss=1.5498 ][Training] 37/57 [==================>...........] - ETA: 26s  [ loss=0.7584 ][Training] 38/57 [===================>..........] - ETA: 24s  [ loss=1.0933 ][Training] 39/57 [===================>..........] - ETA: 23s  [ loss=0.5072 ][Training] 40/57 [====================>.........] - ETA: 22s  [ loss=1.0005 ][Training] 41/57 [====================>.........] - ETA: 20s  [ loss=0.1937 ][Training] 42/57 [=====================>........] - ETA: 19s  [ loss=0.3134 ][Training] 43/57 [=====================>........] - ETA: 18s  [ loss=1.0834 ][Training] 44/57 [======================>.......] - ETA: 16s  [ loss=0.8738 ][Training] 45/57 [======================>.......] - ETA: 15s  [ loss=0.4572 ][Training] 46/57 [=======================>......] - ETA: 14s  [ loss=0.5132 ][Training] 47/57 [=======================>......] - ETA: 13s  [ loss=0.5937 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=0.6458 ][Training] 49/57 [========================>.....] - ETA: 10s  [ loss=0.5647 ][Training] 50/57 [=========================>....] - ETA: 9s  [ loss=0.6737 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=0.8949 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=0.7244 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=1.0798 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=1.2371 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=0.5385 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=1.5629 ][Training] 57/57 [==============================] 1.3s/step  [ loss=0.6169 ]
01/06/2024 08:27:24 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/06/2024 08:27:24 - INFO - root -   ***** Running evaluation on test dataset  *****
01/06/2024 08:27:24 - INFO - root -     Num examples = 269
01/06/2024 08:27:24 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 6s[Evaluating] 2/12 [====>.........................] - ETA: 7s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 5s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 4s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 616.3ms/step
01/06/2024 08:27:31 - INFO - root -   

01/06/2024 08:27:31 - INFO - root -   ***** Eval results  *****
01/06/2024 08:27:31 - INFO - root -    acc: 0.7447 - recall: 0.7700 - f1: 0.7571 - loss: 4.5491 
01/06/2024 08:27:31 - INFO - root -   ***** Entity results  *****
01/06/2024 08:27:31 - INFO - root -   ******* GPE.NAM results ********
01/06/2024 08:27:31 - INFO - root -    acc: 0.8776 - recall: 0.9149 - f1: 0.8958 
01/06/2024 08:27:31 - INFO - root -   ******* GPE.NOM results ********
01/06/2024 08:27:31 - INFO - root -    acc: 0.5000 - recall: 0.5000 - f1: 0.5000 
01/06/2024 08:27:31 - INFO - root -   ******* LOC.NAM results ********
01/06/2024 08:27:31 - INFO - root -    acc: 0.6364 - recall: 0.7368 - f1: 0.6829 
01/06/2024 08:27:31 - INFO - root -   ******* LOC.NOM results ********
01/06/2024 08:27:31 - INFO - root -    acc: 0.4286 - recall: 0.3333 - f1: 0.3750 
01/06/2024 08:27:31 - INFO - root -   ******* ORG.NAM results ********
01/06/2024 08:27:31 - INFO - root -    acc: 0.7073 - recall: 0.7436 - f1: 0.7250 
01/06/2024 08:27:31 - INFO - root -   ******* ORG.NOM results ********
01/06/2024 08:27:31 - INFO - root -    acc: 0.7059 - recall: 0.7059 - f1: 0.7059 
01/06/2024 08:27:31 - INFO - root -   ******* PER.NAM results ********
01/06/2024 08:27:31 - INFO - root -    acc: 0.7913 - recall: 0.8273 - f1: 0.8089 
01/06/2024 08:27:31 - INFO - root -   ******* PER.NOM results ********
01/06/2024 08:27:31 - INFO - root -    acc: 0.7184 - recall: 0.7353 - f1: 0.7267 
01/06/2024 08:27:36 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-912
01/06/2024 08:27:36 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-912
01/06/2024 08:27:36 - INFO - root -   

01/06/2024 08:27:36 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 16/50
[Training] 1/57 [..............................] - ETA: 1:07  [ loss=0.4406 ][Training] 2/57 [>.............................] - ETA: 1:06  [ loss=0.5695 ][Training] 3/57 [>.............................] - ETA: 1:06  [ loss=0.8078 ][Training] 4/57 [=>............................] - ETA: 1:06  [ loss=0.4917 ][Training] 5/57 [=>............................] - ETA: 1:06  [ loss=2.2953 ][Training] 6/57 [==>...........................] - ETA: 1:04  [ loss=0.3766 ][Training] 7/57 [==>...........................] - ETA: 1:03  [ loss=0.4648 ][Training] 8/57 [===>..........................] - ETA: 59s  [ loss=0.3072 ][Training] 9/57 [===>..........................] - ETA: 57s  [ loss=0.6873 ][Training] 10/57 [====>.........................] - ETA: 57s  [ loss=0.6396 ][Training] 11/57 [====>.........................] - ETA: 57s  [ loss=0.8857 ][Training] 12/57 [=====>........................] - ETA: 56s  [ loss=0.5683 ][Training] 13/57 [=====>........................] - ETA: 54s  [ loss=0.8692 ][Training] 14/57 [======>.......................] - ETA: 54s  [ loss=0.6622 ][Training] 15/57 [======>.......................] - ETA: 54s  [ loss=0.1893 ][Training] 16/57 [=======>......................] - ETA: 52s  [ loss=0.6117 ][Training] 17/57 [=======>......................] - ETA: 50s  [ loss=0.6049 ][Training] 18/57 [========>.....................] - ETA: 48s  [ loss=0.2796 ][Training] 19/57 [=========>....................] - ETA: 47s  [ loss=0.5028 ][Training] 20/57 [=========>....................] - ETA: 46s  [ loss=0.6564 ][Training] 21/57 [==========>...................] - ETA: 45s  [ loss=1.3897 ][Training] 22/57 [==========>...................] - ETA: 44s  [ loss=0.8102 ][Training] 23/57 [===========>..................] - ETA: 42s  [ loss=0.4071 ][Training] 24/57 [===========>..................] - ETA: 41s  [ loss=0.3769 ][Training] 25/57 [============>.................] - ETA: 39s  [ loss=0.4732 ][Training] 26/57 [============>.................] - ETA: 38s  [ loss=0.9269 ][Training] 27/57 [=============>................] - ETA: 37s  [ loss=0.3804 ][Training] 28/57 [=============>................] - ETA: 36s  [ loss=0.2693 ][Training] 29/57 [==============>...............] - ETA: 34s  [ loss=0.6142 ][Training] 30/57 [==============>...............] - ETA: 33s  [ loss=1.1026 ][Training] 31/57 [===============>..............] - ETA: 32s  [ loss=0.3244 ][Training] 32/57 [===============>..............] - ETA: 31s  [ loss=1.7878 ][Training] 33/57 [================>.............] - ETA: 30s  [ loss=1.3924 ][Training] 34/57 [================>.............] - ETA: 29s  [ loss=1.0633 ][Training] 35/57 [=================>............] - ETA: 28s  [ loss=0.3252 ][Training] 36/57 [=================>............] - ETA: 26s  [ loss=0.3910 ][Training] 37/57 [==================>...........] - ETA: 25s  [ loss=1.0035 ][Training] 38/57 [===================>..........] - ETA: 24s  [ loss=0.5120 ][Training] 39/57 [===================>..........] - ETA: 23s  [ loss=0.7015 ][Training] 40/57 [====================>.........] - ETA: 21s  [ loss=1.0154 ][Training] 41/57 [====================>.........] - ETA: 20s  [ loss=0.3685 ][Training] 42/57 [=====================>........] - ETA: 18s  [ loss=1.5233 ][Training] 43/57 [=====================>........] - ETA: 17s  [ loss=0.7447 ][Training] 44/57 [======================>.......] - ETA: 16s  [ loss=0.4229 ][Training] 45/57 [======================>.......] - ETA: 15s  [ loss=0.8380 ][Training] 46/57 [=======================>......] - ETA: 13s  [ loss=0.4993 ][Training] 47/57 [=======================>......] - ETA: 12s  [ loss=0.3135 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=0.6312 ][Training] 49/57 [========================>.....] - ETA: 10s  [ loss=0.4969 ][Training] 50/57 [=========================>....] - ETA: 8s  [ loss=1.0409 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=1.2900 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=1.4772 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=0.9595 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=0.5188 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=0.2433 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.9366 ][Training] 57/57 [==============================] 1.2s/step  [ loss=1.1919 ]
01/06/2024 08:28:47 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/06/2024 08:28:47 - INFO - root -   ***** Running evaluation on test dataset  *****
01/06/2024 08:28:47 - INFO - root -     Num examples = 269
01/06/2024 08:28:47 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 5s[Evaluating] 2/12 [====>.........................] - ETA: 6s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 5s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 582.5ms/step
01/06/2024 08:28:54 - INFO - root -   

01/06/2024 08:28:54 - INFO - root -   ***** Eval results  *****
01/06/2024 08:28:54 - INFO - root -    acc: 0.7506 - recall: 0.7797 - f1: 0.7648 - loss: 4.5946 
01/06/2024 08:28:54 - INFO - root -   ***** Entity results  *****
01/06/2024 08:28:54 - INFO - root -   ******* GPE.NAM results ********
01/06/2024 08:28:54 - INFO - root -    acc: 0.8913 - recall: 0.8723 - f1: 0.8817 
01/06/2024 08:28:54 - INFO - root -   ******* GPE.NOM results ********
01/06/2024 08:28:54 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/06/2024 08:28:54 - INFO - root -   ******* LOC.NAM results ********
01/06/2024 08:28:54 - INFO - root -    acc: 0.6667 - recall: 0.7368 - f1: 0.7000 
01/06/2024 08:28:54 - INFO - root -   ******* LOC.NOM results ********
01/06/2024 08:28:54 - INFO - root -    acc: 0.7500 - recall: 0.3333 - f1: 0.4615 
01/06/2024 08:28:54 - INFO - root -   ******* ORG.NAM results ********
01/06/2024 08:28:54 - INFO - root -    acc: 0.6667 - recall: 0.6667 - f1: 0.6667 
01/06/2024 08:28:54 - INFO - root -   ******* ORG.NOM results ********
01/06/2024 08:28:54 - INFO - root -    acc: 0.7143 - recall: 0.5882 - f1: 0.6452 
01/06/2024 08:28:54 - INFO - root -   ******* PER.NAM results ********
01/06/2024 08:28:54 - INFO - root -    acc: 0.8053 - recall: 0.8273 - f1: 0.8161 
01/06/2024 08:28:54 - INFO - root -   ******* PER.NOM results ********
01/06/2024 08:28:54 - INFO - root -    acc: 0.7173 - recall: 0.8059 - f1: 0.7590 
01/06/2024 08:28:59 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-969
01/06/2024 08:28:59 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-969
01/06/2024 08:28:59 - INFO - root -   

01/06/2024 08:28:59 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 17/50
[Training] 1/57 [..............................] - ETA: 1:01  [ loss=1.0552 ][Training] 2/57 [>.............................] - ETA: 55s  [ loss=0.2555 ][Training] 3/57 [>.............................] - ETA: 51s  [ loss=0.4624 ][Training] 4/57 [=>............................] - ETA: 54s  [ loss=0.8360 ][Training] 5/57 [=>............................] - ETA: 55s  [ loss=0.5366 ][Training] 6/57 [==>...........................] - ETA: 57s  [ loss=0.3462 ][Training] 7/57 [==>...........................] - ETA: 58s  [ loss=0.5340 ][Training] 8/57 [===>..........................] - ETA: 57s  [ loss=0.1569 ][Training] 9/57 [===>..........................] - ETA: 57s  [ loss=0.9684 ][Training] 10/57 [====>.........................] - ETA: 55s  [ loss=1.2607 ][Training] 11/57 [====>.........................] - ETA: 57s  [ loss=0.8733 ][Training] 12/57 [=====>........................] - ETA: 59s  [ loss=0.9853 ][Training] 13/57 [=====>........................] - ETA: 57s  [ loss=0.4062 ][Training] 14/57 [======>.......................] - ETA: 55s  [ loss=0.7876 ][Training] 15/57 [======>.......................] - ETA: 54s  [ loss=0.6467 ][Training] 16/57 [=======>......................] - ETA: 53s  [ loss=0.9079 ][Training] 17/57 [=======>......................] - ETA: 51s  [ loss=0.1796 ][Training] 18/57 [========>.....................] - ETA: 50s  [ loss=0.7669 ][Training] 19/57 [=========>....................] - ETA: 49s  [ loss=1.1623 ][Training] 20/57 [=========>....................] - ETA: 48s  [ loss=1.1641 ][Training] 21/57 [==========>...................] - ETA: 46s  [ loss=0.9476 ][Training] 22/57 [==========>...................] - ETA: 45s  [ loss=0.8090 ][Training] 23/57 [===========>..................] - ETA: 44s  [ loss=2.0793 ][Training] 24/57 [===========>..................] - ETA: 43s  [ loss=0.2165 ][Training] 25/57 [============>.................] - ETA: 41s  [ loss=0.4534 ][Training] 26/57 [============>.................] - ETA: 40s  [ loss=1.6299 ][Training] 27/57 [=============>................] - ETA: 39s  [ loss=0.9614 ][Training] 28/57 [=============>................] - ETA: 37s  [ loss=0.4245 ][Training] 29/57 [==============>...............] - ETA: 36s  [ loss=0.7700 ][Training] 30/57 [==============>...............] - ETA: 34s  [ loss=0.2248 ][Training] 31/57 [===============>..............] - ETA: 33s  [ loss=0.5629 ][Training] 32/57 [===============>..............] - ETA: 32s  [ loss=0.2944 ][Training] 33/57 [================>.............] - ETA: 30s  [ loss=0.4382 ][Training] 34/57 [================>.............] - ETA: 29s  [ loss=0.8997 ][Training] 35/57 [=================>............] - ETA: 27s  [ loss=1.4329 ][Training] 36/57 [=================>............] - ETA: 26s  [ loss=0.8754 ][Training] 37/57 [==================>...........] - ETA: 24s  [ loss=0.6205 ][Training] 38/57 [===================>..........] - ETA: 23s  [ loss=0.4710 ][Training] 39/57 [===================>..........] - ETA: 21s  [ loss=0.1607 ][Training] 40/57 [====================>.........] - ETA: 20s  [ loss=0.4930 ][Training] 41/57 [====================>.........] - ETA: 18s  [ loss=0.0889 ][Training] 42/57 [=====================>........] - ETA: 17s  [ loss=0.2710 ][Training] 43/57 [=====================>........] - ETA: 16s  [ loss=0.7955 ][Training] 44/57 [======================>.......] - ETA: 15s  [ loss=0.2453 ][Training] 45/57 [======================>.......] - ETA: 14s  [ loss=1.1019 ][Training] 46/57 [=======================>......] - ETA: 13s  [ loss=0.4686 ][Training] 47/57 [=======================>......] - ETA: 11s  [ loss=0.6324 ][Training] 48/57 [========================>.....] - ETA: 10s  [ loss=0.4077 ][Training] 49/57 [========================>.....] - ETA: 9s  [ loss=2.0588 ][Training] 50/57 [=========================>....] - ETA: 8s  [ loss=0.3533 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=1.2503 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=0.3603 ][Training] 53/57 [==========================>...] - ETA: 4s  [ loss=0.5220 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=0.7780 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=0.6507 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=1.3298 ][Training] 57/57 [==============================] 1.2s/step  [ loss=0.5719 ]
01/06/2024 08:30:07 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/06/2024 08:30:07 - INFO - root -   ***** Running evaluation on test dataset  *****
01/06/2024 08:30:07 - INFO - root -     Num examples = 269
01/06/2024 08:30:07 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 7s[Evaluating] 2/12 [====>.........................] - ETA: 7s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 587.3ms/step
01/06/2024 08:30:14 - INFO - root -   

01/06/2024 08:30:14 - INFO - root -   ***** Eval results  *****
01/06/2024 08:30:14 - INFO - root -    acc: 0.7191 - recall: 0.7748 - f1: 0.7459 - loss: 4.6185 
01/06/2024 08:30:14 - INFO - root -   ***** Entity results  *****
01/06/2024 08:30:14 - INFO - root -   ******* GPE.NAM results ********
01/06/2024 08:30:14 - INFO - root -    acc: 0.8913 - recall: 0.8723 - f1: 0.8817 
01/06/2024 08:30:14 - INFO - root -   ******* GPE.NOM results ********
01/06/2024 08:30:14 - INFO - root -    acc: 0.5000 - recall: 0.5000 - f1: 0.5000 
01/06/2024 08:30:14 - INFO - root -   ******* LOC.NAM results ********
01/06/2024 08:30:14 - INFO - root -    acc: 0.6667 - recall: 0.7368 - f1: 0.7000 
01/06/2024 08:30:14 - INFO - root -   ******* LOC.NOM results ********
01/06/2024 08:30:14 - INFO - root -    acc: 0.4000 - recall: 0.4444 - f1: 0.4211 
01/06/2024 08:30:14 - INFO - root -   ******* ORG.NAM results ********
01/06/2024 08:30:14 - INFO - root -    acc: 0.6842 - recall: 0.6667 - f1: 0.6753 
01/06/2024 08:30:14 - INFO - root -   ******* ORG.NOM results ********
01/06/2024 08:30:14 - INFO - root -    acc: 0.6667 - recall: 0.5882 - f1: 0.6250 
01/06/2024 08:30:14 - INFO - root -   ******* PER.NAM results ********
01/06/2024 08:30:14 - INFO - root -    acc: 0.7797 - recall: 0.8364 - f1: 0.8070 
01/06/2024 08:30:14 - INFO - root -   ******* PER.NOM results ********
01/06/2024 08:30:14 - INFO - root -    acc: 0.6769 - recall: 0.7765 - f1: 0.7233 
01/06/2024 08:30:19 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1026
01/06/2024 08:30:19 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1026
01/06/2024 08:30:19 - INFO - root -   

01/06/2024 08:30:19 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 18/50
[Training] 1/57 [..............................] - ETA: 1:28  [ loss=1.5466 ][Training] 2/57 [>.............................] - ETA: 1:07  [ loss=0.7567 ][Training] 3/57 [>.............................] - ETA: 1:14  [ loss=0.8042 ][Training] 4/57 [=>............................] - ETA: 1:09  [ loss=0.4440 ][Training] 5/57 [=>............................] - ETA: 1:12  [ loss=0.5491 ][Training] 6/57 [==>...........................] - ETA: 1:07  [ loss=0.2717 ][Training] 7/57 [==>...........................] - ETA: 1:08  [ loss=0.9041 ][Training] 8/57 [===>..........................] - ETA: 1:05  [ loss=0.6805 ][Training] 9/57 [===>..........................] - ETA: 1:03  [ loss=0.4363 ][Training] 10/57 [====>.........................] - ETA: 1:01  [ loss=0.3896 ][Training] 11/57 [====>.........................] - ETA: 58s  [ loss=0.5178 ][Training] 12/57 [=====>........................] - ETA: 56s  [ loss=0.2933 ][Training] 13/57 [=====>........................] - ETA: 55s  [ loss=0.7241 ][Training] 14/57 [======>.......................] - ETA: 53s  [ loss=0.3551 ][Training] 15/57 [======>.......................] - ETA: 53s  [ loss=0.6454 ][Training] 16/57 [=======>......................] - ETA: 52s  [ loss=0.1730 ][Training] 17/57 [=======>......................] - ETA: 50s  [ loss=0.6089 ][Training] 18/57 [========>.....................] - ETA: 49s  [ loss=0.5850 ][Training] 19/57 [=========>....................] - ETA: 48s  [ loss=0.8019 ][Training] 20/57 [=========>....................] - ETA: 46s  [ loss=0.5185 ][Training] 21/57 [==========>...................] - ETA: 45s  [ loss=0.3889 ][Training] 22/57 [==========>...................] - ETA: 44s  [ loss=0.2230 ][Training] 23/57 [===========>..................] - ETA: 42s  [ loss=0.4921 ][Training] 24/57 [===========>..................] - ETA: 40s  [ loss=0.7898 ][Training] 25/57 [============>.................] - ETA: 39s  [ loss=0.7290 ][Training] 26/57 [============>.................] - ETA: 38s  [ loss=0.2344 ][Training] 27/57 [=============>................] - ETA: 37s  [ loss=1.2049 ][Training] 28/57 [=============>................] - ETA: 36s  [ loss=0.2529 ][Training] 29/57 [==============>...............] - ETA: 35s  [ loss=1.3217 ][Training] 30/57 [==============>...............] - ETA: 34s  [ loss=1.1146 ][Training] 31/57 [===============>..............] - ETA: 32s  [ loss=0.3817 ][Training] 32/57 [===============>..............] - ETA: 31s  [ loss=0.9355 ][Training] 33/57 [================>.............] - ETA: 29s  [ loss=0.4693 ][Training] 34/57 [================>.............] - ETA: 28s  [ loss=0.6380 ][Training] 35/57 [=================>............] - ETA: 26s  [ loss=0.7193 ][Training] 36/57 [=================>............] - ETA: 25s  [ loss=0.5008 ][Training] 37/57 [==================>...........] - ETA: 24s  [ loss=0.9636 ][Training] 38/57 [===================>..........] - ETA: 23s  [ loss=1.1432 ][Training] 39/57 [===================>..........] - ETA: 22s  [ loss=1.6476 ][Training] 40/57 [====================>.........] - ETA: 20s  [ loss=0.5421 ][Training] 41/57 [====================>.........] - ETA: 19s  [ loss=0.7647 ][Training] 42/57 [=====================>........] - ETA: 18s  [ loss=1.2638 ][Training] 43/57 [=====================>........] - ETA: 17s  [ loss=0.6260 ][Training] 44/57 [======================>.......] - ETA: 15s  [ loss=0.9342 ][Training] 45/57 [======================>.......] - ETA: 14s  [ loss=0.6942 ][Training] 46/57 [=======================>......] - ETA: 13s  [ loss=0.3542 ][Training] 47/57 [=======================>......] - ETA: 12s  [ loss=1.0457 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=0.3995 ][Training] 49/57 [========================>.....] - ETA: 9s  [ loss=0.7502 ][Training] 50/57 [=========================>....] - ETA: 8s  [ loss=0.3327 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=0.7012 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=0.5800 ][Training] 53/57 [==========================>...] - ETA: 4s  [ loss=0.8527 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=0.7116 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=0.3805 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.6770 ][Training] 57/57 [==============================] 1.2s/step  [ loss=0.4702 ]
01/06/2024 08:31:29 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/06/2024 08:31:29 - INFO - root -   ***** Running evaluation on test dataset  *****
01/06/2024 08:31:29 - INFO - root -     Num examples = 269
01/06/2024 08:31:29 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 8s[Evaluating] 2/12 [====>.........................] - ETA: 6s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 2s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 573.5ms/step
01/06/2024 08:31:36 - INFO - root -   

01/06/2024 08:31:36 - INFO - root -   ***** Eval results  *****
01/06/2024 08:31:36 - INFO - root -    acc: 0.7392 - recall: 0.7893 - f1: 0.7635 - loss: 4.7756 
01/06/2024 08:31:36 - INFO - root -   ***** Entity results  *****
01/06/2024 08:31:36 - INFO - root -   ******* GPE.NAM results ********
01/06/2024 08:31:36 - INFO - root -    acc: 0.8750 - recall: 0.8936 - f1: 0.8842 
01/06/2024 08:31:36 - INFO - root -   ******* GPE.NOM results ********
01/06/2024 08:31:36 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/06/2024 08:31:36 - INFO - root -   ******* LOC.NAM results ********
01/06/2024 08:31:36 - INFO - root -    acc: 0.6364 - recall: 0.7368 - f1: 0.6829 
01/06/2024 08:31:36 - INFO - root -   ******* LOC.NOM results ********
01/06/2024 08:31:36 - INFO - root -    acc: 0.3333 - recall: 0.3333 - f1: 0.3333 
01/06/2024 08:31:36 - INFO - root -   ******* ORG.NAM results ********
01/06/2024 08:31:36 - INFO - root -    acc: 0.7105 - recall: 0.6923 - f1: 0.7013 
01/06/2024 08:31:36 - INFO - root -   ******* ORG.NOM results ********
01/06/2024 08:31:36 - INFO - root -    acc: 0.8000 - recall: 0.7059 - f1: 0.7500 
01/06/2024 08:31:36 - INFO - root -   ******* PER.NAM results ********
01/06/2024 08:31:36 - INFO - root -    acc: 0.7750 - recall: 0.8455 - f1: 0.8087 
01/06/2024 08:31:36 - INFO - root -   ******* PER.NOM results ********
01/06/2024 08:31:36 - INFO - root -    acc: 0.7181 - recall: 0.7941 - f1: 0.7542 
01/06/2024 08:31:41 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1083
01/06/2024 08:31:41 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1083
01/06/2024 08:31:41 - INFO - root -   

01/06/2024 08:31:41 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 19/50
[Training] 1/57 [..............................] - ETA: 50s  [ loss=0.2090 ][Training] 2/57 [>.............................] - ETA: 1:08  [ loss=0.4993 ][Training] 3/57 [>.............................] - ETA: 1:00  [ loss=0.3772 ][Training] 4/57 [=>............................] - ETA: 1:04  [ loss=0.1642 ][Training] 5/57 [=>............................] - ETA: 1:02  [ loss=0.3240 ][Training] 6/57 [==>...........................] - ETA: 1:01  [ loss=0.4820 ][Training] 7/57 [==>...........................] - ETA: 59s  [ loss=0.5768 ][Training] 8/57 [===>..........................] - ETA: 58s  [ loss=0.7184 ][Training] 9/57 [===>..........................] - ETA: 58s  [ loss=1.0128 ][Training] 10/57 [====>.........................] - ETA: 57s  [ loss=0.7403 ][Training] 11/57 [====>.........................] - ETA: 56s  [ loss=1.0196 ][Training] 12/57 [=====>........................] - ETA: 56s  [ loss=0.5596 ][Training] 13/57 [=====>........................] - ETA: 54s  [ loss=0.3038 ][Training] 14/57 [======>.......................] - ETA: 53s  [ loss=0.6857 ][Training] 15/57 [======>.......................] - ETA: 51s  [ loss=0.3304 ][Training] 16/57 [=======>......................] - ETA: 50s  [ loss=0.4595 ][Training] 17/57 [=======>......................] - ETA: 48s  [ loss=0.5287 ][Training] 18/57 [========>.....................] - ETA: 48s  [ loss=0.6484 ][Training] 19/57 [=========>....................] - ETA: 47s  [ loss=0.8308 ][Training] 20/57 [=========>....................] - ETA: 45s  [ loss=0.1684 ][Training] 21/57 [==========>...................] - ETA: 44s  [ loss=0.7927 ][Training] 22/57 [==========>...................] - ETA: 43s  [ loss=0.5715 ][Training] 23/57 [===========>..................] - ETA: 41s  [ loss=0.3415 ][Training] 24/57 [===========>..................] - ETA: 41s  [ loss=0.6970 ][Training] 25/57 [============>.................] - ETA: 40s  [ loss=0.4940 ][Training] 26/57 [============>.................] - ETA: 38s  [ loss=0.3587 ][Training] 27/57 [=============>................] - ETA: 37s  [ loss=0.5337 ][Training] 28/57 [=============>................] - ETA: 36s  [ loss=0.8123 ][Training] 29/57 [==============>...............] - ETA: 35s  [ loss=0.7973 ][Training] 30/57 [==============>...............] - ETA: 34s  [ loss=0.6872 ][Training] 31/57 [===============>..............] - ETA: 33s  [ loss=0.7890 ][Training] 32/57 [===============>..............] - ETA: 31s  [ loss=0.7387 ][Training] 33/57 [================>.............] - ETA: 30s  [ loss=0.2779 ][Training] 34/57 [================>.............] - ETA: 29s  [ loss=0.1854 ][Training] 35/57 [=================>............] - ETA: 28s  [ loss=0.9163 ][Training] 36/57 [=================>............] - ETA: 26s  [ loss=1.4439 ][Training] 37/57 [==================>...........] - ETA: 25s  [ loss=0.7722 ][Training] 38/57 [===================>..........] - ETA: 24s  [ loss=1.0053 ][Training] 39/57 [===================>..........] - ETA: 23s  [ loss=1.9238 ][Training] 40/57 [====================>.........] - ETA: 22s  [ loss=0.4552 ][Training] 41/57 [====================>.........] - ETA: 20s  [ loss=0.5620 ][Training] 42/57 [=====================>........] - ETA: 19s  [ loss=0.4481 ][Training] 43/57 [=====================>........] - ETA: 18s  [ loss=0.1621 ][Training] 44/57 [======================>.......] - ETA: 16s  [ loss=0.4390 ][Training] 45/57 [======================>.......] - ETA: 15s  [ loss=0.6884 ][Training] 46/57 [=======================>......] - ETA: 14s  [ loss=0.5375 ][Training] 47/57 [=======================>......] - ETA: 12s  [ loss=1.8265 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=0.2144 ][Training] 49/57 [========================>.....] - ETA: 10s  [ loss=1.2997 ][Training] 50/57 [=========================>....] - ETA: 9s  [ loss=0.2031 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=0.5212 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=0.2567 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=1.2983 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=0.4429 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=0.5966 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.9090 ][Training] 57/57 [==============================] 1.3s/step  [ loss=0.2098 ]
01/06/2024 08:32:55 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/06/2024 08:32:55 - INFO - root -   ***** Running evaluation on test dataset  *****
01/06/2024 08:32:55 - INFO - root -     Num examples = 269
01/06/2024 08:32:55 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 6s[Evaluating] 2/12 [====>.........................] - ETA: 5s[Evaluating] 3/12 [======>.......................] - ETA: 4s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 586.1ms/step
01/06/2024 08:33:02 - INFO - root -   

01/06/2024 08:33:02 - INFO - root -   ***** Eval results  *****
01/06/2024 08:33:02 - INFO - root -    acc: 0.7623 - recall: 0.7530 - f1: 0.7576 - loss: 4.6128 
01/06/2024 08:33:02 - INFO - root -   ***** Entity results  *****
01/06/2024 08:33:02 - INFO - root -   ******* GPE.NAM results ********
01/06/2024 08:33:02 - INFO - root -    acc: 0.8600 - recall: 0.9149 - f1: 0.8866 
01/06/2024 08:33:02 - INFO - root -   ******* GPE.NOM results ********
01/06/2024 08:33:02 - INFO - root -    acc: 0.5000 - recall: 0.5000 - f1: 0.5000 
01/06/2024 08:33:02 - INFO - root -   ******* LOC.NAM results ********
01/06/2024 08:33:02 - INFO - root -    acc: 0.6364 - recall: 0.7368 - f1: 0.6829 
01/06/2024 08:33:02 - INFO - root -   ******* LOC.NOM results ********
01/06/2024 08:33:02 - INFO - root -    acc: 0.4000 - recall: 0.4444 - f1: 0.4211 
01/06/2024 08:33:02 - INFO - root -   ******* ORG.NAM results ********
01/06/2024 08:33:02 - INFO - root -    acc: 0.6667 - recall: 0.7179 - f1: 0.6914 
01/06/2024 08:33:02 - INFO - root -   ******* ORG.NOM results ********
01/06/2024 08:33:02 - INFO - root -    acc: 0.8000 - recall: 0.7059 - f1: 0.7500 
01/06/2024 08:33:02 - INFO - root -   ******* PER.NAM results ********
01/06/2024 08:33:02 - INFO - root -    acc: 0.7826 - recall: 0.8182 - f1: 0.8000 
01/06/2024 08:33:02 - INFO - root -   ******* PER.NOM results ********
01/06/2024 08:33:02 - INFO - root -    acc: 0.7829 - recall: 0.7000 - f1: 0.7391 
01/06/2024 08:33:08 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1140
01/06/2024 08:33:08 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1140
01/06/2024 08:33:08 - INFO - root -   

01/06/2024 08:33:08 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 20/50
[Training] 1/57 [..............................] - ETA: 1:19  [ loss=0.6924 ][Training] 2/57 [>.............................] - ETA: 1:10  [ loss=0.1860 ][Training] 3/57 [>.............................] - ETA: 1:09  [ loss=0.3748 ][Training] 4/57 [=>............................] - ETA: 1:07  [ loss=0.5664 ][Training] 5/57 [=>............................] - ETA: 1:04  [ loss=0.5550 ][Training] 6/57 [==>...........................] - ETA: 1:03  [ loss=0.6474 ][Training] 7/57 [==>...........................] - ETA: 1:03  [ loss=0.5942 ][Training] 8/57 [===>..........................] - ETA: 1:01  [ loss=0.7356 ][Training] 9/57 [===>..........................] - ETA: 1:02  [ loss=0.6027 ][Training] 10/57 [====>.........................] - ETA: 1:00  [ loss=0.7232 ][Training] 11/57 [====>.........................] - ETA: 1:00  [ loss=0.5121 ][Training] 12/57 [=====>........................] - ETA: 59s  [ loss=0.3098 ][Training] 13/57 [=====>........................] - ETA: 57s  [ loss=0.3220 ][Training] 14/57 [======>.......................] - ETA: 56s  [ loss=0.3192 ][Training] 15/57 [======>.......................] - ETA: 54s  [ loss=0.2152 ][Training] 16/57 [=======>......................] - ETA: 53s  [ loss=0.4219 ][Training] 17/57 [=======>......................] - ETA: 53s  [ loss=1.4279 ][Training] 18/57 [========>.....................] - ETA: 52s  [ loss=0.8329 ][Training] 19/57 [=========>....................] - ETA: 50s  [ loss=0.5203 ][Training] 20/57 [=========>....................] - ETA: 49s  [ loss=0.2127 ][Training] 21/57 [==========>...................] - ETA: 47s  [ loss=0.8860 ][Training] 22/57 [==========>...................] - ETA: 47s  [ loss=1.1694 ][Training] 23/57 [===========>..................] - ETA: 45s  [ loss=1.1217 ][Training] 24/57 [===========>..................] - ETA: 44s  [ loss=0.4176 ][Training] 25/57 [============>.................] - ETA: 43s  [ loss=0.2567 ][Training] 26/57 [============>.................] - ETA: 41s  [ loss=0.6271 ][Training] 27/57 [=============>................] - ETA: 40s  [ loss=0.5977 ][Training] 28/57 [=============>................] - ETA: 39s  [ loss=1.4454 ][Training] 29/57 [==============>...............] - ETA: 37s  [ loss=0.9518 ][Training] 30/57 [==============>...............] - ETA: 36s  [ loss=0.3197 ][Training] 31/57 [===============>..............] - ETA: 34s  [ loss=0.1296 ][Training] 32/57 [===============>..............] - ETA: 33s  [ loss=0.9597 ][Training] 33/57 [================>.............] - ETA: 32s  [ loss=0.9614 ][Training] 34/57 [================>.............] - ETA: 30s  [ loss=0.2958 ][Training] 35/57 [=================>............] - ETA: 29s  [ loss=1.0285 ][Training] 36/57 [=================>............] - ETA: 28s  [ loss=0.4809 ][Training] 37/57 [==================>...........] - ETA: 26s  [ loss=0.3544 ][Training] 38/57 [===================>..........] - ETA: 25s  [ loss=0.6845 ][Training] 39/57 [===================>..........] - ETA: 23s  [ loss=0.5914 ][Training] 40/57 [====================>.........] - ETA: 22s  [ loss=0.2798 ][Training] 41/57 [====================>.........] - ETA: 21s  [ loss=0.1875 ][Training] 42/57 [=====================>........] - ETA: 19s  [ loss=1.0303 ][Training] 43/57 [=====================>........] - ETA: 18s  [ loss=0.5966 ][Training] 44/57 [======================>.......] - ETA: 17s  [ loss=0.1962 ][Training] 45/57 [======================>.......] - ETA: 15s  [ loss=0.1688 ][Training] 46/57 [=======================>......] - ETA: 14s  [ loss=0.8587 ][Training] 47/57 [=======================>......] - ETA: 13s  [ loss=0.6117 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=0.3535 ][Training] 49/57 [========================>.....] - ETA: 10s  [ loss=0.5730 ][Training] 50/57 [=========================>....] - ETA: 9s  [ loss=0.2887 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=0.4410 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=1.2800 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=0.3559 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=0.2698 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=0.4317 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.2687 ][Training] 57/57 [==============================] 1.3s/step  [ loss=0.8161 ]
01/06/2024 08:34:22 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/06/2024 08:34:23 - INFO - root -   ***** Running evaluation on test dataset  *****
01/06/2024 08:34:23 - INFO - root -     Num examples = 269
01/06/2024 08:34:23 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 5s[Evaluating] 2/12 [====>.........................] - ETA: 6s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 599.7ms/step
01/06/2024 08:34:30 - INFO - root -   

01/06/2024 08:34:30 - INFO - root -   ***** Eval results  *****
01/06/2024 08:34:30 - INFO - root -    acc: 0.7552 - recall: 0.7845 - f1: 0.7696 - loss: 4.7263 
01/06/2024 08:34:30 - INFO - root -   ***** Entity results  *****
01/06/2024 08:34:30 - INFO - root -   ******* GPE.NAM results ********
01/06/2024 08:34:30 - INFO - root -    acc: 0.8750 - recall: 0.8936 - f1: 0.8842 
01/06/2024 08:34:30 - INFO - root -   ******* GPE.NOM results ********
01/06/2024 08:34:30 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/06/2024 08:34:30 - INFO - root -   ******* LOC.NAM results ********
01/06/2024 08:34:30 - INFO - root -    acc: 0.7000 - recall: 0.7368 - f1: 0.7179 
01/06/2024 08:34:30 - INFO - root -   ******* LOC.NOM results ********
01/06/2024 08:34:30 - INFO - root -    acc: 0.6250 - recall: 0.5556 - f1: 0.5882 
01/06/2024 08:34:30 - INFO - root -   ******* ORG.NAM results ********
01/06/2024 08:34:30 - INFO - root -    acc: 0.6757 - recall: 0.6410 - f1: 0.6579 
01/06/2024 08:34:30 - INFO - root -   ******* ORG.NOM results ********
01/06/2024 08:34:30 - INFO - root -    acc: 0.7857 - recall: 0.6471 - f1: 0.7097 
01/06/2024 08:34:30 - INFO - root -   ******* PER.NAM results ********
01/06/2024 08:34:30 - INFO - root -    acc: 0.8108 - recall: 0.8182 - f1: 0.8145 
01/06/2024 08:34:30 - INFO - root -   ******* PER.NOM results ********
01/06/2024 08:34:30 - INFO - root -    acc: 0.7211 - recall: 0.8059 - f1: 0.7611 
01/06/2024 08:34:35 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1197
01/06/2024 08:34:35 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1197
01/06/2024 08:34:35 - INFO - root -   

01/06/2024 08:34:35 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 21/50
[Training] 1/57 [..............................] - ETA: 57s  [ loss=0.1557 ][Training] 2/57 [>.............................] - ETA: 1:05  [ loss=1.0542 ][Training] 3/57 [>.............................] - ETA: 1:04  [ loss=0.9696 ][Training] 4/57 [=>............................] - ETA: 1:04  [ loss=0.1669 ][Training] 5/57 [=>............................] - ETA: 1:02  [ loss=1.0264 ][Training] 6/57 [==>...........................] - ETA: 1:00  [ loss=0.7301 ][Training] 7/57 [==>...........................] - ETA: 1:02  [ loss=0.2232 ][Training] 8/57 [===>..........................] - ETA: 1:01  [ loss=0.4811 ][Training] 9/57 [===>..........................] - ETA: 59s  [ loss=0.1865 ][Training] 10/57 [====>.........................] - ETA: 59s  [ loss=0.8075 ][Training] 11/57 [====>.........................] - ETA: 57s  [ loss=0.5374 ][Training] 12/57 [=====>........................] - ETA: 54s  [ loss=0.1341 ][Training] 13/57 [=====>........................] - ETA: 54s  [ loss=0.7149 ][Training] 14/57 [======>.......................] - ETA: 51s  [ loss=0.3622 ][Training] 15/57 [======>.......................] - ETA: 51s  [ loss=0.9133 ][Training] 16/57 [=======>......................] - ETA: 50s  [ loss=0.4450 ][Training] 17/57 [=======>......................] - ETA: 49s  [ loss=0.9461 ][Training] 18/57 [========>.....................] - ETA: 48s  [ loss=0.4923 ][Training] 19/57 [=========>....................] - ETA: 47s  [ loss=0.2551 ][Training] 20/57 [=========>....................] - ETA: 46s  [ loss=0.3134 ][Training] 21/57 [==========>...................] - ETA: 45s  [ loss=0.5747 ][Training] 22/57 [==========>...................] - ETA: 45s  [ loss=1.0699 ][Training] 23/57 [===========>..................] - ETA: 43s  [ loss=0.8234 ][Training] 24/57 [===========>..................] - ETA: 42s  [ loss=0.4435 ][Training] 25/57 [============>.................] - ETA: 41s  [ loss=0.8633 ][Training] 26/57 [============>.................] - ETA: 40s  [ loss=0.5314 ][Training] 27/57 [=============>................] - ETA: 38s  [ loss=0.2187 ][Training] 28/57 [=============>................] - ETA: 37s  [ loss=0.9066 ][Training] 29/57 [==============>...............] - ETA: 36s  [ loss=0.6902 ][Training] 30/57 [==============>...............] - ETA: 35s  [ loss=0.7666 ][Training] 31/57 [===============>..............] - ETA: 34s  [ loss=0.3382 ][Training] 32/57 [===============>..............] - ETA: 32s  [ loss=0.5018 ][Training] 33/57 [================>.............] - ETA: 31s  [ loss=0.3832 ][Training] 34/57 [================>.............] - ETA: 30s  [ loss=0.5387 ][Training] 35/57 [=================>............] - ETA: 29s  [ loss=1.4348 ][Training] 36/57 [=================>............] - ETA: 27s  [ loss=0.2907 ][Training] 37/57 [==================>...........] - ETA: 26s  [ loss=0.2664 ][Training] 38/57 [===================>..........] - ETA: 24s  [ loss=1.0551 ][Training] 39/57 [===================>..........] - ETA: 23s  [ loss=0.5792 ][Training] 40/57 [====================>.........] - ETA: 22s  [ loss=0.7036 ][Training] 41/57 [====================>.........] - ETA: 21s  [ loss=0.1313 ][Training] 42/57 [=====================>........] - ETA: 19s  [ loss=0.4003 ][Training] 43/57 [=====================>........] - ETA: 18s  [ loss=0.3765 ][Training] 44/57 [======================>.......] - ETA: 17s  [ loss=0.2379 ][Training] 45/57 [======================>.......] - ETA: 15s  [ loss=0.3655 ][Training] 46/57 [=======================>......] - ETA: 14s  [ loss=0.4512 ][Training] 47/57 [=======================>......] - ETA: 13s  [ loss=0.3296 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=0.6083 ][Training] 49/57 [========================>.....] - ETA: 10s  [ loss=0.7208 ][Training] 50/57 [=========================>....] - ETA: 9s  [ loss=0.9346 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=1.1126 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=1.2397 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=0.2205 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=0.3719 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=0.7360 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.3451 ][Training] 57/57 [==============================] 1.3s/step  [ loss=1.1674 ]
01/06/2024 08:35:47 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/06/2024 08:35:47 - INFO - root -   ***** Running evaluation on test dataset  *****
01/06/2024 08:35:47 - INFO - root -     Num examples = 269
01/06/2024 08:35:47 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 5s[Evaluating] 2/12 [====>.........................] - ETA: 4s[Evaluating] 3/12 [======>.......................] - ETA: 4s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 588.0ms/step
01/06/2024 08:35:54 - INFO - root -   

01/06/2024 08:35:54 - INFO - root -   ***** Eval results  *****
01/06/2024 08:35:54 - INFO - root -    acc: 0.7258 - recall: 0.7821 - f1: 0.7529 - loss: 5.0699 
01/06/2024 08:35:54 - INFO - root -   ***** Entity results  *****
01/06/2024 08:35:54 - INFO - root -   ******* GPE.NAM results ********
01/06/2024 08:35:54 - INFO - root -    acc: 0.8600 - recall: 0.9149 - f1: 0.8866 
01/06/2024 08:35:54 - INFO - root -   ******* GPE.NOM results ********
01/06/2024 08:35:54 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/06/2024 08:35:54 - INFO - root -   ******* LOC.NAM results ********
01/06/2024 08:35:54 - INFO - root -    acc: 0.7000 - recall: 0.7368 - f1: 0.7179 
01/06/2024 08:35:54 - INFO - root -   ******* LOC.NOM results ********
01/06/2024 08:35:54 - INFO - root -    acc: 0.3077 - recall: 0.4444 - f1: 0.3636 
01/06/2024 08:35:54 - INFO - root -   ******* ORG.NAM results ********
01/06/2024 08:35:54 - INFO - root -    acc: 0.6585 - recall: 0.6923 - f1: 0.6750 
01/06/2024 08:35:54 - INFO - root -   ******* ORG.NOM results ********
01/06/2024 08:35:54 - INFO - root -    acc: 0.7143 - recall: 0.5882 - f1: 0.6452 
01/06/2024 08:35:54 - INFO - root -   ******* PER.NAM results ********
01/06/2024 08:35:54 - INFO - root -    acc: 0.7895 - recall: 0.8182 - f1: 0.8036 
01/06/2024 08:35:54 - INFO - root -   ******* PER.NOM results ********
01/06/2024 08:35:54 - INFO - root -    acc: 0.7031 - recall: 0.7941 - f1: 0.7459 
01/06/2024 08:36:01 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1254
01/06/2024 08:36:01 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1254
01/06/2024 08:36:01 - INFO - root -   

01/06/2024 08:36:01 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 22/50
[Training] 1/57 [..............................] - ETA: 1:30  [ loss=0.1782 ][Training] 2/57 [>.............................] - ETA: 1:13  [ loss=0.6319 ][Training] 3/57 [>.............................] - ETA: 1:20  [ loss=0.2679 ][Training] 4/57 [=>............................] - ETA: 1:17  [ loss=0.5148 ][Training] 5/57 [=>............................] - ETA: 1:15  [ loss=0.3009 ][Training] 6/57 [==>...........................] - ETA: 1:13  [ loss=0.2974 ][Training] 7/57 [==>...........................] - ETA: 1:09  [ loss=0.5941 ][Training] 8/57 [===>..........................] - ETA: 1:09  [ loss=0.8610 ][Training] 9/57 [===>..........................] - ETA: 1:05  [ loss=0.4620 ][Training] 10/57 [====>.........................] - ETA: 1:03  [ loss=0.6648 ][Training] 11/57 [====>.........................] - ETA: 1:04  [ loss=0.2778 ][Training] 12/57 [=====>........................] - ETA: 1:04  [ loss=0.3081 ][Training] 13/57 [=====>........................] - ETA: 1:03  [ loss=0.3171 ][Training] 14/57 [======>.......................] - ETA: 1:01  [ loss=0.6328 ][Training] 15/57 [======>.......................] - ETA: 59s  [ loss=0.5291 ][Training] 16/57 [=======>......................] - ETA: 57s  [ loss=0.3455 ][Training] 17/57 [=======>......................] - ETA: 56s  [ loss=0.7196 ][Training] 18/57 [========>.....................] - ETA: 54s  [ loss=0.7161 ][Training] 19/57 [=========>....................] - ETA: 53s  [ loss=0.4368 ][Training] 20/57 [=========>....................] - ETA: 52s  [ loss=0.9241 ][Training] 21/57 [==========>...................] - ETA: 51s  [ loss=0.3446 ][Training] 22/57 [==========>...................] - ETA: 49s  [ loss=0.4781 ][Training] 23/57 [===========>..................] - ETA: 48s  [ loss=0.6933 ][Training] 24/57 [===========>..................] - ETA: 47s  [ loss=0.4549 ][Training] 25/57 [============>.................] - ETA: 45s  [ loss=0.3855 ][Training] 26/57 [============>.................] - ETA: 44s  [ loss=0.9122 ][Training] 27/57 [=============>................] - ETA: 42s  [ loss=0.3880 ][Training] 28/57 [=============>................] - ETA: 40s  [ loss=0.3584 ][Training] 29/57 [==============>...............] - ETA: 38s  [ loss=0.2882 ][Training] 30/57 [==============>...............] - ETA: 37s  [ loss=0.2742 ][Training] 31/57 [===============>..............] - ETA: 36s  [ loss=0.2903 ][Training] 32/57 [===============>..............] - ETA: 34s  [ loss=0.9873 ][Training] 33/57 [================>.............] - ETA: 33s  [ loss=0.2334 ][Training] 34/57 [================>.............] - ETA: 31s  [ loss=0.4272 ][Training] 35/57 [=================>............] - ETA: 30s  [ loss=0.4566 ][Training] 36/57 [=================>............] - ETA: 28s  [ loss=0.1789 ][Training] 37/57 [==================>...........] - ETA: 27s  [ loss=0.2943 ][Training] 38/57 [===================>..........] - ETA: 25s  [ loss=0.7438 ][Training] 39/57 [===================>..........] - ETA: 24s  [ loss=0.8633 ][Training] 40/57 [====================>.........] - ETA: 23s  [ loss=0.4489 ][Training] 41/57 [====================>.........] - ETA: 21s  [ loss=0.1809 ][Training] 42/57 [=====================>........] - ETA: 20s  [ loss=0.7110 ][Training] 43/57 [=====================>........] - ETA: 18s  [ loss=0.2399 ][Training] 44/57 [======================>.......] - ETA: 17s  [ loss=0.6098 ][Training] 45/57 [======================>.......] - ETA: 16s  [ loss=0.1913 ][Training] 46/57 [=======================>......] - ETA: 14s  [ loss=1.8004 ][Training] 47/57 [=======================>......] - ETA: 13s  [ loss=0.7255 ][Training] 48/57 [========================>.....] - ETA: 12s  [ loss=1.0580 ][Training] 49/57 [========================>.....] - ETA: 10s  [ loss=1.3092 ][Training] 50/57 [=========================>....] - ETA: 9s  [ loss=0.5070 ][Training] 51/57 [=========================>....] - ETA: 8s  [ loss=0.6148 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=1.7714 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=0.2652 ][Training] 54/57 [===========================>..] - ETA: 4s  [ loss=0.4589 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=0.4038 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.1847 ][Training] 57/57 [==============================] 1.3s/step  [ loss=0.2639 ]
01/06/2024 08:37:17 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/06/2024 08:37:18 - INFO - root -   ***** Running evaluation on test dataset  *****
01/06/2024 08:37:18 - INFO - root -     Num examples = 269
01/06/2024 08:37:18 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 8s[Evaluating] 2/12 [====>.........................] - ETA: 7s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 4s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 609.0ms/step
01/06/2024 08:37:25 - INFO - root -   

01/06/2024 08:37:25 - INFO - root -   ***** Eval results  *****
01/06/2024 08:37:25 - INFO - root -    acc: 0.7323 - recall: 0.8015 - f1: 0.7653 - loss: 5.5074 
01/06/2024 08:37:25 - INFO - root -   ***** Entity results  *****
01/06/2024 08:37:25 - INFO - root -   ******* GPE.NAM results ********
01/06/2024 08:37:25 - INFO - root -    acc: 0.8776 - recall: 0.9149 - f1: 0.8958 
01/06/2024 08:37:25 - INFO - root -   ******* GPE.NOM results ********
01/06/2024 08:37:25 - INFO - root -    acc: 0.5000 - recall: 0.5000 - f1: 0.5000 
01/06/2024 08:37:25 - INFO - root -   ******* LOC.NAM results ********
01/06/2024 08:37:25 - INFO - root -    acc: 0.6364 - recall: 0.7368 - f1: 0.6829 
01/06/2024 08:37:25 - INFO - root -   ******* LOC.NOM results ********
01/06/2024 08:37:25 - INFO - root -    acc: 0.3333 - recall: 0.4444 - f1: 0.3810 
01/06/2024 08:37:25 - INFO - root -   ******* ORG.NAM results ********
01/06/2024 08:37:25 - INFO - root -    acc: 0.6923 - recall: 0.6923 - f1: 0.6923 
01/06/2024 08:37:25 - INFO - root -   ******* ORG.NOM results ********
01/06/2024 08:37:25 - INFO - root -    acc: 0.7647 - recall: 0.7647 - f1: 0.7647 
01/06/2024 08:37:25 - INFO - root -   ******* PER.NAM results ********
01/06/2024 08:37:25 - INFO - root -    acc: 0.7917 - recall: 0.8636 - f1: 0.8261 
01/06/2024 08:37:25 - INFO - root -   ******* PER.NOM results ********
01/06/2024 08:37:25 - INFO - root -    acc: 0.7016 - recall: 0.7882 - f1: 0.7424 
01/06/2024 08:37:31 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1311
01/06/2024 08:37:31 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1311
01/06/2024 08:37:31 - INFO - root -   

01/06/2024 08:37:31 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 23/50
[Training] 1/57 [..............................] - ETA: 1:51  [ loss=0.4654 ][Training] 2/57 [>.............................] - ETA: 1:22  [ loss=0.8114 ][Training] 3/57 [>.............................] - ETA: 1:22  [ loss=0.7126 ][Training] 4/57 [=>............................] - ETA: 1:15  [ loss=0.3846 ][Training] 5/57 [=>............................] - ETA: 1:10  [ loss=0.6575 ][Training] 6/57 [==>...........................] - ETA: 1:10  [ loss=1.1595 ][Training] 7/57 [==>...........................] - ETA: 1:08  [ loss=0.6109 ][Training] 8/57 [===>..........................] - ETA: 1:06  [ loss=0.4290 ][Training] 9/57 [===>..........................] - ETA: 1:05  [ loss=0.6733 ][Training] 10/57 [====>.........................] - ETA: 1:02  [ loss=0.2992 ][Training] 11/57 [====>.........................] - ETA: 1:01  [ loss=0.5623 ][Training] 12/57 [=====>........................] - ETA: 59s  [ loss=0.3942 ][Training] 13/57 [=====>........................] - ETA: 58s  [ loss=0.7324 ][Training] 14/57 [======>.......................] - ETA: 56s  [ loss=0.2096 ][Training] 15/57 [======>.......................] - ETA: 56s  [ loss=0.9963 ][Training] 16/57 [=======>......................] - ETA: 55s  [ loss=0.8864 ][Training] 17/57 [=======>......................] - ETA: 53s  [ loss=0.3613 ][Training] 18/57 [========>.....................] - ETA: 52s  [ loss=0.9416 ][Training] 19/57 [=========>....................] - ETA: 51s  [ loss=0.7513 ][Training] 20/57 [=========>....................] - ETA: 49s  [ loss=0.1198 ][Training] 21/57 [==========>...................] - ETA: 48s  [ loss=0.3657 ][Training] 22/57 [==========>...................] - ETA: 46s  [ loss=0.3125 ][Training] 23/57 [===========>..................] - ETA: 45s  [ loss=0.5959 ][Training] 24/57 [===========>..................] - ETA: 43s  [ loss=0.4952 ][Training] 25/57 [============>.................] - ETA: 42s  [ loss=0.2221 ][Training] 26/57 [============>.................] - ETA: 41s  [ loss=0.3199 ][Training] 27/57 [=============>................] - ETA: 39s  [ loss=0.7556 ][Training] 28/57 [=============>................] - ETA: 38s  [ loss=0.9473 ][Training] 29/57 [==============>...............] - ETA: 37s  [ loss=0.5808 ][Training] 30/57 [==============>...............] - ETA: 35s  [ loss=0.1070 ][Training] 31/57 [===============>..............] - ETA: 34s  [ loss=0.7678 ][Training] 32/57 [===============>..............] - ETA: 33s  [ loss=0.1786 ][Training] 33/57 [================>.............] - ETA: 31s  [ loss=0.1591 ][Training] 34/57 [================>.............] - ETA: 30s  [ loss=0.5582 ][Training] 35/57 [=================>............] - ETA: 28s  [ loss=0.1640 ][Training] 36/57 [=================>............] - ETA: 27s  [ loss=1.0117 ][Training] 37/57 [==================>...........] - ETA: 26s  [ loss=0.3640 ][Training] 38/57 [===================>..........] - ETA: 24s  [ loss=0.2612 ][Training] 39/57 [===================>..........] - ETA: 23s  [ loss=0.7995 ][Training] 40/57 [====================>.........] - ETA: 22s  [ loss=0.8444 ][Training] 41/57 [====================>.........] - ETA: 20s  [ loss=0.7823 ][Training] 42/57 [=====================>........] - ETA: 19s  [ loss=0.0810 ][Training] 43/57 [=====================>........] - ETA: 18s  [ loss=0.1958 ][Training] 44/57 [======================>.......] - ETA: 17s  [ loss=0.3870 ][Training] 45/57 [======================>.......] - ETA: 15s  [ loss=0.7199 ][Training] 46/57 [=======================>......] - ETA: 14s  [ loss=0.3133 ][Training] 47/57 [=======================>......] - ETA: 12s  [ loss=0.2808 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=0.9757 ][Training] 49/57 [========================>.....] - ETA: 10s  [ loss=0.4263 ][Training] 50/57 [=========================>....] - ETA: 9s  [ loss=1.1786 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=0.3009 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=0.6666 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=0.8901 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=0.2289 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=0.7784 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.2786 ][Training] 57/57 [==============================] 1.3s/step  [ loss=0.3288 ]
01/06/2024 08:38:44 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/06/2024 08:38:44 - INFO - root -   ***** Running evaluation on test dataset  *****
01/06/2024 08:38:44 - INFO - root -     Num examples = 269
01/06/2024 08:38:44 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 8s[Evaluating] 2/12 [====>.........................] - ETA: 7s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 588.8ms/step
01/06/2024 08:38:51 - INFO - root -   

01/06/2024 08:38:51 - INFO - root -   ***** Eval results  *****
01/06/2024 08:38:51 - INFO - root -    acc: 0.7403 - recall: 0.7869 - f1: 0.7629 - loss: 5.2022 
01/06/2024 08:38:51 - INFO - root -   ***** Entity results  *****
01/06/2024 08:38:51 - INFO - root -   ******* GPE.NAM results ********
01/06/2024 08:38:51 - INFO - root -    acc: 0.8750 - recall: 0.8936 - f1: 0.8842 
01/06/2024 08:38:51 - INFO - root -   ******* GPE.NOM results ********
01/06/2024 08:38:51 - INFO - root -    acc: 0.5000 - recall: 0.5000 - f1: 0.5000 
01/06/2024 08:38:51 - INFO - root -   ******* LOC.NAM results ********
01/06/2024 08:38:51 - INFO - root -    acc: 0.7000 - recall: 0.7368 - f1: 0.7179 
01/06/2024 08:38:51 - INFO - root -   ******* LOC.NOM results ********
01/06/2024 08:38:51 - INFO - root -    acc: 0.4000 - recall: 0.4444 - f1: 0.4211 
01/06/2024 08:38:51 - INFO - root -   ******* ORG.NAM results ********
01/06/2024 08:38:51 - INFO - root -    acc: 0.7297 - recall: 0.6923 - f1: 0.7105 
01/06/2024 08:38:51 - INFO - root -   ******* ORG.NOM results ********
01/06/2024 08:38:51 - INFO - root -    acc: 0.6111 - recall: 0.6471 - f1: 0.6286 
01/06/2024 08:38:51 - INFO - root -   ******* PER.NAM results ********
01/06/2024 08:38:51 - INFO - root -    acc: 0.7965 - recall: 0.8182 - f1: 0.8072 
01/06/2024 08:38:51 - INFO - root -   ******* PER.NOM results ********
01/06/2024 08:38:51 - INFO - root -    acc: 0.7120 - recall: 0.8000 - f1: 0.7535 
01/06/2024 08:38:56 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1368
01/06/2024 08:38:56 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1368
01/06/2024 08:38:56 - INFO - root -   

01/06/2024 08:38:56 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 24/50
[Training] 1/57 [..............................] - ETA: 1:02  [ loss=0.7767 ][Training] 2/57 [>.............................] - ETA: 1:08  [ loss=0.0929 ][Training] 3/57 [>.............................] - ETA: 1:01  [ loss=0.6561 ][Training] 4/57 [=>............................] - ETA: 1:04  [ loss=0.5317 ][Training] 5/57 [=>............................] - ETA: 1:00  [ loss=0.1180 ][Training] 6/57 [==>...........................] - ETA: 1:00  [ loss=0.3770 ][Training] 7/57 [==>...........................] - ETA: 1:03  [ loss=0.1756 ][Training] 8/57 [===>..........................] - ETA: 1:01  [ loss=0.1978 ][Training] 9/57 [===>..........................] - ETA: 1:01  [ loss=0.9892 ][Training] 10/57 [====>.........................] - ETA: 59s  [ loss=0.2225 ][Training] 11/57 [====>.........................] - ETA: 58s  [ loss=0.4184 ][Training] 12/57 [=====>........................] - ETA: 58s  [ loss=0.2283 ][Training] 13/57 [=====>........................] - ETA: 56s  [ loss=0.4678 ][Training] 14/57 [======>.......................] - ETA: 56s  [ loss=0.7108 ][Training] 15/57 [======>.......................] - ETA: 55s  [ loss=0.5365 ][Training] 16/57 [=======>......................] - ETA: 55s  [ loss=0.3373 ][Training] 17/57 [=======>......................] - ETA: 53s  [ loss=1.4484 ][Training] 18/57 [========>.....................] - ETA: 51s  [ loss=0.2307 ][Training] 19/57 [=========>....................] - ETA: 50s  [ loss=1.5400 ][Training] 20/57 [=========>....................] - ETA: 49s  [ loss=0.3724 ][Training] 21/57 [==========>...................] - ETA: 48s  [ loss=0.1205 ][Training] 22/57 [==========>...................] - ETA: 46s  [ loss=0.8435 ][Training] 23/57 [===========>..................] - ETA: 45s  [ loss=0.6852 ][Training] 24/57 [===========>..................] - ETA: 44s  [ loss=0.4477 ][Training] 25/57 [============>.................] - ETA: 43s  [ loss=0.3471 ][Training] 26/57 [============>.................] - ETA: 41s  [ loss=0.4885 ][Training] 27/57 [=============>................] - ETA: 40s  [ loss=0.7207 ][Training] 28/57 [=============>................] - ETA: 39s  [ loss=0.2199 ][Training] 29/57 [==============>...............] - ETA: 37s  [ loss=0.4416 ][Training] 30/57 [==============>...............] - ETA: 36s  [ loss=0.4384 ][Training] 31/57 [===============>..............] - ETA: 34s  [ loss=0.1629 ][Training] 32/57 [===============>..............] - ETA: 33s  [ loss=0.5998 ][Training] 33/57 [================>.............] - ETA: 32s  [ loss=1.1372 ][Training] 34/57 [================>.............] - ETA: 30s  [ loss=0.2189 ][Training] 35/57 [=================>............] - ETA: 29s  [ loss=0.1792 ][Training] 36/57 [=================>............] - ETA: 27s  [ loss=0.6172 ][Training] 37/57 [==================>...........] - ETA: 26s  [ loss=0.5499 ][Training] 38/57 [===================>..........] - ETA: 25s  [ loss=0.5037 ][Training] 39/57 [===================>..........] - ETA: 23s  [ loss=0.6165 ][Training] 40/57 [====================>.........] - ETA: 22s  [ loss=0.7325 ][Training] 41/57 [====================>.........] - ETA: 21s  [ loss=0.2207 ][Training] 42/57 [=====================>........] - ETA: 19s  [ loss=0.2212 ][Training] 43/57 [=====================>........] - ETA: 18s  [ loss=0.1585 ][Training] 44/57 [======================>.......] - ETA: 16s  [ loss=0.2559 ][Training] 45/57 [======================>.......] - ETA: 15s  [ loss=0.5171 ][Training] 46/57 [=======================>......] - ETA: 14s  [ loss=0.2147 ][Training] 47/57 [=======================>......] - ETA: 12s  [ loss=0.2231 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=1.5390 ][Training] 49/57 [========================>.....] - ETA: 10s  [ loss=0.3369 ][Training] 50/57 [=========================>....] - ETA: 9s  [ loss=0.2414 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=0.4347 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=0.2279 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=0.3131 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=0.6651 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=0.4719 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.2719 ][Training] 57/57 [==============================] 1.3s/step  [ loss=0.3467 ]
01/06/2024 08:40:09 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/06/2024 08:40:09 - INFO - root -   ***** Running evaluation on test dataset  *****
01/06/2024 08:40:09 - INFO - root -     Num examples = 269
01/06/2024 08:40:09 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 5s[Evaluating] 2/12 [====>.........................] - ETA: 6s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 4s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 613.5ms/step
01/06/2024 08:40:16 - INFO - root -   

01/06/2024 08:40:16 - INFO - root -   ***** Eval results  *****
01/06/2024 08:40:16 - INFO - root -    acc: 0.7313 - recall: 0.8039 - f1: 0.7659 - loss: 5.4077 
01/06/2024 08:40:16 - INFO - root -   ***** Entity results  *****
01/06/2024 08:40:16 - INFO - root -   ******* GPE.NAM results ********
01/06/2024 08:40:16 - INFO - root -    acc: 0.8367 - recall: 0.8723 - f1: 0.8542 
01/06/2024 08:40:16 - INFO - root -   ******* GPE.NOM results ********
01/06/2024 08:40:16 - INFO - root -    acc: 1.0000 - recall: 0.5000 - f1: 0.6667 
01/06/2024 08:40:16 - INFO - root -   ******* LOC.NAM results ********
01/06/2024 08:40:16 - INFO - root -    acc: 0.6364 - recall: 0.7368 - f1: 0.6829 
01/06/2024 08:40:16 - INFO - root -   ******* LOC.NOM results ********
01/06/2024 08:40:16 - INFO - root -    acc: 0.4444 - recall: 0.4444 - f1: 0.4444 
01/06/2024 08:40:16 - INFO - root -   ******* ORG.NAM results ********
01/06/2024 08:40:16 - INFO - root -    acc: 0.6905 - recall: 0.7436 - f1: 0.7160 
01/06/2024 08:40:16 - INFO - root -   ******* ORG.NOM results ********
01/06/2024 08:40:16 - INFO - root -    acc: 0.8125 - recall: 0.7647 - f1: 0.7879 
01/06/2024 08:40:16 - INFO - root -   ******* PER.NAM results ********
01/06/2024 08:40:16 - INFO - root -    acc: 0.7899 - recall: 0.8545 - f1: 0.8210 
01/06/2024 08:40:16 - INFO - root -   ******* PER.NOM results ********
01/06/2024 08:40:16 - INFO - root -    acc: 0.6939 - recall: 0.8000 - f1: 0.7432 
01/06/2024 08:40:22 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1425
01/06/2024 08:40:22 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1425
01/06/2024 08:40:22 - INFO - root -   

01/06/2024 08:40:22 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 25/50
[Training] 1/57 [..............................] - ETA: 1:00  [ loss=0.1972 ][Training] 2/57 [>.............................] - ETA: 58s  [ loss=0.6966 ][Training] 3/57 [>.............................] - ETA: 53s  [ loss=0.6664 ][Training] 4/57 [=>............................] - ETA: 56s  [ loss=0.1728 ][Training] 5/57 [=>............................] - ETA: 53s  [ loss=0.7309 ][Training] 6/57 [==>...........................] - ETA: 54s  [ loss=0.1966 ][Training] 7/57 [==>...........................] - ETA: 51s  [ loss=0.2611 ][Training] 8/57 [===>..........................] - ETA: 53s  [ loss=1.0318 ][Training] 9/57 [===>..........................] - ETA: 52s  [ loss=0.1103 ][Training] 10/57 [====>.........................] - ETA: 50s  [ loss=0.5920 ][Training] 11/57 [====>.........................] - ETA: 49s  [ loss=0.4670 ][Training] 12/57 [=====>........................] - ETA: 49s  [ loss=0.2959 ][Training] 13/57 [=====>........................] - ETA: 49s  [ loss=0.8485 ][Training] 14/57 [======>.......................] - ETA: 48s  [ loss=0.2686 ][Training] 15/57 [======>.......................] - ETA: 48s  [ loss=0.5022 ][Training] 16/57 [=======>......................] - ETA: 46s  [ loss=0.8460 ][Training] 17/57 [=======>......................] - ETA: 46s  [ loss=0.2944 ][Training] 18/57 [========>.....................] - ETA: 46s  [ loss=0.0504 ][Training] 19/57 [=========>....................] - ETA: 44s  [ loss=0.2136 ][Training] 20/57 [=========>....................] - ETA: 44s  [ loss=0.5578 ][Training] 21/57 [==========>...................] - ETA: 43s  [ loss=0.3234 ][Training] 22/57 [==========>...................] - ETA: 42s  [ loss=0.5648 ][Training] 23/57 [===========>..................] - ETA: 41s  [ loss=0.3139 ][Training] 24/57 [===========>..................] - ETA: 40s  [ loss=0.6389 ][Training] 25/57 [============>.................] - ETA: 39s  [ loss=0.1709 ][Training] 26/57 [============>.................] - ETA: 37s  [ loss=0.1239 ][Training] 27/57 [=============>................] - ETA: 37s  [ loss=0.6461 ][Training] 28/57 [=============>................] - ETA: 35s  [ loss=0.4706 ][Training] 29/57 [==============>...............] - ETA: 34s  [ loss=0.2932 ][Training] 30/57 [==============>...............] - ETA: 33s  [ loss=0.6000 ][Training] 31/57 [===============>..............] - ETA: 32s  [ loss=0.8184 ][Training] 32/57 [===============>..............] - ETA: 31s  [ loss=0.6675 ][Training] 33/57 [================>.............] - ETA: 29s  [ loss=0.4319 ][Training] 34/57 [================>.............] - ETA: 28s  [ loss=0.3787 ][Training] 35/57 [=================>............] - ETA: 27s  [ loss=0.6313 ][Training] 36/57 [=================>............] - ETA: 26s  [ loss=0.2083 ][Training] 37/57 [==================>...........] - ETA: 25s  [ loss=0.2872 ][Training] 38/57 [===================>..........] - ETA: 23s  [ loss=0.1683 ][Training] 39/57 [===================>..........] - ETA: 22s  [ loss=0.3356 ][Training] 40/57 [====================>.........] - ETA: 21s  [ loss=0.6466 ][Training] 41/57 [====================>.........] - ETA: 19s  [ loss=0.1579 ][Training] 42/57 [=====================>........] - ETA: 18s  [ loss=0.3055 ][Training] 43/57 [=====================>........] - ETA: 17s  [ loss=0.7208 ][Training] 44/57 [======================>.......] - ETA: 16s  [ loss=0.0912 ][Training] 45/57 [======================>.......] - ETA: 15s  [ loss=0.1224 ][Training] 46/57 [=======================>......] - ETA: 13s  [ loss=0.3461 ][Training] 47/57 [=======================>......] - ETA: 12s  [ loss=0.4864 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=1.2481 ][Training] 49/57 [========================>.....] - ETA: 9s  [ loss=1.0976 ][Training] 50/57 [=========================>....] - ETA: 8s  [ loss=0.6370 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=0.4858 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=0.5768 ][Training] 53/57 [==========================>...] - ETA: 4s  [ loss=0.3503 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=0.7598 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=0.8992 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.6989 ][Training] 57/57 [==============================] 1.2s/step  [ loss=0.0802 ]
01/06/2024 08:41:32 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/06/2024 08:41:32 - INFO - root -   ***** Running evaluation on test dataset  *****
01/06/2024 08:41:32 - INFO - root -     Num examples = 269
01/06/2024 08:41:32 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 7s[Evaluating] 2/12 [====>.........................] - ETA: 7s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 582.5ms/step
01/06/2024 08:41:39 - INFO - root -   

01/06/2024 08:41:39 - INFO - root -   ***** Eval results  *****
01/06/2024 08:41:39 - INFO - root -    acc: 0.7667 - recall: 0.7482 - f1: 0.7574 - loss: 4.7344 
01/06/2024 08:41:39 - INFO - root -   ***** Entity results  *****
01/06/2024 08:41:39 - INFO - root -   ******* GPE.NAM results ********
01/06/2024 08:41:39 - INFO - root -    acc: 0.8723 - recall: 0.8723 - f1: 0.8723 
01/06/2024 08:41:39 - INFO - root -   ******* GPE.NOM results ********
01/06/2024 08:41:39 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/06/2024 08:41:39 - INFO - root -   ******* LOC.NAM results ********
01/06/2024 08:41:39 - INFO - root -    acc: 0.6667 - recall: 0.7368 - f1: 0.7000 
01/06/2024 08:41:39 - INFO - root -   ******* LOC.NOM results ********
01/06/2024 08:41:39 - INFO - root -    acc: 0.5000 - recall: 0.3333 - f1: 0.4000 
01/06/2024 08:41:39 - INFO - root -   ******* ORG.NAM results ********
01/06/2024 08:41:39 - INFO - root -    acc: 0.6757 - recall: 0.6410 - f1: 0.6579 
01/06/2024 08:41:39 - INFO - root -   ******* ORG.NOM results ********
01/06/2024 08:41:39 - INFO - root -    acc: 0.6667 - recall: 0.4706 - f1: 0.5517 
01/06/2024 08:41:39 - INFO - root -   ******* PER.NAM results ********
01/06/2024 08:41:39 - INFO - root -    acc: 0.8182 - recall: 0.8182 - f1: 0.8182 
01/06/2024 08:41:39 - INFO - root -   ******* PER.NOM results ********
01/06/2024 08:41:39 - INFO - root -    acc: 0.7574 - recall: 0.7529 - f1: 0.7552 
01/06/2024 08:41:44 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1482
01/06/2024 08:41:44 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1482
01/06/2024 08:41:44 - INFO - root -   

01/06/2024 08:41:44 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 26/50
[Training] 1/57 [..............................] - ETA: 1:06  [ loss=1.1912 ][Training] 2/57 [>.............................] - ETA: 1:16  [ loss=0.4507 ][Training] 3/57 [>.............................] - ETA: 1:19  [ loss=0.6353 ][Training] 4/57 [=>............................] - ETA: 1:13  [ loss=0.0960 ][Training] 5/57 [=>............................] - ETA: 1:12  [ loss=0.1593 ][Training] 6/57 [==>...........................] - ETA: 1:12  [ loss=0.7349 ][Training] 7/57 [==>...........................] - ETA: 1:10  [ loss=0.2351 ][Training] 8/57 [===>..........................] - ETA: 1:06  [ loss=0.6623 ][Training] 9/57 [===>..........................] - ETA: 1:03  [ loss=0.1429 ][Training] 10/57 [====>.........................] - ETA: 1:03  [ loss=0.3413 ][Training] 11/57 [====>.........................] - ETA: 1:00  [ loss=0.1572 ][Training] 12/57 [=====>........................] - ETA: 59s  [ loss=0.2248 ][Training] 13/57 [=====>........................] - ETA: 58s  [ loss=0.4872 ][Training] 14/57 [======>.......................] - ETA: 55s  [ loss=0.1146 ][Training] 15/57 [======>.......................] - ETA: 55s  [ loss=0.3380 ][Training] 16/57 [=======>......................] - ETA: 53s  [ loss=0.4564 ][Training] 17/57 [=======>......................] - ETA: 52s  [ loss=1.0937 ][Training] 18/57 [========>.....................] - ETA: 49s  [ loss=0.3334 ][Training] 19/57 [=========>....................] - ETA: 50s  [ loss=0.7718 ][Training] 20/57 [=========>....................] - ETA: 48s  [ loss=0.1887 ][Training] 21/57 [==========>...................] - ETA: 47s  [ loss=0.2892 ][Training] 22/57 [==========>...................] - ETA: 45s  [ loss=0.2584 ][Training] 23/57 [===========>..................] - ETA: 43s  [ loss=0.3931 ][Training] 24/57 [===========>..................] - ETA: 42s  [ loss=0.6035 ][Training] 25/57 [============>.................] - ETA: 41s  [ loss=0.1060 ][Training] 26/57 [============>.................] - ETA: 40s  [ loss=0.5777 ][Training] 27/57 [=============>................] - ETA: 38s  [ loss=0.0913 ][Training] 28/57 [=============>................] - ETA: 37s  [ loss=0.5040 ][Training] 29/57 [==============>...............] - ETA: 35s  [ loss=0.4300 ][Training] 30/57 [==============>...............] - ETA: 35s  [ loss=0.3826 ][Training] 31/57 [===============>..............] - ETA: 33s  [ loss=0.7372 ][Training] 32/57 [===============>..............] - ETA: 32s  [ loss=0.2728 ][Training] 33/57 [================>.............] - ETA: 31s  [ loss=0.5607 ][Training] 34/57 [================>.............] - ETA: 29s  [ loss=0.3842 ][Training] 35/57 [=================>............] - ETA: 28s  [ loss=0.1123 ][Training] 36/57 [=================>............] - ETA: 27s  [ loss=0.3665 ][Training] 37/57 [==================>...........] - ETA: 25s  [ loss=0.7253 ][Training] 38/57 [===================>..........] - ETA: 24s  [ loss=0.3346 ][Training] 39/57 [===================>..........] - ETA: 23s  [ loss=0.6103 ][Training] 40/57 [====================>.........] - ETA: 22s  [ loss=0.5050 ][Training] 41/57 [====================>.........] - ETA: 20s  [ loss=0.5253 ][Training] 42/57 [=====================>........] - ETA: 19s  [ loss=0.5243 ][Training] 43/57 [=====================>........] - ETA: 17s  [ loss=0.2635 ][Training] 44/57 [======================>.......] - ETA: 16s  [ loss=0.7980 ][Training] 45/57 [======================>.......] - ETA: 15s  [ loss=0.4884 ][Training] 46/57 [=======================>......] - ETA: 14s  [ loss=0.4341 ][Training] 47/57 [=======================>......] - ETA: 13s  [ loss=0.2775 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=0.1439 ][Training] 49/57 [========================>.....] - ETA: 10s  [ loss=0.1469 ][Training] 50/57 [=========================>....] - ETA: 9s  [ loss=0.3547 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=0.3261 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=0.3643 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=0.2984 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=0.7419 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=0.4542 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=1.2165 ][Training] 57/57 [==============================] 1.3s/step  [ loss=0.1478 ]
01/06/2024 08:42:57 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/06/2024 08:42:57 - INFO - root -   ***** Running evaluation on test dataset  *****
01/06/2024 08:42:57 - INFO - root -     Num examples = 269
01/06/2024 08:42:57 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 7s[Evaluating] 2/12 [====>.........................] - ETA: 6s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 3s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 566.8ms/step
01/06/2024 08:43:04 - INFO - root -   

01/06/2024 08:43:04 - INFO - root -   ***** Eval results  *****
01/06/2024 08:43:04 - INFO - root -    acc: 0.7995 - recall: 0.7337 - f1: 0.7652 - loss: 4.8862 
01/06/2024 08:43:04 - INFO - root -   ***** Entity results  *****
01/06/2024 08:43:04 - INFO - root -   ******* GPE.NAM results ********
01/06/2024 08:43:04 - INFO - root -    acc: 0.8571 - recall: 0.8936 - f1: 0.8750 
01/06/2024 08:43:04 - INFO - root -   ******* GPE.NOM results ********
01/06/2024 08:43:04 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/06/2024 08:43:04 - INFO - root -   ******* LOC.NAM results ********
01/06/2024 08:43:04 - INFO - root -    acc: 0.7000 - recall: 0.7368 - f1: 0.7179 
01/06/2024 08:43:04 - INFO - root -   ******* LOC.NOM results ********
01/06/2024 08:43:04 - INFO - root -    acc: 0.5000 - recall: 0.2222 - f1: 0.3077 
01/06/2024 08:43:04 - INFO - root -   ******* ORG.NAM results ********
01/06/2024 08:43:04 - INFO - root -    acc: 0.7143 - recall: 0.6410 - f1: 0.6757 
01/06/2024 08:43:04 - INFO - root -   ******* ORG.NOM results ********
01/06/2024 08:43:04 - INFO - root -    acc: 0.7692 - recall: 0.5882 - f1: 0.6667 
01/06/2024 08:43:04 - INFO - root -   ******* PER.NAM results ********
01/06/2024 08:43:04 - INFO - root -    acc: 0.8241 - recall: 0.8091 - f1: 0.8165 
01/06/2024 08:43:04 - INFO - root -   ******* PER.NOM results ********
01/06/2024 08:43:04 - INFO - root -    acc: 0.8121 - recall: 0.7118 - f1: 0.7586 
01/06/2024 08:43:08 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1539
01/06/2024 08:43:08 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1539
01/06/2024 08:43:08 - INFO - root -   

01/06/2024 08:43:08 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 27/50
[Training] 1/57 [..............................] - ETA: 1:09  [ loss=0.3206 ][Training] 2/57 [>.............................] - ETA: 1:18  [ loss=0.2185 ][Training] 3/57 [>.............................] - ETA: 1:10  [ loss=0.6017 ][Training] 4/57 [=>............................] - ETA: 1:17  [ loss=0.3297 ][Training] 5/57 [=>............................] - ETA: 1:11  [ loss=0.2978 ][Training] 6/57 [==>...........................] - ETA: 1:10  [ loss=0.2816 ][Training] 7/57 [==>...........................] - ETA: 1:06  [ loss=0.1886 ][Training] 8/57 [===>..........................] - ETA: 1:05  [ loss=0.5666 ][Training] 9/57 [===>..........................] - ETA: 1:02  [ loss=0.6499 ][Training] 10/57 [====>.........................] - ETA: 1:00  [ loss=0.1315 ][Training] 11/57 [====>.........................] - ETA: 58s  [ loss=0.3797 ][Training] 12/57 [=====>........................] - ETA: 57s  [ loss=0.0888 ][Training] 13/57 [=====>........................] - ETA: 56s  [ loss=0.2009 ][Training] 14/57 [======>.......................] - ETA: 54s  [ loss=0.1900 ][Training] 15/57 [======>.......................] - ETA: 53s  [ loss=0.3057 ][Training] 16/57 [=======>......................] - ETA: 51s  [ loss=0.1661 ][Training] 17/57 [=======>......................] - ETA: 50s  [ loss=0.3293 ][Training] 18/57 [========>.....................] - ETA: 49s  [ loss=0.1400 ][Training] 19/57 [=========>....................] - ETA: 47s  [ loss=0.1313 ][Training] 20/57 [=========>....................] - ETA: 45s  [ loss=0.6081 ][Training] 21/57 [==========>...................] - ETA: 44s  [ loss=0.9196 ][Training] 22/57 [==========>...................] - ETA: 42s  [ loss=0.2593 ][Training] 23/57 [===========>..................] - ETA: 41s  [ loss=0.5384 ][Training] 24/57 [===========>..................] - ETA: 40s  [ loss=1.0287 ][Training] 25/57 [============>.................] - ETA: 39s  [ loss=0.5877 ][Training] 26/57 [============>.................] - ETA: 38s  [ loss=0.2098 ][Training] 27/57 [=============>................] - ETA: 37s  [ loss=0.7463 ][Training] 28/57 [=============>................] - ETA: 36s  [ loss=0.2957 ][Training] 29/57 [==============>...............] - ETA: 34s  [ loss=0.5154 ][Training] 30/57 [==============>...............] - ETA: 33s  [ loss=0.1314 ][Training] 31/57 [===============>..............] - ETA: 32s  [ loss=0.4243 ][Training] 32/57 [===============>..............] - ETA: 31s  [ loss=0.1057 ][Training] 33/57 [================>.............] - ETA: 30s  [ loss=0.1274 ][Training] 34/57 [================>.............] - ETA: 28s  [ loss=0.1192 ][Training] 35/57 [=================>............] - ETA: 27s  [ loss=1.2502 ][Training] 36/57 [=================>............] - ETA: 26s  [ loss=0.0871 ][Training] 37/57 [==================>...........] - ETA: 25s  [ loss=0.4305 ][Training] 38/57 [===================>..........] - ETA: 23s  [ loss=0.7035 ][Training] 39/57 [===================>..........] - ETA: 22s  [ loss=0.1201 ][Training] 40/57 [====================>.........] - ETA: 21s  [ loss=0.4755 ][Training] 41/57 [====================>.........] - ETA: 20s  [ loss=0.4781 ][Training] 42/57 [=====================>........] - ETA: 18s  [ loss=0.2675 ][Training] 43/57 [=====================>........] - ETA: 17s  [ loss=0.6460 ][Training] 44/57 [======================>.......] - ETA: 16s  [ loss=0.9989 ][Training] 45/57 [======================>.......] - ETA: 15s  [ loss=0.4843 ][Training] 46/57 [=======================>......] - ETA: 13s  [ loss=0.3907 ][Training] 47/57 [=======================>......] - ETA: 12s  [ loss=1.5639 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=0.1913 ][Training] 49/57 [========================>.....] - ETA: 10s  [ loss=0.9459 ][Training] 50/57 [=========================>....] - ETA: 8s  [ loss=0.1568 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=0.7669 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=0.1836 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=0.2169 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=0.5561 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=0.2145 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.6771 ][Training] 57/57 [==============================] 1.2s/step  [ loss=1.6922 ]
01/06/2024 08:44:19 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/06/2024 08:44:19 - INFO - root -   ***** Running evaluation on test dataset  *****
01/06/2024 08:44:19 - INFO - root -     Num examples = 269
01/06/2024 08:44:19 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 9s[Evaluating] 2/12 [====>.........................] - ETA: 7s[Evaluating] 3/12 [======>.......................] - ETA: 6s[Evaluating] 4/12 [=========>....................] - ETA: 5s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 4s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 612.6ms/step
01/06/2024 08:44:27 - INFO - root -   

01/06/2024 08:44:27 - INFO - root -   ***** Eval results  *****
01/06/2024 08:44:27 - INFO - root -    acc: 0.8074 - recall: 0.7409 - f1: 0.7727 - loss: 4.9343 
01/06/2024 08:44:27 - INFO - root -   ***** Entity results  *****
01/06/2024 08:44:27 - INFO - root -   ******* GPE.NAM results ********
01/06/2024 08:44:27 - INFO - root -    acc: 0.8936 - recall: 0.8936 - f1: 0.8936 
01/06/2024 08:44:27 - INFO - root -   ******* GPE.NOM results ********
01/06/2024 08:44:27 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/06/2024 08:44:27 - INFO - root -   ******* LOC.NAM results ********
01/06/2024 08:44:27 - INFO - root -    acc: 0.7000 - recall: 0.7368 - f1: 0.7179 
01/06/2024 08:44:27 - INFO - root -   ******* LOC.NOM results ********
01/06/2024 08:44:27 - INFO - root -    acc: 0.6000 - recall: 0.3333 - f1: 0.4286 
01/06/2024 08:44:27 - INFO - root -   ******* ORG.NAM results ********
01/06/2024 08:44:27 - INFO - root -    acc: 0.7059 - recall: 0.6154 - f1: 0.6575 
01/06/2024 08:44:27 - INFO - root -   ******* ORG.NOM results ********
01/06/2024 08:44:27 - INFO - root -    acc: 0.7143 - recall: 0.5882 - f1: 0.6452 
01/06/2024 08:44:27 - INFO - root -   ******* PER.NAM results ********
01/06/2024 08:44:27 - INFO - root -    acc: 0.8500 - recall: 0.7727 - f1: 0.8095 
01/06/2024 08:44:27 - INFO - root -   ******* PER.NOM results ********
01/06/2024 08:44:27 - INFO - root -    acc: 0.8050 - recall: 0.7529 - f1: 0.7781 
01/06/2024 08:44:32 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1596
01/06/2024 08:44:33 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1596
01/06/2024 08:44:33 - INFO - root -   

01/06/2024 08:44:33 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 28/50
[Training] 1/57 [..............................] - ETA: 1:03  [ loss=0.6618 ][Training] 2/57 [>.............................] - ETA: 1:10  [ loss=0.2721 ][Training] 3/57 [>.............................] - ETA: 1:10  [ loss=0.2311 ][Training] 4/57 [=>............................] - ETA: 1:06  [ loss=0.4007 ][Training] 5/57 [=>............................] - ETA: 1:07  [ loss=0.0915 ][Training] 6/57 [==>...........................] - ETA: 1:02  [ loss=0.4698 ][Training] 7/57 [==>...........................] - ETA: 1:05  [ loss=0.7865 ][Training] 8/57 [===>..........................] - ETA: 1:01  [ loss=0.5032 ][Training] 9/57 [===>..........................] - ETA: 1:00  [ loss=0.1993 ][Training] 10/57 [====>.........................] - ETA: 57s  [ loss=0.4714 ][Training] 11/57 [====>.........................] - ETA: 1:00  [ loss=0.5351 ][Training] 12/57 [=====>........................] - ETA: 59s  [ loss=0.2949 ][Training] 13/57 [=====>........................] - ETA: 56s  [ loss=0.0935 ][Training] 14/57 [======>.......................] - ETA: 55s  [ loss=0.1360 ][Training] 15/57 [======>.......................] - ETA: 53s  [ loss=0.1249 ][Training] 16/57 [=======>......................] - ETA: 52s  [ loss=0.3868 ][Training] 17/57 [=======>......................] - ETA: 50s  [ loss=0.4172 ][Training] 18/57 [========>.....................] - ETA: 49s  [ loss=0.1238 ][Training] 19/57 [=========>....................] - ETA: 47s  [ loss=1.1102 ][Training] 20/57 [=========>....................] - ETA: 47s  [ loss=0.7087 ][Training] 21/57 [==========>...................] - ETA: 45s  [ loss=0.5783 ][Training] 22/57 [==========>...................] - ETA: 44s  [ loss=0.1527 ][Training] 23/57 [===========>..................] - ETA: 42s  [ loss=0.0859 ][Training] 24/57 [===========>..................] - ETA: 41s  [ loss=0.4876 ][Training] 25/57 [============>.................] - ETA: 40s  [ loss=0.3757 ][Training] 26/57 [============>.................] - ETA: 39s  [ loss=0.1293 ][Training] 27/57 [=============>................] - ETA: 37s  [ loss=0.2924 ][Training] 28/57 [=============>................] - ETA: 36s  [ loss=0.6332 ][Training] 29/57 [==============>...............] - ETA: 34s  [ loss=0.4756 ][Training] 30/57 [==============>...............] - ETA: 33s  [ loss=0.0963 ][Training] 31/57 [===============>..............] - ETA: 32s  [ loss=0.3270 ][Training] 32/57 [===============>..............] - ETA: 30s  [ loss=0.7641 ][Training] 33/57 [================>.............] - ETA: 29s  [ loss=0.1831 ][Training] 34/57 [================>.............] - ETA: 28s  [ loss=0.4888 ][Training] 35/57 [=================>............] - ETA: 26s  [ loss=0.1435 ][Training] 36/57 [=================>............] - ETA: 25s  [ loss=0.4543 ][Training] 37/57 [==================>...........] - ETA: 24s  [ loss=0.1310 ][Training] 38/57 [===================>..........] - ETA: 23s  [ loss=0.7866 ][Training] 39/57 [===================>..........] - ETA: 22s  [ loss=0.4491 ][Training] 40/57 [====================>.........] - ETA: 20s  [ loss=0.7657 ][Training] 41/57 [====================>.........] - ETA: 19s  [ loss=0.1377 ][Training] 42/57 [=====================>........] - ETA: 18s  [ loss=0.2395 ][Training] 43/57 [=====================>........] - ETA: 17s  [ loss=0.3143 ][Training] 44/57 [======================>.......] - ETA: 16s  [ loss=0.0822 ][Training] 45/57 [======================>.......] - ETA: 14s  [ loss=0.3834 ][Training] 46/57 [=======================>......] - ETA: 13s  [ loss=0.4847 ][Training] 47/57 [=======================>......] - ETA: 12s  [ loss=0.3300 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=1.3345 ][Training] 49/57 [========================>.....] - ETA: 9s  [ loss=0.3411 ][Training] 50/57 [=========================>....] - ETA: 8s  [ loss=0.4474 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=0.3222 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=0.1244 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=0.6665 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=0.3690 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=0.6801 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.1724 ][Training] 57/57 [==============================] 1.2s/step  [ loss=0.0319 ]
01/06/2024 08:45:44 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/06/2024 08:45:44 - INFO - root -   ***** Running evaluation on test dataset  *****
01/06/2024 08:45:44 - INFO - root -     Num examples = 269
01/06/2024 08:45:44 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 6s[Evaluating] 2/12 [====>.........................] - ETA: 6s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 588.1ms/step
01/06/2024 08:45:51 - INFO - root -   

01/06/2024 08:45:51 - INFO - root -   ***** Eval results  *****
01/06/2024 08:45:51 - INFO - root -    acc: 0.7535 - recall: 0.7772 - f1: 0.7652 - loss: 5.0594 
01/06/2024 08:45:51 - INFO - root -   ***** Entity results  *****
01/06/2024 08:45:51 - INFO - root -   ******* GPE.NAM results ********
01/06/2024 08:45:51 - INFO - root -    acc: 0.8776 - recall: 0.9149 - f1: 0.8958 
01/06/2024 08:45:51 - INFO - root -   ******* GPE.NOM results ********
01/06/2024 08:45:51 - INFO - root -    acc: 0.5000 - recall: 0.5000 - f1: 0.5000 
01/06/2024 08:45:51 - INFO - root -   ******* LOC.NAM results ********
01/06/2024 08:45:51 - INFO - root -    acc: 0.6364 - recall: 0.7368 - f1: 0.6829 
01/06/2024 08:45:51 - INFO - root -   ******* LOC.NOM results ********
01/06/2024 08:45:51 - INFO - root -    acc: 0.4167 - recall: 0.5556 - f1: 0.4762 
01/06/2024 08:45:51 - INFO - root -   ******* ORG.NAM results ********
01/06/2024 08:45:51 - INFO - root -    acc: 0.6571 - recall: 0.5897 - f1: 0.6216 
01/06/2024 08:45:51 - INFO - root -   ******* ORG.NOM results ********
01/06/2024 08:45:51 - INFO - root -    acc: 0.8000 - recall: 0.7059 - f1: 0.7500 
01/06/2024 08:45:51 - INFO - root -   ******* PER.NAM results ********
01/06/2024 08:45:51 - INFO - root -    acc: 0.8381 - recall: 0.8000 - f1: 0.8186 
01/06/2024 08:45:51 - INFO - root -   ******* PER.NOM results ********
01/06/2024 08:45:51 - INFO - root -    acc: 0.7258 - recall: 0.7941 - f1: 0.7584 
01/06/2024 08:45:59 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1653
01/06/2024 08:45:59 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1653
01/06/2024 08:45:59 - INFO - root -   

01/06/2024 08:45:59 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 29/50
[Training] 1/57 [..............................] - ETA: 1:03  [ loss=0.0923 ][Training] 2/57 [>.............................] - ETA: 56s  [ loss=0.1278 ][Training] 3/57 [>.............................] - ETA: 1:05  [ loss=0.3436 ][Training] 4/57 [=>............................] - ETA: 1:09  [ loss=0.7324 ][Training] 5/57 [=>............................] - ETA: 1:05  [ loss=0.2007 ][Training] 6/57 [==>...........................] - ETA: 1:06  [ loss=0.2748 ][Training] 7/57 [==>...........................] - ETA: 1:03  [ loss=0.1234 ][Training] 8/57 [===>..........................] - ETA: 1:04  [ loss=0.4881 ][Training] 9/57 [===>..........................] - ETA: 1:03  [ loss=0.6157 ][Training] 10/57 [====>.........................] - ETA: 59s  [ loss=0.1391 ][Training] 11/57 [====>.........................] - ETA: 1:00  [ loss=0.1941 ][Training] 12/57 [=====>........................] - ETA: 58s  [ loss=0.1150 ][Training] 13/57 [=====>........................] - ETA: 56s  [ loss=0.0555 ][Training] 14/57 [======>.......................] - ETA: 54s  [ loss=0.1176 ][Training] 15/57 [======>.......................] - ETA: 54s  [ loss=0.4388 ][Training] 16/57 [=======>......................] - ETA: 51s  [ loss=0.1406 ][Training] 17/57 [=======>......................] - ETA: 51s  [ loss=0.2229 ][Training] 18/57 [========>.....................] - ETA: 50s  [ loss=0.2444 ][Training] 19/57 [=========>....................] - ETA: 49s  [ loss=0.3160 ][Training] 20/57 [=========>....................] - ETA: 47s  [ loss=0.1215 ][Training] 21/57 [==========>...................] - ETA: 46s  [ loss=0.2435 ][Training] 22/57 [==========>...................] - ETA: 45s  [ loss=0.5502 ][Training] 23/57 [===========>..................] - ETA: 44s  [ loss=0.5222 ][Training] 24/57 [===========>..................] - ETA: 43s  [ loss=0.6582 ][Training] 25/57 [============>.................] - ETA: 41s  [ loss=0.5436 ][Training] 26/57 [============>.................] - ETA: 40s  [ loss=0.0792 ][Training] 27/57 [=============>................] - ETA: 38s  [ loss=0.1917 ][Training] 28/57 [=============>................] - ETA: 37s  [ loss=0.1948 ][Training] 29/57 [==============>...............] - ETA: 36s  [ loss=1.5637 ][Training] 30/57 [==============>...............] - ETA: 35s  [ loss=0.6407 ][Training] 31/57 [===============>..............] - ETA: 33s  [ loss=0.7108 ][Training] 32/57 [===============>..............] - ETA: 32s  [ loss=0.5252 ][Training] 33/57 [================>.............] - ETA: 31s  [ loss=0.5217 ][Training] 34/57 [================>.............] - ETA: 29s  [ loss=0.0824 ][Training] 35/57 [=================>............] - ETA: 28s  [ loss=0.1201 ][Training] 36/57 [=================>............] - ETA: 27s  [ loss=0.5114 ][Training] 37/57 [==================>...........] - ETA: 26s  [ loss=0.4782 ][Training] 38/57 [===================>..........] - ETA: 24s  [ loss=0.8484 ][Training] 39/57 [===================>..........] - ETA: 23s  [ loss=0.8746 ][Training] 40/57 [====================>.........] - ETA: 22s  [ loss=1.3750 ][Training] 41/57 [====================>.........] - ETA: 20s  [ loss=0.5030 ][Training] 42/57 [=====================>........] - ETA: 19s  [ loss=0.1466 ][Training] 43/57 [=====================>........] - ETA: 18s  [ loss=0.2816 ][Training] 44/57 [======================>.......] - ETA: 17s  [ loss=1.0491 ][Training] 45/57 [======================>.......] - ETA: 15s  [ loss=0.1918 ][Training] 46/57 [=======================>......] - ETA: 14s  [ loss=0.1925 ][Training] 47/57 [=======================>......] - ETA: 13s  [ loss=0.1981 ][Training] 48/57 [========================>.....] - ETA: 11s  [ loss=0.6859 ][Training] 49/57 [========================>.....] - ETA: 10s  [ loss=0.5832 ][Training] 50/57 [=========================>....] - ETA: 9s  [ loss=0.1854 ][Training] 51/57 [=========================>....] - ETA: 7s  [ loss=0.1674 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=0.1633 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=0.4088 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=0.1912 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=0.3776 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.4322 ][Training] 57/57 [==============================] 1.3s/step  [ loss=0.3692 ]
01/06/2024 08:47:13 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/06/2024 08:47:14 - INFO - root -   ***** Running evaluation on test dataset  *****
01/06/2024 08:47:14 - INFO - root -     Num examples = 269
01/06/2024 08:47:14 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 7s[Evaluating] 2/12 [====>.........................] - ETA: 7s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 586.3ms/step
01/06/2024 08:47:21 - INFO - root -   

01/06/2024 08:47:21 - INFO - root -   ***** Eval results  *****
01/06/2024 08:47:21 - INFO - root -    acc: 0.7656 - recall: 0.7748 - f1: 0.7702 - loss: 5.0694 
01/06/2024 08:47:21 - INFO - root -   ***** Entity results  *****
01/06/2024 08:47:21 - INFO - root -   ******* GPE.NAM results ********
01/06/2024 08:47:21 - INFO - root -    acc: 0.8750 - recall: 0.8936 - f1: 0.8842 
01/06/2024 08:47:21 - INFO - root -   ******* GPE.NOM results ********
01/06/2024 08:47:21 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/06/2024 08:47:21 - INFO - root -   ******* LOC.NAM results ********
01/06/2024 08:47:21 - INFO - root -    acc: 0.6667 - recall: 0.7368 - f1: 0.7000 
01/06/2024 08:47:21 - INFO - root -   ******* LOC.NOM results ********
01/06/2024 08:47:21 - INFO - root -    acc: 0.4000 - recall: 0.2222 - f1: 0.2857 
01/06/2024 08:47:21 - INFO - root -   ******* ORG.NAM results ********
01/06/2024 08:47:21 - INFO - root -    acc: 0.6579 - recall: 0.6410 - f1: 0.6494 
01/06/2024 08:47:21 - INFO - root -   ******* ORG.NOM results ********
01/06/2024 08:47:21 - INFO - root -    acc: 0.7647 - recall: 0.7647 - f1: 0.7647 
01/06/2024 08:47:21 - INFO - root -   ******* PER.NAM results ********
01/06/2024 08:47:21 - INFO - root -    acc: 0.8182 - recall: 0.8182 - f1: 0.8182 
01/06/2024 08:47:21 - INFO - root -   ******* PER.NOM results ********
01/06/2024 08:47:21 - INFO - root -    acc: 0.7486 - recall: 0.7882 - f1: 0.7679 
01/06/2024 08:47:27 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1710
01/06/2024 08:47:27 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1710
01/06/2024 08:47:27 - INFO - root -   

01/06/2024 08:47:27 - INFO - root -   Backbone bert_estor_crf param is not freeze

Epoch: 30/50
[Training] 1/57 [..............................] - ETA: 1:27  [ loss=0.6393 ][Training] 2/57 [>.............................] - ETA: 1:32  [ loss=0.2907 ][Training] 3/57 [>.............................] - ETA: 1:34  [ loss=0.2705 ][Training] 4/57 [=>............................] - ETA: 1:36  [ loss=0.3234 ][Training] 5/57 [=>............................] - ETA: 1:33  [ loss=0.2702 ]Traceback (most recent call last):
  File "main.py", line 567, in <module>
    main()
  File "main.py", line 507, in main
    global_step, tr_loss = train(args, train_dataset, model, tokenizer,tag2spans_list)
  File "main.py", line 180, in train
    outputs = model(**inputs)
  File "/mnt/storage/wubinghong.wbh/project/pytorch-3.8/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/storage/wubinghong.wbh/deepl/torch_ner_new/models/bert_pos_crf.py", line 18, in forward
    outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)
  File "/mnt/storage/wubinghong.wbh/project/pytorch-3.8/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/storage/wubinghong.wbh/project/pytorch-3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py", line 1013, in forward
    encoder_outputs = self.encoder(
  File "/mnt/storage/wubinghong.wbh/project/pytorch-3.8/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/storage/wubinghong.wbh/project/pytorch-3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py", line 607, in forward
    layer_outputs = layer_module(
  File "/mnt/storage/wubinghong.wbh/project/pytorch-3.8/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/storage/wubinghong.wbh/project/pytorch-3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py", line 497, in forward
    self_attention_outputs = self.attention(
  File "/mnt/storage/wubinghong.wbh/project/pytorch-3.8/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/storage/wubinghong.wbh/project/pytorch-3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py", line 427, in forward
    self_outputs = self.self(
  File "/mnt/storage/wubinghong.wbh/project/pytorch-3.8/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/mnt/storage/wubinghong.wbh/project/pytorch-3.8/lib/python3.8/site-packages/transformers/models/bert/modeling_bert.py", line 325, in forward
    attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 46.00 MiB (GPU 0; 31.75 GiB total capacity; 11.75 GiB already allocated; 9.69 MiB free; 13.34 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
