nohup: ignoring input
01/03/2024 15:35:15 - WARNING - root -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
Some weights of BertCrf were not initialized from the model checkpoint at /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/prev_trained_model/roberta-large-chinese and are newly initialized: ['classifier.weight', 'crf.transitions', 'crf.end_transitions', 'crf.start_transitions', 'classifier.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/03/2024 15:35:26 - INFO - root -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, adv_epsilon=1.0, adv_name='word_embeddings', backbone='bert_crf', cache_dir='', config_name='', contrastive_alpha=0.1, crf_learning_rate=0.001, data_dir='/mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/', device=device(type='cuda'), do_adv=False, do_eval=False, do_lower_case=True, do_predict=False, do_train=True, enumerate_mode='gate', eval_all_checkpoints=False, eval_max_seq_length=512, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', freeze_backbone_epoch=0, gate_dropout_rate=0.5, gate_scaling_rate=0.6, gradient_accumulation_steps=1, id2label={0: 'X', 1: 'O', 2: '[START]', 3: '[END]', 4: 'B-PER.NAM', 5: 'I-PER.NAM', 6: 'B-PER.NOM', 7: 'I-PER.NOM', 8: 'B-LOC.NAM', 9: 'I-LOC.NAM', 10: 'B-LOC.NOM', 11: 'I-LOC.NOM', 12: 'B-GPE.NAM', 13: 'I-GPE.NAM', 14: 'B-GPE.NOM', 15: 'I-GPE.NOM', 16: 'B-ORG.NAM', 17: 'I-ORG.NAM', 18: 'B-ORG.NOM', 19: 'I-ORG.NOM'}, id2tag={0: 'THUOCL_lishimingren', 1: 'Company-Shorter-Form', 2: 'Chinese_Names_Corpus', 3: 'Tsingtao_roads', 4: 'Organization-Names-Corpus', 5: 'Company-Names-Corpus', 6: 'relationship', 7: 'THUOCL_diming'}, if_add_a_self_attention=True, if_contrastive_learn=True, if_merge_by_add=True, label2id={'X': 0, 'O': 1, '[START]': 2, '[END]': 3, 'B-PER.NAM': 4, 'I-PER.NAM': 5, 'B-PER.NOM': 6, 'I-PER.NOM': 7, 'B-LOC.NAM': 8, 'I-LOC.NAM': 9, 'B-LOC.NOM': 10, 'I-LOC.NOM': 11, 'B-GPE.NAM': 12, 'I-GPE.NAM': 13, 'B-GPE.NOM': 14, 'I-GPE.NOM': 15, 'B-ORG.NAM': 16, 'I-ORG.NAM': 17, 'B-ORG.NOM': 18, 'I-ORG.NOM': 19}, learning_rate=3e-05, local_rank=-1, logging_steps=-1, loss_type='ce', markup='bio', max_grad_norm=1.0, max_steps=-1, model_name_or_path='/mnt/storage/wubinghong.wbh/deepl/torch_ner_new/prev_trained_model/roberta-large-chinese', n_gpu=1, no_cuda=False, num_train_epochs=30.0, output_dir='/mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=24, per_gpu_train_batch_size=24, pos_learning_rate=5e-05, predict_checkpoints=0, save_steps=-1, seed=42, tag2id={'THUOCL_lishimingren': 0, 'Company-Shorter-Form': 1, 'Chinese_Names_Corpus': 2, 'Tsingtao_roads': 3, 'Organization-Names-Corpus': 4, 'Company-Names-Corpus': 5, 'relationship': 6, 'THUOCL_diming': 7}, tagging_rate=1.0, task_name='weibo', tokenizer_name='', train_max_seq_length=128, warmup_proportion=0.1, weight_decay=0.01)
01/03/2024 15:35:26 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-train_roberta-large-chinese_128_weibo
01/03/2024 15:35:26 - INFO - root -   The model without entity_enumerator
/mnt/storage/wubinghong.wbh/project/pytorch-3.8/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
01/03/2024 15:35:26 - INFO - root -   ***** Running training *****
01/03/2024 15:35:26 - INFO - root -     Num examples = 1349
01/03/2024 15:35:26 - INFO - root -     Num Epochs = 30
01/03/2024 15:35:26 - INFO - root -     Instantaneous batch size per GPU = 24
01/03/2024 15:35:26 - INFO - root -     Total train batch size (w. parallel, distributed & accumulation) = 24
01/03/2024 15:35:26 - INFO - root -     Gradient Accumulation steps = 1
01/03/2024 15:35:26 - INFO - root -     Total optimization steps = 1710
01/03/2024 15:35:26 - INFO - root -   Backbone bert_crf param is not freeze
['X', 'O', '[START]', '[END]', 'B-PER.NAM', 'I-PER.NAM', 'B-PER.NOM', 'I-PER.NOM', 'B-LOC.NAM', 'I-LOC.NAM', 'B-LOC.NOM', 'I-LOC.NOM', 'B-GPE.NAM', 'I-GPE.NAM', 'B-GPE.NOM', 'I-GPE.NOM', 'B-ORG.NAM', 'I-ORG.NAM', 'B-ORG.NOM', 'I-ORG.NOM'] ['THUOCL_lishimingren', 'Company-Shorter-Form', 'Chinese_Names_Corpus', 'Tsingtao_roads', 'Organization-Names-Corpus', 'Company-Names-Corpus', 'relationship', 'THUOCL_diming']

Epoch: 0/30
[Training] 1/57 [..............................] - ETA: 2:41  [ loss=187.6108 ][Training] 2/57 [>.............................] - ETA: 2:00  [ loss=211.7389 ][Training] 3/57 [>.............................] - ETA: 1:46  [ loss=210.8399 ][Training] 4/57 [=>............................] - ETA: 1:34  [ loss=177.7296 ][Training] 5/57 [=>............................] - ETA: 1:32  [ loss=232.3034 ][Training] 6/57 [==>...........................] - ETA: 1:29  [ loss=215.1123 ][Training] 7/57 [==>...........................] - ETA: 1:24  [ loss=237.8473 ][Training] 8/57 [===>..........................] - ETA: 1:23  [ loss=176.8837 ][Training] 9/57 [===>..........................] - ETA: 1:19  [ loss=203.8392 ][Training] 10/57 [====>.........................] - ETA: 1:16  [ loss=184.8080 ][Training] 11/57 [====>.........................] - ETA: 1:15  [ loss=178.5580 ][Training] 12/57 [=====>........................] - ETA: 1:12  [ loss=175.8302 ][Training] 13/57 [=====>........................] - ETA: 1:09  [ loss=184.2794 ][Training] 14/57 [======>.......................] - ETA: 1:07  [ loss=171.4808 ][Training] 15/57 [======>.......................] - ETA: 1:05  [ loss=141.8562 ][Training] 16/57 [=======>......................] - ETA: 1:02  [ loss=137.5512 ][Training] 17/57 [=======>......................] - ETA: 1:00  [ loss=149.7258 ][Training] 18/57 [========>.....................] - ETA: 58s  [ loss=116.1553 ][Training] 19/57 [=========>....................] - ETA: 57s  [ loss=134.8316 ][Training] 20/57 [=========>....................] - ETA: 56s  [ loss=127.3415 ][Training] 21/57 [==========>...................] - ETA: 54s  [ loss=113.6301 ][Training] 22/57 [==========>...................] - ETA: 52s  [ loss=123.1685 ][Training] 23/57 [===========>..................] - ETA: 51s  [ loss=90.8749 ][Training] 24/57 [===========>..................] - ETA: 49s  [ loss=95.7427 ][Training] 25/57 [============>.................] - ETA: 47s  [ loss=83.9042 ][Training] 26/57 [============>.................] - ETA: 46s  [ loss=99.9963 ][Training] 27/57 [=============>................] - ETA: 44s  [ loss=64.0071 ][Training] 28/57 [=============>................] - ETA: 42s  [ loss=69.3538 ][Training] 29/57 [==============>...............] - ETA: 41s  [ loss=52.0037 ][Training] 30/57 [==============>...............] - ETA: 39s  [ loss=63.1476 ][Training] 31/57 [===============>..............] - ETA: 38s  [ loss=34.4364 ][Training] 32/57 [===============>..............] - ETA: 36s  [ loss=34.2191 ][Training] 33/57 [================>.............] - ETA: 35s  [ loss=27.5845 ][Training] 34/57 [================>.............] - ETA: 33s  [ loss=38.0070 ][Training] 35/57 [=================>............] - ETA: 32s  [ loss=23.1542 ][Training] 36/57 [=================>............] - ETA: 30s  [ loss=18.1915 ][Training] 37/57 [==================>...........] - ETA: 29s  [ loss=16.2775 ][Training] 38/57 [===================>..........] - ETA: 27s  [ loss=38.4434 ][Training] 39/57 [===================>..........] - ETA: 26s  [ loss=23.6610 ][Training] 40/57 [====================>.........] - ETA: 24s  [ loss=29.4397 ][Training] 41/57 [====================>.........] - ETA: 23s  [ loss=19.8668 ][Training] 42/57 [=====================>........] - ETA: 21s  [ loss=9.0738 ][Training] 43/57 [=====================>........] - ETA: 20s  [ loss=30.8543 ][Training] 44/57 [======================>.......] - ETA: 18s  [ loss=16.4131 ][Training] 45/57 [======================>.......] - ETA: 17s  [ loss=16.4592 ][Training] 46/57 [=======================>......] - ETA: 15s  [ loss=20.6555 ][Training] 47/57 [=======================>......] - ETA: 14s  [ loss=22.2329 ][Training] 48/57 [========================>.....] - ETA: 13s  [ loss=18.8116 ][Training] 49/57 [========================>.....] - ETA: 11s  [ loss=23.0404 ][Training] 50/57 [=========================>....] - ETA: 10s  [ loss=22.3286 ][Training] 51/57 [=========================>....] - ETA: 8s  [ loss=11.1153 ][Training] 52/57 [==========================>...] - ETA: 7s  [ loss=20.8398 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=22.7192 ][Training] 54/57 [===========================>..] - ETA: 4s  [ loss=25.2449 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=14.3988 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=10.1822 ][Training] 57/57 [==============================] 1.4s/step  [ loss=14.5645 ]
/mnt/storage/wubinghong.wbh/deepl/torch_ner_new/models/layers/crf.py:233: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at ../aten/src/ATen/native/TensorCompare.cpp:493.)
  score = torch.where(mask[i].unsqueeze(1), next_score, score)
01/03/2024 15:36:47 - INFO - root -   Creating features from dataset file at /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/
 
  0%|          | 0/8 [00:00<?, ?it/s] 25%|██▌       | 2/8 [00:00<00:01,  3.16it/s] 38%|███▊      | 3/8 [00:02<00:05,  1.16s/it] 62%|██████▎   | 5/8 [00:04<00:03,  1.06s/it] 75%|███████▌  | 6/8 [00:14<00:06,  3.49s/it]100%|██████████| 8/8 [00:14<00:00,  1.85s/it]
  0%|          | 0/8 [00:00<?, ?it/s] 25%|██▌       | 2/8 [00:00<00:00, 11.82it/s] 50%|█████     | 4/8 [00:00<00:00,  4.13it/s] 62%|██████▎   | 5/8 [00:01<00:01,  2.65it/s] 75%|███████▌  | 6/8 [00:05<00:03,  1.52s/it]100%|██████████| 8/8 [00:05<00:00,  1.37it/s]
['THUOCL_lishimingren', 'Company-Shorter-Form', 'Chinese_Names_Corpus', 'Tsingtao_roads', 'Organization-Names-Corpus', 'Company-Names-Corpus', 'relationship', 'THUOCL_diming']
  0%|          | 0/269 [00:00<?, ?it/s]01/03/2024 15:37:08 - INFO - processors.ner_seq -   Writing example 0 of 269
01/03/2024 15:37:08 - INFO - processors.ner_seq -   *** Example ***
01/03/2024 15:37:08 - INFO - processors.ner_seq -   guid: test-1
01/03/2024 15:37:08 - INFO - processors.ner_seq -   tokens: [CLS] 回 复 支 持 ， 赞 成 ， 哈 哈 米 八 吴 够 历 史 要 的 陈 小 奥 丁 丁 我 爱 小 肥 肥 一 族 大 头 仔 大 家 团 结 一 致 ， 誓 要 去 台 湾 饮 喜 酒 ， 由 包 机 ， 团 结 的 力 量 大 [SEP]
01/03/2024 15:37:08 - INFO - processors.ner_seq -   input_ids: 101 1726 1908 3118 2898 8024 6614 2768 8024 1506 1506 5101 1061 1426 1916 1325 1380 6206 4638 7357 2207 1952 672 672 2769 4263 2207 5503 5503 671 3184 1920 1928 798 1920 2157 1730 5310 671 5636 8024 6292 6206 1343 1378 3968 7650 1599 6983 8024 4507 1259 3322 8024 1730 5310 4638 1213 7030 1920 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 15:37:08 - INFO - processors.ner_seq -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 15:37:08 - INFO - processors.ner_seq -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 15:37:08 - INFO - processors.ner_seq -   label_ids: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 5 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 12 13 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 15:37:08 - INFO - processors.ner_seq -   idx: 0
01/03/2024 15:37:08 - INFO - processors.ner_seq -   tag_to_spans: defaultdict(<class 'list'>, {6: [[27, 28], [28, 29], [32, 33], [33, 34], [35, 36], [27, 29], [29, 31], [31, 33], [32, 34], [34, 36]], 1: [[10, 12], [20, 22], [21, 23], [22, 24], [29, 31], [31, 33], [36, 38], [54, 56], [31, 34]], 0: [[44, 46], [44, 46], [19, 22]]})
  0%|          | 1/269 [00:00<02:49,  1.59it/s]01/03/2024 15:37:08 - INFO - processors.ner_seq -   *** Example ***
01/03/2024 15:37:08 - INFO - processors.ner_seq -   guid: test-2
01/03/2024 15:37:08 - INFO - processors.ner_seq -   tokens: [CLS] 剑 网 乱 世 长 安 公 测 盛 典 今 日 开 启 ， 海 量 豪 礼 火 爆 开 送 精 美 挂 件 、 听 雨 · 汉 服 娃 娃 、 诙 谐 双 骑 独 轮 车 等 你 来 拿 ， 更 有 千 台 红 米 手 机 、 等 十 四 重 惊 喜 转 发 即 抽 活 动 地 址 ： 已 有 人 参 与 剑 网 官 方 微 博 剑 网 客 户 服 务 [SEP]
01/03/2024 15:37:08 - INFO - processors.ner_seq -   input_ids: 101 1187 5381 744 686 7270 2128 1062 3844 4670 1073 791 3189 2458 1423 8024 3862 7030 6498 4851 4125 4255 2458 6843 5125 5401 2899 816 510 1420 7433 185 3727 3302 2015 2015 510 6410 6455 1352 7744 4324 6762 6756 5023 872 3341 2897 8024 3291 3300 1283 1378 5273 5101 2797 3322 510 5023 1282 1724 7028 2661 1599 6760 1355 1315 2853 3833 1220 1765 1770 8038 2347 3300 782 1346 680 1187 5381 2135 3175 2544 1300 1187 5381 2145 2787 3302 1218 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 15:37:08 - INFO - processors.ner_seq -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 15:37:08 - INFO - processors.ner_seq -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 15:37:08 - INFO - processors.ner_seq -   label_ids: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 15:37:08 - INFO - processors.ner_seq -   idx: 1
01/03/2024 15:37:08 - INFO - processors.ner_seq -   tag_to_spans: defaultdict(<class 'list'>, {6: [[7, 8], [34, 35], [35, 36], [75, 76], [34, 36], [59, 61]], 1: [[9, 11], [16, 18], [18, 20], [32, 34], [52, 54], [53, 55], [85, 87], [32, 36]], 7: [[51, 53]], 2: [[81, 83]]})
01/03/2024 15:37:08 - INFO - processors.ner_seq -   *** Example ***
01/03/2024 15:37:08 - INFO - processors.ner_seq -   guid: test-3
01/03/2024 15:37:08 - INFO - processors.ner_seq -   tokens: [CLS] 在 街 上 听 见 音 乐 我 舞 动 起 来 很 丢 人 ？ 真 的 很 丢 人 吗 ？ [SEP]
01/03/2024 15:37:08 - INFO - processors.ner_seq -   input_ids: 101 1762 6125 677 1420 6224 7509 727 2769 5659 1220 6629 3341 2523 696 782 8043 4696 4638 2523 696 782 1408 8043 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 15:37:08 - INFO - processors.ner_seq -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 15:37:08 - INFO - processors.ner_seq -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 15:37:08 - INFO - processors.ner_seq -   label_ids: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 15:37:08 - INFO - processors.ner_seq -   idx: 2
01/03/2024 15:37:08 - INFO - processors.ner_seq -   tag_to_spans: defaultdict(<class 'list'>, {6: [[15, 16], [21, 22]], 1: [[7, 9], [10, 13]]})
01/03/2024 15:37:08 - INFO - processors.ner_seq -   *** Example ***
01/03/2024 15:37:08 - INFO - processors.ner_seq -   guid: test-4
01/03/2024 15:37:08 - INFO - processors.ner_seq -   tokens: [CLS] 三 毛 说 我 唯 一 锲 而 不 舍 ， 愿 意 以 自 己 的 生 命 去 努 力 的 ， 只 不 过 是 保 守 我 个 人 的 心 怀 意 念 ， 在 我 有 生 之 日 ， 做 一 个 真 诚 的 人 ， 不 放 弃 对 生 活 的 热 爱 和 执 着 ， 在 有 限 的 时 空 里 ， 过 无 限 广 [SEP]
01/03/2024 15:37:08 - INFO - processors.ner_seq -   input_ids: 101 676 3688 6432 2769 1546 671 7244 5445 679 5650 8024 2703 2692 809 5632 2346 4638 4495 1462 1343 1222 1213 4638 8024 1372 679 6814 3221 924 2127 2769 702 782 4638 2552 2577 2692 2573 8024 1762 2769 3300 4495 722 3189 8024 976 671 702 4696 6411 4638 782 8024 679 3123 2461 2190 4495 3833 4638 4178 4263 1469 2809 4708 8024 1762 3300 7361 4638 3198 4958 7027 8024 6814 3187 7361 2408 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 15:37:08 - INFO - processors.ner_seq -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 15:37:08 - INFO - processors.ner_seq -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 15:37:08 - INFO - processors.ner_seq -   label_ids: 1 4 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 15:37:08 - INFO - processors.ner_seq -   idx: 3
01/03/2024 15:37:08 - INFO - processors.ner_seq -   tag_to_spans: defaultdict(<class 'list'>, {6: [[2, 3], [33, 34], [53, 54]], 0: [[1, 3], [1, 3]], 1: [[1, 3], [5, 7], [37, 39], [50, 52], [63, 65]]})
01/03/2024 15:37:08 - INFO - processors.ner_seq -   *** Example ***
01/03/2024 15:37:08 - INFO - processors.ner_seq -   guid: test-5
01/03/2024 15:37:08 - INFO - processors.ner_seq -   tokens: [CLS] 星 期 天 的 早 晨 七 点 学 车 ， 驾 校 太 给 力 。 我 的 头 发 都 没 有 洗 [SEP]
01/03/2024 15:37:08 - INFO - processors.ner_seq -   input_ids: 101 3215 3309 1921 4638 3193 3247 673 4157 2110 6756 8024 7730 3413 1922 5314 1213 511 2769 4638 1928 1355 6963 3766 3300 3819 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 15:37:08 - INFO - processors.ner_seq -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 15:37:08 - INFO - processors.ner_seq -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 15:37:08 - INFO - processors.ner_seq -   label_ids: 1 1 1 1 1 1 1 1 1 1 1 1 18 19 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/03/2024 15:37:08 - INFO - processors.ner_seq -   idx: 4
01/03/2024 15:37:08 - INFO - processors.ner_seq -   tag_to_spans: defaultdict(<class 'list'>, {6: [[14, 15], [20, 21]], 1: [[7, 9], [9, 11], [15, 17], [21, 23], [1, 4]]})
 30%|███       | 82/269 [00:01<00:02, 70.58it/s] 90%|█████████ | 243/269 [00:01<00:00, 239.48it/s]100%|██████████| 269/269 [00:01<00:00, 183.45it/s]
01/03/2024 15:37:11 - INFO - root -   Saving features into cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 15:37:12 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 15:37:12 - INFO - root -     Num examples = 269
01/03/2024 15:37:12 - INFO - root -     Batch size = 24
[Evaluating] 1/12 [=>............................] - ETA: 7s[Evaluating] 2/12 [====>.........................] - ETA: 5s[Evaluating] 3/12 [======>.......................] - ETA: 4s[Evaluating] 4/12 [=========>....................] - ETA: 3s[Evaluating] 5/12 [===========>..................] - ETA: 3s[Evaluating] 6/12 [==============>...............] - ETA: 2s[Evaluating] 7/12 [================>.............] - ETA: 2s[Evaluating] 8/12 [===================>..........] - ETA: 1s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 0s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 465.9ms/step
01/03/2024 15:37:17 - INFO - root -   

01/03/2024 15:37:17 - INFO - root -   ***** Eval results  *****
01/03/2024 15:37:17 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 - loss: 17.9609 
01/03/2024 15:37:17 - INFO - root -   ***** Entity results  *****
01/03/2024 15:37:17 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 15:37:17 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 15:37:17 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 15:37:17 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 15:37:17 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 15:37:17 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 15:37:17 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 15:37:17 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 15:37:17 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 15:37:17 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 15:37:17 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 15:37:17 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 15:37:17 - INFO - root -   ******* PER.NAM results ********
01/03/2024 15:37:17 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 15:37:17 - INFO - root -   ******* PER.NOM results ********
01/03/2024 15:37:17 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 15:37:24 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-57
01/03/2024 15:37:24 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-57
01/03/2024 15:37:24 - INFO - root -   

01/03/2024 15:37:24 - INFO - root -   Backbone bert_crf param is not freeze

Epoch: 1/30
[Training] 1/57 [..............................] - ETA: 1:16  [ loss=13.1344 ][Training] 2/57 [>.............................] - ETA: 1:25  [ loss=15.8696 ][Training] 3/57 [>.............................] - ETA: 1:21  [ loss=19.8335 ][Training] 4/57 [=>............................] - ETA: 1:18  [ loss=9.5326 ][Training] 5/57 [=>............................] - ETA: 1:17  [ loss=11.7827 ][Training] 6/57 [==>...........................] - ETA: 1:14  [ loss=13.0943 ][Training] 7/57 [==>...........................] - ETA: 1:14  [ loss=11.1151 ][Training] 8/57 [===>..........................] - ETA: 1:11  [ loss=11.8772 ][Training] 9/57 [===>..........................] - ETA: 1:10  [ loss=8.5440 ][Training] 10/57 [====>.........................] - ETA: 1:09  [ loss=11.5544 ][Training] 11/57 [====>.........................] - ETA: 1:07  [ loss=11.4740 ][Training] 12/57 [=====>........................] - ETA: 1:06  [ loss=7.5153 ][Training] 13/57 [=====>........................] - ETA: 1:04  [ loss=18.3175 ][Training] 14/57 [======>.......................] - ETA: 1:04  [ loss=9.0359 ][Training] 15/57 [======>.......................] - ETA: 1:02  [ loss=14.4845 ][Training] 16/57 [=======>......................] - ETA: 1:01  [ loss=12.8672 ][Training] 17/57 [=======>......................] - ETA: 59s  [ loss=16.5989 ][Training] 18/57 [========>.....................] - ETA: 58s  [ loss=12.1949 ][Training] 19/57 [=========>....................] - ETA: 57s  [ loss=7.4085 ][Training] 20/57 [=========>....................] - ETA: 56s  [ loss=14.2474 ][Training] 21/57 [==========>...................] - ETA: 54s  [ loss=5.2215 ][Training] 22/57 [==========>...................] - ETA: 53s  [ loss=9.5078 ][Training] 23/57 [===========>..................] - ETA: 52s  [ loss=4.4765 ][Training] 24/57 [===========>..................] - ETA: 50s  [ loss=10.8212 ][Training] 25/57 [============>.................] - ETA: 48s  [ loss=4.0565 ][Training] 26/57 [============>.................] - ETA: 46s  [ loss=3.5583 ][Training] 27/57 [=============>................] - ETA: 45s  [ loss=10.1557 ][Training] 28/57 [=============>................] - ETA: 43s  [ loss=11.6999 ][Training] 29/57 [==============>...............] - ETA: 42s  [ loss=8.8097 ][Training] 30/57 [==============>...............] - ETA: 40s  [ loss=6.6275 ][Training] 31/57 [===============>..............] - ETA: 39s  [ loss=4.7438 ][Training] 32/57 [===============>..............] - ETA: 37s  [ loss=5.6584 ][Training] 33/57 [================>.............] - ETA: 36s  [ loss=6.3293 ][Training] 34/57 [================>.............] - ETA: 34s  [ loss=8.8919 ][Training] 35/57 [=================>............] - ETA: 32s  [ loss=3.6797 ][Training] 36/57 [=================>............] - ETA: 31s  [ loss=15.3699 ][Training] 37/57 [==================>...........] - ETA: 29s  [ loss=10.2476 ][Training] 38/57 [===================>..........] - ETA: 28s  [ loss=2.4761 ][Training] 39/57 [===================>..........] - ETA: 26s  [ loss=11.2456 ][Training] 40/57 [====================>.........] - ETA: 25s  [ loss=6.0962 ][Training] 41/57 [====================>.........] - ETA: 23s  [ loss=6.4936 ][Training] 42/57 [=====================>........] - ETA: 22s  [ loss=8.5528 ][Training] 43/57 [=====================>........] - ETA: 20s  [ loss=11.7887 ][Training] 44/57 [======================>.......] - ETA: 19s  [ loss=4.2879 ][Training] 45/57 [======================>.......] - ETA: 17s  [ loss=6.4361 ][Training] 46/57 [=======================>......] - ETA: 16s  [ loss=1.6365 ][Training] 47/57 [=======================>......] - ETA: 14s  [ loss=7.3145 ][Training] 48/57 [========================>.....] - ETA: 13s  [ loss=6.5731 ][Training] 49/57 [========================>.....] - ETA: 11s  [ loss=6.3981 ][Training] 50/57 [=========================>....] - ETA: 10s  [ loss=3.6557 ][Training] 51/57 [=========================>....] - ETA: 8s  [ loss=5.7115 ][Training] 52/57 [==========================>...] - ETA: 7s  [ loss=6.6650 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=10.5720 ][Training] 54/57 [===========================>..] - ETA: 4s  [ loss=2.8039 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=2.0105 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=11.5561 ][Training] 57/57 [==============================] 1.5s/step  [ loss=1.8574 ]
01/03/2024 15:38:48 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 15:38:48 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 15:38:48 - INFO - root -     Num examples = 269
01/03/2024 15:38:48 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 6s[Evaluating] 2/12 [====>.........................] - ETA: 4s[Evaluating] 3/12 [======>.......................] - ETA: 3s[Evaluating] 4/12 [=========>....................] - ETA: 3s[Evaluating] 5/12 [===========>..................] - ETA: 3s[Evaluating] 6/12 [==============>...............] - ETA: 2s[Evaluating] 7/12 [================>.............] - ETA: 2s[Evaluating] 8/12 [===================>..........] - ETA: 1s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 0s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 457.2ms/step
01/03/2024 15:38:54 - INFO - root -   

01/03/2024 15:38:54 - INFO - root -   ***** Eval results  *****
01/03/2024 15:38:54 - INFO - root -    acc: 0.7161 - recall: 0.5375 - f1: 0.6141 - loss: 6.9611 
01/03/2024 15:38:54 - INFO - root -   ***** Entity results  *****
01/03/2024 15:38:54 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 15:38:54 - INFO - root -    acc: 0.6719 - recall: 0.9149 - f1: 0.7748 
01/03/2024 15:38:54 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 15:38:54 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 15:38:54 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 15:38:54 - INFO - root -    acc: 0.5000 - recall: 0.0526 - f1: 0.0952 
01/03/2024 15:38:54 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 15:38:54 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 15:38:54 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 15:38:54 - INFO - root -    acc: 0.6000 - recall: 0.2308 - f1: 0.3333 
01/03/2024 15:38:54 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 15:38:54 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 15:38:54 - INFO - root -   ******* PER.NAM results ********
01/03/2024 15:38:54 - INFO - root -    acc: 0.8111 - recall: 0.6636 - f1: 0.7300 
01/03/2024 15:38:54 - INFO - root -   ******* PER.NOM results ********
01/03/2024 15:38:54 - INFO - root -    acc: 0.6906 - recall: 0.5647 - f1: 0.6214 
01/03/2024 15:38:59 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-114
01/03/2024 15:38:59 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-114
01/03/2024 15:38:59 - INFO - root -   

01/03/2024 15:38:59 - INFO - root -   Backbone bert_crf param is not freeze

Epoch: 2/30
[Training] 1/57 [..............................] - ETA: 1:29  [ loss=6.1253 ][Training] 2/57 [>.............................] - ETA: 1:25  [ loss=4.0081 ][Training] 3/57 [>.............................] - ETA: 1:16  [ loss=3.0933 ][Training] 4/57 [=>............................] - ETA: 1:12  [ loss=3.4035 ][Training] 5/57 [=>............................] - ETA: 1:14  [ loss=2.3587 ][Training] 6/57 [==>...........................] - ETA: 1:13  [ loss=3.8753 ][Training] 7/57 [==>...........................] - ETA: 1:14  [ loss=5.9569 ][Training] 8/57 [===>..........................] - ETA: 1:12  [ loss=3.7875 ][Training] 9/57 [===>..........................] - ETA: 1:10  [ loss=3.6356 ][Training] 10/57 [====>.........................] - ETA: 1:08  [ loss=3.3092 ][Training] 11/57 [====>.........................] - ETA: 1:06  [ loss=5.9965 ][Training] 12/57 [=====>........................] - ETA: 1:05  [ loss=4.7543 ][Training] 13/57 [=====>........................] - ETA: 1:03  [ loss=4.3749 ][Training] 14/57 [======>.......................] - ETA: 1:01  [ loss=5.5930 ][Training] 15/57 [======>.......................] - ETA: 59s  [ loss=1.3137 ][Training] 16/57 [=======>......................] - ETA: 57s  [ loss=2.9687 ][Training] 17/57 [=======>......................] - ETA: 56s  [ loss=5.3604 ][Training] 18/57 [========>.....................] - ETA: 55s  [ loss=10.6469 ][Training] 19/57 [=========>....................] - ETA: 53s  [ loss=2.6373 ][Training] 20/57 [=========>....................] - ETA: 52s  [ loss=3.7165 ][Training] 21/57 [==========>...................] - ETA: 50s  [ loss=3.6521 ][Training] 22/57 [==========>...................] - ETA: 49s  [ loss=3.2916 ][Training] 23/57 [===========>..................] - ETA: 48s  [ loss=4.9393 ][Training] 24/57 [===========>..................] - ETA: 46s  [ loss=5.0540 ][Training] 25/57 [============>.................] - ETA: 45s  [ loss=3.5050 ][Training] 26/57 [============>.................] - ETA: 43s  [ loss=3.4979 ][Training] 27/57 [=============>................] - ETA: 42s  [ loss=1.7716 ][Training] 28/57 [=============>................] - ETA: 40s  [ loss=5.2035 ][Training] 29/57 [==============>...............] - ETA: 39s  [ loss=2.0850 ][Training] 30/57 [==============>...............] - ETA: 37s  [ loss=6.9439 ][Training] 31/57 [===============>..............] - ETA: 36s  [ loss=2.8864 ][Training] 32/57 [===============>..............] - ETA: 34s  [ loss=6.4408 ][Training] 33/57 [================>.............] - ETA: 33s  [ loss=1.5772 ][Training] 34/57 [================>.............] - ETA: 32s  [ loss=4.5936 ][Training] 35/57 [=================>............] - ETA: 30s  [ loss=4.3244 ][Training] 36/57 [=================>............] - ETA: 29s  [ loss=2.6800 ][Training] 37/57 [==================>...........] - ETA: 27s  [ loss=2.8575 ][Training] 38/57 [===================>..........] - ETA: 26s  [ loss=4.0407 ][Training] 39/57 [===================>..........] - ETA: 24s  [ loss=3.7832 ][Training] 40/57 [====================>.........] - ETA: 23s  [ loss=7.0808 ][Training] 41/57 [====================>.........] - ETA: 22s  [ loss=4.1857 ][Training] 42/57 [=====================>........] - ETA: 20s  [ loss=7.0372 ][Training] 43/57 [=====================>........] - ETA: 19s  [ loss=3.6582 ][Training] 44/57 [======================>.......] - ETA: 18s  [ loss=4.5915 ][Training] 45/57 [======================>.......] - ETA: 16s  [ loss=4.7275 ][Training] 46/57 [=======================>......] - ETA: 15s  [ loss=2.6752 ][Training] 47/57 [=======================>......] - ETA: 13s  [ loss=4.6991 ][Training] 48/57 [========================>.....] - ETA: 12s  [ loss=3.7131 ][Training] 49/57 [========================>.....] - ETA: 11s  [ loss=5.6551 ][Training] 50/57 [=========================>....] - ETA: 9s  [ loss=6.0647 ][Training] 51/57 [=========================>....] - ETA: 8s  [ loss=3.6377 ][Training] 52/57 [==========================>...] - ETA: 7s  [ loss=3.7063 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=2.3528 ][Training] 54/57 [===========================>..] - ETA: 4s  [ loss=5.4919 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=4.6916 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=2.7358 ][Training] 57/57 [==============================] 1.4s/step  [ loss=5.9741 ]
01/03/2024 15:40:19 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 15:40:19 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 15:40:19 - INFO - root -     Num examples = 269
01/03/2024 15:40:19 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 3s[Evaluating] 2/12 [====>.........................] - ETA: 4s[Evaluating] 3/12 [======>.......................] - ETA: 3s[Evaluating] 4/12 [=========>....................] - ETA: 3s[Evaluating] 5/12 [===========>..................] - ETA: 3s[Evaluating] 6/12 [==============>...............] - ETA: 2s[Evaluating] 7/12 [================>.............] - ETA: 2s[Evaluating] 8/12 [===================>..........] - ETA: 1s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 0s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 446.9ms/step
01/03/2024 15:40:24 - INFO - root -   

01/03/2024 15:40:24 - INFO - root -   ***** Eval results  *****
01/03/2024 15:40:24 - INFO - root -    acc: 0.6156 - recall: 0.6707 - f1: 0.6419 - loss: 7.6388 
01/03/2024 15:40:24 - INFO - root -   ***** Entity results  *****
01/03/2024 15:40:24 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 15:40:24 - INFO - root -    acc: 0.7547 - recall: 0.8511 - f1: 0.8000 
01/03/2024 15:40:24 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 15:40:24 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 15:40:24 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 15:40:24 - INFO - root -    acc: 0.2727 - recall: 0.1579 - f1: 0.2000 
01/03/2024 15:40:24 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 15:40:24 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 15:40:24 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 15:40:24 - INFO - root -    acc: 0.4091 - recall: 0.4615 - f1: 0.4337 
01/03/2024 15:40:24 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 15:40:24 - INFO - root -    acc: 0.6667 - recall: 0.3529 - f1: 0.4615 
01/03/2024 15:40:24 - INFO - root -   ******* PER.NAM results ********
01/03/2024 15:40:24 - INFO - root -    acc: 0.7525 - recall: 0.6909 - f1: 0.7204 
01/03/2024 15:40:24 - INFO - root -   ******* PER.NOM results ********
01/03/2024 15:40:24 - INFO - root -    acc: 0.5956 - recall: 0.7882 - f1: 0.6785 
01/03/2024 15:40:32 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-171
01/03/2024 15:40:32 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-171
01/03/2024 15:40:32 - INFO - root -   

01/03/2024 15:40:32 - INFO - root -   Backbone bert_crf param is not freeze

Epoch: 3/30
[Training] 1/57 [..............................] - ETA: 59s  [ loss=3.5526 ][Training] 2/57 [>.............................] - ETA: 1:12  [ loss=5.1324 ][Training] 3/57 [>.............................] - ETA: 1:14  [ loss=2.1807 ][Training] 4/57 [=>............................] - ETA: 1:11  [ loss=5.0250 ][Training] 5/57 [=>............................] - ETA: 1:13  [ loss=1.4598 ][Training] 6/57 [==>...........................] - ETA: 1:11  [ loss=1.1575 ][Training] 7/57 [==>...........................] - ETA: 1:11  [ loss=1.2424 ][Training] 8/57 [===>..........................] - ETA: 1:10  [ loss=0.8971 ][Training] 9/57 [===>..........................] - ETA: 1:08  [ loss=1.5298 ][Training] 10/57 [====>.........................] - ETA: 1:08  [ loss=2.8612 ][Training] 11/57 [====>.........................] - ETA: 1:06  [ loss=2.4661 ][Training] 12/57 [=====>........................] - ETA: 1:06  [ loss=1.9632 ][Training] 13/57 [=====>........................] - ETA: 1:05  [ loss=3.6676 ][Training] 14/57 [======>.......................] - ETA: 1:04  [ loss=2.3245 ][Training] 15/57 [======>.......................] - ETA: 1:02  [ loss=2.3539 ][Training] 16/57 [=======>......................] - ETA: 1:00  [ loss=2.0308 ][Training] 17/57 [=======>......................] - ETA: 59s  [ loss=0.6832 ][Training] 18/57 [========>.....................] - ETA: 58s  [ loss=3.7139 ][Training] 19/57 [=========>....................] - ETA: 56s  [ loss=2.2708 ][Training] 20/57 [=========>....................] - ETA: 54s  [ loss=2.4556 ][Training] 21/57 [==========>...................] - ETA: 53s  [ loss=2.2390 ][Training] 22/57 [==========>...................] - ETA: 51s  [ loss=0.8179 ][Training] 23/57 [===========>..................] - ETA: 49s  [ loss=3.2828 ][Training] 24/57 [===========>..................] - ETA: 48s  [ loss=2.9565 ][Training] 25/57 [============>.................] - ETA: 46s  [ loss=3.8128 ][Training] 26/57 [============>.................] - ETA: 45s  [ loss=1.9382 ][Training] 27/57 [=============>................] - ETA: 43s  [ loss=3.8375 ][Training] 28/57 [=============>................] - ETA: 42s  [ loss=4.2884 ][Training] 29/57 [==============>...............] - ETA: 40s  [ loss=1.8165 ][Training] 30/57 [==============>...............] - ETA: 39s  [ loss=2.0843 ][Training] 31/57 [===============>..............] - ETA: 37s  [ loss=3.4559 ][Training] 32/57 [===============>..............] - ETA: 36s  [ loss=3.0865 ][Training] 33/57 [================>.............] - ETA: 34s  [ loss=2.1946 ][Training] 34/57 [================>.............] - ETA: 33s  [ loss=1.9775 ][Training] 35/57 [=================>............] - ETA: 31s  [ loss=2.8029 ][Training] 36/57 [=================>............] - ETA: 30s  [ loss=1.8148 ][Training] 37/57 [==================>...........] - ETA: 28s  [ loss=1.6054 ][Training] 38/57 [===================>..........] - ETA: 27s  [ loss=2.9810 ][Training] 39/57 [===================>..........] - ETA: 25s  [ loss=2.6814 ][Training] 40/57 [====================>.........] - ETA: 24s  [ loss=4.5683 ][Training] 41/57 [====================>.........] - ETA: 22s  [ loss=3.0604 ][Training] 42/57 [=====================>........] - ETA: 21s  [ loss=2.9100 ][Training] 43/57 [=====================>........] - ETA: 20s  [ loss=3.9207 ][Training] 44/57 [======================>.......] - ETA: 18s  [ loss=2.8744 ][Training] 45/57 [======================>.......] - ETA: 17s  [ loss=3.5701 ][Training] 46/57 [=======================>......] - ETA: 15s  [ loss=2.6944 ][Training] 47/57 [=======================>......] - ETA: 14s  [ loss=2.1341 ][Training] 48/57 [========================>.....] - ETA: 12s  [ loss=2.8254 ][Training] 49/57 [========================>.....] - ETA: 11s  [ loss=3.1984 ][Training] 50/57 [=========================>....] - ETA: 9s  [ loss=4.2697 ][Training] 51/57 [=========================>....] - ETA: 8s  [ loss=1.1231 ][Training] 52/57 [==========================>...] - ETA: 7s  [ loss=2.2762 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=1.1917 ][Training] 54/57 [===========================>..] - ETA: 4s  [ loss=1.4422 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=3.9721 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.5284 ][Training] 57/57 [==============================] 1.4s/step  [ loss=0.9405 ]
01/03/2024 15:41:53 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 15:41:53 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 15:41:53 - INFO - root -     Num examples = 269
01/03/2024 15:41:53 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 6s[Evaluating] 2/12 [====>.........................] - ETA: 4s[Evaluating] 3/12 [======>.......................] - ETA: 4s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 3s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 2s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 0s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 469.5ms/step
01/03/2024 15:41:58 - INFO - root -   

01/03/2024 15:41:58 - INFO - root -   ***** Eval results  *****
01/03/2024 15:41:58 - INFO - root -    acc: 0.7132 - recall: 0.6683 - f1: 0.6900 - loss: 6.9632 
01/03/2024 15:41:58 - INFO - root -   ***** Entity results  *****
01/03/2024 15:41:58 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 15:41:58 - INFO - root -    acc: 0.7759 - recall: 0.9574 - f1: 0.8571 
01/03/2024 15:41:58 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 15:41:58 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 15:41:58 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 15:41:58 - INFO - root -    acc: 0.4444 - recall: 0.2105 - f1: 0.2857 
01/03/2024 15:41:58 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 15:41:58 - INFO - root -    acc: 0.3750 - recall: 0.3333 - f1: 0.3529 
01/03/2024 15:41:58 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 15:41:58 - INFO - root -    acc: 0.5000 - recall: 0.5128 - f1: 0.5063 
01/03/2024 15:41:58 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 15:41:58 - INFO - root -    acc: 0.7778 - recall: 0.4118 - f1: 0.5385 
01/03/2024 15:41:58 - INFO - root -   ******* PER.NAM results ********
01/03/2024 15:41:58 - INFO - root -    acc: 0.7935 - recall: 0.6636 - f1: 0.7228 
01/03/2024 15:41:58 - INFO - root -   ******* PER.NOM results ********
01/03/2024 15:41:58 - INFO - root -    acc: 0.7251 - recall: 0.7294 - f1: 0.7273 
01/03/2024 15:42:19 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-228
01/03/2024 15:42:19 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-228
01/03/2024 15:42:19 - INFO - root -   

01/03/2024 15:42:19 - INFO - root -   Backbone bert_crf param is not freeze

Epoch: 4/30
[Training] 1/57 [..............................] - ETA: 1:14  [ loss=1.8467 ][Training] 2/57 [>.............................] - ETA: 1:20  [ loss=1.1804 ][Training] 3/57 [>.............................] - ETA: 1:17  [ loss=4.4146 ][Training] 4/57 [=>............................] - ETA: 1:12  [ loss=2.0761 ][Training] 5/57 [=>............................] - ETA: 1:14  [ loss=0.8950 ][Training] 6/57 [==>...........................] - ETA: 1:13  [ loss=0.2934 ][Training] 7/57 [==>...........................] - ETA: 1:10  [ loss=1.3812 ][Training] 8/57 [===>..........................] - ETA: 1:09  [ loss=2.3176 ][Training] 9/57 [===>..........................] - ETA: 1:07  [ loss=2.0912 ][Training] 10/57 [====>.........................] - ETA: 1:06  [ loss=4.1855 ][Training] 11/57 [====>.........................] - ETA: 1:05  [ loss=0.9580 ][Training] 12/57 [=====>........................] - ETA: 1:03  [ loss=1.6795 ][Training] 13/57 [=====>........................] - ETA: 1:01  [ loss=1.6049 ][Training] 14/57 [======>.......................] - ETA: 1:00  [ loss=1.7862 ][Training] 15/57 [======>.......................] - ETA: 59s  [ loss=1.5672 ][Training] 16/57 [=======>......................] - ETA: 58s  [ loss=0.4660 ][Training] 17/57 [=======>......................] - ETA: 56s  [ loss=1.1723 ][Training] 18/57 [========>.....................] - ETA: 55s  [ loss=1.2668 ][Training] 19/57 [=========>....................] - ETA: 53s  [ loss=1.4553 ][Training] 20/57 [=========>....................] - ETA: 53s  [ loss=0.7656 ][Training] 21/57 [==========>...................] - ETA: 51s  [ loss=0.5172 ][Training] 22/57 [==========>...................] - ETA: 50s  [ loss=0.6708 ][Training] 23/57 [===========>..................] - ETA: 49s  [ loss=0.5588 ][Training] 24/57 [===========>..................] - ETA: 48s  [ loss=1.7504 ][Training] 25/57 [============>.................] - ETA: 46s  [ loss=0.8494 ][Training] 26/57 [============>.................] - ETA: 45s  [ loss=1.0863 ][Training] 27/57 [=============>................] - ETA: 43s  [ loss=0.4316 ][Training] 28/57 [=============>................] - ETA: 42s  [ loss=4.2156 ][Training] 29/57 [==============>...............] - ETA: 40s  [ loss=1.9173 ][Training] 30/57 [==============>...............] - ETA: 39s  [ loss=0.5559 ][Training] 31/57 [===============>..............] - ETA: 37s  [ loss=3.3394 ][Training] 32/57 [===============>..............] - ETA: 36s  [ loss=1.9684 ][Training] 33/57 [================>.............] - ETA: 35s  [ loss=1.4892 ][Training] 34/57 [================>.............] - ETA: 33s  [ loss=3.7917 ][Training] 35/57 [=================>............] - ETA: 32s  [ loss=1.9842 ][Training] 36/57 [=================>............] - ETA: 30s  [ loss=3.6428 ][Training] 37/57 [==================>...........] - ETA: 29s  [ loss=2.2024 ][Training] 38/57 [===================>..........] - ETA: 27s  [ loss=0.5608 ][Training] 39/57 [===================>..........] - ETA: 26s  [ loss=2.2495 ][Training] 40/57 [====================>.........] - ETA: 24s  [ loss=3.7843 ][Training] 41/57 [====================>.........] - ETA: 23s  [ loss=1.4830 ][Training] 42/57 [=====================>........] - ETA: 21s  [ loss=3.0665 ][Training] 43/57 [=====================>........] - ETA: 20s  [ loss=0.8600 ][Training] 44/57 [======================>.......] - ETA: 19s  [ loss=0.7243 ][Training] 45/57 [======================>.......] - ETA: 17s  [ loss=2.0740 ][Training] 46/57 [=======================>......] - ETA: 16s  [ loss=1.2946 ][Training] 47/57 [=======================>......] - ETA: 14s  [ loss=2.7544 ][Training] 48/57 [========================>.....] - ETA: 13s  [ loss=1.4000 ][Training] 49/57 [========================>.....] - ETA: 11s  [ loss=1.9518 ][Training] 50/57 [=========================>....] - ETA: 10s  [ loss=1.1617 ][Training] 51/57 [=========================>....] - ETA: 8s  [ loss=1.3700 ][Training] 52/57 [==========================>...] - ETA: 7s  [ loss=2.3198 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=1.7487 ][Training] 54/57 [===========================>..] - ETA: 4s  [ loss=0.3914 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=2.8321 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=1.9158 ][Training] 57/57 [==============================] 1.4s/step  [ loss=0.0682 ]
01/03/2024 15:43:41 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 15:43:41 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 15:43:41 - INFO - root -     Num examples = 269
01/03/2024 15:43:41 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 4s[Evaluating] 2/12 [====>.........................] - ETA: 4s[Evaluating] 3/12 [======>.......................] - ETA: 4s[Evaluating] 4/12 [=========>....................] - ETA: 3s[Evaluating] 5/12 [===========>..................] - ETA: 3s[Evaluating] 6/12 [==============>...............] - ETA: 2s[Evaluating] 7/12 [================>.............] - ETA: 2s[Evaluating] 8/12 [===================>..........] - ETA: 1s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 0s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 466.4ms/step
01/03/2024 15:43:47 - INFO - root -   

01/03/2024 15:43:47 - INFO - root -   ***** Eval results  *****
01/03/2024 15:43:47 - INFO - root -    acc: 0.7151 - recall: 0.5835 - f1: 0.6427 - loss: 9.2159 
01/03/2024 15:43:47 - INFO - root -   ***** Entity results  *****
01/03/2024 15:43:47 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 15:43:47 - INFO - root -    acc: 0.7826 - recall: 0.7660 - f1: 0.7742 
01/03/2024 15:43:47 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 15:43:47 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 15:43:47 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 15:43:47 - INFO - root -    acc: 0.4000 - recall: 0.4211 - f1: 0.4103 
01/03/2024 15:43:47 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 15:43:47 - INFO - root -    acc: 0.2000 - recall: 0.1111 - f1: 0.1429 
01/03/2024 15:43:47 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 15:43:47 - INFO - root -    acc: 0.5417 - recall: 0.3333 - f1: 0.4127 
01/03/2024 15:43:47 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 15:43:47 - INFO - root -    acc: 0.4545 - recall: 0.2941 - f1: 0.3571 
01/03/2024 15:43:47 - INFO - root -   ******* PER.NAM results ********
01/03/2024 15:43:47 - INFO - root -    acc: 0.8471 - recall: 0.6545 - f1: 0.7385 
01/03/2024 15:43:47 - INFO - root -   ******* PER.NOM results ********
01/03/2024 15:43:47 - INFO - root -    acc: 0.7260 - recall: 0.6235 - f1: 0.6709 
01/03/2024 15:43:55 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-285
01/03/2024 15:43:55 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-285
01/03/2024 15:43:55 - INFO - root -   

01/03/2024 15:43:55 - INFO - root -   Backbone bert_crf param is not freeze

Epoch: 5/30
[Training] 1/57 [..............................] - ETA: 1:36  [ loss=0.4574 ][Training] 2/57 [>.............................] - ETA: 1:20  [ loss=0.2572 ][Training] 3/57 [>.............................] - ETA: 1:22  [ loss=1.5421 ][Training] 4/57 [=>............................] - ETA: 1:17  [ loss=1.1001 ][Training] 5/57 [=>............................] - ETA: 1:14  [ loss=0.5127 ][Training] 6/57 [==>...........................] - ETA: 1:12  [ loss=2.8500 ][Training] 7/57 [==>...........................] - ETA: 1:09  [ loss=0.7741 ][Training] 8/57 [===>..........................] - ETA: 1:07  [ loss=0.5119 ][Training] 9/57 [===>..........................] - ETA: 1:05  [ loss=0.6303 ][Training] 10/57 [====>.........................] - ETA: 1:03  [ loss=1.8483 ][Training] 11/57 [====>.........................] - ETA: 1:02  [ loss=0.5369 ][Training] 12/57 [=====>........................] - ETA: 1:02  [ loss=3.7028 ][Training] 13/57 [=====>........................] - ETA: 1:00  [ loss=0.1968 ][Training] 14/57 [======>.......................] - ETA: 59s  [ loss=1.9986 ][Training] 15/57 [======>.......................] - ETA: 58s  [ loss=0.8375 ][Training] 16/57 [=======>......................] - ETA: 56s  [ loss=0.8558 ][Training] 17/57 [=======>......................] - ETA: 55s  [ loss=0.5814 ][Training] 18/57 [========>.....................] - ETA: 54s  [ loss=0.5984 ][Training] 19/57 [=========>....................] - ETA: 52s  [ loss=1.7834 ][Training] 20/57 [=========>....................] - ETA: 51s  [ loss=0.8380 ][Training] 21/57 [==========>...................] - ETA: 50s  [ loss=0.6133 ][Training] 22/57 [==========>...................] - ETA: 48s  [ loss=4.8380 ][Training] 23/57 [===========>..................] - ETA: 47s  [ loss=0.3919 ][Training] 24/57 [===========>..................] - ETA: 46s  [ loss=0.8896 ][Training] 25/57 [============>.................] - ETA: 45s  [ loss=0.8835 ][Training] 26/57 [============>.................] - ETA: 43s  [ loss=0.8469 ][Training] 27/57 [=============>................] - ETA: 42s  [ loss=0.8176 ][Training] 28/57 [=============>................] - ETA: 40s  [ loss=1.0169 ][Training] 29/57 [==============>...............] - ETA: 39s  [ loss=1.9017 ][Training] 30/57 [==============>...............] - ETA: 37s  [ loss=0.9904 ][Training] 31/57 [===============>..............] - ETA: 36s  [ loss=0.9501 ][Training] 32/57 [===============>..............] - ETA: 34s  [ loss=2.2788 ][Training] 33/57 [================>.............] - ETA: 33s  [ loss=0.7763 ][Training] 34/57 [================>.............] - ETA: 31s  [ loss=1.3341 ][Training] 35/57 [=================>............] - ETA: 30s  [ loss=0.9159 ][Training] 36/57 [=================>............] - ETA: 28s  [ loss=0.3587 ][Training] 37/57 [==================>...........] - ETA: 27s  [ loss=3.4676 ][Training] 38/57 [===================>..........] - ETA: 26s  [ loss=0.0624 ][Training] 39/57 [===================>..........] - ETA: 24s  [ loss=0.7201 ][Training] 40/57 [====================>.........] - ETA: 23s  [ loss=1.3219 ][Training] 41/57 [====================>.........] - ETA: 22s  [ loss=2.2928 ][Training] 42/57 [=====================>........] - ETA: 20s  [ loss=0.8732 ][Training] 43/57 [=====================>........] - ETA: 19s  [ loss=0.3144 ][Training] 44/57 [======================>.......] - ETA: 17s  [ loss=0.7437 ][Training] 45/57 [======================>.......] - ETA: 16s  [ loss=0.3646 ][Training] 46/57 [=======================>......] - ETA: 15s  [ loss=1.1744 ][Training] 47/57 [=======================>......] - ETA: 13s  [ loss=2.1286 ][Training] 48/57 [========================>.....] - ETA: 12s  [ loss=3.1667 ][Training] 49/57 [========================>.....] - ETA: 11s  [ loss=2.2288 ][Training] 50/57 [=========================>....] - ETA: 9s  [ loss=2.8231 ][Training] 51/57 [=========================>....] - ETA: 8s  [ loss=0.8821 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=1.3901 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=1.8001 ][Training] 54/57 [===========================>..] - ETA: 4s  [ loss=1.0846 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=0.3381 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=1.5267 ][Training] 57/57 [==============================] 1.4s/step  [ loss=0.7697 ]
01/03/2024 15:45:13 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 15:45:13 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 15:45:13 - INFO - root -     Num examples = 269
01/03/2024 15:45:13 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 6s[Evaluating] 2/12 [====>.........................] - ETA: 4s[Evaluating] 3/12 [======>.......................] - ETA: 4s[Evaluating] 4/12 [=========>....................] - ETA: 3s[Evaluating] 5/12 [===========>..................] - ETA: 3s[Evaluating] 6/12 [==============>...............] - ETA: 2s[Evaluating] 7/12 [================>.............] - ETA: 2s[Evaluating] 8/12 [===================>..........] - ETA: 1s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 0s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 456.5ms/step
01/03/2024 15:45:19 - INFO - root -   

01/03/2024 15:45:19 - INFO - root -   ***** Eval results  *****
01/03/2024 15:45:19 - INFO - root -    acc: 0.6912 - recall: 0.6828 - f1: 0.6870 - loss: 8.6769 
01/03/2024 15:45:19 - INFO - root -   ***** Entity results  *****
01/03/2024 15:45:19 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 15:45:19 - INFO - root -    acc: 0.7895 - recall: 0.9574 - f1: 0.8654 
01/03/2024 15:45:19 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 15:45:19 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 15:45:19 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 15:45:19 - INFO - root -    acc: 0.5333 - recall: 0.4211 - f1: 0.4706 
01/03/2024 15:45:19 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 15:45:19 - INFO - root -    acc: 0.4000 - recall: 0.4444 - f1: 0.4211 
01/03/2024 15:45:19 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 15:45:19 - INFO - root -    acc: 0.5714 - recall: 0.5128 - f1: 0.5405 
01/03/2024 15:45:19 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 15:45:19 - INFO - root -    acc: 0.5385 - recall: 0.4118 - f1: 0.4667 
01/03/2024 15:45:19 - INFO - root -   ******* PER.NAM results ********
01/03/2024 15:45:19 - INFO - root -    acc: 0.7426 - recall: 0.6818 - f1: 0.7109 
01/03/2024 15:45:19 - INFO - root -   ******* PER.NOM results ********
01/03/2024 15:45:19 - INFO - root -    acc: 0.6949 - recall: 0.7235 - f1: 0.7089 
01/03/2024 15:45:26 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-342
01/03/2024 15:45:26 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-342
01/03/2024 15:45:26 - INFO - root -   

01/03/2024 15:45:27 - INFO - root -   Backbone bert_crf param is not freeze

Epoch: 6/30
[Training] 1/57 [..............................] - ETA: 1:07  [ loss=1.4025 ][Training] 2/57 [>.............................] - ETA: 1:18  [ loss=0.9259 ][Training] 3/57 [>.............................] - ETA: 1:18  [ loss=0.7098 ][Training] 4/57 [=>............................] - ETA: 1:20  [ loss=1.6404 ][Training] 5/57 [=>............................] - ETA: 1:21  [ loss=0.2702 ][Training] 6/57 [==>...........................] - ETA: 1:18  [ loss=3.0431 ][Training] 7/57 [==>...........................] - ETA: 1:15  [ loss=1.0258 ][Training] 8/57 [===>..........................] - ETA: 1:15  [ loss=0.8724 ][Training] 9/57 [===>..........................] - ETA: 1:14  [ loss=0.5317 ][Training] 10/57 [====>.........................] - ETA: 1:12  [ loss=0.3985 ][Training] 11/57 [====>.........................] - ETA: 1:09  [ loss=0.7980 ][Training] 12/57 [=====>........................] - ETA: 1:06  [ loss=0.1169 ][Training] 13/57 [=====>........................] - ETA: 1:05  [ loss=0.9268 ][Training] 14/57 [======>.......................] - ETA: 1:04  [ loss=0.5097 ][Training] 15/57 [======>.......................] - ETA: 1:02  [ loss=1.2638 ][Training] 16/57 [=======>......................] - ETA: 1:01  [ loss=0.8314 ][Training] 17/57 [=======>......................] - ETA: 59s  [ loss=0.9103 ][Training] 18/57 [========>.....................] - ETA: 57s  [ loss=0.2910 ][Training] 19/57 [=========>....................] - ETA: 56s  [ loss=0.8596 ][Training] 20/57 [=========>....................] - ETA: 54s  [ loss=0.3428 ][Training] 21/57 [==========>...................] - ETA: 52s  [ loss=0.5415 ][Training] 22/57 [==========>...................] - ETA: 50s  [ loss=0.3032 ][Training] 23/57 [===========>..................] - ETA: 49s  [ loss=0.4710 ][Training] 24/57 [===========>..................] - ETA: 48s  [ loss=0.4076 ][Training] 25/57 [============>.................] - ETA: 46s  [ loss=1.2682 ][Training] 26/57 [============>.................] - ETA: 45s  [ loss=0.7620 ][Training] 27/57 [=============>................] - ETA: 43s  [ loss=1.1220 ][Training] 28/57 [=============>................] - ETA: 42s  [ loss=0.5779 ][Training] 29/57 [==============>...............] - ETA: 40s  [ loss=0.0930 ][Training] 30/57 [==============>...............] - ETA: 39s  [ loss=0.9552 ][Training] 31/57 [===============>..............] - ETA: 37s  [ loss=0.5801 ][Training] 32/57 [===============>..............] - ETA: 36s  [ loss=3.7506 ][Training] 33/57 [================>.............] - ETA: 35s  [ loss=0.5510 ][Training] 34/57 [================>.............] - ETA: 33s  [ loss=0.7603 ][Training] 35/57 [=================>............] - ETA: 32s  [ loss=1.5761 ][Training] 36/57 [=================>............] - ETA: 30s  [ loss=1.3333 ][Training] 37/57 [==================>...........] - ETA: 29s  [ loss=0.0815 ][Training] 38/57 [===================>..........] - ETA: 27s  [ loss=1.0057 ][Training] 39/57 [===================>..........] - ETA: 26s  [ loss=0.8781 ][Training] 40/57 [====================>.........] - ETA: 24s  [ loss=2.8848 ][Training] 41/57 [====================>.........] - ETA: 23s  [ loss=1.5951 ][Training] 42/57 [=====================>........] - ETA: 21s  [ loss=1.8517 ][Training] 43/57 [=====================>........] - ETA: 20s  [ loss=0.5304 ][Training] 44/57 [======================>.......] - ETA: 18s  [ loss=1.6927 ][Training] 45/57 [======================>.......] - ETA: 17s  [ loss=1.4693 ][Training] 46/57 [=======================>......] - ETA: 15s  [ loss=0.4350 ][Training] 47/57 [=======================>......] - ETA: 14s  [ loss=0.3993 ][Training] 48/57 [========================>.....] - ETA: 13s  [ loss=0.5513 ][Training] 49/57 [========================>.....] - ETA: 11s  [ loss=0.9256 ][Training] 50/57 [=========================>....] - ETA: 10s  [ loss=0.2277 ][Training] 51/57 [=========================>....] - ETA: 8s  [ loss=0.3237 ][Training] 52/57 [==========================>...] - ETA: 7s  [ loss=1.3229 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=0.3815 ][Training] 54/57 [===========================>..] - ETA: 4s  [ loss=0.3333 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=0.5041 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.7052 ][Training] 57/57 [==============================] 1.4s/step  [ loss=0.2901 ]
01/03/2024 15:46:48 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 15:46:48 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 15:46:48 - INFO - root -     Num examples = 269
01/03/2024 15:46:48 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 4s[Evaluating] 2/12 [====>.........................] - ETA: 4s[Evaluating] 3/12 [======>.......................] - ETA: 4s[Evaluating] 4/12 [=========>....................] - ETA: 3s[Evaluating] 5/12 [===========>..................] - ETA: 3s[Evaluating] 6/12 [==============>...............] - ETA: 2s[Evaluating] 7/12 [================>.............] - ETA: 2s[Evaluating] 8/12 [===================>..........] - ETA: 1s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 473.8ms/step
01/03/2024 15:46:54 - INFO - root -   

01/03/2024 15:46:54 - INFO - root -   ***** Eval results  *****
01/03/2024 15:46:54 - INFO - root -    acc: 0.6729 - recall: 0.6925 - f1: 0.6826 - loss: 9.7316 
01/03/2024 15:46:54 - INFO - root -   ***** Entity results  *****
01/03/2024 15:46:54 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 15:46:54 - INFO - root -    acc: 0.7885 - recall: 0.8723 - f1: 0.8283 
01/03/2024 15:46:54 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 15:46:54 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 15:46:54 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 15:46:54 - INFO - root -    acc: 0.5000 - recall: 0.2632 - f1: 0.3448 
01/03/2024 15:46:54 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 15:46:54 - INFO - root -    acc: 0.1429 - recall: 0.1111 - f1: 0.1250 
01/03/2024 15:46:54 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 15:46:54 - INFO - root -    acc: 0.4651 - recall: 0.5128 - f1: 0.4878 
01/03/2024 15:46:54 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 15:46:54 - INFO - root -    acc: 0.5833 - recall: 0.4118 - f1: 0.4828 
01/03/2024 15:46:54 - INFO - root -   ******* PER.NAM results ********
01/03/2024 15:46:54 - INFO - root -    acc: 0.7105 - recall: 0.7364 - f1: 0.7232 
01/03/2024 15:46:54 - INFO - root -   ******* PER.NOM results ********
01/03/2024 15:46:54 - INFO - root -    acc: 0.7005 - recall: 0.7706 - f1: 0.7339 
01/03/2024 15:47:01 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-399
01/03/2024 15:47:01 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-399
01/03/2024 15:47:01 - INFO - root -   

01/03/2024 15:47:02 - INFO - root -   Backbone bert_crf param is not freeze

Epoch: 7/30
[Training] 1/57 [..............................] - ETA: 1:19  [ loss=1.0356 ][Training] 2/57 [>.............................] - ETA: 1:21  [ loss=0.7924 ][Training] 3/57 [>.............................] - ETA: 1:17  [ loss=0.1647 ][Training] 4/57 [=>............................] - ETA: 1:13  [ loss=0.3110 ][Training] 5/57 [=>............................] - ETA: 1:15  [ loss=0.3647 ][Training] 6/57 [==>...........................] - ETA: 1:14  [ loss=0.8127 ][Training] 7/57 [==>...........................] - ETA: 1:15  [ loss=1.1918 ][Training] 8/57 [===>..........................] - ETA: 1:12  [ loss=0.6143 ][Training] 9/57 [===>..........................] - ETA: 1:12  [ loss=0.7055 ][Training] 10/57 [====>.........................] - ETA: 1:09  [ loss=0.2872 ][Training] 11/57 [====>.........................] - ETA: 1:08  [ loss=1.0788 ][Training] 12/57 [=====>........................] - ETA: 1:06  [ loss=0.0433 ][Training] 13/57 [=====>........................] - ETA: 1:05  [ loss=0.9769 ][Training] 14/57 [======>.......................] - ETA: 1:04  [ loss=0.6010 ][Training] 15/57 [======>.......................] - ETA: 1:02  [ loss=1.0357 ][Training] 16/57 [=======>......................] - ETA: 1:00  [ loss=2.2876 ][Training] 17/57 [=======>......................] - ETA: 58s  [ loss=0.0857 ][Training] 18/57 [========>.....................] - ETA: 56s  [ loss=0.6433 ][Training] 19/57 [=========>....................] - ETA: 54s  [ loss=0.4929 ][Training] 20/57 [=========>....................] - ETA: 53s  [ loss=0.3244 ][Training] 21/57 [==========>...................] - ETA: 52s  [ loss=0.3333 ][Training] 22/57 [==========>...................] - ETA: 50s  [ loss=0.0841 ][Training] 23/57 [===========>..................] - ETA: 49s  [ loss=0.9096 ][Training] 24/57 [===========>..................] - ETA: 48s  [ loss=0.9821 ][Training] 25/57 [============>.................] - ETA: 46s  [ loss=1.5812 ][Training] 26/57 [============>.................] - ETA: 45s  [ loss=0.1823 ][Training] 27/57 [=============>................] - ETA: 44s  [ loss=0.1647 ][Training] 28/57 [=============>................] - ETA: 43s  [ loss=0.3964 ][Training] 29/57 [==============>...............] - ETA: 41s  [ loss=1.1131 ][Training] 30/57 [==============>...............] - ETA: 39s  [ loss=0.7167 ][Training] 31/57 [===============>..............] - ETA: 38s  [ loss=0.3467 ][Training] 32/57 [===============>..............] - ETA: 37s  [ loss=0.6953 ][Training] 33/57 [================>.............] - ETA: 35s  [ loss=1.2555 ][Training] 34/57 [================>.............] - ETA: 33s  [ loss=1.8331 ][Training] 35/57 [=================>............] - ETA: 32s  [ loss=0.2826 ][Training] 36/57 [=================>............] - ETA: 30s  [ loss=0.6555 ][Training] 37/57 [==================>...........] - ETA: 29s  [ loss=0.3154 ][Training] 38/57 [===================>..........] - ETA: 27s  [ loss=1.2446 ][Training] 39/57 [===================>..........] - ETA: 26s  [ loss=0.2347 ][Training] 40/57 [====================>.........] - ETA: 24s  [ loss=0.2596 ][Training] 41/57 [====================>.........] - ETA: 23s  [ loss=0.9700 ][Training] 42/57 [=====================>........] - ETA: 21s  [ loss=1.1077 ][Training] 43/57 [=====================>........] - ETA: 20s  [ loss=0.4466 ][Training] 44/57 [======================>.......] - ETA: 18s  [ loss=1.7516 ][Training] 45/57 [======================>.......] - ETA: 17s  [ loss=0.3046 ][Training] 46/57 [=======================>......] - ETA: 15s  [ loss=0.5160 ][Training] 47/57 [=======================>......] - ETA: 14s  [ loss=0.3179 ][Training] 48/57 [========================>.....] - ETA: 13s  [ loss=2.0167 ][Training] 49/57 [========================>.....] - ETA: 11s  [ loss=0.9069 ][Training] 50/57 [=========================>....] - ETA: 10s  [ loss=1.2601 ][Training] 51/57 [=========================>....] - ETA: 8s  [ loss=1.3141 ][Training] 52/57 [==========================>...] - ETA: 7s  [ loss=0.3110 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=0.3026 ][Training] 54/57 [===========================>..] - ETA: 4s  [ loss=2.2164 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=0.8677 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.4898 ][Training] 57/57 [==============================] 1.4s/step  [ loss=4.7743 ]
01/03/2024 15:48:24 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 15:48:24 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 15:48:24 - INFO - root -     Num examples = 269
01/03/2024 15:48:24 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 7s[Evaluating] 2/12 [====>.........................] - ETA: 5s[Evaluating] 3/12 [======>.......................] - ETA: 4s[Evaluating] 4/12 [=========>....................] - ETA: 3s[Evaluating] 5/12 [===========>..................] - ETA: 3s[Evaluating] 6/12 [==============>...............] - ETA: 2s[Evaluating] 7/12 [================>.............] - ETA: 2s[Evaluating] 8/12 [===================>..........] - ETA: 1s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 0s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 461.7ms/step
01/03/2024 15:48:30 - INFO - root -   

01/03/2024 15:48:30 - INFO - root -   ***** Eval results  *****
01/03/2024 15:48:30 - INFO - root -    acc: 0.6936 - recall: 0.6852 - f1: 0.6894 - loss: 9.6171 
01/03/2024 15:48:30 - INFO - root -   ***** Entity results  *****
01/03/2024 15:48:30 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 15:48:30 - INFO - root -    acc: 0.7895 - recall: 0.9574 - f1: 0.8654 
01/03/2024 15:48:30 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 15:48:30 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 15:48:30 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 15:48:30 - INFO - root -    acc: 0.3500 - recall: 0.3684 - f1: 0.3590 
01/03/2024 15:48:30 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 15:48:30 - INFO - root -    acc: 0.3000 - recall: 0.3333 - f1: 0.3158 
01/03/2024 15:48:30 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 15:48:30 - INFO - root -    acc: 0.4615 - recall: 0.4615 - f1: 0.4615 
01/03/2024 15:48:30 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 15:48:30 - INFO - root -    acc: 0.5625 - recall: 0.5294 - f1: 0.5455 
01/03/2024 15:48:30 - INFO - root -   ******* PER.NAM results ********
01/03/2024 15:48:30 - INFO - root -    acc: 0.7593 - recall: 0.7455 - f1: 0.7523 
01/03/2024 15:48:30 - INFO - root -   ******* PER.NOM results ********
01/03/2024 15:48:30 - INFO - root -    acc: 0.7532 - recall: 0.7000 - f1: 0.7256 
01/03/2024 15:48:39 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-456
01/03/2024 15:48:39 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-456
01/03/2024 15:48:39 - INFO - root -   

01/03/2024 15:48:39 - INFO - root -   Backbone bert_crf param is not freeze

Epoch: 8/30
[Training] 1/57 [..............................] - ETA: 1:28  [ loss=0.0401 ][Training] 2/57 [>.............................] - ETA: 1:22  [ loss=1.2308 ][Training] 3/57 [>.............................] - ETA: 1:23  [ loss=0.1041 ][Training] 4/57 [=>............................] - ETA: 1:24  [ loss=0.2543 ][Training] 5/57 [=>............................] - ETA: 1:19  [ loss=1.1877 ][Training] 6/57 [==>...........................] - ETA: 1:14  [ loss=0.2286 ][Training] 7/57 [==>...........................] - ETA: 1:14  [ loss=1.9396 ][Training] 8/57 [===>..........................] - ETA: 1:14  [ loss=0.6080 ][Training] 9/57 [===>..........................] - ETA: 1:12  [ loss=0.3021 ][Training] 10/57 [====>.........................] - ETA: 1:09  [ loss=0.0272 ][Training] 11/57 [====>.........................] - ETA: 1:07  [ loss=0.1096 ][Training] 12/57 [=====>........................] - ETA: 1:05  [ loss=0.4923 ][Training] 13/57 [=====>........................] - ETA: 1:03  [ loss=0.1000 ][Training] 14/57 [======>.......................] - ETA: 1:02  [ loss=0.1370 ][Training] 15/57 [======>.......................] - ETA: 1:00  [ loss=0.8688 ][Training] 16/57 [=======>......................] - ETA: 58s  [ loss=0.0230 ][Training] 17/57 [=======>......................] - ETA: 57s  [ loss=0.3071 ][Training] 18/57 [========>.....................] - ETA: 55s  [ loss=0.6727 ][Training] 19/57 [=========>....................] - ETA: 53s  [ loss=0.8800 ][Training] 20/57 [=========>....................] - ETA: 52s  [ loss=0.3299 ][Training] 21/57 [==========>...................] - ETA: 50s  [ loss=0.3856 ][Training] 22/57 [==========>...................] - ETA: 49s  [ loss=2.2044 ][Training] 23/57 [===========>..................] - ETA: 48s  [ loss=0.0559 ][Training] 24/57 [===========>..................] - ETA: 46s  [ loss=0.6486 ][Training] 25/57 [============>.................] - ETA: 45s  [ loss=0.2511 ][Training] 26/57 [============>.................] - ETA: 43s  [ loss=0.9316 ][Training] 27/57 [=============>................] - ETA: 42s  [ loss=0.4191 ][Training] 28/57 [=============>................] - ETA: 41s  [ loss=0.0701 ][Training] 29/57 [==============>...............] - ETA: 39s  [ loss=1.1550 ][Training] 30/57 [==============>...............] - ETA: 37s  [ loss=1.4672 ][Training] 31/57 [===============>..............] - ETA: 36s  [ loss=0.2862 ][Training] 32/57 [===============>..............] - ETA: 34s  [ loss=0.6206 ][Training] 33/57 [================>.............] - ETA: 33s  [ loss=0.9351 ][Training] 34/57 [================>.............] - ETA: 32s  [ loss=0.7894 ][Training] 35/57 [=================>............] - ETA: 30s  [ loss=0.3049 ][Training] 36/57 [=================>............] - ETA: 29s  [ loss=0.0711 ][Training] 37/57 [==================>...........] - ETA: 27s  [ loss=0.9023 ][Training] 38/57 [===================>..........] - ETA: 26s  [ loss=0.1621 ][Training] 39/57 [===================>..........] - ETA: 25s  [ loss=0.3206 ][Training] 40/57 [====================>.........] - ETA: 23s  [ loss=3.0894 ][Training] 41/57 [====================>.........] - ETA: 22s  [ loss=0.3872 ][Training] 42/57 [=====================>........] - ETA: 21s  [ loss=0.4302 ][Training] 43/57 [=====================>........] - ETA: 19s  [ loss=0.8995 ][Training] 44/57 [======================>.......] - ETA: 18s  [ loss=1.1902 ][Training] 45/57 [======================>.......] - ETA: 16s  [ loss=1.6742 ][Training] 46/57 [=======================>......] - ETA: 15s  [ loss=0.0974 ][Training] 47/57 [=======================>......] - ETA: 14s  [ loss=0.6551 ][Training] 48/57 [========================>.....] - ETA: 12s  [ loss=0.5152 ][Training] 49/57 [========================>.....] - ETA: 11s  [ loss=1.0438 ][Training] 50/57 [=========================>....] - ETA: 9s  [ loss=1.0213 ][Training] 51/57 [=========================>....] - ETA: 8s  [ loss=0.8187 ][Training] 52/57 [==========================>...] - ETA: 7s  [ loss=0.9730 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=0.4274 ][Training] 54/57 [===========================>..] - ETA: 4s  [ loss=0.1786 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=0.1918 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.1291 ][Training] 57/57 [==============================] 1.4s/step  [ loss=0.3742 ]
01/03/2024 15:49:59 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 15:49:59 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 15:49:59 - INFO - root -     Num examples = 269
01/03/2024 15:49:59 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 5s[Evaluating] 2/12 [====>.........................] - ETA: 4s[Evaluating] 3/12 [======>.......................] - ETA: 4s[Evaluating] 4/12 [=========>....................] - ETA: 3s[Evaluating] 5/12 [===========>..................] - ETA: 3s[Evaluating] 6/12 [==============>...............] - ETA: 2s[Evaluating] 7/12 [================>.............] - ETA: 2s[Evaluating] 8/12 [===================>..........] - ETA: 1s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 0s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 442.6ms/step
01/03/2024 15:50:04 - INFO - root -   

01/03/2024 15:50:04 - INFO - root -   ***** Eval results  *****
01/03/2024 15:50:04 - INFO - root -    acc: 0.6797 - recall: 0.7143 - f1: 0.6966 - loss: 10.5959 
01/03/2024 15:50:04 - INFO - root -   ***** Entity results  *****
01/03/2024 15:50:04 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 15:50:04 - INFO - root -    acc: 0.7818 - recall: 0.9149 - f1: 0.8431 
01/03/2024 15:50:04 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 15:50:04 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 15:50:04 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 15:50:04 - INFO - root -    acc: 0.5294 - recall: 0.4737 - f1: 0.5000 
01/03/2024 15:50:04 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 15:50:04 - INFO - root -    acc: 0.3333 - recall: 0.4444 - f1: 0.3810 
01/03/2024 15:50:04 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 15:50:04 - INFO - root -    acc: 0.5000 - recall: 0.4615 - f1: 0.4800 
01/03/2024 15:50:04 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 15:50:04 - INFO - root -    acc: 0.6000 - recall: 0.5294 - f1: 0.5625 
01/03/2024 15:50:04 - INFO - root -   ******* PER.NAM results ********
01/03/2024 15:50:04 - INFO - root -    acc: 0.7885 - recall: 0.7455 - f1: 0.7664 
01/03/2024 15:50:04 - INFO - root -   ******* PER.NOM results ********
01/03/2024 15:50:04 - INFO - root -    acc: 0.6667 - recall: 0.7647 - f1: 0.7123 
01/03/2024 15:50:17 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-513
01/03/2024 15:50:17 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-513
01/03/2024 15:50:17 - INFO - root -   

01/03/2024 15:50:17 - INFO - root -   Backbone bert_crf param is not freeze

Epoch: 9/30
[Training] 1/57 [..............................] - ETA: 1:22  [ loss=1.4300 ][Training] 2/57 [>.............................] - ETA: 1:18  [ loss=0.0535 ][Training] 3/57 [>.............................] - ETA: 1:23  [ loss=0.0113 ][Training] 4/57 [=>............................] - ETA: 1:19  [ loss=0.2379 ][Training] 5/57 [=>............................] - ETA: 1:15  [ loss=0.5112 ][Training] 6/57 [==>...........................] - ETA: 1:13  [ loss=0.0177 ][Training] 7/57 [==>...........................] - ETA: 1:10  [ loss=0.0056 ][Training] 8/57 [===>..........................] - ETA: 1:10  [ loss=0.0289 ][Training] 9/57 [===>..........................] - ETA: 1:09  [ loss=0.8997 ][Training] 10/57 [====>.........................] - ETA: 1:07  [ loss=0.2737 ][Training] 11/57 [====>.........................] - ETA: 1:07  [ loss=1.6352 ][Training] 12/57 [=====>........................] - ETA: 1:05  [ loss=1.4002 ][Training] 13/57 [=====>........................] - ETA: 1:03  [ loss=0.0427 ][Training] 14/57 [======>.......................] - ETA: 1:01  [ loss=1.1489 ][Training] 15/57 [======>.......................] - ETA: 1:00  [ loss=0.6707 ][Training] 16/57 [=======>......................] - ETA: 59s  [ loss=0.8024 ][Training] 17/57 [=======>......................] - ETA: 57s  [ loss=0.2445 ][Training] 18/57 [========>.....................] - ETA: 56s  [ loss=0.6535 ][Training] 19/57 [=========>....................] - ETA: 54s  [ loss=1.2573 ][Training] 20/57 [=========>....................] - ETA: 52s  [ loss=0.1074 ][Training] 21/57 [==========>...................] - ETA: 50s  [ loss=0.3394 ][Training] 22/57 [==========>...................] - ETA: 49s  [ loss=0.6658 ][Training] 23/57 [===========>..................] - ETA: 48s  [ loss=3.4166 ][Training] 24/57 [===========>..................] - ETA: 46s  [ loss=0.0262 ][Training] 25/57 [============>.................] - ETA: 45s  [ loss=0.1592 ][Training] 26/57 [============>.................] - ETA: 44s  [ loss=2.3434 ][Training] 27/57 [=============>................] - ETA: 42s  [ loss=0.2666 ][Training] 28/57 [=============>................] - ETA: 41s  [ loss=0.8402 ][Training] 29/57 [==============>...............] - ETA: 39s  [ loss=0.1333 ][Training] 30/57 [==============>...............] - ETA: 38s  [ loss=0.7586 ][Training] 31/57 [===============>..............] - ETA: 36s  [ loss=1.3842 ][Training] 32/57 [===============>..............] - ETA: 35s  [ loss=0.0680 ][Training] 33/57 [================>.............] - ETA: 34s  [ loss=0.1480 ][Training] 34/57 [================>.............] - ETA: 32s  [ loss=0.3557 ][Training] 35/57 [=================>............] - ETA: 31s  [ loss=0.0935 ][Training] 36/57 [=================>............] - ETA: 29s  [ loss=0.4049 ][Training] 37/57 [==================>...........] - ETA: 28s  [ loss=0.1430 ][Training] 38/57 [===================>..........] - ETA: 27s  [ loss=0.8176 ][Training] 39/57 [===================>..........] - ETA: 25s  [ loss=0.8433 ][Training] 40/57 [====================>.........] - ETA: 24s  [ loss=0.3272 ][Training] 41/57 [====================>.........] - ETA: 22s  [ loss=0.1636 ][Training] 42/57 [=====================>........] - ETA: 21s  [ loss=0.1559 ][Training] 43/57 [=====================>........] - ETA: 19s  [ loss=0.7152 ][Training] 44/57 [======================>.......] - ETA: 18s  [ loss=0.6074 ][Training] 45/57 [======================>.......] - ETA: 17s  [ loss=0.1535 ][Training] 46/57 [=======================>......] - ETA: 15s  [ loss=0.2214 ][Training] 47/57 [=======================>......] - ETA: 14s  [ loss=0.6779 ][Training] 48/57 [========================>.....] - ETA: 12s  [ loss=0.1152 ][Training] 49/57 [========================>.....] - ETA: 11s  [ loss=0.6922 ][Training] 50/57 [=========================>....] - ETA: 10s  [ loss=0.0157 ][Training] 51/57 [=========================>....] - ETA: 8s  [ loss=0.7793 ][Training] 52/57 [==========================>...] - ETA: 7s  [ loss=0.4985 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=0.5627 ][Training] 54/57 [===========================>..] - ETA: 4s  [ loss=0.3456 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=0.4825 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.2447 ][Training] 57/57 [==============================] 1.4s/step  [ loss=10.5863 ]
01/03/2024 15:51:39 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 15:51:39 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 15:51:39 - INFO - root -     Num examples = 269
01/03/2024 15:51:39 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 6s[Evaluating] 2/12 [====>.........................] - ETA: 4s[Evaluating] 3/12 [======>.......................] - ETA: 4s[Evaluating] 4/12 [=========>....................] - ETA: 3s[Evaluating] 5/12 [===========>..................] - ETA: 3s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 2s[Evaluating] 8/12 [===================>..........] - ETA: 1s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 0s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 467.0ms/step
01/03/2024 15:51:44 - INFO - root -   

01/03/2024 15:51:44 - INFO - root -   ***** Eval results  *****
01/03/2024 15:51:44 - INFO - root -    acc: 0.6854 - recall: 0.7070 - f1: 0.6961 - loss: 11.2182 
01/03/2024 15:51:44 - INFO - root -   ***** Entity results  *****
01/03/2024 15:51:44 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 15:51:44 - INFO - root -    acc: 0.7500 - recall: 0.9574 - f1: 0.8411 
01/03/2024 15:51:44 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 15:51:44 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 15:51:44 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 15:51:44 - INFO - root -    acc: 0.6667 - recall: 0.4211 - f1: 0.5161 
01/03/2024 15:51:44 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 15:51:44 - INFO - root -    acc: 0.2308 - recall: 0.3333 - f1: 0.2727 
01/03/2024 15:51:44 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 15:51:44 - INFO - root -    acc: 0.5333 - recall: 0.4103 - f1: 0.4638 
01/03/2024 15:51:44 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 15:51:44 - INFO - root -    acc: 0.4737 - recall: 0.5294 - f1: 0.5000 
01/03/2024 15:51:44 - INFO - root -   ******* PER.NAM results ********
01/03/2024 15:51:44 - INFO - root -    acc: 0.7810 - recall: 0.7455 - f1: 0.7628 
01/03/2024 15:51:44 - INFO - root -   ******* PER.NOM results ********
01/03/2024 15:51:44 - INFO - root -    acc: 0.6898 - recall: 0.7588 - f1: 0.7227 
01/03/2024 15:51:52 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-570
01/03/2024 15:51:52 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-570
01/03/2024 15:51:52 - INFO - root -   

01/03/2024 15:51:52 - INFO - root -   Backbone bert_crf param is not freeze

Epoch: 10/30
[Training] 1/57 [..............................] - ETA: 1:18  [ loss=0.2707 ][Training] 2/57 [>.............................] - ETA: 1:10  [ loss=0.0485 ][Training] 3/57 [>.............................] - ETA: 1:15  [ loss=0.7791 ][Training] 4/57 [=>............................] - ETA: 1:13  [ loss=0.1443 ][Training] 5/57 [=>............................] - ETA: 1:13  [ loss=0.2501 ][Training] 6/57 [==>...........................] - ETA: 1:12  [ loss=0.4107 ][Training] 7/57 [==>...........................] - ETA: 1:10  [ loss=0.1895 ][Training] 8/57 [===>..........................] - ETA: 1:08  [ loss=0.4881 ][Training] 9/57 [===>..........................] - ETA: 1:06  [ loss=0.0775 ][Training] 10/57 [====>.........................] - ETA: 1:04  [ loss=0.1112 ][Training] 11/57 [====>.........................] - ETA: 1:03  [ loss=0.1039 ][Training] 12/57 [=====>........................] - ETA: 1:02  [ loss=0.5599 ][Training] 13/57 [=====>........................] - ETA: 1:00  [ loss=0.8817 ][Training] 14/57 [======>.......................] - ETA: 59s  [ loss=0.4202 ][Training] 15/57 [======>.......................] - ETA: 58s  [ loss=0.1524 ][Training] 16/57 [=======>......................] - ETA: 56s  [ loss=0.2212 ][Training] 17/57 [=======>......................] - ETA: 54s  [ loss=0.7116 ][Training] 18/57 [========>.....................] - ETA: 53s  [ loss=0.4764 ][Training] 19/57 [=========>....................] - ETA: 51s  [ loss=0.5562 ][Training] 20/57 [=========>....................] - ETA: 50s  [ loss=1.1208 ][Training] 21/57 [==========>...................] - ETA: 48s  [ loss=1.5671 ][Training] 22/57 [==========>...................] - ETA: 47s  [ loss=0.0196 ][Training] 23/57 [===========>..................] - ETA: 46s  [ loss=0.3269 ][Training] 24/57 [===========>..................] - ETA: 44s  [ loss=0.0292 ][Training] 25/57 [============>.................] - ETA: 43s  [ loss=0.8320 ][Training] 26/57 [============>.................] - ETA: 42s  [ loss=1.4919 ][Training] 27/57 [=============>................] - ETA: 41s  [ loss=1.8686 ][Training] 28/57 [=============>................] - ETA: 40s  [ loss=0.6116 ][Training] 29/57 [==============>...............] - ETA: 39s  [ loss=3.3837 ][Training] 30/57 [==============>...............] - ETA: 37s  [ loss=0.5131 ][Training] 31/57 [===============>..............] - ETA: 36s  [ loss=0.3681 ][Training] 32/57 [===============>..............] - ETA: 34s  [ loss=0.5883 ][Training] 33/57 [================>.............] - ETA: 33s  [ loss=0.3509 ][Training] 34/57 [================>.............] - ETA: 32s  [ loss=0.0280 ][Training] 35/57 [=================>............] - ETA: 30s  [ loss=0.0485 ][Training] 36/57 [=================>............] - ETA: 29s  [ loss=0.5723 ][Training] 37/57 [==================>...........] - ETA: 28s  [ loss=0.5779 ][Training] 38/57 [===================>..........] - ETA: 26s  [ loss=3.8742 ][Training] 39/57 [===================>..........] - ETA: 25s  [ loss=0.0771 ][Training] 40/57 [====================>.........] - ETA: 24s  [ loss=0.0438 ][Training] 41/57 [====================>.........] - ETA: 22s  [ loss=1.0209 ][Training] 42/57 [=====================>........] - ETA: 21s  [ loss=0.1567 ][Training] 43/57 [=====================>........] - ETA: 19s  [ loss=0.2671 ][Training] 44/57 [======================>.......] - ETA: 18s  [ loss=0.0229 ][Training] 45/57 [======================>.......] - ETA: 16s  [ loss=0.7788 ][Training] 46/57 [=======================>......] - ETA: 15s  [ loss=0.0133 ][Training] 47/57 [=======================>......] - ETA: 14s  [ loss=0.0284 ][Training] 48/57 [========================>.....] - ETA: 12s  [ loss=0.0200 ][Training] 49/57 [========================>.....] - ETA: 11s  [ loss=0.2877 ][Training] 50/57 [=========================>....] - ETA: 9s  [ loss=0.0258 ][Training] 51/57 [=========================>....] - ETA: 8s  [ loss=0.0050 ][Training] 52/57 [==========================>...] - ETA: 7s  [ loss=0.3307 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=0.2118 ][Training] 54/57 [===========================>..] - ETA: 4s  [ loss=0.0873 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=0.8231 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=1.4982 ][Training] 57/57 [==============================] 1.4s/step  [ loss=3.7855 ]
01/03/2024 15:53:13 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 15:53:13 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 15:53:13 - INFO - root -     Num examples = 269
01/03/2024 15:53:13 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 6s[Evaluating] 2/12 [====>.........................] - ETA: 4s[Evaluating] 3/12 [======>.......................] - ETA: 4s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 3s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 2s[Evaluating] 8/12 [===================>..........] - ETA: 1s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 0s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 453.8ms/step
01/03/2024 15:53:18 - INFO - root -   

01/03/2024 15:53:18 - INFO - root -   ***** Eval results  *****
01/03/2024 15:53:18 - INFO - root -    acc: 0.7020 - recall: 0.6901 - f1: 0.6960 - loss: 13.5153 
01/03/2024 15:53:18 - INFO - root -   ***** Entity results  *****
01/03/2024 15:53:18 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 15:53:18 - INFO - root -    acc: 0.7885 - recall: 0.8723 - f1: 0.8283 
01/03/2024 15:53:18 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 15:53:18 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 15:53:18 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 15:53:18 - INFO - root -    acc: 0.4211 - recall: 0.4211 - f1: 0.4211 
01/03/2024 15:53:18 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 15:53:18 - INFO - root -    acc: 0.1429 - recall: 0.1111 - f1: 0.1250 
01/03/2024 15:53:18 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 15:53:18 - INFO - root -    acc: 0.5484 - recall: 0.4359 - f1: 0.4857 
01/03/2024 15:53:18 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 15:53:18 - INFO - root -    acc: 0.5625 - recall: 0.5294 - f1: 0.5455 
01/03/2024 15:53:18 - INFO - root -   ******* PER.NAM results ********
01/03/2024 15:53:18 - INFO - root -    acc: 0.7830 - recall: 0.7545 - f1: 0.7685 
01/03/2024 15:53:18 - INFO - root -   ******* PER.NOM results ********
01/03/2024 15:53:18 - INFO - root -    acc: 0.7200 - recall: 0.7412 - f1: 0.7304 
01/03/2024 15:53:26 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-627
01/03/2024 15:53:26 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-627
01/03/2024 15:53:26 - INFO - root -   

01/03/2024 15:53:26 - INFO - root -   Backbone bert_crf param is not freeze

Epoch: 11/30
[Training] 1/57 [..............................] - ETA: 1:30  [ loss=0.3101 ][Training] 2/57 [>.............................] - ETA: 1:23  [ loss=0.0082 ][Training] 3/57 [>.............................] - ETA: 1:17  [ loss=0.0655 ][Training] 4/57 [=>............................] - ETA: 1:15  [ loss=0.5339 ][Training] 5/57 [=>............................] - ETA: 1:12  [ loss=0.1555 ][Training] 6/57 [==>...........................] - ETA: 1:10  [ loss=1.8135 ][Training] 7/57 [==>...........................] - ETA: 1:08  [ loss=0.0375 ][Training] 8/57 [===>..........................] - ETA: 1:08  [ loss=0.2696 ][Training] 9/57 [===>..........................] - ETA: 1:07  [ loss=0.8977 ][Training] 10/57 [====>.........................] - ETA: 1:05  [ loss=0.1882 ][Training] 11/57 [====>.........................] - ETA: 1:03  [ loss=0.0085 ][Training] 12/57 [=====>........................] - ETA: 1:02  [ loss=0.2777 ][Training] 13/57 [=====>........................] - ETA: 1:00  [ loss=0.5607 ][Training] 14/57 [======>.......................] - ETA: 1:00  [ loss=0.0172 ][Training] 15/57 [======>.......................] - ETA: 58s  [ loss=0.5574 ][Training] 16/57 [=======>......................] - ETA: 57s  [ loss=0.3255 ][Training] 17/57 [=======>......................] - ETA: 56s  [ loss=1.7173 ][Training] 18/57 [========>.....................] - ETA: 55s  [ loss=0.0504 ][Training] 19/57 [=========>....................] - ETA: 53s  [ loss=0.5208 ][Training] 20/57 [=========>....................] - ETA: 52s  [ loss=1.1507 ][Training] 21/57 [==========>...................] - ETA: 50s  [ loss=0.2157 ][Training] 22/57 [==========>...................] - ETA: 49s  [ loss=0.0200 ][Training] 23/57 [===========>..................] - ETA: 47s  [ loss=1.6296 ][Training] 24/57 [===========>..................] - ETA: 46s  [ loss=0.0442 ][Training] 25/57 [============>.................] - ETA: 45s  [ loss=0.0375 ][Training] 26/57 [============>.................] - ETA: 44s  [ loss=0.0068 ][Training] 27/57 [=============>................] - ETA: 42s  [ loss=0.1904 ][Training] 28/57 [=============>................] - ETA: 41s  [ loss=0.7710 ][Training] 29/57 [==============>...............] - ETA: 39s  [ loss=0.7252 ][Training] 30/57 [==============>...............] - ETA: 38s  [ loss=1.3179 ][Training] 31/57 [===============>..............] - ETA: 37s  [ loss=0.0172 ][Training] 32/57 [===============>..............] - ETA: 35s  [ loss=0.2437 ][Training] 33/57 [================>.............] - ETA: 34s  [ loss=0.1469 ][Training] 34/57 [================>.............] - ETA: 33s  [ loss=1.3016 ][Training] 35/57 [=================>............] - ETA: 31s  [ loss=0.3116 ][Training] 36/57 [=================>............] - ETA: 30s  [ loss=0.3529 ][Training] 37/57 [==================>...........] - ETA: 29s  [ loss=0.9946 ][Training] 38/57 [===================>..........] - ETA: 27s  [ loss=0.1016 ][Training] 39/57 [===================>..........] - ETA: 26s  [ loss=0.7941 ][Training] 40/57 [====================>.........] - ETA: 24s  [ loss=1.0792 ][Training] 41/57 [====================>.........] - ETA: 23s  [ loss=0.6740 ][Training] 42/57 [=====================>........] - ETA: 21s  [ loss=0.3643 ][Training] 43/57 [=====================>........] - ETA: 20s  [ loss=0.7379 ][Training] 44/57 [======================>.......] - ETA: 19s  [ loss=0.4003 ][Training] 45/57 [======================>.......] - ETA: 17s  [ loss=0.1460 ][Training] 46/57 [=======================>......] - ETA: 16s  [ loss=0.5184 ][Training] 47/57 [=======================>......] - ETA: 14s  [ loss=0.1193 ][Training] 48/57 [========================>.....] - ETA: 13s  [ loss=0.7192 ][Training] 49/57 [========================>.....] - ETA: 11s  [ loss=0.0294 ][Training] 50/57 [=========================>....] - ETA: 10s  [ loss=0.1548 ][Training] 51/57 [=========================>....] - ETA: 8s  [ loss=0.0338 ][Training] 52/57 [==========================>...] - ETA: 7s  [ loss=0.1358 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=0.3384 ][Training] 54/57 [===========================>..] - ETA: 4s  [ loss=0.0413 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=0.1702 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.7805 ][Training] 57/57 [==============================] 1.4s/step  [ loss=0.0383 ]
01/03/2024 15:54:48 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 15:54:48 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 15:54:48 - INFO - root -     Num examples = 269
01/03/2024 15:54:48 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 6s[Evaluating] 2/12 [====>.........................] - ETA: 4s[Evaluating] 3/12 [======>.......................] - ETA: 4s[Evaluating] 4/12 [=========>....................] - ETA: 3s[Evaluating] 5/12 [===========>..................] - ETA: 3s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 2s[Evaluating] 8/12 [===================>..........] - ETA: 1s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 0s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 465.4ms/step
01/03/2024 15:54:54 - INFO - root -   

01/03/2024 15:54:54 - INFO - root -   ***** Eval results  *****
01/03/2024 15:54:54 - INFO - root -    acc: 0.6752 - recall: 0.7046 - f1: 0.6896 - loss: 12.2026 
01/03/2024 15:54:54 - INFO - root -   ***** Entity results  *****
01/03/2024 15:54:54 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 15:54:54 - INFO - root -    acc: 0.7778 - recall: 0.8936 - f1: 0.8317 
01/03/2024 15:54:54 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 15:54:54 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 15:54:54 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 15:54:54 - INFO - root -    acc: 0.4211 - recall: 0.4211 - f1: 0.4211 
01/03/2024 15:54:54 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 15:54:54 - INFO - root -    acc: 0.3333 - recall: 0.3333 - f1: 0.3333 
01/03/2024 15:54:54 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 15:54:54 - INFO - root -    acc: 0.4615 - recall: 0.4615 - f1: 0.4615 
01/03/2024 15:54:54 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 15:54:54 - INFO - root -    acc: 0.5000 - recall: 0.5882 - f1: 0.5405 
01/03/2024 15:54:54 - INFO - root -   ******* PER.NAM results ********
01/03/2024 15:54:54 - INFO - root -    acc: 0.7545 - recall: 0.7545 - f1: 0.7545 
01/03/2024 15:54:54 - INFO - root -   ******* PER.NOM results ********
01/03/2024 15:54:54 - INFO - root -    acc: 0.7056 - recall: 0.7471 - f1: 0.7257 
01/03/2024 15:55:02 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-684
01/03/2024 15:55:02 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-684
01/03/2024 15:55:02 - INFO - root -   

01/03/2024 15:55:02 - INFO - root -   Backbone bert_crf param is not freeze

Epoch: 12/30
[Training] 1/57 [..............................] - ETA: 1:13  [ loss=0.0116 ][Training] 2/57 [>.............................] - ETA: 1:13  [ loss=0.0818 ][Training] 3/57 [>.............................] - ETA: 1:12  [ loss=0.0198 ][Training] 4/57 [=>............................] - ETA: 1:11  [ loss=0.1561 ][Training] 5/57 [=>............................] - ETA: 1:13  [ loss=0.7510 ][Training] 6/57 [==>...........................] - ETA: 1:13  [ loss=1.9737 ][Training] 7/57 [==>...........................] - ETA: 1:10  [ loss=0.0392 ][Training] 8/57 [===>..........................] - ETA: 1:10  [ loss=0.1636 ][Training] 9/57 [===>..........................] - ETA: 1:10  [ loss=0.0129 ][Training] 10/57 [====>.........................] - ETA: 1:09  [ loss=1.0311 ][Training] 11/57 [====>.........................] - ETA: 1:06  [ loss=0.3905 ][Training] 12/57 [=====>........................] - ETA: 1:04  [ loss=0.1944 ][Training] 13/57 [=====>........................] - ETA: 1:04  [ loss=0.6298 ][Training] 14/57 [======>.......................] - ETA: 1:01  [ loss=0.0786 ][Training] 15/57 [======>.......................] - ETA: 1:00  [ loss=0.1437 ][Training] 16/57 [=======>......................] - ETA: 59s  [ loss=0.2206 ][Training] 17/57 [=======>......................] - ETA: 58s  [ loss=0.2714 ][Training] 18/57 [========>.....................] - ETA: 56s  [ loss=0.0564 ][Training] 19/57 [=========>....................] - ETA: 54s  [ loss=1.2467 ][Training] 20/57 [=========>....................] - ETA: 53s  [ loss=0.8656 ][Training] 21/57 [==========>...................] - ETA: 51s  [ loss=0.0272 ][Training] 22/57 [==========>...................] - ETA: 50s  [ loss=0.5276 ][Training] 23/57 [===========>..................] - ETA: 48s  [ loss=0.3301 ][Training] 24/57 [===========>..................] - ETA: 46s  [ loss=0.1409 ][Training] 25/57 [============>.................] - ETA: 45s  [ loss=0.9040 ][Training] 26/57 [============>.................] - ETA: 44s  [ loss=0.8689 ][Training] 27/57 [=============>................] - ETA: 42s  [ loss=0.4209 ][Training] 28/57 [=============>................] - ETA: 41s  [ loss=0.0064 ][Training] 29/57 [==============>...............] - ETA: 39s  [ loss=0.4312 ][Training] 30/57 [==============>...............] - ETA: 38s  [ loss=0.1694 ][Training] 31/57 [===============>..............] - ETA: 37s  [ loss=0.0110 ][Training] 32/57 [===============>..............] - ETA: 35s  [ loss=0.1676 ][Training] 33/57 [================>.............] - ETA: 34s  [ loss=0.0482 ][Training] 34/57 [================>.............] - ETA: 33s  [ loss=0.1282 ][Training] 35/57 [=================>............] - ETA: 31s  [ loss=0.7221 ][Training] 36/57 [=================>............] - ETA: 30s  [ loss=0.7504 ][Training] 37/57 [==================>...........] - ETA: 28s  [ loss=0.4002 ][Training] 38/57 [===================>..........] - ETA: 27s  [ loss=0.7866 ][Training] 39/57 [===================>..........] - ETA: 25s  [ loss=0.1423 ][Training] 40/57 [====================>.........] - ETA: 24s  [ loss=0.1293 ][Training] 41/57 [====================>.........] - ETA: 22s  [ loss=0.6699 ][Training] 42/57 [=====================>........] - ETA: 21s  [ loss=0.1241 ][Training] 43/57 [=====================>........] - ETA: 19s  [ loss=0.2804 ][Training] 44/57 [======================>.......] - ETA: 18s  [ loss=0.1999 ][Training] 45/57 [======================>.......] - ETA: 17s  [ loss=0.0148 ][Training] 46/57 [=======================>......] - ETA: 15s  [ loss=0.2139 ][Training] 47/57 [=======================>......] - ETA: 14s  [ loss=0.1100 ][Training] 48/57 [========================>.....] - ETA: 12s  [ loss=0.3493 ][Training] 49/57 [========================>.....] - ETA: 11s  [ loss=0.0377 ][Training] 50/57 [=========================>....] - ETA: 10s  [ loss=2.0973 ][Training] 51/57 [=========================>....] - ETA: 8s  [ loss=0.1748 ][Training] 52/57 [==========================>...] - ETA: 7s  [ loss=0.0058 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=0.0263 ][Training] 54/57 [===========================>..] - ETA: 4s  [ loss=0.2979 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=1.0458 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.9335 ][Training] 57/57 [==============================] 1.4s/step  [ loss=0.0536 ]
01/03/2024 15:56:23 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 15:56:23 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 15:56:23 - INFO - root -     Num examples = 269
01/03/2024 15:56:23 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 4s[Evaluating] 2/12 [====>.........................] - ETA: 4s[Evaluating] 3/12 [======>.......................] - ETA: 4s[Evaluating] 4/12 [=========>....................] - ETA: 3s[Evaluating] 5/12 [===========>..................] - ETA: 3s[Evaluating] 6/12 [==============>...............] - ETA: 2s[Evaluating] 7/12 [================>.............] - ETA: 2s[Evaluating] 8/12 [===================>..........] - ETA: 1s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 0s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 451.6ms/step
01/03/2024 15:56:29 - INFO - root -   

01/03/2024 15:56:29 - INFO - root -   ***** Eval results  *****
01/03/2024 15:56:29 - INFO - root -    acc: 0.6763 - recall: 0.7337 - f1: 0.7038 - loss: 12.6117 
01/03/2024 15:56:29 - INFO - root -   ***** Entity results  *****
01/03/2024 15:56:29 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 15:56:29 - INFO - root -    acc: 0.8400 - recall: 0.8936 - f1: 0.8660 
01/03/2024 15:56:29 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 15:56:29 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 15:56:29 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 15:56:29 - INFO - root -    acc: 0.5294 - recall: 0.4737 - f1: 0.5000 
01/03/2024 15:56:29 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 15:56:29 - INFO - root -    acc: 0.2857 - recall: 0.4444 - f1: 0.3478 
01/03/2024 15:56:29 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 15:56:29 - INFO - root -    acc: 0.4583 - recall: 0.5641 - f1: 0.5057 
01/03/2024 15:56:29 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 15:56:29 - INFO - root -    acc: 0.6875 - recall: 0.6471 - f1: 0.6667 
01/03/2024 15:56:29 - INFO - root -   ******* PER.NAM results ********
01/03/2024 15:56:29 - INFO - root -    acc: 0.7434 - recall: 0.7636 - f1: 0.7534 
01/03/2024 15:56:29 - INFO - root -   ******* PER.NOM results ********
01/03/2024 15:56:29 - INFO - root -    acc: 0.6895 - recall: 0.7706 - f1: 0.7278 
01/03/2024 15:56:37 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-741
01/03/2024 15:56:37 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-741
01/03/2024 15:56:37 - INFO - root -   

01/03/2024 15:56:37 - INFO - root -   Backbone bert_crf param is not freeze

Epoch: 13/30
[Training] 1/57 [..............................] - ETA: 1:22  [ loss=0.6609 ][Training] 2/57 [>.............................] - ETA: 1:15  [ loss=0.2765 ][Training] 3/57 [>.............................] - ETA: 1:18  [ loss=0.3525 ][Training] 4/57 [=>............................] - ETA: 1:15  [ loss=0.0152 ][Training] 5/57 [=>............................] - ETA: 1:09  [ loss=0.0040 ][Training] 6/57 [==>...........................] - ETA: 1:09  [ loss=0.8668 ][Training] 7/57 [==>...........................] - ETA: 1:07  [ loss=0.0499 ][Training] 8/57 [===>..........................] - ETA: 1:06  [ loss=1.1507 ][Training] 9/57 [===>..........................] - ETA: 1:04  [ loss=0.0350 ][Training] 10/57 [====>.........................] - ETA: 1:03  [ loss=0.3398 ][Training] 11/57 [====>.........................] - ETA: 1:01  [ loss=0.2910 ][Training] 12/57 [=====>........................] - ETA: 1:00  [ loss=0.2706 ][Training] 13/57 [=====>........................] - ETA: 58s  [ loss=0.0304 ][Training] 14/57 [======>.......................] - ETA: 57s  [ loss=0.6492 ][Training] 15/57 [======>.......................] - ETA: 55s  [ loss=0.0076 ][Training] 16/57 [=======>......................] - ETA: 53s  [ loss=0.3220 ][Training] 17/57 [=======>......................] - ETA: 52s  [ loss=0.4238 ][Training] 18/57 [========>.....................] - ETA: 51s  [ loss=0.2927 ][Training] 19/57 [=========>....................] - ETA: 50s  [ loss=0.0117 ][Training] 20/57 [=========>....................] - ETA: 49s  [ loss=0.9612 ][Training] 21/57 [==========>...................] - ETA: 48s  [ loss=1.1064 ][Training] 22/57 [==========>...................] - ETA: 47s  [ loss=0.1692 ][Training] 23/57 [===========>..................] - ETA: 45s  [ loss=0.2784 ][Training] 24/57 [===========>..................] - ETA: 44s  [ loss=0.1903 ][Training] 25/57 [============>.................] - ETA: 43s  [ loss=0.0929 ][Training] 26/57 [============>.................] - ETA: 42s  [ loss=0.1121 ][Training] 27/57 [=============>................] - ETA: 40s  [ loss=0.4556 ][Training] 28/57 [=============>................] - ETA: 39s  [ loss=0.0111 ][Training] 29/57 [==============>...............] - ETA: 38s  [ loss=1.2668 ][Training] 30/57 [==============>...............] - ETA: 37s  [ loss=0.5836 ][Training] 31/57 [===============>..............] - ETA: 35s  [ loss=0.1457 ][Training] 32/57 [===============>..............] - ETA: 34s  [ loss=0.2168 ][Training] 33/57 [================>.............] - ETA: 33s  [ loss=0.1730 ][Training] 34/57 [================>.............] - ETA: 31s  [ loss=0.2928 ][Training] 35/57 [=================>............] - ETA: 30s  [ loss=0.0177 ][Training] 36/57 [=================>............] - ETA: 28s  [ loss=0.4467 ][Training] 37/57 [==================>...........] - ETA: 27s  [ loss=0.0661 ][Training] 38/57 [===================>..........] - ETA: 26s  [ loss=0.2662 ][Training] 39/57 [===================>..........] - ETA: 24s  [ loss=0.3478 ][Training] 40/57 [====================>.........] - ETA: 23s  [ loss=0.3879 ][Training] 41/57 [====================>.........] - ETA: 21s  [ loss=0.9654 ][Training] 42/57 [=====================>........] - ETA: 20s  [ loss=0.2802 ][Training] 43/57 [=====================>........] - ETA: 19s  [ loss=0.0298 ][Training] 44/57 [======================>.......] - ETA: 17s  [ loss=0.0911 ][Training] 45/57 [======================>.......] - ETA: 16s  [ loss=0.0552 ][Training] 46/57 [=======================>......] - ETA: 15s  [ loss=0.3538 ][Training] 47/57 [=======================>......] - ETA: 13s  [ loss=0.0685 ][Training] 48/57 [========================>.....] - ETA: 12s  [ loss=0.0138 ][Training] 49/57 [========================>.....] - ETA: 11s  [ loss=0.6959 ][Training] 50/57 [=========================>....] - ETA: 9s  [ loss=0.4744 ][Training] 51/57 [=========================>....] - ETA: 8s  [ loss=0.0094 ][Training] 52/57 [==========================>...] - ETA: 6s  [ loss=0.1055 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=0.3603 ][Training] 54/57 [===========================>..] - ETA: 4s  [ loss=0.6040 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=0.8998 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=1.6210 ][Training] 57/57 [==============================] 1.4s/step  [ loss=0.0053 ]
01/03/2024 15:57:56 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 15:57:56 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 15:57:56 - INFO - root -     Num examples = 269
01/03/2024 15:57:56 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 6s[Evaluating] 2/12 [====>.........................] - ETA: 4s[Evaluating] 3/12 [======>.......................] - ETA: 4s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 3s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 2s[Evaluating] 8/12 [===================>..........] - ETA: 1s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 0s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 456.1ms/step
01/03/2024 15:58:01 - INFO - root -   

01/03/2024 15:58:01 - INFO - root -   ***** Eval results  *****
01/03/2024 15:58:01 - INFO - root -    acc: 0.6712 - recall: 0.7167 - f1: 0.6932 - loss: 13.2224 
01/03/2024 15:58:01 - INFO - root -   ***** Entity results  *****
01/03/2024 15:58:01 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 15:58:01 - INFO - root -    acc: 0.7925 - recall: 0.8936 - f1: 0.8400 
01/03/2024 15:58:01 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 15:58:01 - INFO - root -    acc: 0.5000 - recall: 0.5000 - f1: 0.5000 
01/03/2024 15:58:01 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 15:58:01 - INFO - root -    acc: 0.4211 - recall: 0.4211 - f1: 0.4211 
01/03/2024 15:58:01 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 15:58:01 - INFO - root -    acc: 0.3000 - recall: 0.3333 - f1: 0.3158 
01/03/2024 15:58:01 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 15:58:01 - INFO - root -    acc: 0.5405 - recall: 0.5128 - f1: 0.5263 
01/03/2024 15:58:01 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 15:58:01 - INFO - root -    acc: 0.5789 - recall: 0.6471 - f1: 0.6111 
01/03/2024 15:58:01 - INFO - root -   ******* PER.NAM results ********
01/03/2024 15:58:01 - INFO - root -    acc: 0.7241 - recall: 0.7636 - f1: 0.7434 
01/03/2024 15:58:01 - INFO - root -   ******* PER.NOM results ********
01/03/2024 15:58:01 - INFO - root -    acc: 0.6865 - recall: 0.7471 - f1: 0.7155 
01/03/2024 15:58:21 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-798
01/03/2024 15:58:21 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-798
01/03/2024 15:58:21 - INFO - root -   

01/03/2024 15:58:21 - INFO - root -   Backbone bert_crf param is not freeze

Epoch: 14/30
[Training] 1/57 [..............................] - ETA: 1:18  [ loss=0.0049 ][Training] 2/57 [>.............................] - ETA: 1:17  [ loss=0.8559 ][Training] 3/57 [>.............................] - ETA: 1:21  [ loss=0.0315 ][Training] 4/57 [=>............................] - ETA: 1:16  [ loss=0.1077 ][Training] 5/57 [=>............................] - ETA: 1:18  [ loss=0.4727 ][Training] 6/57 [==>...........................] - ETA: 1:18  [ loss=0.1747 ][Training] 7/57 [==>...........................] - ETA: 1:14  [ loss=0.1001 ][Training] 8/57 [===>..........................] - ETA: 1:11  [ loss=1.1965 ][Training] 9/57 [===>..........................] - ETA: 1:09  [ loss=0.0103 ][Training] 10/57 [====>.........................] - ETA: 1:08  [ loss=0.5595 ][Training] 11/57 [====>.........................] - ETA: 1:07  [ loss=0.0619 ][Training] 12/57 [=====>........................] - ETA: 1:03  [ loss=0.0092 ][Training] 13/57 [=====>........................] - ETA: 1:02  [ loss=0.0082 ][Training] 14/57 [======>.......................] - ETA: 1:00  [ loss=0.1473 ][Training] 15/57 [======>.......................] - ETA: 59s  [ loss=0.9799 ][Training] 16/57 [=======>......................] - ETA: 57s  [ loss=0.2782 ][Training] 17/57 [=======>......................] - ETA: 55s  [ loss=0.5294 ][Training] 18/57 [========>.....................] - ETA: 54s  [ loss=0.2001 ][Training] 19/57 [=========>....................] - ETA: 53s  [ loss=1.7242 ][Training] 20/57 [=========>....................] - ETA: 51s  [ loss=0.1987 ][Training] 21/57 [==========>...................] - ETA: 50s  [ loss=2.1794 ][Training] 22/57 [==========>...................] - ETA: 49s  [ loss=0.0716 ][Training] 23/57 [===========>..................] - ETA: 47s  [ loss=0.9936 ][Training] 24/57 [===========>..................] - ETA: 46s  [ loss=0.2373 ][Training] 25/57 [============>.................] - ETA: 45s  [ loss=0.2490 ][Training] 26/57 [============>.................] - ETA: 43s  [ loss=0.2662 ][Training] 27/57 [=============>................] - ETA: 42s  [ loss=0.1671 ][Training] 28/57 [=============>................] - ETA: 40s  [ loss=0.1982 ][Training] 29/57 [==============>...............] - ETA: 39s  [ loss=0.0069 ][Training] 30/57 [==============>...............] - ETA: 37s  [ loss=0.0044 ][Training] 31/57 [===============>..............] - ETA: 36s  [ loss=0.0054 ][Training] 32/57 [===============>..............] - ETA: 34s  [ loss=0.1747 ][Training] 33/57 [================>.............] - ETA: 33s  [ loss=0.4664 ][Training] 34/57 [================>.............] - ETA: 32s  [ loss=0.1395 ][Training] 35/57 [=================>............] - ETA: 30s  [ loss=0.1979 ][Training] 36/57 [=================>............] - ETA: 29s  [ loss=0.3752 ][Training] 37/57 [==================>...........] - ETA: 27s  [ loss=0.5250 ][Training] 38/57 [===================>..........] - ETA: 26s  [ loss=0.0649 ][Training] 39/57 [===================>..........] - ETA: 25s  [ loss=0.0841 ][Training] 40/57 [====================>.........] - ETA: 23s  [ loss=0.2043 ][Training] 41/57 [====================>.........] - ETA: 22s  [ loss=0.7765 ][Training] 42/57 [=====================>........] - ETA: 20s  [ loss=0.3489 ][Training] 43/57 [=====================>........] - ETA: 19s  [ loss=0.2116 ][Training] 44/57 [======================>.......] - ETA: 18s  [ loss=0.2060 ][Training] 45/57 [======================>.......] - ETA: 16s  [ loss=0.2062 ][Training] 46/57 [=======================>......] - ETA: 15s  [ loss=0.7259 ][Training] 47/57 [=======================>......] - ETA: 14s  [ loss=0.0718 ][Training] 48/57 [========================>.....] - ETA: 12s  [ loss=0.4459 ][Training] 49/57 [========================>.....] - ETA: 11s  [ loss=0.7528 ][Training] 50/57 [=========================>....] - ETA: 9s  [ loss=0.0133 ][Training] 51/57 [=========================>....] - ETA: 8s  [ loss=0.0045 ][Training] 52/57 [==========================>...] - ETA: 7s  [ loss=0.3389 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=0.0112 ][Training] 54/57 [===========================>..] - ETA: 4s  [ loss=0.2432 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=0.5370 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.7078 ][Training] 57/57 [==============================] 1.4s/step  [ loss=0.0083 ]
01/03/2024 15:59:41 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 15:59:41 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 15:59:41 - INFO - root -     Num examples = 269
01/03/2024 15:59:41 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 6s[Evaluating] 2/12 [====>.........................] - ETA: 4s[Evaluating] 3/12 [======>.......................] - ETA: 3s[Evaluating] 4/12 [=========>....................] - ETA: 3s[Evaluating] 5/12 [===========>..................] - ETA: 3s[Evaluating] 6/12 [==============>...............] - ETA: 2s[Evaluating] 7/12 [================>.............] - ETA: 2s[Evaluating] 8/12 [===================>..........] - ETA: 1s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 0s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 448.7ms/step
01/03/2024 15:59:46 - INFO - root -   

01/03/2024 15:59:47 - INFO - root -   ***** Eval results  *****
01/03/2024 15:59:47 - INFO - root -    acc: 0.7050 - recall: 0.7119 - f1: 0.7084 - loss: 12.6633 
01/03/2024 15:59:47 - INFO - root -   ***** Entity results  *****
01/03/2024 15:59:47 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 15:59:47 - INFO - root -    acc: 0.8235 - recall: 0.8936 - f1: 0.8571 
01/03/2024 15:59:47 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 15:59:47 - INFO - root -    acc: 0.6667 - recall: 1.0000 - f1: 0.8000 
01/03/2024 15:59:47 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 15:59:47 - INFO - root -    acc: 0.4500 - recall: 0.4737 - f1: 0.4615 
01/03/2024 15:59:47 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 15:59:47 - INFO - root -    acc: 0.4000 - recall: 0.4444 - f1: 0.4211 
01/03/2024 15:59:47 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 15:59:47 - INFO - root -    acc: 0.6071 - recall: 0.4359 - f1: 0.5075 
01/03/2024 15:59:47 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 15:59:47 - INFO - root -    acc: 0.5556 - recall: 0.5882 - f1: 0.5714 
01/03/2024 15:59:47 - INFO - root -   ******* PER.NAM results ********
01/03/2024 15:59:47 - INFO - root -    acc: 0.8000 - recall: 0.7273 - f1: 0.7619 
01/03/2024 15:59:47 - INFO - root -   ******* PER.NOM results ********
01/03/2024 15:59:47 - INFO - root -    acc: 0.6952 - recall: 0.7647 - f1: 0.7283 
01/03/2024 15:59:54 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-855
01/03/2024 15:59:54 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-855
01/03/2024 15:59:54 - INFO - root -   

01/03/2024 15:59:54 - INFO - root -   Backbone bert_crf param is not freeze

Epoch: 15/30
[Training] 1/57 [..............................] - ETA: 1:19  [ loss=0.3530 ][Training] 2/57 [>.............................] - ETA: 1:13  [ loss=0.0561 ][Training] 3/57 [>.............................] - ETA: 1:16  [ loss=0.0065 ][Training] 4/57 [=>............................] - ETA: 1:11  [ loss=0.0525 ][Training] 5/57 [=>............................] - ETA: 1:10  [ loss=0.1179 ][Training] 6/57 [==>...........................] - ETA: 1:11  [ loss=0.0987 ][Training] 7/57 [==>...........................] - ETA: 1:09  [ loss=0.0043 ][Training] 8/57 [===>..........................] - ETA: 1:09  [ loss=0.5528 ][Training] 9/57 [===>..........................] - ETA: 1:07  [ loss=0.0107 ][Training] 10/57 [====>.........................] - ETA: 1:07  [ loss=0.8222 ][Training] 11/57 [====>.........................] - ETA: 1:05  [ loss=0.0982 ][Training] 12/57 [=====>........................] - ETA: 1:04  [ loss=0.1460 ][Training] 13/57 [=====>........................] - ETA: 1:03  [ loss=0.0047 ][Training] 14/57 [======>.......................] - ETA: 1:02  [ loss=0.0057 ][Training] 15/57 [======>.......................] - ETA: 1:01  [ loss=0.3906 ][Training] 16/57 [=======>......................] - ETA: 59s  [ loss=0.2075 ][Training] 17/57 [=======>......................] - ETA: 57s  [ loss=0.2949 ][Training] 18/57 [========>.....................] - ETA: 56s  [ loss=0.2858 ][Training] 19/57 [=========>....................] - ETA: 55s  [ loss=0.5626 ][Training] 20/57 [=========>....................] - ETA: 53s  [ loss=0.2776 ][Training] 21/57 [==========>...................] - ETA: 52s  [ loss=1.6542 ][Training] 22/57 [==========>...................] - ETA: 50s  [ loss=0.4323 ][Training] 23/57 [===========>..................] - ETA: 49s  [ loss=0.0037 ][Training] 24/57 [===========>..................] - ETA: 47s  [ loss=0.4761 ][Training] 25/57 [============>.................] - ETA: 46s  [ loss=0.3892 ][Training] 26/57 [============>.................] - ETA: 44s  [ loss=0.0479 ][Training] 27/57 [=============>................] - ETA: 43s  [ loss=1.7748 ][Training] 28/57 [=============>................] - ETA: 41s  [ loss=0.0077 ][Training] 29/57 [==============>...............] - ETA: 40s  [ loss=0.3926 ][Training] 30/57 [==============>...............] - ETA: 39s  [ loss=0.0383 ][Training] 31/57 [===============>..............] - ETA: 37s  [ loss=0.2399 ][Training] 32/57 [===============>..............] - ETA: 36s  [ loss=0.0082 ][Training] 33/57 [================>.............] - ETA: 34s  [ loss=0.2061 ][Training] 34/57 [================>.............] - ETA: 33s  [ loss=0.0040 ][Training] 35/57 [=================>............] - ETA: 31s  [ loss=0.7074 ][Training] 36/57 [=================>............] - ETA: 30s  [ loss=0.3087 ][Training] 37/57 [==================>...........] - ETA: 28s  [ loss=0.2770 ][Training] 38/57 [===================>..........] - ETA: 27s  [ loss=0.8261 ][Training] 39/57 [===================>..........] - ETA: 25s  [ loss=0.0140 ][Training] 40/57 [====================>.........] - ETA: 24s  [ loss=0.4791 ][Training] 41/57 [====================>.........] - ETA: 23s  [ loss=0.0161 ][Training] 42/57 [=====================>........] - ETA: 21s  [ loss=0.0552 ][Training] 43/57 [=====================>........] - ETA: 20s  [ loss=0.2699 ][Training] 44/57 [======================>.......] - ETA: 18s  [ loss=0.0663 ][Training] 45/57 [======================>.......] - ETA: 17s  [ loss=0.0045 ][Training] 46/57 [=======================>......] - ETA: 15s  [ loss=0.0144 ][Training] 47/57 [=======================>......] - ETA: 14s  [ loss=0.1415 ][Training] 48/57 [========================>.....] - ETA: 12s  [ loss=0.0087 ][Training] 49/57 [========================>.....] - ETA: 11s  [ loss=0.2418 ][Training] 50/57 [=========================>....] - ETA: 10s  [ loss=0.5567 ][Training] 51/57 [=========================>....] - ETA: 8s  [ loss=0.1200 ][Training] 52/57 [==========================>...] - ETA: 7s  [ loss=0.1975 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=0.6142 ][Training] 54/57 [===========================>..] - ETA: 4s  [ loss=1.5542 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=0.0542 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.7253 ][Training] 57/57 [==============================] 1.4s/step  [ loss=0.2088 ]
01/03/2024 16:01:15 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 16:01:15 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 16:01:15 - INFO - root -     Num examples = 269
01/03/2024 16:01:15 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 4s[Evaluating] 2/12 [====>.........................] - ETA: 4s[Evaluating] 3/12 [======>.......................] - ETA: 4s[Evaluating] 4/12 [=========>....................] - ETA: 3s[Evaluating] 5/12 [===========>..................] - ETA: 3s[Evaluating] 6/12 [==============>...............] - ETA: 2s[Evaluating] 7/12 [================>.............] - ETA: 2s[Evaluating] 8/12 [===================>..........] - ETA: 1s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 0s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 444.6ms/step
01/03/2024 16:01:21 - INFO - root -   

01/03/2024 16:01:21 - INFO - root -   ***** Eval results  *****
01/03/2024 16:01:21 - INFO - root -    acc: 0.7207 - recall: 0.6998 - f1: 0.7101 - loss: 13.7265 
01/03/2024 16:01:21 - INFO - root -   ***** Entity results  *****
01/03/2024 16:01:21 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 16:01:21 - INFO - root -    acc: 0.8200 - recall: 0.8723 - f1: 0.8454 
01/03/2024 16:01:21 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 16:01:21 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 16:01:21 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 16:01:21 - INFO - root -    acc: 0.4000 - recall: 0.3158 - f1: 0.3529 
01/03/2024 16:01:21 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 16:01:21 - INFO - root -    acc: 0.3333 - recall: 0.2222 - f1: 0.2667 
01/03/2024 16:01:21 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 16:01:21 - INFO - root -    acc: 0.6061 - recall: 0.5128 - f1: 0.5556 
01/03/2024 16:01:21 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 16:01:21 - INFO - root -    acc: 0.8571 - recall: 0.7059 - f1: 0.7742 
01/03/2024 16:01:21 - INFO - root -   ******* PER.NAM results ********
01/03/2024 16:01:21 - INFO - root -    acc: 0.7843 - recall: 0.7273 - f1: 0.7547 
01/03/2024 16:01:21 - INFO - root -   ******* PER.NOM results ********
01/03/2024 16:01:21 - INFO - root -    acc: 0.7072 - recall: 0.7529 - f1: 0.7293 
01/03/2024 16:01:28 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-912
01/03/2024 16:01:28 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-912
01/03/2024 16:01:28 - INFO - root -   

01/03/2024 16:01:28 - INFO - root -   Backbone bert_crf param is not freeze

Epoch: 16/30
[Training] 1/57 [..............................] - ETA: 1:31  [ loss=0.0858 ][Training] 2/57 [>.............................] - ETA: 1:25  [ loss=0.2157 ][Training] 3/57 [>.............................] - ETA: 1:17  [ loss=0.2103 ][Training] 4/57 [=>............................] - ETA: 1:19  [ loss=0.2938 ][Training] 5/57 [=>............................] - ETA: 1:18  [ loss=0.6187 ][Training] 6/57 [==>...........................] - ETA: 1:18  [ loss=0.1131 ][Training] 7/57 [==>...........................] - ETA: 1:18  [ loss=0.1011 ][Training] 8/57 [===>..........................] - ETA: 1:13  [ loss=0.0062 ][Training] 9/57 [===>..........................] - ETA: 1:11  [ loss=0.1618 ][Training] 10/57 [====>.........................] - ETA: 1:09  [ loss=0.2686 ][Training] 11/57 [====>.........................] - ETA: 1:07  [ loss=0.1500 ][Training] 12/57 [=====>........................] - ETA: 1:06  [ loss=0.6194 ][Training] 13/57 [=====>........................] - ETA: 1:04  [ loss=0.0467 ][Training] 14/57 [======>.......................] - ETA: 1:03  [ loss=0.2837 ][Training] 15/57 [======>.......................] - ETA: 1:02  [ loss=0.0067 ][Training] 16/57 [=======>......................] - ETA: 1:00  [ loss=0.3646 ][Training] 17/57 [=======>......................] - ETA: 58s  [ loss=0.2007 ][Training] 18/57 [========>.....................] - ETA: 57s  [ loss=0.2337 ][Training] 19/57 [=========>....................] - ETA: 55s  [ loss=0.2438 ][Training] 20/57 [=========>....................] - ETA: 54s  [ loss=0.0320 ][Training] 21/57 [==========>...................] - ETA: 52s  [ loss=0.0980 ][Training] 22/57 [==========>...................] - ETA: 51s  [ loss=0.5515 ][Training] 23/57 [===========>..................] - ETA: 49s  [ loss=0.5088 ][Training] 24/57 [===========>..................] - ETA: 48s  [ loss=0.4434 ][Training] 25/57 [============>.................] - ETA: 46s  [ loss=0.1406 ][Training] 26/57 [============>.................] - ETA: 44s  [ loss=0.0082 ][Training] 27/57 [=============>................] - ETA: 43s  [ loss=0.0049 ][Training] 28/57 [=============>................] - ETA: 41s  [ loss=0.0845 ][Training] 29/57 [==============>...............] - ETA: 40s  [ loss=0.1306 ][Training] 30/57 [==============>...............] - ETA: 38s  [ loss=0.4675 ][Training] 31/57 [===============>..............] - ETA: 37s  [ loss=0.1312 ][Training] 32/57 [===============>..............] - ETA: 35s  [ loss=0.1972 ][Training] 33/57 [================>.............] - ETA: 34s  [ loss=0.3747 ][Training] 34/57 [================>.............] - ETA: 33s  [ loss=0.5552 ][Training] 35/57 [=================>............] - ETA: 31s  [ loss=0.0048 ][Training] 36/57 [=================>............] - ETA: 30s  [ loss=0.0362 ][Training] 37/57 [==================>...........] - ETA: 28s  [ loss=0.1227 ][Training] 38/57 [===================>..........] - ETA: 27s  [ loss=0.2116 ][Training] 39/57 [===================>..........] - ETA: 25s  [ loss=0.5949 ][Training] 40/57 [====================>.........] - ETA: 24s  [ loss=1.1256 ][Training] 41/57 [====================>.........] - ETA: 22s  [ loss=0.1081 ][Training] 42/57 [=====================>........] - ETA: 21s  [ loss=1.0974 ][Training] 43/57 [=====================>........] - ETA: 19s  [ loss=0.1216 ][Training] 44/57 [======================>.......] - ETA: 18s  [ loss=0.0410 ][Training] 45/57 [======================>.......] - ETA: 16s  [ loss=0.0154 ][Training] 46/57 [=======================>......] - ETA: 15s  [ loss=0.0971 ][Training] 47/57 [=======================>......] - ETA: 14s  [ loss=0.2023 ][Training] 48/57 [========================>.....] - ETA: 12s  [ loss=0.1683 ][Training] 49/57 [========================>.....] - ETA: 11s  [ loss=0.5390 ][Training] 50/57 [=========================>....] - ETA: 9s  [ loss=0.0049 ][Training] 51/57 [=========================>....] - ETA: 8s  [ loss=0.5621 ][Training] 52/57 [==========================>...] - ETA: 7s  [ loss=0.4356 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=0.4173 ][Training] 54/57 [===========================>..] - ETA: 4s  [ loss=0.0036 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=0.0410 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.8707 ][Training] 57/57 [==============================] 1.4s/step  [ loss=0.0036 ]
01/03/2024 16:02:48 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 16:02:48 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 16:02:48 - INFO - root -     Num examples = 269
01/03/2024 16:02:48 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 4s[Evaluating] 2/12 [====>.........................] - ETA: 5s[Evaluating] 3/12 [======>.......................] - ETA: 4s[Evaluating] 4/12 [=========>....................] - ETA: 3s[Evaluating] 5/12 [===========>..................] - ETA: 3s[Evaluating] 6/12 [==============>...............] - ETA: 2s[Evaluating] 7/12 [================>.............] - ETA: 2s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 465.0ms/step
01/03/2024 16:02:53 - INFO - root -   

01/03/2024 16:02:53 - INFO - root -   ***** Eval results  *****
01/03/2024 16:02:53 - INFO - root -    acc: 0.6902 - recall: 0.7337 - f1: 0.7113 - loss: 14.2447 
01/03/2024 16:02:53 - INFO - root -   ***** Entity results  *****
01/03/2024 16:02:53 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 16:02:53 - INFO - root -    acc: 0.7963 - recall: 0.9149 - f1: 0.8515 
01/03/2024 16:02:53 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 16:02:53 - INFO - root -    acc: 1.0000 - recall: 1.0000 - f1: 1.0000 
01/03/2024 16:02:53 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 16:02:53 - INFO - root -    acc: 0.4706 - recall: 0.4211 - f1: 0.4444 
01/03/2024 16:02:53 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 16:02:53 - INFO - root -    acc: 0.4286 - recall: 0.3333 - f1: 0.3750 
01/03/2024 16:02:53 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 16:02:53 - INFO - root -    acc: 0.5556 - recall: 0.5128 - f1: 0.5333 
01/03/2024 16:02:53 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 16:02:53 - INFO - root -    acc: 0.6316 - recall: 0.7059 - f1: 0.6667 
01/03/2024 16:02:53 - INFO - root -   ******* PER.NAM results ********
01/03/2024 16:02:53 - INFO - root -    acc: 0.7155 - recall: 0.7545 - f1: 0.7345 
01/03/2024 16:02:53 - INFO - root -   ******* PER.NOM results ********
01/03/2024 16:02:53 - INFO - root -    acc: 0.7021 - recall: 0.7765 - f1: 0.7374 
01/03/2024 16:03:02 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-969
01/03/2024 16:03:02 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-969
01/03/2024 16:03:02 - INFO - root -   

01/03/2024 16:03:02 - INFO - root -   Backbone bert_crf param is not freeze

Epoch: 17/30
[Training] 1/57 [..............................] - ETA: 1:36  [ loss=0.6379 ][Training] 2/57 [>.............................] - ETA: 1:17  [ loss=0.1325 ][Training] 3/57 [>.............................] - ETA: 1:09  [ loss=0.2663 ][Training] 4/57 [=>............................] - ETA: 1:14  [ loss=0.0070 ][Training] 5/57 [=>............................] - ETA: 1:12  [ loss=0.6746 ][Training] 6/57 [==>...........................] - ETA: 1:09  [ loss=0.1526 ][Training] 7/57 [==>...........................] - ETA: 1:10  [ loss=0.5957 ][Training] 8/57 [===>..........................] - ETA: 1:09  [ loss=0.0222 ][Training] 9/57 [===>..........................] - ETA: 1:06  [ loss=0.1285 ][Training] 10/57 [====>.........................] - ETA: 1:05  [ loss=0.1805 ][Training] 11/57 [====>.........................] - ETA: 1:04  [ loss=0.3043 ][Training] 12/57 [=====>........................] - ETA: 1:03  [ loss=0.0972 ][Training] 13/57 [=====>........................] - ETA: 1:02  [ loss=0.0039 ][Training] 14/57 [======>.......................] - ETA: 1:01  [ loss=0.4767 ][Training] 15/57 [======>.......................] - ETA: 59s  [ loss=0.2042 ][Training] 16/57 [=======>......................] - ETA: 59s  [ loss=0.0508 ][Training] 17/57 [=======>......................] - ETA: 57s  [ loss=0.0036 ][Training] 18/57 [========>.....................] - ETA: 56s  [ loss=1.0351 ][Training] 19/57 [=========>....................] - ETA: 54s  [ loss=0.1810 ][Training] 20/57 [=========>....................] - ETA: 53s  [ loss=0.1930 ][Training] 21/57 [==========>...................] - ETA: 51s  [ loss=0.3367 ][Training] 22/57 [==========>...................] - ETA: 50s  [ loss=0.4101 ][Training] 23/57 [===========>..................] - ETA: 48s  [ loss=0.7044 ][Training] 24/57 [===========>..................] - ETA: 47s  [ loss=0.0333 ][Training] 25/57 [============>.................] - ETA: 45s  [ loss=0.3087 ][Training] 26/57 [============>.................] - ETA: 44s  [ loss=0.4732 ][Training] 27/57 [=============>................] - ETA: 42s  [ loss=0.6794 ][Training] 28/57 [=============>................] - ETA: 41s  [ loss=0.1528 ][Training] 29/57 [==============>...............] - ETA: 39s  [ loss=0.1884 ][Training] 30/57 [==============>...............] - ETA: 38s  [ loss=0.0091 ][Training] 31/57 [===============>..............] - ETA: 37s  [ loss=0.2345 ][Training] 32/57 [===============>..............] - ETA: 35s  [ loss=0.0056 ][Training] 33/57 [================>.............] - ETA: 34s  [ loss=0.0265 ][Training] 34/57 [================>.............] - ETA: 32s  [ loss=0.1702 ][Training] 35/57 [=================>............] - ETA: 31s  [ loss=1.0725 ][Training] 36/57 [=================>............] - ETA: 29s  [ loss=0.3483 ][Training] 37/57 [==================>...........] - ETA: 28s  [ loss=0.1469 ][Training] 38/57 [===================>..........] - ETA: 26s  [ loss=0.1418 ][Training] 39/57 [===================>..........] - ETA: 25s  [ loss=0.0048 ][Training] 40/57 [====================>.........] - ETA: 24s  [ loss=0.2058 ][Training] 41/57 [====================>.........] - ETA: 22s  [ loss=0.0032 ][Training] 42/57 [=====================>........] - ETA: 21s  [ loss=0.0108 ][Training] 43/57 [=====================>........] - ETA: 19s  [ loss=0.0057 ][Training] 44/57 [======================>.......] - ETA: 18s  [ loss=0.2592 ][Training] 45/57 [======================>.......] - ETA: 17s  [ loss=0.2466 ][Training] 46/57 [=======================>......] - ETA: 15s  [ loss=0.2624 ][Training] 47/57 [=======================>......] - ETA: 14s  [ loss=0.0089 ][Training] 48/57 [========================>.....] - ETA: 12s  [ loss=0.0784 ][Training] 49/57 [========================>.....] - ETA: 11s  [ loss=0.6789 ][Training] 50/57 [=========================>....] - ETA: 9s  [ loss=0.1000 ][Training] 51/57 [=========================>....] - ETA: 8s  [ loss=0.7239 ][Training] 52/57 [==========================>...] - ETA: 7s  [ loss=0.0042 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=0.0785 ][Training] 54/57 [===========================>..] - ETA: 4s  [ loss=0.2674 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=0.0047 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.3884 ][Training] 57/57 [==============================] 1.4s/step  [ loss=0.0023 ]
01/03/2024 16:04:22 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 16:04:22 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 16:04:22 - INFO - root -     Num examples = 269
01/03/2024 16:04:22 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 6s[Evaluating] 2/12 [====>.........................] - ETA: 4s[Evaluating] 3/12 [======>.......................] - ETA: 4s[Evaluating] 4/12 [=========>....................] - ETA: 3s[Evaluating] 5/12 [===========>..................] - ETA: 3s[Evaluating] 6/12 [==============>...............] - ETA: 2s[Evaluating] 7/12 [================>.............] - ETA: 2s[Evaluating] 8/12 [===================>..........] - ETA: 1s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 0s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 444.5ms/step
01/03/2024 16:04:27 - INFO - root -   

01/03/2024 16:04:27 - INFO - root -   ***** Eval results  *****
01/03/2024 16:04:27 - INFO - root -    acc: 0.7070 - recall: 0.7361 - f1: 0.7212 - loss: 13.5052 
01/03/2024 16:04:27 - INFO - root -   ***** Entity results  *****
01/03/2024 16:04:27 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 16:04:27 - INFO - root -    acc: 0.7778 - recall: 0.8936 - f1: 0.8317 
01/03/2024 16:04:27 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 16:04:27 - INFO - root -    acc: 1.0000 - recall: 0.5000 - f1: 0.6667 
01/03/2024 16:04:27 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 16:04:27 - INFO - root -    acc: 0.4444 - recall: 0.4211 - f1: 0.4324 
01/03/2024 16:04:27 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 16:04:27 - INFO - root -    acc: 0.4286 - recall: 0.3333 - f1: 0.3750 
01/03/2024 16:04:27 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 16:04:27 - INFO - root -    acc: 0.5122 - recall: 0.5385 - f1: 0.5250 
01/03/2024 16:04:27 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 16:04:27 - INFO - root -    acc: 0.6667 - recall: 0.8235 - f1: 0.7368 
01/03/2024 16:04:27 - INFO - root -   ******* PER.NAM results ********
01/03/2024 16:04:27 - INFO - root -    acc: 0.7850 - recall: 0.7636 - f1: 0.7742 
01/03/2024 16:04:27 - INFO - root -   ******* PER.NOM results ********
01/03/2024 16:04:27 - INFO - root -    acc: 0.7238 - recall: 0.7706 - f1: 0.7464 
01/03/2024 16:04:33 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-1026
01/03/2024 16:04:33 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-1026
01/03/2024 16:04:33 - INFO - root -   

01/03/2024 16:04:33 - INFO - root -   Backbone bert_crf param is not freeze

Epoch: 18/30
[Training] 1/57 [..............................] - ETA: 1:20  [ loss=0.0652 ][Training] 2/57 [>.............................] - ETA: 1:16  [ loss=0.0063 ][Training] 3/57 [>.............................] - ETA: 1:12  [ loss=0.0383 ][Training] 4/57 [=>............................] - ETA: 1:16  [ loss=0.6280 ][Training] 5/57 [=>............................] - ETA: 1:15  [ loss=0.1151 ][Training] 6/57 [==>...........................] - ETA: 1:15  [ loss=0.3055 ][Training] 7/57 [==>...........................] - ETA: 1:13  [ loss=0.0747 ][Training] 8/57 [===>..........................] - ETA: 1:09  [ loss=0.4484 ][Training] 9/57 [===>..........................] - ETA: 1:09  [ loss=0.0383 ][Training] 10/57 [====>.........................] - ETA: 1:08  [ loss=0.2223 ][Training] 11/57 [====>.........................] - ETA: 1:06  [ loss=0.0760 ][Training] 12/57 [=====>........................] - ETA: 1:04  [ loss=0.0160 ][Training] 13/57 [=====>........................] - ETA: 1:02  [ loss=0.3684 ][Training] 14/57 [======>.......................] - ETA: 1:00  [ loss=0.0443 ][Training] 15/57 [======>.......................] - ETA: 59s  [ loss=0.0060 ][Training] 16/57 [=======>......................] - ETA: 58s  [ loss=0.0029 ][Training] 17/57 [=======>......................] - ETA: 56s  [ loss=0.3452 ][Training] 18/57 [========>.....................] - ETA: 54s  [ loss=0.0753 ][Training] 19/57 [=========>....................] - ETA: 53s  [ loss=0.0061 ][Training] 20/57 [=========>....................] - ETA: 51s  [ loss=0.1092 ][Training] 21/57 [==========>...................] - ETA: 50s  [ loss=0.9148 ][Training] 22/57 [==========>...................] - ETA: 49s  [ loss=0.0028 ][Training] 23/57 [===========>..................] - ETA: 47s  [ loss=0.1139 ][Training] 24/57 [===========>..................] - ETA: 46s  [ loss=0.4286 ][Training] 25/57 [============>.................] - ETA: 44s  [ loss=0.3435 ][Training] 26/57 [============>.................] - ETA: 43s  [ loss=0.0767 ][Training] 27/57 [=============>................] - ETA: 42s  [ loss=0.0542 ][Training] 28/57 [=============>................] - ETA: 40s  [ loss=0.0031 ][Training] 29/57 [==============>...............] - ETA: 39s  [ loss=1.1460 ][Training] 30/57 [==============>...............] - ETA: 38s  [ loss=0.4286 ][Training] 31/57 [===============>..............] - ETA: 36s  [ loss=0.0337 ][Training] 32/57 [===============>..............] - ETA: 35s  [ loss=0.5284 ][Training] 33/57 [================>.............] - ETA: 33s  [ loss=0.0441 ][Training] 34/57 [================>.............] - ETA: 32s  [ loss=0.1479 ][Training] 35/57 [=================>............] - ETA: 31s  [ loss=0.0081 ][Training] 36/57 [=================>............] - ETA: 29s  [ loss=0.0033 ][Training] 37/57 [==================>...........] - ETA: 28s  [ loss=1.1762 ][Training] 38/57 [===================>..........] - ETA: 27s  [ loss=0.4863 ][Training] 39/57 [===================>..........] - ETA: 25s  [ loss=0.4418 ][Training] 40/57 [====================>.........] - ETA: 24s  [ loss=0.5273 ][Training] 41/57 [====================>.........] - ETA: 22s  [ loss=0.2550 ][Training] 42/57 [=====================>........] - ETA: 21s  [ loss=0.0085 ][Training] 43/57 [=====================>........] - ETA: 20s  [ loss=0.0026 ][Training] 44/57 [======================>.......] - ETA: 18s  [ loss=0.0034 ][Training] 45/57 [======================>.......] - ETA: 17s  [ loss=0.0967 ][Training] 46/57 [=======================>......] - ETA: 15s  [ loss=0.2780 ][Training] 47/57 [=======================>......] - ETA: 14s  [ loss=0.1664 ][Training] 48/57 [========================>.....] - ETA: 12s  [ loss=0.0798 ][Training] 49/57 [========================>.....] - ETA: 11s  [ loss=0.4689 ][Training] 50/57 [=========================>....] - ETA: 10s  [ loss=0.3529 ][Training] 51/57 [=========================>....] - ETA: 8s  [ loss=0.1104 ][Training] 52/57 [==========================>...] - ETA: 7s  [ loss=0.2171 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=0.2797 ][Training] 54/57 [===========================>..] - ETA: 4s  [ loss=0.1117 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=0.0608 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.2063 ][Training] 57/57 [==============================] 1.4s/step  [ loss=0.0023 ]
01/03/2024 16:05:54 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 16:05:55 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 16:05:55 - INFO - root -     Num examples = 269
01/03/2024 16:05:55 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 6s[Evaluating] 2/12 [====>.........................] - ETA: 5s[Evaluating] 3/12 [======>.......................] - ETA: 4s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 3s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 2s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 480.8ms/step
01/03/2024 16:06:00 - INFO - root -   

01/03/2024 16:06:00 - INFO - root -   ***** Eval results  *****
01/03/2024 16:06:00 - INFO - root -    acc: 0.6923 - recall: 0.7191 - f1: 0.7055 - loss: 13.9784 
01/03/2024 16:06:00 - INFO - root -   ***** Entity results  *****
01/03/2024 16:06:00 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 16:06:00 - INFO - root -    acc: 0.7818 - recall: 0.9149 - f1: 0.8431 
01/03/2024 16:06:00 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 16:06:00 - INFO - root -    acc: 1.0000 - recall: 1.0000 - f1: 1.0000 
01/03/2024 16:06:00 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 16:06:00 - INFO - root -    acc: 0.3750 - recall: 0.3158 - f1: 0.3429 
01/03/2024 16:06:00 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 16:06:00 - INFO - root -    acc: 0.2500 - recall: 0.2222 - f1: 0.2353 
01/03/2024 16:06:00 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 16:06:00 - INFO - root -    acc: 0.5938 - recall: 0.4872 - f1: 0.5352 
01/03/2024 16:06:00 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 16:06:00 - INFO - root -    acc: 0.5000 - recall: 0.5294 - f1: 0.5143 
01/03/2024 16:06:00 - INFO - root -   ******* PER.NAM results ********
01/03/2024 16:06:00 - INFO - root -    acc: 0.7636 - recall: 0.7636 - f1: 0.7636 
01/03/2024 16:06:00 - INFO - root -   ******* PER.NOM results ********
01/03/2024 16:06:00 - INFO - root -    acc: 0.7021 - recall: 0.7765 - f1: 0.7374 
01/03/2024 16:06:18 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-1083
01/03/2024 16:06:18 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-1083
01/03/2024 16:06:18 - INFO - root -   

01/03/2024 16:06:18 - INFO - root -   Backbone bert_crf param is not freeze

Epoch: 19/30
[Training] 1/57 [..............................] - ETA: 1:19  [ loss=0.0649 ][Training] 2/57 [>.............................] - ETA: 1:21  [ loss=0.0033 ][Training] 3/57 [>.............................] - ETA: 1:20  [ loss=0.1296 ][Training] 4/57 [=>............................] - ETA: 1:16  [ loss=0.0112 ][Training] 5/57 [=>............................] - ETA: 1:15  [ loss=0.0027 ][Training] 6/57 [==>...........................] - ETA: 1:12  [ loss=0.0189 ][Training] 7/57 [==>...........................] - ETA: 1:11  [ loss=0.1729 ][Training] 8/57 [===>..........................] - ETA: 1:08  [ loss=0.0153 ][Training] 9/57 [===>..........................] - ETA: 1:08  [ loss=0.0126 ][Training] 10/57 [====>.........................] - ETA: 1:06  [ loss=0.1066 ][Training] 11/57 [====>.........................] - ETA: 1:06  [ loss=0.2324 ][Training] 12/57 [=====>........................] - ETA: 1:04  [ loss=0.1926 ][Training] 13/57 [=====>........................] - ETA: 1:03  [ loss=0.0038 ][Training] 14/57 [======>.......................] - ETA: 1:01  [ loss=0.3415 ][Training] 15/57 [======>.......................] - ETA: 1:00  [ loss=0.1915 ][Training] 16/57 [=======>......................] - ETA: 59s  [ loss=0.1353 ][Training] 17/57 [=======>......................] - ETA: 58s  [ loss=0.0024 ][Training] 18/57 [========>.....................] - ETA: 56s  [ loss=0.4741 ][Training] 19/57 [=========>....................] - ETA: 54s  [ loss=0.0789 ][Training] 20/57 [=========>....................] - ETA: 52s  [ loss=0.0541 ][Training] 21/57 [==========>...................] - ETA: 51s  [ loss=0.1458 ][Training] 22/57 [==========>...................] - ETA: 49s  [ loss=0.0937 ][Training] 23/57 [===========>..................] - ETA: 48s  [ loss=0.0045 ][Training] 24/57 [===========>..................] - ETA: 46s  [ loss=0.2869 ][Training] 25/57 [============>.................] - ETA: 45s  [ loss=0.0622 ][Training] 26/57 [============>.................] - ETA: 43s  [ loss=0.0020 ][Training] 27/57 [=============>................] - ETA: 42s  [ loss=0.1397 ][Training] 28/57 [=============>................] - ETA: 40s  [ loss=0.4991 ][Training] 29/57 [==============>...............] - ETA: 39s  [ loss=0.1734 ][Training] 30/57 [==============>...............] - ETA: 37s  [ loss=0.3246 ][Training] 31/57 [===============>..............] - ETA: 36s  [ loss=0.3403 ][Training] 32/57 [===============>..............] - ETA: 34s  [ loss=0.2603 ][Training] 33/57 [================>.............] - ETA: 33s  [ loss=0.0301 ][Training] 34/57 [================>.............] - ETA: 31s  [ loss=0.0025 ][Training] 35/57 [=================>............] - ETA: 30s  [ loss=0.2531 ][Training] 36/57 [=================>............] - ETA: 28s  [ loss=1.0195 ][Training] 37/57 [==================>...........] - ETA: 27s  [ loss=0.0212 ][Training] 38/57 [===================>..........] - ETA: 25s  [ loss=0.3721 ][Training] 39/57 [===================>..........] - ETA: 23s  [ loss=0.6866 ][Training] 40/57 [====================>.........] - ETA: 22s  [ loss=0.1112 ][Training] 41/57 [====================>.........] - ETA: 20s  [ loss=0.6538 ][Training] 42/57 [=====================>........] - ETA: 19s  [ loss=0.1806 ][Training] 43/57 [=====================>........] - ETA: 17s  [ loss=0.0022 ][Training] 44/57 [======================>.......] - ETA: 16s  [ loss=0.4838 ][Training] 45/57 [======================>.......] - ETA: 14s  [ loss=0.2836 ][Training] 46/57 [=======================>......] - ETA: 13s  [ loss=0.0941 ][Training] 47/57 [=======================>......] - ETA: 12s  [ loss=1.1925 ][Training] 48/57 [========================>.....] - ETA: 10s  [ loss=0.0095 ][Training] 49/57 [========================>.....] - ETA: 9s  [ loss=0.1148 ][Training] 50/57 [=========================>....] - ETA: 8s  [ loss=0.5758 ][Training] 51/57 [=========================>....] - ETA: 6s  [ loss=0.0166 ][Training] 52/57 [==========================>...] - ETA: 5s  [ loss=0.1469 ][Training] 53/57 [==========================>...] - ETA: 4s  [ loss=0.6829 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=0.0038 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=0.0399 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.2398 ][Training] 57/57 [==============================] 1.1s/step  [ loss=0.0028 ]
01/03/2024 16:07:21 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 16:07:21 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 16:07:21 - INFO - root -     Num examples = 269
01/03/2024 16:07:21 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 2s[Evaluating] 2/12 [====>.........................] - ETA: 2s[Evaluating] 3/12 [======>.......................] - ETA: 2s[Evaluating] 4/12 [=========>....................] - ETA: 1s[Evaluating] 5/12 [===========>..................] - ETA: 1s[Evaluating] 6/12 [==============>...............] - ETA: 1s[Evaluating] 7/12 [================>.............] - ETA: 1s[Evaluating] 8/12 [===================>..........] - ETA: 0s[Evaluating] 9/12 [=====================>........] - ETA: 0s[Evaluating] 10/12 [========================>.....] - ETA: 0s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 225.3ms/step
01/03/2024 16:07:24 - INFO - root -   

01/03/2024 16:07:24 - INFO - root -   ***** Eval results  *****
01/03/2024 16:07:24 - INFO - root -    acc: 0.6958 - recall: 0.7143 - f1: 0.7049 - loss: 14.0052 
01/03/2024 16:07:24 - INFO - root -   ***** Entity results  *****
01/03/2024 16:07:24 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 16:07:24 - INFO - root -    acc: 0.8077 - recall: 0.8936 - f1: 0.8485 
01/03/2024 16:07:24 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 16:07:24 - INFO - root -    acc: 1.0000 - recall: 0.5000 - f1: 0.6667 
01/03/2024 16:07:24 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 16:07:24 - INFO - root -    acc: 0.4118 - recall: 0.3684 - f1: 0.3889 
01/03/2024 16:07:24 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 16:07:24 - INFO - root -    acc: 0.4286 - recall: 0.3333 - f1: 0.3750 
01/03/2024 16:07:24 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 16:07:24 - INFO - root -    acc: 0.5588 - recall: 0.4872 - f1: 0.5205 
01/03/2024 16:07:24 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 16:07:24 - INFO - root -    acc: 0.5882 - recall: 0.5882 - f1: 0.5882 
01/03/2024 16:07:24 - INFO - root -   ******* PER.NAM results ********
01/03/2024 16:07:24 - INFO - root -    acc: 0.7778 - recall: 0.7636 - f1: 0.7706 
01/03/2024 16:07:24 - INFO - root -   ******* PER.NOM results ********
01/03/2024 16:07:24 - INFO - root -    acc: 0.6862 - recall: 0.7588 - f1: 0.7207 
01/03/2024 16:07:36 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-1140
01/03/2024 16:07:36 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-1140
01/03/2024 16:07:36 - INFO - root -   

01/03/2024 16:07:36 - INFO - root -   Backbone bert_crf param is not freeze

Epoch: 20/30
[Training] 1/57 [..............................] - ETA: 1:32  [ loss=0.3430 ][Training] 2/57 [>.............................] - ETA: 1:22  [ loss=0.0341 ][Training] 3/57 [>.............................] - ETA: 1:25  [ loss=0.0041 ][Training] 4/57 [=>............................] - ETA: 1:18  [ loss=0.1851 ][Training] 5/57 [=>............................] - ETA: 1:13  [ loss=0.2353 ][Training] 6/57 [==>...........................] - ETA: 1:13  [ loss=0.1426 ][Training] 7/57 [==>...........................] - ETA: 1:11  [ loss=0.1052 ][Training] 8/57 [===>..........................] - ETA: 1:09  [ loss=0.2123 ][Training] 9/57 [===>..........................] - ETA: 1:08  [ loss=0.0047 ][Training] 10/57 [====>.........................] - ETA: 1:06  [ loss=0.2338 ][Training] 11/57 [====>.........................] - ETA: 1:04  [ loss=0.1382 ][Training] 12/57 [=====>........................] - ETA: 1:02  [ loss=0.1754 ][Training] 13/57 [=====>........................] - ETA: 1:02  [ loss=0.1661 ][Training] 14/57 [======>.......................] - ETA: 1:00  [ loss=0.0020 ][Training] 15/57 [======>.......................] - ETA: 59s  [ loss=0.0086 ][Training] 16/57 [=======>......................] - ETA: 57s  [ loss=0.0041 ][Training] 17/57 [=======>......................] - ETA: 55s  [ loss=0.0490 ][Training] 18/57 [========>.....................] - ETA: 54s  [ loss=0.3081 ][Training] 19/57 [=========>....................] - ETA: 54s  [ loss=0.0024 ][Training] 20/57 [=========>....................] - ETA: 52s  [ loss=0.0026 ][Training] 21/57 [==========>...................] - ETA: 51s  [ loss=0.3275 ][Training] 22/57 [==========>...................] - ETA: 49s  [ loss=1.2580 ][Training] 23/57 [===========>..................] - ETA: 48s  [ loss=0.5787 ][Training] 24/57 [===========>..................] - ETA: 47s  [ loss=0.0298 ][Training] 25/57 [============>.................] - ETA: 45s  [ loss=0.2124 ][Training] 26/57 [============>.................] - ETA: 44s  [ loss=0.2884 ][Training] 27/57 [=============>................] - ETA: 42s  [ loss=0.0509 ][Training] 28/57 [=============>................] - ETA: 41s  [ loss=1.1701 ][Training] 29/57 [==============>...............] - ETA: 40s  [ loss=0.0457 ][Training] 30/57 [==============>...............] - ETA: 38s  [ loss=0.0027 ][Training] 31/57 [===============>..............] - ETA: 37s  [ loss=0.3101 ][Training] 32/57 [===============>..............] - ETA: 36s  [ loss=0.4144 ][Training] 33/57 [================>.............] - ETA: 34s  [ loss=0.2451 ][Training] 34/57 [================>.............] - ETA: 33s  [ loss=0.0030 ][Training] 35/57 [=================>............] - ETA: 31s  [ loss=0.3693 ][Training] 36/57 [=================>............] - ETA: 30s  [ loss=0.0092 ][Training] 37/57 [==================>...........] - ETA: 29s  [ loss=0.2039 ][Training] 38/57 [===================>..........] - ETA: 27s  [ loss=0.7111 ][Training] 39/57 [===================>..........] - ETA: 26s  [ loss=0.3169 ][Training] 40/57 [====================>.........] - ETA: 24s  [ loss=0.0032 ][Training] 41/57 [====================>.........] - ETA: 23s  [ loss=0.0046 ][Training] 42/57 [=====================>........] - ETA: 21s  [ loss=0.0642 ][Training] 43/57 [=====================>........] - ETA: 20s  [ loss=0.1352 ][Training] 44/57 [======================>.......] - ETA: 18s  [ loss=0.0038 ][Training] 45/57 [======================>.......] - ETA: 17s  [ loss=0.1616 ][Training] 46/57 [=======================>......] - ETA: 15s  [ loss=0.1337 ][Training] 47/57 [=======================>......] - ETA: 14s  [ loss=0.4661 ][Training] 48/57 [========================>.....] - ETA: 12s  [ loss=0.1322 ][Training] 49/57 [========================>.....] - ETA: 11s  [ loss=0.0032 ][Training] 50/57 [=========================>....] - ETA: 10s  [ loss=0.0822 ][Training] 51/57 [=========================>....] - ETA: 8s  [ loss=0.0833 ][Training] 52/57 [==========================>...] - ETA: 7s  [ loss=0.1177 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=0.1090 ][Training] 54/57 [===========================>..] - ETA: 4s  [ loss=0.1417 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=0.0561 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.9402 ][Training] 57/57 [==============================] 1.4s/step  [ loss=0.3558 ]
01/03/2024 16:08:57 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 16:08:58 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 16:08:58 - INFO - root -     Num examples = 269
01/03/2024 16:08:58 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 6s[Evaluating] 2/12 [====>.........................] - ETA: 4s[Evaluating] 3/12 [======>.......................] - ETA: 4s[Evaluating] 4/12 [=========>....................] - ETA: 3s[Evaluating] 5/12 [===========>..................] - ETA: 3s[Evaluating] 6/12 [==============>...............] - ETA: 2s[Evaluating] 7/12 [================>.............] - ETA: 2s[Evaluating] 8/12 [===================>..........] - ETA: 1s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 0s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 451.4ms/step
01/03/2024 16:09:03 - INFO - root -   

01/03/2024 16:09:03 - INFO - root -   ***** Eval results  *****
01/03/2024 16:09:03 - INFO - root -    acc: 0.6879 - recall: 0.7312 - f1: 0.7089 - loss: 14.3223 
01/03/2024 16:09:03 - INFO - root -   ***** Entity results  *****
01/03/2024 16:09:03 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 16:09:03 - INFO - root -    acc: 0.7778 - recall: 0.8936 - f1: 0.8317 
01/03/2024 16:09:03 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 16:09:03 - INFO - root -    acc: 1.0000 - recall: 1.0000 - f1: 1.0000 
01/03/2024 16:09:03 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 16:09:03 - INFO - root -    acc: 0.4706 - recall: 0.4211 - f1: 0.4444 
01/03/2024 16:09:03 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 16:09:03 - INFO - root -    acc: 0.3750 - recall: 0.3333 - f1: 0.3529 
01/03/2024 16:09:03 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 16:09:03 - INFO - root -    acc: 0.5714 - recall: 0.5128 - f1: 0.5405 
01/03/2024 16:09:03 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 16:09:03 - INFO - root -    acc: 0.5417 - recall: 0.7647 - f1: 0.6341 
01/03/2024 16:09:03 - INFO - root -   ******* PER.NAM results ********
01/03/2024 16:09:03 - INFO - root -    acc: 0.7265 - recall: 0.7727 - f1: 0.7489 
01/03/2024 16:09:03 - INFO - root -   ******* PER.NOM results ********
01/03/2024 16:09:03 - INFO - root -    acc: 0.7088 - recall: 0.7588 - f1: 0.7330 
01/03/2024 16:09:25 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-1197
01/03/2024 16:09:25 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-1197
01/03/2024 16:09:25 - INFO - root -   

01/03/2024 16:09:25 - INFO - root -   Backbone bert_crf param is not freeze

Epoch: 21/30
[Training] 1/57 [..............................] - ETA: 1:20  [ loss=0.0034 ][Training] 2/57 [>.............................] - ETA: 1:15  [ loss=0.0900 ][Training] 3/57 [>.............................] - ETA: 1:15  [ loss=0.6990 ][Training] 4/57 [=>............................] - ETA: 1:17  [ loss=0.0384 ][Training] 5/57 [=>............................] - ETA: 1:13  [ loss=0.6238 ][Training] 6/57 [==>...........................] - ETA: 1:14  [ loss=0.0650 ][Training] 7/57 [==>...........................] - ETA: 1:13  [ loss=0.0117 ][Training] 8/57 [===>..........................] - ETA: 1:11  [ loss=0.0819 ][Training] 9/57 [===>..........................] - ETA: 1:10  [ loss=0.1407 ][Training] 10/57 [====>.........................] - ETA: 1:09  [ loss=0.2481 ][Training] 11/57 [====>.........................] - ETA: 1:07  [ loss=0.2898 ][Training] 12/57 [=====>........................] - ETA: 1:04  [ loss=0.0046 ][Training] 13/57 [=====>........................] - ETA: 1:02  [ loss=0.1537 ][Training] 14/57 [======>.......................] - ETA: 1:01  [ loss=0.0038 ][Training] 15/57 [======>.......................] - ETA: 1:00  [ loss=0.3881 ][Training] 16/57 [=======>......................] - ETA: 58s  [ loss=0.0416 ][Training] 17/57 [=======>......................] - ETA: 57s  [ loss=0.3786 ][Training] 18/57 [========>.....................] - ETA: 55s  [ loss=0.0025 ][Training] 19/57 [=========>....................] - ETA: 53s  [ loss=0.1559 ][Training] 20/57 [=========>....................] - ETA: 52s  [ loss=0.0022 ][Training] 21/57 [==========>...................] - ETA: 51s  [ loss=0.4346 ][Training] 22/57 [==========>...................] - ETA: 49s  [ loss=0.0030 ][Training] 23/57 [===========>..................] - ETA: 48s  [ loss=0.3400 ][Training] 24/57 [===========>..................] - ETA: 46s  [ loss=0.2223 ][Training] 25/57 [============>.................] - ETA: 45s  [ loss=0.3608 ][Training] 26/57 [============>.................] - ETA: 44s  [ loss=0.0141 ][Training] 27/57 [=============>................] - ETA: 42s  [ loss=0.0020 ][Training] 28/57 [=============>................] - ETA: 41s  [ loss=0.3764 ][Training] 29/57 [==============>...............] - ETA: 39s  [ loss=0.0546 ][Training] 30/57 [==============>...............] - ETA: 38s  [ loss=0.0035 ][Training] 31/57 [===============>..............] - ETA: 37s  [ loss=0.0028 ][Training] 32/57 [===============>..............] - ETA: 35s  [ loss=0.0036 ][Training] 33/57 [================>.............] - ETA: 34s  [ loss=0.1121 ][Training] 34/57 [================>.............] - ETA: 32s  [ loss=0.0030 ][Training] 35/57 [=================>............] - ETA: 31s  [ loss=0.8043 ][Training] 36/57 [=================>............] - ETA: 30s  [ loss=0.0534 ][Training] 37/57 [==================>...........] - ETA: 28s  [ loss=0.0026 ][Training] 38/57 [===================>..........] - ETA: 27s  [ loss=0.3813 ][Training] 39/57 [===================>..........] - ETA: 25s  [ loss=0.3185 ][Training] 40/57 [====================>.........] - ETA: 24s  [ loss=0.3540 ][Training] 41/57 [====================>.........] - ETA: 22s  [ loss=0.2380 ][Training] 42/57 [=====================>........] - ETA: 21s  [ loss=0.0520 ][Training] 43/57 [=====================>........] - ETA: 19s  [ loss=0.1136 ][Training] 44/57 [======================>.......] - ETA: 18s  [ loss=0.0199 ][Training] 45/57 [======================>.......] - ETA: 17s  [ loss=0.1967 ][Training] 46/57 [=======================>......] - ETA: 15s  [ loss=0.1037 ][Training] 47/57 [=======================>......] - ETA: 14s  [ loss=0.0015 ][Training] 48/57 [========================>.....] - ETA: 12s  [ loss=0.0735 ][Training] 49/57 [========================>.....] - ETA: 11s  [ loss=0.1992 ][Training] 50/57 [=========================>....] - ETA: 9s  [ loss=0.4979 ][Training] 51/57 [=========================>....] - ETA: 8s  [ loss=0.4700 ][Training] 52/57 [==========================>...] - ETA: 7s  [ loss=0.3793 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=0.1095 ][Training] 54/57 [===========================>..] - ETA: 4s  [ loss=0.0038 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=0.1548 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.1391 ][Training] 57/57 [==============================] 1.4s/step  [ loss=0.0060 ]
01/03/2024 16:10:45 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 16:10:45 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 16:10:45 - INFO - root -     Num examples = 269
01/03/2024 16:10:45 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 5s[Evaluating] 2/12 [====>.........................] - ETA: 5s[Evaluating] 3/12 [======>.......................] - ETA: 4s[Evaluating] 4/12 [=========>....................] - ETA: 3s[Evaluating] 5/12 [===========>..................] - ETA: 3s[Evaluating] 6/12 [==============>...............] - ETA: 2s[Evaluating] 7/12 [================>.............] - ETA: 2s[Evaluating] 8/12 [===================>..........] - ETA: 1s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 0s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 461.4ms/step
01/03/2024 16:10:51 - INFO - root -   

01/03/2024 16:10:51 - INFO - root -   ***** Eval results  *****
01/03/2024 16:10:51 - INFO - root -    acc: 0.7068 - recall: 0.6828 - f1: 0.6946 - loss: 14.9525 
01/03/2024 16:10:51 - INFO - root -   ***** Entity results  *****
01/03/2024 16:10:51 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 16:10:51 - INFO - root -    acc: 0.8039 - recall: 0.8723 - f1: 0.8367 
01/03/2024 16:10:51 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 16:10:51 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 16:10:51 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 16:10:51 - INFO - root -    acc: 0.3333 - recall: 0.2632 - f1: 0.2941 
01/03/2024 16:10:51 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 16:10:51 - INFO - root -    acc: 0.1429 - recall: 0.1111 - f1: 0.1250 
01/03/2024 16:10:51 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 16:10:51 - INFO - root -    acc: 0.5625 - recall: 0.4615 - f1: 0.5070 
01/03/2024 16:10:51 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 16:10:51 - INFO - root -    acc: 0.6000 - recall: 0.5294 - f1: 0.5625 
01/03/2024 16:10:51 - INFO - root -   ******* PER.NAM results ********
01/03/2024 16:10:51 - INFO - root -    acc: 0.7864 - recall: 0.7364 - f1: 0.7606 
01/03/2024 16:10:51 - INFO - root -   ******* PER.NOM results ********
01/03/2024 16:10:51 - INFO - root -    acc: 0.7216 - recall: 0.7471 - f1: 0.7341 
01/03/2024 16:10:58 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-1254
01/03/2024 16:10:58 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-1254
01/03/2024 16:10:58 - INFO - root -   

01/03/2024 16:10:58 - INFO - root -   Backbone bert_crf param is not freeze

Epoch: 22/30
[Training] 1/57 [..............................] - ETA: 1:16  [ loss=0.0372 ][Training] 2/57 [>.............................] - ETA: 1:16  [ loss=0.1949 ][Training] 3/57 [>.............................] - ETA: 1:17  [ loss=0.0038 ][Training] 4/57 [=>............................] - ETA: 1:14  [ loss=0.1178 ][Training] 5/57 [=>............................] - ETA: 1:16  [ loss=0.0695 ][Training] 6/57 [==>...........................] - ETA: 1:14  [ loss=0.0085 ][Training] 7/57 [==>...........................] - ETA: 1:11  [ loss=0.1533 ][Training] 8/57 [===>..........................] - ETA: 1:09  [ loss=0.5127 ][Training] 9/57 [===>..........................] - ETA: 1:07  [ loss=0.2912 ][Training] 10/57 [====>.........................] - ETA: 1:06  [ loss=0.0938 ][Training] 11/57 [====>.........................] - ETA: 1:04  [ loss=0.0031 ][Training] 12/57 [=====>........................] - ETA: 1:04  [ loss=0.0192 ][Training] 13/57 [=====>........................] - ETA: 1:03  [ loss=0.0730 ][Training] 14/57 [======>.......................] - ETA: 1:02  [ loss=0.2983 ][Training] 15/57 [======>.......................] - ETA: 1:01  [ loss=0.0033 ][Training] 16/57 [=======>......................] - ETA: 59s  [ loss=0.0705 ][Training] 17/57 [=======>......................] - ETA: 58s  [ loss=0.2475 ][Training] 18/57 [========>.....................] - ETA: 57s  [ loss=0.7389 ][Training] 19/57 [=========>....................] - ETA: 56s  [ loss=0.1662 ][Training] 20/57 [=========>....................] - ETA: 55s  [ loss=0.2812 ][Training] 21/57 [==========>...................] - ETA: 53s  [ loss=0.2103 ][Training] 22/57 [==========>...................] - ETA: 52s  [ loss=0.1518 ][Training] 23/57 [===========>..................] - ETA: 51s  [ loss=0.2865 ][Training] 24/57 [===========>..................] - ETA: 49s  [ loss=0.0646 ][Training] 25/57 [============>.................] - ETA: 48s  [ loss=0.0023 ][Training] 26/57 [============>.................] - ETA: 47s  [ loss=0.1897 ][Training] 27/57 [=============>................] - ETA: 45s  [ loss=0.0027 ][Training] 28/57 [=============>................] - ETA: 43s  [ loss=0.0405 ][Training] 29/57 [==============>...............] - ETA: 41s  [ loss=0.0406 ][Training] 30/57 [==============>...............] - ETA: 40s  [ loss=0.0725 ][Training] 31/57 [===============>..............] - ETA: 38s  [ loss=0.0025 ][Training] 32/57 [===============>..............] - ETA: 37s  [ loss=0.1955 ][Training] 33/57 [================>.............] - ETA: 35s  [ loss=0.0363 ][Training] 34/57 [================>.............] - ETA: 34s  [ loss=0.0023 ][Training] 35/57 [=================>............] - ETA: 33s  [ loss=0.1677 ][Training] 36/57 [=================>............] - ETA: 31s  [ loss=0.0020 ][Training] 37/57 [==================>...........] - ETA: 29s  [ loss=0.0026 ][Training] 38/57 [===================>..........] - ETA: 28s  [ loss=0.9269 ][Training] 39/57 [===================>..........] - ETA: 26s  [ loss=0.2294 ][Training] 40/57 [====================>.........] - ETA: 25s  [ loss=0.0483 ][Training] 41/57 [====================>.........] - ETA: 24s  [ loss=0.0014 ][Training] 42/57 [=====================>........] - ETA: 22s  [ loss=0.4343 ][Training] 43/57 [=====================>........] - ETA: 20s  [ loss=0.0019 ][Training] 44/57 [======================>.......] - ETA: 19s  [ loss=0.2747 ][Training] 45/57 [======================>.......] - ETA: 17s  [ loss=0.0026 ][Training] 46/57 [=======================>......] - ETA: 16s  [ loss=0.4254 ][Training] 47/57 [=======================>......] - ETA: 14s  [ loss=0.3387 ][Training] 48/57 [========================>.....] - ETA: 13s  [ loss=0.4162 ][Training] 49/57 [========================>.....] - ETA: 11s  [ loss=0.0824 ][Training] 50/57 [=========================>....] - ETA: 10s  [ loss=0.0035 ][Training] 51/57 [=========================>....] - ETA: 8s  [ loss=0.3049 ][Training] 52/57 [==========================>...] - ETA: 7s  [ loss=2.2165 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=0.2474 ][Training] 54/57 [===========================>..] - ETA: 4s  [ loss=0.3744 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=0.1288 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.2144 ][Training] 57/57 [==============================] 1.5s/step  [ loss=0.0031 ]
01/03/2024 16:12:22 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 16:12:22 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 16:12:22 - INFO - root -     Num examples = 269
01/03/2024 16:12:22 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 5s[Evaluating] 2/12 [====>.........................] - ETA: 5s[Evaluating] 3/12 [======>.......................] - ETA: 4s[Evaluating] 4/12 [=========>....................] - ETA: 3s[Evaluating] 5/12 [===========>..................] - ETA: 3s[Evaluating] 6/12 [==============>...............] - ETA: 2s[Evaluating] 7/12 [================>.............] - ETA: 2s[Evaluating] 8/12 [===================>..........] - ETA: 1s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 0s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 466.8ms/step
01/03/2024 16:12:28 - INFO - root -   

01/03/2024 16:12:28 - INFO - root -   ***** Eval results  *****
01/03/2024 16:12:28 - INFO - root -    acc: 0.6911 - recall: 0.7312 - f1: 0.7106 - loss: 14.8963 
01/03/2024 16:12:28 - INFO - root -   ***** Entity results  *****
01/03/2024 16:12:28 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 16:12:28 - INFO - root -    acc: 0.7925 - recall: 0.8936 - f1: 0.8400 
01/03/2024 16:12:28 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 16:12:28 - INFO - root -    acc: 0.5000 - recall: 0.5000 - f1: 0.5000 
01/03/2024 16:12:28 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 16:12:28 - INFO - root -    acc: 0.4706 - recall: 0.4211 - f1: 0.4444 
01/03/2024 16:12:28 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 16:12:28 - INFO - root -    acc: 0.4286 - recall: 0.3333 - f1: 0.3750 
01/03/2024 16:12:28 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 16:12:28 - INFO - root -    acc: 0.5128 - recall: 0.5128 - f1: 0.5128 
01/03/2024 16:12:28 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 16:12:28 - INFO - root -    acc: 0.6190 - recall: 0.7647 - f1: 0.6842 
01/03/2024 16:12:28 - INFO - root -   ******* PER.NAM results ********
01/03/2024 16:12:28 - INFO - root -    acc: 0.7500 - recall: 0.7636 - f1: 0.7568 
01/03/2024 16:12:28 - INFO - root -   ******* PER.NOM results ********
01/03/2024 16:12:28 - INFO - root -    acc: 0.7043 - recall: 0.7706 - f1: 0.7360 
01/03/2024 16:12:48 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-1311
01/03/2024 16:12:48 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-1311
01/03/2024 16:12:48 - INFO - root -   

01/03/2024 16:12:48 - INFO - root -   Backbone bert_crf param is not freeze

Epoch: 23/30
[Training] 1/57 [..............................] - ETA: 1:25  [ loss=0.0037 ][Training] 2/57 [>.............................] - ETA: 1:19  [ loss=0.0026 ][Training] 3/57 [>.............................] - ETA: 1:15  [ loss=0.1664 ][Training] 4/57 [=>............................] - ETA: 1:09  [ loss=0.0020 ][Training] 5/57 [=>............................] - ETA: 1:08  [ loss=0.3353 ][Training] 6/57 [==>...........................] - ETA: 1:06  [ loss=0.1110 ][Training] 7/57 [==>...........................] - ETA: 1:06  [ loss=0.0023 ][Training] 8/57 [===>..........................] - ETA: 1:04  [ loss=0.0672 ][Training] 9/57 [===>..........................] - ETA: 1:04  [ loss=0.1870 ][Training] 10/57 [====>.........................] - ETA: 1:03  [ loss=0.0687 ][Training] 11/57 [====>.........................] - ETA: 1:02  [ loss=0.1440 ][Training] 12/57 [=====>........................] - ETA: 1:00  [ loss=0.0630 ][Training] 13/57 [=====>........................] - ETA: 59s  [ loss=0.2357 ][Training] 14/57 [======>.......................] - ETA: 58s  [ loss=0.0954 ][Training] 15/57 [======>.......................] - ETA: 57s  [ loss=0.1593 ][Training] 16/57 [=======>......................] - ETA: 56s  [ loss=0.0525 ][Training] 17/57 [=======>......................] - ETA: 55s  [ loss=0.0465 ][Training] 18/57 [========>.....................] - ETA: 54s  [ loss=0.0041 ][Training] 19/57 [=========>....................] - ETA: 52s  [ loss=0.4091 ][Training] 20/57 [=========>....................] - ETA: 51s  [ loss=0.0030 ][Training] 21/57 [==========>...................] - ETA: 50s  [ loss=0.0022 ][Training] 22/57 [==========>...................] - ETA: 49s  [ loss=0.0030 ][Training] 23/57 [===========>..................] - ETA: 48s  [ loss=0.1984 ][Training] 24/57 [===========>..................] - ETA: 46s  [ loss=0.1889 ][Training] 25/57 [============>.................] - ETA: 45s  [ loss=0.0374 ][Training] 26/57 [============>.................] - ETA: 43s  [ loss=0.4819 ][Training] 27/57 [=============>................] - ETA: 42s  [ loss=0.0816 ][Training] 28/57 [=============>................] - ETA: 41s  [ loss=0.0066 ][Training] 29/57 [==============>...............] - ETA: 39s  [ loss=0.5914 ][Training] 30/57 [==============>...............] - ETA: 38s  [ loss=0.0016 ][Training] 31/57 [===============>..............] - ETA: 36s  [ loss=0.5669 ][Training] 32/57 [===============>..............] - ETA: 35s  [ loss=0.3488 ][Training] 33/57 [================>.............] - ETA: 34s  [ loss=0.0023 ][Training] 34/57 [================>.............] - ETA: 32s  [ loss=0.4030 ][Training] 35/57 [=================>............] - ETA: 31s  [ loss=0.0021 ][Training] 36/57 [=================>............] - ETA: 29s  [ loss=0.2180 ][Training] 37/57 [==================>...........] - ETA: 28s  [ loss=0.1753 ][Training] 38/57 [===================>..........] - ETA: 26s  [ loss=0.0670 ][Training] 39/57 [===================>..........] - ETA: 25s  [ loss=0.6123 ][Training] 40/57 [====================>.........] - ETA: 24s  [ loss=0.3247 ][Training] 41/57 [====================>.........] - ETA: 22s  [ loss=0.1876 ][Training] 42/57 [=====================>........] - ETA: 21s  [ loss=0.0020 ][Training] 43/57 [=====================>........] - ETA: 19s  [ loss=0.2043 ][Training] 44/57 [======================>.......] - ETA: 18s  [ loss=0.0718 ][Training] 45/57 [======================>.......] - ETA: 17s  [ loss=0.4385 ][Training] 46/57 [=======================>......] - ETA: 15s  [ loss=0.0487 ][Training] 47/57 [=======================>......] - ETA: 14s  [ loss=0.1664 ][Training] 48/57 [========================>.....] - ETA: 12s  [ loss=0.2684 ][Training] 49/57 [========================>.....] - ETA: 11s  [ loss=0.0023 ][Training] 50/57 [=========================>....] - ETA: 9s  [ loss=0.7363 ][Training] 51/57 [=========================>....] - ETA: 8s  [ loss=0.1451 ][Training] 52/57 [==========================>...] - ETA: 7s  [ loss=0.2194 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=0.2538 ][Training] 54/57 [===========================>..] - ETA: 4s  [ loss=0.0019 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=0.3874 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.0707 ][Training] 57/57 [==============================] 1.4s/step  [ loss=0.0032 ]
01/03/2024 16:14:08 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 16:14:09 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 16:14:09 - INFO - root -     Num examples = 269
01/03/2024 16:14:09 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 4s[Evaluating] 2/12 [====>.........................] - ETA: 4s[Evaluating] 3/12 [======>.......................] - ETA: 4s[Evaluating] 4/12 [=========>....................] - ETA: 3s[Evaluating] 5/12 [===========>..................] - ETA: 3s[Evaluating] 6/12 [==============>...............] - ETA: 2s[Evaluating] 7/12 [================>.............] - ETA: 2s[Evaluating] 8/12 [===================>..........] - ETA: 1s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 0s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 473.8ms/step
01/03/2024 16:14:14 - INFO - root -   

01/03/2024 16:14:14 - INFO - root -   ***** Eval results  *****
01/03/2024 16:14:14 - INFO - root -    acc: 0.7012 - recall: 0.7215 - f1: 0.7112 - loss: 14.6174 
01/03/2024 16:14:14 - INFO - root -   ***** Entity results  *****
01/03/2024 16:14:14 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 16:14:14 - INFO - root -    acc: 0.8077 - recall: 0.8936 - f1: 0.8485 
01/03/2024 16:14:14 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 16:14:14 - INFO - root -    acc: 1.0000 - recall: 0.5000 - f1: 0.6667 
01/03/2024 16:14:14 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 16:14:14 - INFO - root -    acc: 0.4706 - recall: 0.4211 - f1: 0.4444 
01/03/2024 16:14:14 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 16:14:14 - INFO - root -    acc: 0.4286 - recall: 0.3333 - f1: 0.3750 
01/03/2024 16:14:14 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 16:14:14 - INFO - root -    acc: 0.5588 - recall: 0.4872 - f1: 0.5205 
01/03/2024 16:14:14 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 16:14:14 - INFO - root -    acc: 0.5238 - recall: 0.6471 - f1: 0.5789 
01/03/2024 16:14:14 - INFO - root -   ******* PER.NAM results ********
01/03/2024 16:14:14 - INFO - root -    acc: 0.7706 - recall: 0.7636 - f1: 0.7671 
01/03/2024 16:14:14 - INFO - root -   ******* PER.NOM results ********
01/03/2024 16:14:14 - INFO - root -    acc: 0.7065 - recall: 0.7647 - f1: 0.7345 
01/03/2024 16:14:21 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-1368
01/03/2024 16:14:21 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-1368
01/03/2024 16:14:21 - INFO - root -   

01/03/2024 16:14:22 - INFO - root -   Backbone bert_crf param is not freeze

Epoch: 24/30
[Training] 1/57 [..............................] - ETA: 1:08  [ loss=0.0513 ][Training] 2/57 [>.............................] - ETA: 1:12  [ loss=0.0025 ][Training] 3/57 [>.............................] - ETA: 1:18  [ loss=0.4655 ][Training] 4/57 [=>............................] - ETA: 1:16  [ loss=0.2464 ][Training] 5/57 [=>............................] - ETA: 1:14  [ loss=0.0023 ][Training] 6/57 [==>...........................] - ETA: 1:16  [ loss=0.1491 ][Training] 7/57 [==>...........................] - ETA: 1:14  [ loss=0.1306 ][Training] 8/57 [===>..........................] - ETA: 1:11  [ loss=0.2999 ][Training] 9/57 [===>..........................] - ETA: 1:11  [ loss=0.1581 ][Training] 10/57 [====>.........................] - ETA: 1:09  [ loss=0.0653 ][Training] 11/57 [====>.........................] - ETA: 1:07  [ loss=0.0874 ][Training] 12/57 [=====>........................] - ETA: 1:05  [ loss=0.0596 ][Training] 13/57 [=====>........................] - ETA: 1:03  [ loss=0.1283 ][Training] 14/57 [======>.......................] - ETA: 1:03  [ loss=0.4942 ][Training] 15/57 [======>.......................] - ETA: 1:01  [ loss=0.0661 ][Training] 16/57 [=======>......................] - ETA: 1:00  [ loss=0.1084 ][Training] 17/57 [=======>......................] - ETA: 58s  [ loss=0.1966 ][Training] 18/57 [========>.....................] - ETA: 56s  [ loss=0.0035 ][Training] 19/57 [=========>....................] - ETA: 56s  [ loss=0.4035 ][Training] 20/57 [=========>....................] - ETA: 54s  [ loss=0.3521 ][Training] 21/57 [==========>...................] - ETA: 53s  [ loss=0.0936 ][Training] 22/57 [==========>...................] - ETA: 51s  [ loss=0.2713 ][Training] 23/57 [===========>..................] - ETA: 50s  [ loss=0.2548 ][Training] 24/57 [===========>..................] - ETA: 48s  [ loss=0.8455 ][Training] 25/57 [============>.................] - ETA: 47s  [ loss=0.0773 ][Training] 26/57 [============>.................] - ETA: 45s  [ loss=0.0579 ][Training] 27/57 [=============>................] - ETA: 44s  [ loss=0.3550 ][Training] 28/57 [=============>................] - ETA: 42s  [ loss=0.2166 ][Training] 29/57 [==============>...............] - ETA: 40s  [ loss=0.0027 ][Training] 30/57 [==============>...............] - ETA: 39s  [ loss=0.1215 ][Training] 31/57 [===============>..............] - ETA: 37s  [ loss=0.1372 ][Training] 32/57 [===============>..............] - ETA: 36s  [ loss=0.2726 ][Training] 33/57 [================>.............] - ETA: 34s  [ loss=0.1394 ][Training] 34/57 [================>.............] - ETA: 33s  [ loss=0.0027 ][Training] 35/57 [=================>............] - ETA: 31s  [ loss=0.0019 ][Training] 36/57 [=================>............] - ETA: 30s  [ loss=0.1339 ][Training] 37/57 [==================>...........] - ETA: 28s  [ loss=0.0029 ][Training] 38/57 [===================>..........] - ETA: 27s  [ loss=0.0032 ][Training] 39/57 [===================>..........] - ETA: 25s  [ loss=0.2794 ][Training] 40/57 [====================>.........] - ETA: 24s  [ loss=0.1124 ][Training] 41/57 [====================>.........] - ETA: 22s  [ loss=0.0998 ][Training] 42/57 [=====================>........] - ETA: 21s  [ loss=0.2153 ][Training] 43/57 [=====================>........] - ETA: 20s  [ loss=0.1426 ][Training] 44/57 [======================>.......] - ETA: 18s  [ loss=0.0032 ][Training] 45/57 [======================>.......] - ETA: 17s  [ loss=0.1439 ][Training] 46/57 [=======================>......] - ETA: 15s  [ loss=0.0025 ][Training] 47/57 [=======================>......] - ETA: 14s  [ loss=0.0904 ][Training] 48/57 [========================>.....] - ETA: 12s  [ loss=0.6254 ][Training] 49/57 [========================>.....] - ETA: 11s  [ loss=0.0018 ][Training] 50/57 [=========================>....] - ETA: 10s  [ loss=0.0773 ][Training] 51/57 [=========================>....] - ETA: 8s  [ loss=0.3498 ][Training] 52/57 [==========================>...] - ETA: 7s  [ loss=0.0416 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=0.0510 ][Training] 54/57 [===========================>..] - ETA: 4s  [ loss=0.1008 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=0.0583 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.0567 ][Training] 57/57 [==============================] 1.4s/step  [ loss=0.0018 ]
01/03/2024 16:15:42 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 16:15:42 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 16:15:42 - INFO - root -     Num examples = 269
01/03/2024 16:15:42 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 6s[Evaluating] 2/12 [====>.........................] - ETA: 5s[Evaluating] 3/12 [======>.......................] - ETA: 4s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 3s[Evaluating] 6/12 [==============>...............] - ETA: 2s[Evaluating] 7/12 [================>.............] - ETA: 2s[Evaluating] 8/12 [===================>..........] - ETA: 1s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 457.5ms/step
01/03/2024 16:15:48 - INFO - root -   

01/03/2024 16:15:48 - INFO - root -   ***** Eval results  *****
01/03/2024 16:15:48 - INFO - root -    acc: 0.6929 - recall: 0.7046 - f1: 0.6987 - loss: 15.1866 
01/03/2024 16:15:48 - INFO - root -   ***** Entity results  *****
01/03/2024 16:15:48 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 16:15:48 - INFO - root -    acc: 0.8039 - recall: 0.8723 - f1: 0.8367 
01/03/2024 16:15:48 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 16:15:48 - INFO - root -    acc: 1.0000 - recall: 0.5000 - f1: 0.6667 
01/03/2024 16:15:48 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 16:15:48 - INFO - root -    acc: 0.3684 - recall: 0.3684 - f1: 0.3684 
01/03/2024 16:15:48 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 16:15:48 - INFO - root -    acc: 0.2222 - recall: 0.2222 - f1: 0.2222 
01/03/2024 16:15:48 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 16:15:48 - INFO - root -    acc: 0.5429 - recall: 0.4872 - f1: 0.5135 
01/03/2024 16:15:48 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 16:15:48 - INFO - root -    acc: 0.5294 - recall: 0.5294 - f1: 0.5294 
01/03/2024 16:15:48 - INFO - root -   ******* PER.NAM results ********
01/03/2024 16:15:48 - INFO - root -    acc: 0.7706 - recall: 0.7636 - f1: 0.7671 
01/03/2024 16:15:48 - INFO - root -   ******* PER.NOM results ********
01/03/2024 16:15:48 - INFO - root -    acc: 0.7151 - recall: 0.7529 - f1: 0.7335 
01/03/2024 16:15:55 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-1425
01/03/2024 16:15:55 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-1425
01/03/2024 16:15:55 - INFO - root -   

01/03/2024 16:15:55 - INFO - root -   Backbone bert_crf param is not freeze

Epoch: 25/30
[Training] 1/57 [..............................] - ETA: 1:17  [ loss=0.1724 ][Training] 2/57 [>.............................] - ETA: 1:11  [ loss=0.0615 ][Training] 3/57 [>.............................] - ETA: 1:15  [ loss=0.1183 ][Training] 4/57 [=>............................] - ETA: 1:14  [ loss=0.0328 ][Training] 5/57 [=>............................] - ETA: 1:13  [ loss=0.4631 ][Training] 6/57 [==>...........................] - ETA: 1:10  [ loss=0.0021 ][Training] 7/57 [==>...........................] - ETA: 1:10  [ loss=0.2658 ][Training] 8/57 [===>..........................] - ETA: 1:09  [ loss=0.0036 ][Training] 9/57 [===>..........................] - ETA: 1:07  [ loss=0.0019 ][Training] 10/57 [====>.........................] - ETA: 1:05  [ loss=0.1692 ][Training] 11/57 [====>.........................] - ETA: 1:05  [ loss=0.1064 ][Training] 12/57 [=====>........................] - ETA: 1:03  [ loss=0.1500 ][Training] 13/57 [=====>........................] - ETA: 1:02  [ loss=0.2560 ][Training] 14/57 [======>.......................] - ETA: 1:01  [ loss=0.0024 ][Training] 15/57 [======>.......................] - ETA: 1:00  [ loss=0.1229 ][Training] 16/57 [=======>......................] - ETA: 58s  [ loss=0.3054 ][Training] 17/57 [=======>......................] - ETA: 57s  [ loss=0.0923 ][Training] 18/57 [========>.....................] - ETA: 55s  [ loss=0.0020 ][Training] 19/57 [=========>....................] - ETA: 54s  [ loss=0.1458 ][Training] 20/57 [=========>....................] - ETA: 53s  [ loss=0.1706 ][Training] 21/57 [==========>...................] - ETA: 51s  [ loss=0.0432 ][Training] 22/57 [==========>...................] - ETA: 49s  [ loss=0.2742 ][Training] 23/57 [===========>..................] - ETA: 48s  [ loss=0.1593 ][Training] 24/57 [===========>..................] - ETA: 47s  [ loss=0.0035 ][Training] 25/57 [============>.................] - ETA: 46s  [ loss=0.0024 ][Training] 26/57 [============>.................] - ETA: 44s  [ loss=0.0779 ][Training] 27/57 [=============>................] - ETA: 43s  [ loss=0.1541 ][Training] 28/57 [=============>................] - ETA: 41s  [ loss=0.2166 ][Training] 29/57 [==============>...............] - ETA: 40s  [ loss=0.1721 ][Training] 30/57 [==============>...............] - ETA: 38s  [ loss=0.4945 ][Training] 31/57 [===============>..............] - ETA: 37s  [ loss=0.1291 ][Training] 32/57 [===============>..............] - ETA: 35s  [ loss=0.0027 ][Training] 33/57 [================>.............] - ETA: 34s  [ loss=0.0829 ][Training] 34/57 [================>.............] - ETA: 32s  [ loss=0.0025 ][Training] 35/57 [=================>............] - ETA: 31s  [ loss=0.6454 ][Training] 36/57 [=================>............] - ETA: 29s  [ loss=0.0821 ][Training] 37/57 [==================>...........] - ETA: 28s  [ loss=0.1212 ][Training] 38/57 [===================>..........] - ETA: 27s  [ loss=0.0518 ][Training] 39/57 [===================>..........] - ETA: 25s  [ loss=0.1771 ][Training] 40/57 [====================>.........] - ETA: 23s  [ loss=0.2886 ][Training] 41/57 [====================>.........] - ETA: 22s  [ loss=0.0015 ][Training] 42/57 [=====================>........] - ETA: 21s  [ loss=0.0397 ][Training] 43/57 [=====================>........] - ETA: 19s  [ loss=0.0021 ][Training] 44/57 [======================>.......] - ETA: 18s  [ loss=0.0017 ][Training] 45/57 [======================>.......] - ETA: 17s  [ loss=0.0587 ][Training] 46/57 [=======================>......] - ETA: 15s  [ loss=0.0024 ][Training] 47/57 [=======================>......] - ETA: 14s  [ loss=0.0019 ][Training] 48/57 [========================>.....] - ETA: 12s  [ loss=0.5428 ][Training] 49/57 [========================>.....] - ETA: 11s  [ loss=0.1354 ][Training] 50/57 [=========================>....] - ETA: 9s  [ loss=0.2747 ][Training] 51/57 [=========================>....] - ETA: 8s  [ loss=0.0963 ][Training] 52/57 [==========================>...] - ETA: 7s  [ loss=0.3473 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=0.1972 ][Training] 54/57 [===========================>..] - ETA: 4s  [ loss=0.1303 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=0.2289 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.2533 ][Training] 57/57 [==============================] 1.4s/step  [ loss=0.0012 ]
01/03/2024 16:17:14 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 16:17:14 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 16:17:14 - INFO - root -     Num examples = 269
01/03/2024 16:17:14 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 6s[Evaluating] 2/12 [====>.........................] - ETA: 5s[Evaluating] 3/12 [======>.......................] - ETA: 4s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 3s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 2s[Evaluating] 8/12 [===================>..........] - ETA: 1s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 0s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 477.8ms/step
01/03/2024 16:17:20 - INFO - root -   

01/03/2024 16:17:20 - INFO - root -   ***** Eval results  *****
01/03/2024 16:17:20 - INFO - root -    acc: 0.7132 - recall: 0.7046 - f1: 0.7089 - loss: 15.3312 
01/03/2024 16:17:20 - INFO - root -   ***** Entity results  *****
01/03/2024 16:17:20 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 16:17:20 - INFO - root -    acc: 0.8039 - recall: 0.8723 - f1: 0.8367 
01/03/2024 16:17:20 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 16:17:20 - INFO - root -    acc: 1.0000 - recall: 0.5000 - f1: 0.6667 
01/03/2024 16:17:20 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 16:17:20 - INFO - root -    acc: 0.4444 - recall: 0.4211 - f1: 0.4324 
01/03/2024 16:17:20 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 16:17:20 - INFO - root -    acc: 0.3333 - recall: 0.2222 - f1: 0.2667 
01/03/2024 16:17:20 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 16:17:20 - INFO - root -    acc: 0.5667 - recall: 0.4359 - f1: 0.4928 
01/03/2024 16:17:20 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 16:17:20 - INFO - root -    acc: 0.5882 - recall: 0.5882 - f1: 0.5882 
01/03/2024 16:17:20 - INFO - root -   ******* PER.NAM results ********
01/03/2024 16:17:20 - INFO - root -    acc: 0.7664 - recall: 0.7455 - f1: 0.7558 
01/03/2024 16:17:20 - INFO - root -   ******* PER.NOM results ********
01/03/2024 16:17:20 - INFO - root -    acc: 0.7303 - recall: 0.7647 - f1: 0.7471 
01/03/2024 16:17:27 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-1482
01/03/2024 16:17:27 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-1482
01/03/2024 16:17:27 - INFO - root -   

01/03/2024 16:17:27 - INFO - root -   Backbone bert_crf param is not freeze

Epoch: 26/30
[Training] 1/57 [..............................] - ETA: 1:33  [ loss=0.6084 ][Training] 2/57 [>.............................] - ETA: 1:31  [ loss=0.2439 ][Training] 3/57 [>.............................] - ETA: 1:25  [ loss=0.4326 ][Training] 4/57 [=>............................] - ETA: 1:26  [ loss=0.0016 ][Training] 5/57 [=>............................] - ETA: 1:21  [ loss=0.0214 ][Training] 6/57 [==>...........................] - ETA: 1:18  [ loss=0.1642 ][Training] 7/57 [==>...........................] - ETA: 1:17  [ loss=0.0306 ][Training] 8/57 [===>..........................] - ETA: 1:13  [ loss=0.0023 ][Training] 9/57 [===>..........................] - ETA: 1:11  [ loss=0.0016 ][Training] 10/57 [====>.........................] - ETA: 1:10  [ loss=0.0027 ][Training] 11/57 [====>.........................] - ETA: 1:08  [ loss=0.0014 ][Training] 12/57 [=====>........................] - ETA: 1:07  [ loss=0.0013 ][Training] 13/57 [=====>........................] - ETA: 1:05  [ loss=0.0025 ][Training] 14/57 [======>.......................] - ETA: 1:04  [ loss=0.0032 ][Training] 15/57 [======>.......................] - ETA: 1:02  [ loss=0.0020 ][Training] 16/57 [=======>......................] - ETA: 1:00  [ loss=0.0754 ][Training] 17/57 [=======>......................] - ETA: 59s  [ loss=0.4695 ][Training] 18/57 [========>.....................] - ETA: 57s  [ loss=0.0883 ][Training] 19/57 [=========>....................] - ETA: 56s  [ loss=0.2185 ][Training] 20/57 [=========>....................] - ETA: 55s  [ loss=0.0781 ][Training] 21/57 [==========>...................] - ETA: 53s  [ loss=0.0021 ][Training] 22/57 [==========>...................] - ETA: 52s  [ loss=0.0023 ][Training] 23/57 [===========>..................] - ETA: 50s  [ loss=0.3981 ][Training] 24/57 [===========>..................] - ETA: 49s  [ loss=0.1113 ][Training] 25/57 [============>.................] - ETA: 47s  [ loss=0.0020 ][Training] 26/57 [============>.................] - ETA: 46s  [ loss=0.2425 ][Training] 27/57 [=============>................] - ETA: 44s  [ loss=0.0016 ][Training] 28/57 [=============>................] - ETA: 43s  [ loss=0.1060 ][Training] 29/57 [==============>...............] - ETA: 41s  [ loss=0.1327 ][Training] 30/57 [==============>...............] - ETA: 40s  [ loss=0.0505 ][Training] 31/57 [===============>..............] - ETA: 38s  [ loss=0.2183 ][Training] 32/57 [===============>..............] - ETA: 37s  [ loss=0.0436 ][Training] 33/57 [================>.............] - ETA: 35s  [ loss=0.1371 ][Training] 34/57 [================>.............] - ETA: 33s  [ loss=0.2729 ][Training] 35/57 [=================>............] - ETA: 32s  [ loss=0.0017 ][Training] 36/57 [=================>............] - ETA: 30s  [ loss=0.1305 ][Training] 37/57 [==================>...........] - ETA: 29s  [ loss=0.2835 ][Training] 38/57 [===================>..........] - ETA: 27s  [ loss=0.0046 ][Training] 39/57 [===================>..........] - ETA: 26s  [ loss=0.1318 ][Training] 40/57 [====================>.........] - ETA: 24s  [ loss=0.2254 ][Training] 41/57 [====================>.........] - ETA: 23s  [ loss=0.0022 ][Training] 42/57 [=====================>........] - ETA: 21s  [ loss=0.1594 ][Training] 43/57 [=====================>........] - ETA: 20s  [ loss=0.1631 ][Training] 44/57 [======================>.......] - ETA: 18s  [ loss=0.0776 ][Training] 45/57 [======================>.......] - ETA: 17s  [ loss=0.1546 ][Training] 46/57 [=======================>......] - ETA: 16s  [ loss=0.2376 ][Training] 47/57 [=======================>......] - ETA: 14s  [ loss=0.1722 ][Training] 48/57 [========================>.....] - ETA: 13s  [ loss=0.0021 ][Training] 49/57 [========================>.....] - ETA: 11s  [ loss=0.4411 ][Training] 50/57 [=========================>....] - ETA: 10s  [ loss=0.0334 ][Training] 51/57 [=========================>....] - ETA: 8s  [ loss=0.0022 ][Training] 52/57 [==========================>...] - ETA: 7s  [ loss=0.0025 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=0.1259 ][Training] 54/57 [===========================>..] - ETA: 4s  [ loss=0.3510 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=0.1647 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.8532 ][Training] 57/57 [==============================] 1.4s/step  [ loss=0.0018 ]
01/03/2024 16:18:50 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 16:18:50 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 16:18:50 - INFO - root -     Num examples = 269
01/03/2024 16:18:50 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 7s[Evaluating] 2/12 [====>.........................] - ETA: 5s[Evaluating] 3/12 [======>.......................] - ETA: 4s[Evaluating] 4/12 [=========>....................] - ETA: 3s[Evaluating] 5/12 [===========>..................] - ETA: 3s[Evaluating] 6/12 [==============>...............] - ETA: 2s[Evaluating] 7/12 [================>.............] - ETA: 2s[Evaluating] 8/12 [===================>..........] - ETA: 1s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 0s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 460.8ms/step
01/03/2024 16:18:55 - INFO - root -   

01/03/2024 16:18:55 - INFO - root -   ***** Eval results  *****
01/03/2024 16:18:55 - INFO - root -    acc: 0.7049 - recall: 0.6998 - f1: 0.7023 - loss: 15.4608 
01/03/2024 16:18:55 - INFO - root -   ***** Entity results  *****
01/03/2024 16:18:55 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 16:18:55 - INFO - root -    acc: 0.7885 - recall: 0.8723 - f1: 0.8283 
01/03/2024 16:18:55 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 16:18:55 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/03/2024 16:18:55 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 16:18:55 - INFO - root -    acc: 0.3684 - recall: 0.3684 - f1: 0.3684 
01/03/2024 16:18:55 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 16:18:55 - INFO - root -    acc: 0.3333 - recall: 0.2222 - f1: 0.2667 
01/03/2024 16:18:55 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 16:18:55 - INFO - root -    acc: 0.5312 - recall: 0.4359 - f1: 0.4789 
01/03/2024 16:18:55 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 16:18:55 - INFO - root -    acc: 0.6250 - recall: 0.5882 - f1: 0.6061 
01/03/2024 16:18:55 - INFO - root -   ******* PER.NAM results ********
01/03/2024 16:18:55 - INFO - root -    acc: 0.7664 - recall: 0.7455 - f1: 0.7558 
01/03/2024 16:18:55 - INFO - root -   ******* PER.NOM results ********
01/03/2024 16:18:55 - INFO - root -    acc: 0.7303 - recall: 0.7647 - f1: 0.7471 
01/03/2024 16:19:06 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-1539
01/03/2024 16:19:06 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-1539
01/03/2024 16:19:06 - INFO - root -   

01/03/2024 16:19:06 - INFO - root -   Backbone bert_crf param is not freeze

Epoch: 27/30
[Training] 1/57 [..............................] - ETA: 1:37  [ loss=0.0668 ][Training] 2/57 [>.............................] - ETA: 1:25  [ loss=0.0780 ][Training] 3/57 [>.............................] - ETA: 1:27  [ loss=0.1974 ][Training] 4/57 [=>............................] - ETA: 1:28  [ loss=0.0022 ][Training] 5/57 [=>............................] - ETA: 1:24  [ loss=0.1186 ][Training] 6/57 [==>...........................] - ETA: 1:24  [ loss=0.2621 ][Training] 7/57 [==>...........................] - ETA: 1:20  [ loss=0.0457 ][Training] 8/57 [===>..........................] - ETA: 1:20  [ loss=0.2923 ][Training] 9/57 [===>..........................] - ETA: 1:19  [ loss=0.6125 ][Training] 10/57 [====>.........................] - ETA: 1:17  [ loss=0.0788 ][Training] 11/57 [====>.........................] - ETA: 1:14  [ loss=0.0023 ][Training] 12/57 [=====>........................] - ETA: 1:11  [ loss=0.0018 ][Training] 13/57 [=====>........................] - ETA: 1:10  [ loss=0.0026 ][Training] 14/57 [======>.......................] - ETA: 1:07  [ loss=0.0022 ][Training] 15/57 [======>.......................] - ETA: 1:05  [ loss=0.0548 ][Training] 16/57 [=======>......................] - ETA: 1:03  [ loss=0.0023 ][Training] 17/57 [=======>......................] - ETA: 1:01  [ loss=0.0030 ][Training] 18/57 [========>.....................] - ETA: 59s  [ loss=0.0520 ][Training] 19/57 [=========>....................] - ETA: 58s  [ loss=0.0341 ][Training] 20/57 [=========>....................] - ETA: 56s  [ loss=0.1688 ][Training] 21/57 [==========>...................] - ETA: 55s  [ loss=0.1538 ][Training] 22/57 [==========>...................] - ETA: 53s  [ loss=0.0539 ][Training] 23/57 [===========>..................] - ETA: 52s  [ loss=0.0020 ][Training] 24/57 [===========>..................] - ETA: 50s  [ loss=0.3185 ][Training] 25/57 [============>.................] - ETA: 49s  [ loss=0.0346 ][Training] 26/57 [============>.................] - ETA: 47s  [ loss=0.2041 ][Training] 27/57 [=============>................] - ETA: 45s  [ loss=0.1154 ][Training] 28/57 [=============>................] - ETA: 44s  [ loss=0.2369 ][Training] 29/57 [==============>...............] - ETA: 42s  [ loss=0.2103 ][Training] 30/57 [==============>...............] - ETA: 40s  [ loss=0.0024 ][Training] 31/57 [===============>..............] - ETA: 39s  [ loss=0.0837 ][Training] 32/57 [===============>..............] - ETA: 37s  [ loss=0.0663 ][Training] 33/57 [================>.............] - ETA: 36s  [ loss=0.0028 ][Training] 34/57 [================>.............] - ETA: 34s  [ loss=0.0574 ][Training] 35/57 [=================>............] - ETA: 32s  [ loss=0.2412 ][Training] 36/57 [=================>............] - ETA: 31s  [ loss=0.0018 ][Training] 37/57 [==================>...........] - ETA: 29s  [ loss=0.0404 ][Training] 38/57 [===================>..........] - ETA: 28s  [ loss=0.1104 ][Training] 39/57 [===================>..........] - ETA: 26s  [ loss=0.1276 ][Training] 40/57 [====================>.........] - ETA: 25s  [ loss=0.1283 ][Training] 41/57 [====================>.........] - ETA: 23s  [ loss=0.1948 ][Training] 42/57 [=====================>........] - ETA: 22s  [ loss=0.1149 ][Training] 43/57 [=====================>........] - ETA: 20s  [ loss=0.1908 ][Training] 44/57 [======================>.......] - ETA: 19s  [ loss=0.5275 ][Training] 45/57 [======================>.......] - ETA: 17s  [ loss=0.1800 ][Training] 46/57 [=======================>......] - ETA: 16s  [ loss=0.1836 ][Training] 47/57 [=======================>......] - ETA: 14s  [ loss=0.3412 ][Training] 48/57 [========================>.....] - ETA: 13s  [ loss=0.0021 ][Training] 49/57 [========================>.....] - ETA: 11s  [ loss=0.3418 ][Training] 50/57 [=========================>....] - ETA: 10s  [ loss=0.0771 ][Training] 51/57 [=========================>....] - ETA: 8s  [ loss=0.2343 ][Training] 52/57 [==========================>...] - ETA: 7s  [ loss=0.0576 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=0.1097 ][Training] 54/57 [===========================>..] - ETA: 4s  [ loss=0.2166 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=0.1542 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.1102 ][Training] 57/57 [==============================] 1.5s/step  [ loss=0.3945 ]
01/03/2024 16:20:29 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 16:20:30 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 16:20:30 - INFO - root -     Num examples = 269
01/03/2024 16:20:30 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 3s[Evaluating] 2/12 [====>.........................] - ETA: 4s[Evaluating] 3/12 [======>.......................] - ETA: 3s[Evaluating] 4/12 [=========>....................] - ETA: 3s[Evaluating] 5/12 [===========>..................] - ETA: 3s[Evaluating] 6/12 [==============>...............] - ETA: 2s[Evaluating] 7/12 [================>.............] - ETA: 2s[Evaluating] 8/12 [===================>..........] - ETA: 1s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 0s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 451.9ms/step
01/03/2024 16:20:35 - INFO - root -   

01/03/2024 16:20:35 - INFO - root -   ***** Eval results  *****
01/03/2024 16:20:35 - INFO - root -    acc: 0.6952 - recall: 0.7070 - f1: 0.7011 - loss: 15.3647 
01/03/2024 16:20:35 - INFO - root -   ***** Entity results  *****
01/03/2024 16:20:35 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 16:20:35 - INFO - root -    acc: 0.8039 - recall: 0.8723 - f1: 0.8367 
01/03/2024 16:20:35 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 16:20:35 - INFO - root -    acc: 1.0000 - recall: 0.5000 - f1: 0.6667 
01/03/2024 16:20:35 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 16:20:35 - INFO - root -    acc: 0.3684 - recall: 0.3684 - f1: 0.3684 
01/03/2024 16:20:35 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 16:20:35 - INFO - root -    acc: 0.4286 - recall: 0.3333 - f1: 0.3750 
01/03/2024 16:20:35 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 16:20:35 - INFO - root -    acc: 0.5294 - recall: 0.4615 - f1: 0.4932 
01/03/2024 16:20:35 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 16:20:35 - INFO - root -    acc: 0.5500 - recall: 0.6471 - f1: 0.5946 
01/03/2024 16:20:35 - INFO - root -   ******* PER.NAM results ********
01/03/2024 16:20:35 - INFO - root -    acc: 0.7664 - recall: 0.7455 - f1: 0.7558 
01/03/2024 16:20:35 - INFO - root -   ******* PER.NOM results ********
01/03/2024 16:20:35 - INFO - root -    acc: 0.7127 - recall: 0.7588 - f1: 0.7350 
01/03/2024 16:20:42 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-1596
01/03/2024 16:20:42 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-1596
01/03/2024 16:20:42 - INFO - root -   

01/03/2024 16:20:42 - INFO - root -   Backbone bert_crf param is not freeze

Epoch: 28/30
[Training] 1/57 [..............................] - ETA: 1:31  [ loss=0.1622 ][Training] 2/57 [>.............................] - ETA: 1:21  [ loss=0.1204 ][Training] 3/57 [>.............................] - ETA: 1:19  [ loss=0.0024 ][Training] 4/57 [=>............................] - ETA: 1:18  [ loss=0.2079 ][Training] 5/57 [=>............................] - ETA: 1:15  [ loss=0.0030 ][Training] 6/57 [==>...........................] - ETA: 1:10  [ loss=0.2689 ][Training] 7/57 [==>...........................] - ETA: 1:11  [ loss=0.1455 ][Training] 8/57 [===>..........................] - ETA: 1:09  [ loss=0.2105 ][Training] 9/57 [===>..........................] - ETA: 1:08  [ loss=0.1008 ][Training] 10/57 [====>.........................] - ETA: 1:06  [ loss=0.0658 ][Training] 11/57 [====>.........................] - ETA: 1:05  [ loss=0.3295 ][Training] 12/57 [=====>........................] - ETA: 1:03  [ loss=0.4533 ][Training] 13/57 [=====>........................] - ETA: 1:01  [ loss=0.0020 ][Training] 14/57 [======>.......................] - ETA: 1:00  [ loss=0.0449 ][Training] 15/57 [======>.......................] - ETA: 59s  [ loss=0.0021 ][Training] 16/57 [=======>......................] - ETA: 58s  [ loss=0.0566 ][Training] 17/57 [=======>......................] - ETA: 56s  [ loss=0.0779 ][Training] 18/57 [========>.....................] - ETA: 55s  [ loss=0.1115 ][Training] 19/57 [=========>....................] - ETA: 54s  [ loss=0.2537 ][Training] 20/57 [=========>....................] - ETA: 52s  [ loss=0.4969 ][Training] 21/57 [==========>...................] - ETA: 51s  [ loss=0.0626 ][Training] 22/57 [==========>...................] - ETA: 49s  [ loss=0.1446 ][Training] 23/57 [===========>..................] - ETA: 48s  [ loss=0.0016 ][Training] 24/57 [===========>..................] - ETA: 47s  [ loss=0.1244 ][Training] 25/57 [============>.................] - ETA: 45s  [ loss=0.2762 ][Training] 26/57 [============>.................] - ETA: 44s  [ loss=0.0017 ][Training] 27/57 [=============>................] - ETA: 43s  [ loss=0.3258 ][Training] 28/57 [=============>................] - ETA: 41s  [ loss=0.1606 ][Training] 29/57 [==============>...............] - ETA: 40s  [ loss=0.2032 ][Training] 30/57 [==============>...............] - ETA: 39s  [ loss=0.1319 ][Training] 31/57 [===============>..............] - ETA: 37s  [ loss=0.0029 ][Training] 32/57 [===============>..............] - ETA: 35s  [ loss=0.2097 ][Training] 33/57 [================>.............] - ETA: 34s  [ loss=0.0378 ][Training] 34/57 [================>.............] - ETA: 33s  [ loss=0.1298 ][Training] 35/57 [=================>............] - ETA: 31s  [ loss=0.0020 ][Training] 36/57 [=================>............] - ETA: 30s  [ loss=0.1030 ][Training] 37/57 [==================>...........] - ETA: 28s  [ loss=0.0021 ][Training] 38/57 [===================>..........] - ETA: 27s  [ loss=0.1959 ][Training] 39/57 [===================>..........] - ETA: 25s  [ loss=0.0748 ][Training] 40/57 [====================>.........] - ETA: 24s  [ loss=0.1267 ][Training] 41/57 [====================>.........] - ETA: 22s  [ loss=0.0358 ][Training] 42/57 [=====================>........] - ETA: 21s  [ loss=0.0040 ][Training] 43/57 [=====================>........] - ETA: 19s  [ loss=0.0024 ][Training] 44/57 [======================>.......] - ETA: 18s  [ loss=0.0333 ][Training] 45/57 [======================>.......] - ETA: 17s  [ loss=0.3420 ][Training] 46/57 [=======================>......] - ETA: 15s  [ loss=0.1777 ][Training] 47/57 [=======================>......] - ETA: 14s  [ loss=0.0426 ][Training] 48/57 [========================>.....] - ETA: 12s  [ loss=0.2274 ][Training] 49/57 [========================>.....] - ETA: 11s  [ loss=0.1387 ][Training] 50/57 [=========================>....] - ETA: 9s  [ loss=0.0350 ][Training] 51/57 [=========================>....] - ETA: 8s  [ loss=0.1681 ][Training] 52/57 [==========================>...] - ETA: 7s  [ loss=0.1274 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=0.1313 ][Training] 54/57 [===========================>..] - ETA: 4s  [ loss=0.0042 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=0.1646 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.0021 ][Training] 57/57 [==============================] 1.4s/step  [ loss=0.0028 ]
01/03/2024 16:22:03 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 16:22:03 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 16:22:03 - INFO - root -     Num examples = 269
01/03/2024 16:22:03 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 6s[Evaluating] 2/12 [====>.........................] - ETA: 4s[Evaluating] 3/12 [======>.......................] - ETA: 4s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 3s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 2s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 491.0ms/step
01/03/2024 16:22:09 - INFO - root -   

01/03/2024 16:22:09 - INFO - root -   ***** Eval results  *****
01/03/2024 16:22:09 - INFO - root -    acc: 0.6929 - recall: 0.7046 - f1: 0.6987 - loss: 15.4435 
01/03/2024 16:22:09 - INFO - root -   ***** Entity results  *****
01/03/2024 16:22:09 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 16:22:09 - INFO - root -    acc: 0.8039 - recall: 0.8723 - f1: 0.8367 
01/03/2024 16:22:09 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 16:22:09 - INFO - root -    acc: 1.0000 - recall: 0.5000 - f1: 0.6667 
01/03/2024 16:22:09 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 16:22:09 - INFO - root -    acc: 0.3684 - recall: 0.3684 - f1: 0.3684 
01/03/2024 16:22:09 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 16:22:09 - INFO - root -    acc: 0.2857 - recall: 0.2222 - f1: 0.2500 
01/03/2024 16:22:09 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 16:22:09 - INFO - root -    acc: 0.5294 - recall: 0.4615 - f1: 0.4932 
01/03/2024 16:22:09 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 16:22:09 - INFO - root -    acc: 0.5500 - recall: 0.6471 - f1: 0.5946 
01/03/2024 16:22:09 - INFO - root -   ******* PER.NAM results ********
01/03/2024 16:22:09 - INFO - root -    acc: 0.7664 - recall: 0.7455 - f1: 0.7558 
01/03/2024 16:22:09 - INFO - root -   ******* PER.NOM results ********
01/03/2024 16:22:09 - INFO - root -    acc: 0.7127 - recall: 0.7588 - f1: 0.7350 
01/03/2024 16:22:25 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-1653
01/03/2024 16:22:25 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-1653
01/03/2024 16:22:25 - INFO - root -   

01/03/2024 16:22:25 - INFO - root -   Backbone bert_crf param is not freeze

Epoch: 29/30
[Training] 1/57 [..............................] - ETA: 1:20  [ loss=0.0983 ][Training] 2/57 [>.............................] - ETA: 1:15  [ loss=0.0022 ][Training] 3/57 [>.............................] - ETA: 1:13  [ loss=0.1042 ][Training] 4/57 [=>............................] - ETA: 1:11  [ loss=0.1832 ][Training] 5/57 [=>............................] - ETA: 1:09  [ loss=0.1959 ][Training] 6/57 [==>...........................] - ETA: 1:08  [ loss=0.2625 ][Training] 7/57 [==>...........................] - ETA: 1:06  [ loss=0.0027 ][Training] 8/57 [===>..........................] - ETA: 1:05  [ loss=0.1502 ][Training] 9/57 [===>..........................] - ETA: 1:03  [ loss=0.1488 ][Training] 10/57 [====>.........................] - ETA: 1:03  [ loss=0.0975 ][Training] 11/57 [====>.........................] - ETA: 1:02  [ loss=0.0023 ][Training] 12/57 [=====>........................] - ETA: 1:01  [ loss=0.0366 ][Training] 13/57 [=====>........................] - ETA: 1:00  [ loss=0.0021 ][Training] 14/57 [======>.......................] - ETA: 59s  [ loss=0.0019 ][Training] 15/57 [======>.......................] - ETA: 57s  [ loss=0.3040 ][Training] 16/57 [=======>......................] - ETA: 57s  [ loss=0.0019 ][Training] 17/57 [=======>......................] - ETA: 55s  [ loss=0.1044 ][Training] 18/57 [========>.....................] - ETA: 54s  [ loss=0.0836 ][Training] 19/57 [=========>....................] - ETA: 52s  [ loss=0.0522 ][Training] 20/57 [=========>....................] - ETA: 51s  [ loss=0.0017 ][Training] 21/57 [==========>...................] - ETA: 50s  [ loss=0.4272 ][Training] 22/57 [==========>...................] - ETA: 49s  [ loss=0.2715 ][Training] 23/57 [===========>..................] - ETA: 47s  [ loss=0.0775 ][Training] 24/57 [===========>..................] - ETA: 46s  [ loss=0.1272 ][Training] 25/57 [============>.................] - ETA: 44s  [ loss=0.0498 ][Training] 26/57 [============>.................] - ETA: 43s  [ loss=0.0015 ][Training] 27/57 [=============>................] - ETA: 41s  [ loss=0.3316 ][Training] 28/57 [=============>................] - ETA: 40s  [ loss=0.1080 ][Training] 29/57 [==============>...............] - ETA: 39s  [ loss=0.6097 ][Training] 30/57 [==============>...............] - ETA: 37s  [ loss=0.3075 ][Training] 31/57 [===============>..............] - ETA: 36s  [ loss=0.3182 ][Training] 32/57 [===============>..............] - ETA: 35s  [ loss=0.1981 ][Training] 33/57 [================>.............] - ETA: 33s  [ loss=0.0688 ][Training] 34/57 [================>.............] - ETA: 32s  [ loss=0.0023 ][Training] 35/57 [=================>............] - ETA: 30s  [ loss=0.0021 ][Training] 36/57 [=================>............] - ETA: 29s  [ loss=0.0370 ][Training] 37/57 [==================>...........] - ETA: 28s  [ loss=0.2693 ][Training] 38/57 [===================>..........] - ETA: 26s  [ loss=0.1257 ][Training] 39/57 [===================>..........] - ETA: 25s  [ loss=0.1191 ][Training] 40/57 [====================>.........] - ETA: 24s  [ loss=0.3840 ][Training] 41/57 [====================>.........] - ETA: 22s  [ loss=0.2136 ][Training] 42/57 [=====================>........] - ETA: 21s  [ loss=0.0800 ][Training] 43/57 [=====================>........] - ETA: 19s  [ loss=0.0015 ][Training] 44/57 [======================>.......] - ETA: 18s  [ loss=0.2607 ][Training] 45/57 [======================>.......] - ETA: 17s  [ loss=0.0032 ][Training] 46/57 [=======================>......] - ETA: 15s  [ loss=0.0319 ][Training] 47/57 [=======================>......] - ETA: 14s  [ loss=0.0020 ][Training] 48/57 [========================>.....] - ETA: 12s  [ loss=0.0854 ][Training] 49/57 [========================>.....] - ETA: 11s  [ loss=0.1516 ][Training] 50/57 [=========================>....] - ETA: 9s  [ loss=0.0030 ][Training] 51/57 [=========================>....] - ETA: 8s  [ loss=0.0015 ][Training] 52/57 [==========================>...] - ETA: 7s  [ loss=0.1740 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=0.0020 ][Training] 54/57 [===========================>..] - ETA: 4s  [ loss=0.0380 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=0.0026 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=0.0233 ][Training] 57/57 [==============================] 1.4s/step  [ loss=0.0027 ]
01/03/2024 16:23:45 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/03/2024 16:23:45 - INFO - root -   ***** Running evaluation on test dataset  *****
01/03/2024 16:23:45 - INFO - root -     Num examples = 269
01/03/2024 16:23:45 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 5s[Evaluating] 2/12 [====>.........................] - ETA: 4s[Evaluating] 3/12 [======>.......................] - ETA: 4s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 3s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 2s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 493.6ms/step
01/03/2024 16:23:51 - INFO - root -   

01/03/2024 16:23:51 - INFO - root -   ***** Eval results  *****
01/03/2024 16:23:51 - INFO - root -    acc: 0.6929 - recall: 0.7046 - f1: 0.6987 - loss: 15.4849 
01/03/2024 16:23:51 - INFO - root -   ***** Entity results  *****
01/03/2024 16:23:51 - INFO - root -   ******* GPE.NAM results ********
01/03/2024 16:23:51 - INFO - root -    acc: 0.8039 - recall: 0.8723 - f1: 0.8367 
01/03/2024 16:23:51 - INFO - root -   ******* GPE.NOM results ********
01/03/2024 16:23:51 - INFO - root -    acc: 1.0000 - recall: 0.5000 - f1: 0.6667 
01/03/2024 16:23:51 - INFO - root -   ******* LOC.NAM results ********
01/03/2024 16:23:51 - INFO - root -    acc: 0.3684 - recall: 0.3684 - f1: 0.3684 
01/03/2024 16:23:51 - INFO - root -   ******* LOC.NOM results ********
01/03/2024 16:23:51 - INFO - root -    acc: 0.2857 - recall: 0.2222 - f1: 0.2500 
01/03/2024 16:23:51 - INFO - root -   ******* ORG.NAM results ********
01/03/2024 16:23:51 - INFO - root -    acc: 0.5294 - recall: 0.4615 - f1: 0.4932 
01/03/2024 16:23:51 - INFO - root -   ******* ORG.NOM results ********
01/03/2024 16:23:51 - INFO - root -    acc: 0.5500 - recall: 0.6471 - f1: 0.5946 
01/03/2024 16:23:51 - INFO - root -   ******* PER.NAM results ********
01/03/2024 16:23:51 - INFO - root -    acc: 0.7664 - recall: 0.7455 - f1: 0.7558 
01/03/2024 16:23:51 - INFO - root -   ******* PER.NOM results ********
01/03/2024 16:23:51 - INFO - root -    acc: 0.7127 - recall: 0.7588 - f1: 0.7350 
01/03/2024 16:23:57 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-1710
01/03/2024 16:23:57 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf/checkpoint-1710
01/03/2024 16:23:57 - INFO - root -   

01/03/2024 16:23:57 - INFO - root -    global_step = 1710, average loss = 3.8224581602772245
01/03/2024 16:23:57 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_crf
