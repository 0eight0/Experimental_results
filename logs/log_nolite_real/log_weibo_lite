nohup: ignoring input
01/08/2024 11:21:51 - WARNING - root -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False
Some weights of BertEstorCrf were not initialized from the model checkpoint at /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/prev_trained_model/roberta-large-chinese and are newly initialized: ['crf.start_transitions', 'estor.encoder.linear1.weight', 'estor.self_attention.in_proj_weight', 'estor.self_attention.in_proj_bias', 'estor.encoder.self_attn.in_proj_bias', 'estor.encoder.linear1.bias', 'crf.end_transitions', 'estor.self_attention.out_proj.weight', 'classifier.bias', 'estor.encoder.norm1.weight', 'classifier.weight', 'estor.att_norm.bias', 'estor.reshape_linear.bias', 'estor.encoder.norm2.bias', 'estor.tag_embedding_layer.weight', 'estor.gate_linear.bias', 'crf.transitions', 'estor.hidden_size_to_tag_hidden_size.bias', 'estor.attention.in_proj_bias', 'estor.attention.out_proj.bias', 'estor.hidden_size_to_tag_hidden_size.weight', 'estor.gate_linear.weight', 'estor.encoder.linear2.weight', 'estor.encoder.norm2.weight', 'estor.self_attention.out_proj.bias', 'estor.encoder.self_attn.out_proj.weight', 'estor.encoder.norm1.bias', 'estor.encoder.self_attn.in_proj_weight', 'estor.att_norm.weight', 'estor.attention.out_proj.weight', 'estor.reshape_linear.weight', 'estor.encoder.linear2.bias', 'estor.positional_embedding.embeddings', 'estor.attention.in_proj_weight', 'estor.encoder.self_attn.out_proj.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
01/08/2024 11:22:04 - INFO - root -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, adv_epsilon=1.0, adv_name='word_embeddings', backbone='bert_estor_crf', cache_dir='', config_name='', contrastive_alpha=0.1, crf_learning_rate=0.001, data_dir='/mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/', device=device(type='cuda'), do_adv=False, do_eval=False, do_lower_case=True, do_predict=False, do_train=True, enumerate_mode='gate', eval_all_checkpoints=False, eval_max_seq_length=512, evaluate_during_training=False, fp16=False, fp16_opt_level='O1', freeze_backbone_epoch=30, gate_dropout_rate=0.5, gate_scaling_rate=0.8, gradient_accumulation_steps=1, id2label={0: 'X', 1: 'O', 2: '[START]', 3: '[END]', 4: 'B-PER.NAM', 5: 'I-PER.NAM', 6: 'B-PER.NOM', 7: 'I-PER.NOM', 8: 'B-LOC.NAM', 9: 'I-LOC.NAM', 10: 'B-LOC.NOM', 11: 'I-LOC.NOM', 12: 'B-GPE.NAM', 13: 'I-GPE.NAM', 14: 'B-GPE.NOM', 15: 'I-GPE.NOM', 16: 'B-ORG.NAM', 17: 'I-ORG.NAM', 18: 'B-ORG.NOM', 19: 'I-ORG.NOM'}, id2tag={0: 'THUOCL_lishimingren', 1: 'Company-Shorter-Form', 2: 'Chinese_Names_Corpus', 3: 'Tsingtao_roads', 4: 'Organization-Names-Corpus', 5: 'Company-Names-Corpus', 6: 'relationship', 7: 'THUOCL_diming'}, if_add_a_self_attention=True, if_contrastive_learn=True, if_merge_by_add=True, label2id={'X': 0, 'O': 1, '[START]': 2, '[END]': 3, 'B-PER.NAM': 4, 'I-PER.NAM': 5, 'B-PER.NOM': 6, 'I-PER.NOM': 7, 'B-LOC.NAM': 8, 'I-LOC.NAM': 9, 'B-LOC.NOM': 10, 'I-LOC.NOM': 11, 'B-GPE.NAM': 12, 'I-GPE.NAM': 13, 'B-GPE.NOM': 14, 'I-GPE.NOM': 15, 'B-ORG.NAM': 16, 'I-ORG.NAM': 17, 'B-ORG.NOM': 18, 'I-ORG.NOM': 19}, learning_rate=3e-05, local_rank=-1, logging_steps=-1, loss_type='ce', markup='bio', max_grad_norm=1.0, max_steps=-1, model_name_or_path='/mnt/storage/wubinghong.wbh/deepl/torch_ner_new/prev_trained_model/roberta-large-chinese', n_gpu=1, no_cuda=False, num_train_epochs=50.0, output_dir='/mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=24, per_gpu_train_batch_size=24, pos_learning_rate=5e-05, predict_checkpoints=0, save_steps=-1, seed=42, tag2id={'THUOCL_lishimingren': 0, 'Company-Shorter-Form': 1, 'Chinese_Names_Corpus': 2, 'Tsingtao_roads': 3, 'Organization-Names-Corpus': 4, 'Company-Names-Corpus': 5, 'relationship': 6, 'THUOCL_diming': 7}, tagging_rate=1.0, task_name='weibo', tokenizer_name='', train_max_seq_length=128, warmup_proportion=0.1, weight_decay=0.01)
01/08/2024 11:22:04 - INFO - root -   Creating features from dataset file at /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/
['X', 'O', '[START]', '[END]', 'B-PER.NAM', 'I-PER.NAM', 'B-PER.NOM', 'I-PER.NOM', 'B-LOC.NAM', 'I-LOC.NAM', 'B-LOC.NOM', 'I-LOC.NOM', 'B-GPE.NAM', 'I-GPE.NAM', 'B-GPE.NOM', 'I-GPE.NOM', 'B-ORG.NAM', 'I-ORG.NAM', 'B-ORG.NOM', 'I-ORG.NOM'] ['THUOCL_lishimingren', 'Company-Shorter-Form', 'Chinese_Names_Corpus', 'Tsingtao_roads', 'Organization-Names-Corpus', 'Company-Names-Corpus', 'relationship', 'THUOCL_diming']
  0%|          | 0/8 [00:00<?, ?it/s] 12%|█▎        | 1/8 [00:00<00:01,  3.62it/s] 25%|██▌       | 2/8 [00:01<00:05,  1.11it/s] 38%|███▊      | 3/8 [00:09<00:20,  4.18s/it] 62%|██████▎   | 5/8 [00:16<00:11,  3.76s/it] 75%|███████▌  | 6/8 [00:42<00:20, 10.25s/it]100%|██████████| 8/8 [00:43<00:00,  5.66s/it]100%|██████████| 8/8 [00:43<00:00,  5.38s/it]
  0%|          | 0/8 [00:00<?, ?it/s] 25%|██▌       | 2/8 [00:00<00:00,  8.01it/s] 38%|███▊      | 3/8 [00:01<00:02,  2.10it/s] 62%|██████▎   | 5/8 [00:02<00:01,  2.06it/s] 75%|███████▌  | 6/8 [00:07<00:03,  1.69s/it]100%|██████████| 8/8 [00:07<00:00,  1.13it/s]
['THUOCL_lishimingren', 'Company-Shorter-Form', 'Chinese_Names_Corpus', 'Tsingtao_roads', 'Organization-Names-Corpus', 'Company-Names-Corpus', 'relationship', 'THUOCL_diming']
  0%|          | 0/1349 [00:00<?, ?it/s]01/08/2024 11:22:54 - INFO - processors.ner_seq -   Writing example 0 of 1349
01/08/2024 11:22:54 - INFO - processors.ner_seq -   *** Example ***
01/08/2024 11:22:54 - INFO - processors.ner_seq -   guid: train-1
01/08/2024 11:22:54 - INFO - processors.ner_seq -   tokens: [CLS] 对 ， 输 给 一 个 女 人 ， 的 成 绩 。 失 望 [SEP]
01/08/2024 11:22:54 - INFO - processors.ner_seq -   input_ids: 101 2190 8024 6783 5314 671 702 1957 782 8024 4638 2768 5327 511 1927 3307 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/08/2024 11:22:54 - INFO - processors.ner_seq -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/08/2024 11:22:54 - INFO - processors.ner_seq -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/08/2024 11:22:54 - INFO - processors.ner_seq -   label_ids: 1 1 1 1 1 1 1 6 7 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/08/2024 11:22:54 - INFO - processors.ner_seq -   idx: 0
01/08/2024 11:22:54 - INFO - processors.ner_seq -   tag_to_spans: defaultdict(<class 'list'>, {6: [[7, 8], [8, 9], [7, 9]]})
01/08/2024 11:22:54 - INFO - processors.ner_seq -   *** Example ***
01/08/2024 11:22:54 - INFO - processors.ner_seq -   guid: train-2
01/08/2024 11:22:54 - INFO - processors.ner_seq -   tokens: [CLS] 今 天 下 午 起 来 看 到 外 面 的 太 阳 。 。 。 。 我 第 一 反 应 竟 然 是 强 烈 的 想 回 家 泪 想 我 们 一 起 在 嘉 鱼 个 时 候 了 。 。 。 。 有 好 多 好 多 的 话 想 对 你 说 李 巾 凡 想 要 瘦 瘦 瘦 成 李 帆 我 是 想 切 开 云 朵 的 心 [SEP]
01/08/2024 11:22:54 - INFO - processors.ner_seq -   input_ids: 101 791 1921 678 1286 6629 3341 4692 1168 1912 7481 4638 1922 7345 511 511 511 511 2769 5018 671 1353 2418 4994 4197 3221 2487 4164 4638 2682 1726 2157 3801 2682 2769 812 671 6629 1762 1649 7824 702 3198 952 749 511 511 511 511 3300 1962 1914 1962 1914 4638 6413 2682 2190 872 6432 3330 2353 1127 2682 6206 4607 4607 4607 2768 3330 2359 2769 3221 2682 1147 2458 756 3321 4638 2552 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/08/2024 11:22:54 - INFO - processors.ner_seq -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/08/2024 11:22:54 - INFO - processors.ner_seq -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/08/2024 11:22:54 - INFO - processors.ner_seq -   label_ids: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 8 9 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 5 5 1 1 1 1 1 1 4 5 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/08/2024 11:22:54 - INFO - processors.ner_seq -   idx: 1
01/08/2024 11:22:54 - INFO - processors.ner_seq -   tag_to_spans: defaultdict(<class 'list'>, {6: [[12, 13], [31, 32]], 1: [[2, 4], [12, 14], [62, 64], [75, 77], [76, 78]], 2: [[69, 71], [75, 77]]})
01/08/2024 11:22:54 - INFO - processors.ner_seq -   *** Example ***
01/08/2024 11:22:54 - INFO - processors.ner_seq -   guid: train-3
01/08/2024 11:22:54 - INFO - processors.ner_seq -   tokens: [CLS] 今 年 拜 年 不 短 信 ， 就 在 微 博 拜 大 年 寻 龙 记 [SEP]
01/08/2024 11:22:54 - INFO - processors.ner_seq -   input_ids: 101 791 2399 2876 2399 679 4764 928 8024 2218 1762 2544 1300 2876 1920 2399 2192 7987 6381 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/08/2024 11:22:54 - INFO - processors.ner_seq -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/08/2024 11:22:54 - INFO - processors.ner_seq -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/08/2024 11:22:54 - INFO - processors.ner_seq -   label_ids: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/08/2024 11:22:54 - INFO - processors.ner_seq -   idx: 2
01/08/2024 11:22:54 - INFO - processors.ner_seq -   tag_to_spans: defaultdict(<class 'list'>, {1: [[16, 18], [17, 19], [16, 19]]})
01/08/2024 11:22:54 - INFO - processors.ner_seq -   *** Example ***
01/08/2024 11:22:54 - INFO - processors.ner_seq -   guid: train-4
01/08/2024 11:22:54 - INFO - processors.ner_seq -   tokens: [CLS] 浑 身 酸 疼 ， 两 腿 无 力 ， 眼 神 呆 滞 ， 怎 么 了 [SEP]
01/08/2024 11:22:54 - INFO - processors.ner_seq -   input_ids: 101 3847 6716 7000 4563 8024 697 5597 3187 1213 8024 4706 4868 1438 4005 8024 2582 720 749 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/08/2024 11:22:54 - INFO - processors.ner_seq -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/08/2024 11:22:54 - INFO - processors.ner_seq -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/08/2024 11:22:54 - INFO - processors.ner_seq -   label_ids: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/08/2024 11:22:54 - INFO - processors.ner_seq -   idx: 3
01/08/2024 11:22:54 - INFO - processors.ner_seq -   tag_to_spans: defaultdict(<class 'list'>, {6: [[12, 13]]})
01/08/2024 11:22:54 - INFO - processors.ner_seq -   *** Example ***
01/08/2024 11:22:54 - INFO - processors.ner_seq -   guid: train-5
01/08/2024 11:22:54 - INFO - processors.ner_seq -   tokens: [CLS] 明 显 紧 张 状 态 没 出 来 ， 失 误 多 。 [SEP]
01/08/2024 11:22:54 - INFO - processors.ner_seq -   input_ids: 101 3209 3227 5165 2476 4307 2578 3766 1139 3341 8024 1927 6428 1914 511 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/08/2024 11:22:54 - INFO - processors.ner_seq -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/08/2024 11:22:54 - INFO - processors.ner_seq -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/08/2024 11:22:54 - INFO - processors.ner_seq -   label_ids: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/08/2024 11:22:54 - INFO - processors.ner_seq -   idx: 4
01/08/2024 11:22:54 - INFO - processors.ner_seq -   tag_to_spans: defaultdict(<class 'list'>, {})
  9%|▉         | 125/1349 [00:00<00:06, 190.59it/s] 26%|██▌       | 346/1349 [00:00<00:01, 551.64it/s] 40%|████      | 546/1349 [00:00<00:00, 845.96it/s] 53%|█████▎    | 712/1349 [00:00<00:00, 1008.33it/s] 65%|██████▍   | 873/1349 [00:01<00:00, 1111.95it/s] 76%|███████▌  | 1026/1349 [00:01<00:00, 1118.72it/s] 86%|████████▋ | 1166/1349 [00:01<00:00, 1105.24it/s] 96%|█████████▌| 1295/1349 [00:01<00:00, 1139.77it/s]100%|██████████| 1349/1349 [00:01<00:00, 905.34it/s] 
01/08/2024 11:22:58 - INFO - root -   Saving features into cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-train_roberta-large-chinese_128_weibo
01/08/2024 11:22:58 - INFO - root -   The model with entity_enumerator
/mnt/storage/wubinghong.wbh/project/pytorch-3.8/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning
  warnings.warn(
01/08/2024 11:22:58 - INFO - root -   ***** Running training *****
01/08/2024 11:22:58 - INFO - root -     Num examples = 1349
01/08/2024 11:22:58 - INFO - root -     Num Epochs = 50
01/08/2024 11:22:58 - INFO - root -     Instantaneous batch size per GPU = 24
01/08/2024 11:22:58 - INFO - root -     Total train batch size (w. parallel, distributed & accumulation) = 24
01/08/2024 11:22:58 - INFO - root -     Gradient Accumulation steps = 1
01/08/2024 11:22:58 - INFO - root -     Total optimization steps = 2850
01/08/2024 11:22:58 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 0/50
[Training] 1/57 [..............................] - ETA: 3:00  [ loss=190.7035 ][Training] 2/57 [>.............................] - ETA: 2:08  [ loss=211.2176 ][Training] 3/57 [>.............................] - ETA: 1:54  [ loss=208.0665 ][Training] 4/57 [=>............................] - ETA: 1:42  [ loss=176.3046 ][Training] 5/57 [=>............................] - ETA: 1:40  [ loss=232.0140 ][Training] 6/57 [==>...........................] - ETA: 1:35  [ loss=212.2842 ][Training] 7/57 [==>...........................] - ETA: 1:31  [ loss=236.0681 ][Training] 8/57 [===>..........................] - ETA: 1:28  [ loss=174.4463 ][Training] 9/57 [===>..........................] - ETA: 1:26  [ loss=208.6559 ][Training] 10/57 [====>.........................] - ETA: 1:23  [ loss=193.3512 ][Training] 11/57 [====>.........................] - ETA: 1:21  [ loss=186.0283 ][Training] 12/57 [=====>........................] - ETA: 1:17  [ loss=189.2244 ][Training] 13/57 [=====>........................] - ETA: 1:15  [ loss=198.4108 ][Training] 14/57 [======>.......................] - ETA: 1:13  [ loss=193.6453 ][Training] 15/57 [======>.......................] - ETA: 1:10  [ loss=159.3823 ][Training] 16/57 [=======>......................] - ETA: 1:07  [ loss=158.9298 ][Training] 17/57 [=======>......................] - ETA: 1:05  [ loss=180.2079 ][Training] 18/57 [========>.....................] - ETA: 1:03  [ loss=148.7408 ][Training] 19/57 [=========>....................] - ETA: 1:01  [ loss=177.5505 ][Training] 20/57 [=========>....................] - ETA: 59s  [ loss=168.7002 ][Training] 21/57 [==========>...................] - ETA: 56s  [ loss=154.6226 ][Training] 22/57 [==========>...................] - ETA: 55s  [ loss=182.7510 ][Training] 23/57 [===========>..................] - ETA: 53s  [ loss=145.8233 ][Training] 24/57 [===========>..................] - ETA: 51s  [ loss=159.8160 ][Training] 25/57 [============>.................] - ETA: 49s  [ loss=159.2827 ][Training] 26/57 [============>.................] - ETA: 48s  [ loss=199.9409 ][Training] 27/57 [=============>................] - ETA: 46s  [ loss=138.4615 ][Training] 28/57 [=============>................] - ETA: 44s  [ loss=184.9993 ][Training] 29/57 [==============>...............] - ETA: 43s  [ loss=137.5584 ][Training] 30/57 [==============>...............] - ETA: 41s  [ loss=171.5707 ][Training] 31/57 [===============>..............] - ETA: 39s  [ loss=154.6317 ][Training] 32/57 [===============>..............] - ETA: 38s  [ loss=129.1817 ][Training] 33/57 [================>.............] - ETA: 36s  [ loss=153.6777 ][Training] 34/57 [================>.............] - ETA: 35s  [ loss=149.1892 ][Training] 35/57 [=================>............] - ETA: 33s  [ loss=156.0319 ][Training] 36/57 [=================>............] - ETA: 31s  [ loss=107.9746 ][Training] 37/57 [==================>...........] - ETA: 30s  [ loss=129.5491 ][Training] 38/57 [===================>..........] - ETA: 28s  [ loss=179.6615 ][Training] 39/57 [===================>..........] - ETA: 27s  [ loss=135.5763 ][Training] 40/57 [====================>.........] - ETA: 26s  [ loss=165.6469 ][Training] 41/57 [====================>.........] - ETA: 24s  [ loss=150.9771 ][Training] 42/57 [=====================>........] - ETA: 22s  [ loss=132.2797 ][Training] 43/57 [=====================>........] - ETA: 21s  [ loss=178.6915 ][Training] 44/57 [======================>.......] - ETA: 19s  [ loss=146.2681 ][Training] 45/57 [======================>.......] - ETA: 18s  [ loss=136.4355 ][Training] 46/57 [=======================>......] - ETA: 16s  [ loss=149.8643 ][Training] 47/57 [=======================>......] - ETA: 15s  [ loss=144.8052 ][Training] 48/57 [========================>.....] - ETA: 13s  [ loss=154.2114 ][Training] 49/57 [========================>.....] - ETA: 12s  [ loss=148.4093 ][Training] 50/57 [=========================>....] - ETA: 10s  [ loss=131.4790 ][Training] 51/57 [=========================>....] - ETA: 9s  [ loss=115.7451 ][Training] 52/57 [==========================>...] - ETA: 7s  [ loss=145.8188 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=129.8028 ][Training] 54/57 [===========================>..] - ETA: 4s  [ loss=146.5208 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=133.5533 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=129.4888 ][Training] 57/57 [==============================] 1.5s/step  [ loss=174.1509 ]
/mnt/storage/wubinghong.wbh/deepl/torch_ner_new/models/layers/crf.py:233: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at ../aten/src/ATen/native/TensorCompare.cpp:493.)
  score = torch.where(mask[i].unsqueeze(1), next_score, score)
01/08/2024 11:24:22 - INFO - root -   Creating features from dataset file at /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/
 
  0%|          | 0/8 [00:00<?, ?it/s] 25%|██▌       | 2/8 [00:00<00:01,  4.81it/s] 38%|███▊      | 3/8 [00:02<00:04,  1.13it/s] 62%|██████▎   | 5/8 [00:04<00:03,  1.00s/it] 75%|███████▌  | 6/8 [00:16<00:08,  4.05s/it]100%|██████████| 8/8 [00:16<00:00,  2.05s/it]
  0%|          | 0/8 [00:00<?, ?it/s] 25%|██▌       | 2/8 [00:00<00:00,  9.43it/s] 38%|███▊      | 3/8 [00:01<00:02,  2.43it/s] 62%|██████▎   | 5/8 [00:01<00:01,  2.42it/s] 75%|███████▌  | 6/8 [00:06<00:03,  1.64s/it]100%|██████████| 8/8 [00:06<00:00,  1.19it/s]
['THUOCL_lishimingren', 'Company-Shorter-Form', 'Chinese_Names_Corpus', 'Tsingtao_roads', 'Organization-Names-Corpus', 'Company-Names-Corpus', 'relationship', 'THUOCL_diming']
  0%|          | 0/269 [00:00<?, ?it/s]01/08/2024 11:24:46 - INFO - processors.ner_seq -   Writing example 0 of 269
01/08/2024 11:24:46 - INFO - processors.ner_seq -   *** Example ***
01/08/2024 11:24:46 - INFO - processors.ner_seq -   guid: test-1
01/08/2024 11:24:46 - INFO - processors.ner_seq -   tokens: [CLS] 回 复 支 持 ， 赞 成 ， 哈 哈 米 八 吴 够 历 史 要 的 陈 小 奥 丁 丁 我 爱 小 肥 肥 一 族 大 头 仔 大 家 团 结 一 致 ， 誓 要 去 台 湾 饮 喜 酒 ， 由 包 机 ， 团 结 的 力 量 大 [SEP]
01/08/2024 11:24:46 - INFO - processors.ner_seq -   input_ids: 101 1726 1908 3118 2898 8024 6614 2768 8024 1506 1506 5101 1061 1426 1916 1325 1380 6206 4638 7357 2207 1952 672 672 2769 4263 2207 5503 5503 671 3184 1920 1928 798 1920 2157 1730 5310 671 5636 8024 6292 6206 1343 1378 3968 7650 1599 6983 8024 4507 1259 3322 8024 1730 5310 4638 1213 7030 1920 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/08/2024 11:24:46 - INFO - processors.ner_seq -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/08/2024 11:24:46 - INFO - processors.ner_seq -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/08/2024 11:24:46 - INFO - processors.ner_seq -   label_ids: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 5 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 12 13 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/08/2024 11:24:46 - INFO - processors.ner_seq -   idx: 0
01/08/2024 11:24:46 - INFO - processors.ner_seq -   tag_to_spans: defaultdict(<class 'list'>, {6: [[27, 28], [28, 29], [32, 33], [33, 34], [35, 36], [27, 29], [29, 31], [31, 33], [32, 34], [34, 36]], 1: [[10, 12], [20, 22], [21, 23], [22, 24], [29, 31], [31, 33], [36, 38], [54, 56], [31, 34]], 0: [[44, 46], [44, 46], [19, 22]]})
01/08/2024 11:24:46 - INFO - processors.ner_seq -   *** Example ***
01/08/2024 11:24:46 - INFO - processors.ner_seq -   guid: test-2
01/08/2024 11:24:46 - INFO - processors.ner_seq -   tokens: [CLS] 剑 网 乱 世 长 安 公 测 盛 典 今 日 开 启 ， 海 量 豪 礼 火 爆 开 送 精 美 挂 件 、 听 雨 · 汉 服 娃 娃 、 诙 谐 双 骑 独 轮 车 等 你 来 拿 ， 更 有 千 台 红 米 手 机 、 等 十 四 重 惊 喜 转 发 即 抽 活 动 地 址 ： 已 有 人 参 与 剑 网 官 方 微 博 剑 网 客 户 服 务 [SEP]
01/08/2024 11:24:46 - INFO - processors.ner_seq -   input_ids: 101 1187 5381 744 686 7270 2128 1062 3844 4670 1073 791 3189 2458 1423 8024 3862 7030 6498 4851 4125 4255 2458 6843 5125 5401 2899 816 510 1420 7433 185 3727 3302 2015 2015 510 6410 6455 1352 7744 4324 6762 6756 5023 872 3341 2897 8024 3291 3300 1283 1378 5273 5101 2797 3322 510 5023 1282 1724 7028 2661 1599 6760 1355 1315 2853 3833 1220 1765 1770 8038 2347 3300 782 1346 680 1187 5381 2135 3175 2544 1300 1187 5381 2145 2787 3302 1218 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/08/2024 11:24:46 - INFO - processors.ner_seq -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/08/2024 11:24:46 - INFO - processors.ner_seq -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/08/2024 11:24:46 - INFO - processors.ner_seq -   label_ids: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/08/2024 11:24:46 - INFO - processors.ner_seq -   idx: 1
01/08/2024 11:24:46 - INFO - processors.ner_seq -   tag_to_spans: defaultdict(<class 'list'>, {6: [[7, 8], [34, 35], [35, 36], [75, 76], [34, 36], [59, 61]], 1: [[9, 11], [16, 18], [18, 20], [32, 34], [52, 54], [53, 55], [85, 87], [32, 36]], 7: [[51, 53]], 2: [[81, 83]]})
01/08/2024 11:24:46 - INFO - processors.ner_seq -   *** Example ***
01/08/2024 11:24:46 - INFO - processors.ner_seq -   guid: test-3
01/08/2024 11:24:46 - INFO - processors.ner_seq -   tokens: [CLS] 在 街 上 听 见 音 乐 我 舞 动 起 来 很 丢 人 ？ 真 的 很 丢 人 吗 ？ [SEP]
01/08/2024 11:24:46 - INFO - processors.ner_seq -   input_ids: 101 1762 6125 677 1420 6224 7509 727 2769 5659 1220 6629 3341 2523 696 782 8043 4696 4638 2523 696 782 1408 8043 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/08/2024 11:24:46 - INFO - processors.ner_seq -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/08/2024 11:24:46 - INFO - processors.ner_seq -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/08/2024 11:24:46 - INFO - processors.ner_seq -   label_ids: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/08/2024 11:24:46 - INFO - processors.ner_seq -   idx: 2
01/08/2024 11:24:46 - INFO - processors.ner_seq -   tag_to_spans: defaultdict(<class 'list'>, {6: [[15, 16], [21, 22]], 1: [[7, 9], [10, 13]]})
01/08/2024 11:24:46 - INFO - processors.ner_seq -   *** Example ***
01/08/2024 11:24:46 - INFO - processors.ner_seq -   guid: test-4
01/08/2024 11:24:46 - INFO - processors.ner_seq -   tokens: [CLS] 三 毛 说 我 唯 一 锲 而 不 舍 ， 愿 意 以 自 己 的 生 命 去 努 力 的 ， 只 不 过 是 保 守 我 个 人 的 心 怀 意 念 ， 在 我 有 生 之 日 ， 做 一 个 真 诚 的 人 ， 不 放 弃 对 生 活 的 热 爱 和 执 着 ， 在 有 限 的 时 空 里 ， 过 无 限 广 [SEP]
01/08/2024 11:24:46 - INFO - processors.ner_seq -   input_ids: 101 676 3688 6432 2769 1546 671 7244 5445 679 5650 8024 2703 2692 809 5632 2346 4638 4495 1462 1343 1222 1213 4638 8024 1372 679 6814 3221 924 2127 2769 702 782 4638 2552 2577 2692 2573 8024 1762 2769 3300 4495 722 3189 8024 976 671 702 4696 6411 4638 782 8024 679 3123 2461 2190 4495 3833 4638 4178 4263 1469 2809 4708 8024 1762 3300 7361 4638 3198 4958 7027 8024 6814 3187 7361 2408 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/08/2024 11:24:46 - INFO - processors.ner_seq -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/08/2024 11:24:46 - INFO - processors.ner_seq -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/08/2024 11:24:46 - INFO - processors.ner_seq -   label_ids: 1 4 5 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/08/2024 11:24:46 - INFO - processors.ner_seq -   idx: 3
01/08/2024 11:24:46 - INFO - processors.ner_seq -   tag_to_spans: defaultdict(<class 'list'>, {6: [[2, 3], [33, 34], [53, 54]], 0: [[1, 3], [1, 3]], 1: [[1, 3], [5, 7], [37, 39], [50, 52], [63, 65]]})
01/08/2024 11:24:46 - INFO - processors.ner_seq -   *** Example ***
01/08/2024 11:24:46 - INFO - processors.ner_seq -   guid: test-5
01/08/2024 11:24:46 - INFO - processors.ner_seq -   tokens: [CLS] 星 期 天 的 早 晨 七 点 学 车 ， 驾 校 太 给 力 。 我 的 头 发 都 没 有 洗 [SEP]
01/08/2024 11:24:46 - INFO - processors.ner_seq -   input_ids: 101 3215 3309 1921 4638 3193 3247 673 4157 2110 6756 8024 7730 3413 1922 5314 1213 511 2769 4638 1928 1355 6963 3766 3300 3819 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/08/2024 11:24:46 - INFO - processors.ner_seq -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/08/2024 11:24:46 - INFO - processors.ner_seq -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/08/2024 11:24:46 - INFO - processors.ner_seq -   label_ids: 1 1 1 1 1 1 1 1 1 1 1 1 18 19 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
01/08/2024 11:24:46 - INFO - processors.ner_seq -   idx: 4
01/08/2024 11:24:46 - INFO - processors.ner_seq -   tag_to_spans: defaultdict(<class 'list'>, {6: [[14, 15], [20, 21]], 1: [[7, 9], [9, 11], [15, 17], [21, 23], [1, 4]]})
  5%|▌         | 14/269 [00:00<00:10, 24.09it/s] 63%|██████▎   | 170/269 [00:00<00:00, 327.10it/s]100%|██████████| 269/269 [00:00<00:00, 352.80it/s]
01/08/2024 11:24:48 - INFO - root -   Saving features into cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/08/2024 11:24:49 - INFO - root -   ***** Running evaluation on test dataset  *****
01/08/2024 11:24:49 - INFO - root -     Num examples = 269
01/08/2024 11:24:49 - INFO - root -     Batch size = 24
[Evaluating] 1/12 [=>............................] - ETA: 11s[Evaluating] 2/12 [====>.........................] - ETA: 8s[Evaluating] 3/12 [======>.......................] - ETA: 7s[Evaluating] 4/12 [=========>....................] - ETA: 6s[Evaluating] 5/12 [===========>..................] - ETA: 5s[Evaluating] 6/12 [==============>...............] - ETA: 4s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 2s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 658.8ms/step
01/08/2024 11:24:57 - INFO - root -   

01/08/2024 11:24:57 - INFO - root -   ***** Eval results  *****
01/08/2024 11:24:57 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 - loss: 127.0755 
01/08/2024 11:24:57 - INFO - root -   ***** Entity results  *****
01/08/2024 11:24:57 - INFO - root -   ******* GPE.NAM results ********
01/08/2024 11:24:57 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:24:57 - INFO - root -   ******* GPE.NOM results ********
01/08/2024 11:24:57 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:24:57 - INFO - root -   ******* LOC.NAM results ********
01/08/2024 11:24:57 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:24:57 - INFO - root -   ******* LOC.NOM results ********
01/08/2024 11:24:57 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:24:57 - INFO - root -   ******* ORG.NAM results ********
01/08/2024 11:24:57 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:24:57 - INFO - root -   ******* ORG.NOM results ********
01/08/2024 11:24:57 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:24:57 - INFO - root -   ******* PER.NAM results ********
01/08/2024 11:24:57 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:24:57 - INFO - root -   ******* PER.NOM results ********
01/08/2024 11:24:57 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:25:02 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-57
01/08/2024 11:25:02 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-57
01/08/2024 11:25:02 - INFO - root -   

01/08/2024 11:25:02 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 1/50
[Training] 1/57 [..............................] - ETA: 1:15  [ loss=147.3669 ][Training] 2/57 [>.............................] - ETA: 1:19  [ loss=146.5212 ][Training] 3/57 [>.............................] - ETA: 1:22  [ loss=122.6064 ][Training] 4/57 [=>............................] - ETA: 1:15  [ loss=100.4757 ][Training] 5/57 [=>............................] - ETA: 1:14  [ loss=109.3955 ][Training] 6/57 [==>...........................] - ETA: 1:12  [ loss=105.3735 ][Training] 7/57 [==>...........................] - ETA: 1:13  [ loss=146.6556 ][Training] 8/57 [===>..........................] - ETA: 1:11  [ loss=104.9570 ][Training] 9/57 [===>..........................] - ETA: 1:09  [ loss=118.0272 ][Training] 10/57 [====>.........................] - ETA: 1:07  [ loss=105.8630 ][Training] 11/57 [====>.........................] - ETA: 1:05  [ loss=118.6420 ][Training] 12/57 [=====>........................] - ETA: 1:03  [ loss=114.5129 ][Training] 13/57 [=====>........................] - ETA: 1:03  [ loss=133.6096 ][Training] 14/57 [======>.......................] - ETA: 1:01  [ loss=99.0918 ][Training] 15/57 [======>.......................] - ETA: 59s  [ loss=127.1162 ][Training] 16/57 [=======>......................] - ETA: 58s  [ loss=102.6164 ][Training] 17/57 [=======>......................] - ETA: 58s  [ loss=122.1505 ][Training] 18/57 [========>.....................] - ETA: 57s  [ loss=141.8143 ][Training] 19/57 [=========>....................] - ETA: 55s  [ loss=105.5424 ][Training] 20/57 [=========>....................] - ETA: 54s  [ loss=109.3346 ][Training] 21/57 [==========>...................] - ETA: 52s  [ loss=107.3543 ][Training] 22/57 [==========>...................] - ETA: 51s  [ loss=107.7971 ][Training] 23/57 [===========>..................] - ETA: 49s  [ loss=108.0915 ][Training] 24/57 [===========>..................] - ETA: 48s  [ loss=118.8510 ][Training] 25/57 [============>.................] - ETA: 46s  [ loss=83.9855 ][Training] 26/57 [============>.................] - ETA: 45s  [ loss=94.8032 ][Training] 27/57 [=============>................] - ETA: 43s  [ loss=109.3402 ][Training] 28/57 [=============>................] - ETA: 42s  [ loss=104.5283 ][Training] 29/57 [==============>...............] - ETA: 40s  [ loss=98.9277 ][Training] 30/57 [==============>...............] - ETA: 39s  [ loss=83.9612 ][Training] 31/57 [===============>..............] - ETA: 37s  [ loss=94.7377 ][Training] 32/57 [===============>..............] - ETA: 36s  [ loss=104.6064 ][Training] 33/57 [================>.............] - ETA: 34s  [ loss=91.2243 ][Training] 34/57 [================>.............] - ETA: 33s  [ loss=94.8738 ][Training] 35/57 [=================>............] - ETA: 31s  [ loss=106.0467 ][Training] 36/57 [=================>............] - ETA: 30s  [ loss=91.0011 ][Training] 37/57 [==================>...........] - ETA: 29s  [ loss=107.0911 ][Training] 38/57 [===================>..........] - ETA: 27s  [ loss=84.1435 ][Training] 39/57 [===================>..........] - ETA: 26s  [ loss=100.6959 ][Training] 40/57 [====================>.........] - ETA: 24s  [ loss=87.2408 ][Training] 41/57 [====================>.........] - ETA: 23s  [ loss=96.8519 ][Training] 42/57 [=====================>........] - ETA: 21s  [ loss=86.0334 ][Training] 43/57 [=====================>........] - ETA: 20s  [ loss=98.1769 ][Training] 44/57 [======================>.......] - ETA: 18s  [ loss=94.1697 ][Training] 45/57 [======================>.......] - ETA: 17s  [ loss=83.7833 ][Training] 46/57 [=======================>......] - ETA: 15s  [ loss=71.2909 ][Training] 47/57 [=======================>......] - ETA: 14s  [ loss=71.5628 ][Training] 48/57 [========================>.....] - ETA: 13s  [ loss=86.5608 ][Training] 49/57 [========================>.....] - ETA: 11s  [ loss=88.6233 ][Training] 50/57 [=========================>....] - ETA: 10s  [ loss=90.3651 ][Training] 51/57 [=========================>....] - ETA: 8s  [ loss=87.9172 ][Training] 52/57 [==========================>...] - ETA: 7s  [ loss=78.4902 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=92.5370 ][Training] 54/57 [===========================>..] - ETA: 4s  [ loss=71.5658 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=73.8516 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=86.2314 ][Training] 57/57 [==============================] 1.5s/step  [ loss=81.6566 ]
01/08/2024 11:26:26 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/08/2024 11:26:26 - INFO - root -   ***** Running evaluation on test dataset  *****
01/08/2024 11:26:26 - INFO - root -     Num examples = 269
01/08/2024 11:26:26 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 8s[Evaluating] 2/12 [====>.........................] - ETA: 8s[Evaluating] 3/12 [======>.......................] - ETA: 7s[Evaluating] 4/12 [=========>....................] - ETA: 6s[Evaluating] 5/12 [===========>..................] - ETA: 5s[Evaluating] 6/12 [==============>...............] - ETA: 4s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 3s[Evaluating] 9/12 [=====================>........] - ETA: 2s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 749.5ms/step
01/08/2024 11:26:35 - INFO - root -   

01/08/2024 11:26:35 - INFO - root -   ***** Eval results  *****
01/08/2024 11:26:35 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 - loss: 66.4319 
01/08/2024 11:26:35 - INFO - root -   ***** Entity results  *****
01/08/2024 11:26:35 - INFO - root -   ******* GPE.NAM results ********
01/08/2024 11:26:35 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:26:35 - INFO - root -   ******* GPE.NOM results ********
01/08/2024 11:26:35 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:26:35 - INFO - root -   ******* LOC.NAM results ********
01/08/2024 11:26:35 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:26:35 - INFO - root -   ******* LOC.NOM results ********
01/08/2024 11:26:35 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:26:35 - INFO - root -   ******* ORG.NAM results ********
01/08/2024 11:26:35 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:26:35 - INFO - root -   ******* ORG.NOM results ********
01/08/2024 11:26:35 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:26:35 - INFO - root -   ******* PER.NAM results ********
01/08/2024 11:26:35 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:26:35 - INFO - root -   ******* PER.NOM results ********
01/08/2024 11:26:35 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:26:42 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-114
01/08/2024 11:26:42 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-114
01/08/2024 11:26:42 - INFO - root -   

01/08/2024 11:26:42 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 2/50
[Training] 1/57 [..............................] - ETA: 1:39  [ loss=73.4621 ][Training] 2/57 [>.............................] - ETA: 1:34  [ loss=69.4363 ][Training] 3/57 [>.............................] - ETA: 1:31  [ loss=54.7449 ][Training] 4/57 [=>............................] - ETA: 1:31  [ loss=66.1707 ][Training] 5/57 [=>............................] - ETA: 1:32  [ loss=68.5851 ][Training] 6/57 [==>...........................] - ETA: 1:30  [ loss=71.2747 ][Training] 7/57 [==>...........................] - ETA: 1:31  [ loss=88.4062 ][Training] 8/57 [===>..........................] - ETA: 1:26  [ loss=71.1577 ][Training] 9/57 [===>..........................] - ETA: 1:23  [ loss=76.9738 ][Training] 10/57 [====>.........................] - ETA: 1:20  [ loss=65.3150 ][Training] 11/57 [====>.........................] - ETA: 1:20  [ loss=73.9193 ][Training] 12/57 [=====>........................] - ETA: 1:17  [ loss=58.6325 ][Training] 13/57 [=====>........................] - ETA: 1:16  [ loss=64.5816 ][Training] 14/57 [======>.......................] - ETA: 1:13  [ loss=65.8992 ][Training] 15/57 [======>.......................] - ETA: 1:10  [ loss=43.8195 ][Training] 16/57 [=======>......................] - ETA: 1:08  [ loss=55.1517 ][Training] 17/57 [=======>......................] - ETA: 1:07  [ loss=65.7037 ][Training] 18/57 [========>.....................] - ETA: 1:06  [ loss=79.8773 ][Training] 19/57 [=========>....................] - ETA: 1:05  [ loss=58.6215 ][Training] 20/57 [=========>....................] - ETA: 1:02  [ loss=50.5062 ][Training] 21/57 [==========>...................] - ETA: 1:00  [ loss=63.3381 ][Training] 22/57 [==========>...................] - ETA: 58s  [ loss=62.2327 ][Training] 23/57 [===========>..................] - ETA: 57s  [ loss=65.6102 ][Training] 24/57 [===========>..................] - ETA: 56s  [ loss=49.6736 ][Training] 25/57 [============>.................] - ETA: 54s  [ loss=40.4807 ][Training] 26/57 [============>.................] - ETA: 52s  [ loss=50.0180 ][Training] 27/57 [=============>................] - ETA: 50s  [ loss=54.6444 ][Training] 28/57 [=============>................] - ETA: 48s  [ loss=50.6585 ][Training] 29/57 [==============>...............] - ETA: 47s  [ loss=47.9522 ][Training] 30/57 [==============>...............] - ETA: 45s  [ loss=59.9557 ][Training] 31/57 [===============>..............] - ETA: 43s  [ loss=56.3777 ][Training] 32/57 [===============>..............] - ETA: 41s  [ loss=57.5992 ][Training] 33/57 [================>.............] - ETA: 39s  [ loss=47.6853 ][Training] 34/57 [================>.............] - ETA: 37s  [ loss=56.4899 ][Training] 35/57 [=================>............] - ETA: 35s  [ loss=52.9444 ][Training] 36/57 [=================>............] - ETA: 33s  [ loss=45.1863 ][Training] 37/57 [==================>...........] - ETA: 31s  [ loss=39.1454 ][Training] 38/57 [===================>..........] - ETA: 30s  [ loss=40.1447 ][Training] 39/57 [===================>..........] - ETA: 28s  [ loss=52.7520 ][Training] 40/57 [====================>.........] - ETA: 26s  [ loss=50.3923 ][Training] 41/57 [====================>.........] - ETA: 24s  [ loss=47.3833 ][Training] 42/57 [=====================>........] - ETA: 23s  [ loss=54.2174 ][Training] 43/57 [=====================>........] - ETA: 21s  [ loss=57.4098 ][Training] 44/57 [======================>.......] - ETA: 19s  [ loss=41.2506 ][Training] 45/57 [======================>.......] - ETA: 18s  [ loss=38.7208 ][Training] 46/57 [=======================>......] - ETA: 16s  [ loss=43.3237 ][Training] 47/57 [=======================>......] - ETA: 15s  [ loss=52.5940 ][Training] 48/57 [========================>.....] - ETA: 13s  [ loss=42.0238 ][Training] 49/57 [========================>.....] - ETA: 12s  [ loss=40.3729 ][Training] 50/57 [=========================>....] - ETA: 10s  [ loss=41.7144 ][Training] 51/57 [=========================>....] - ETA: 9s  [ loss=45.5774 ][Training] 52/57 [==========================>...] - ETA: 7s  [ loss=36.9624 ][Training] 53/57 [==========================>...] - ETA: 5s  [ loss=30.8166 ][Training] 54/57 [===========================>..] - ETA: 4s  [ loss=41.8891 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=36.9730 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=28.1392 ][Training] 57/57 [==============================] 1.5s/step  [ loss=58.3271 ]
01/08/2024 11:28:06 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/08/2024 11:28:06 - INFO - root -   ***** Running evaluation on test dataset  *****
01/08/2024 11:28:06 - INFO - root -     Num examples = 269
01/08/2024 11:28:06 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 5s[Evaluating] 2/12 [====>.........................] - ETA: 7s[Evaluating] 3/12 [======>.......................] - ETA: 6s[Evaluating] 4/12 [=========>....................] - ETA: 5s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 4s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 2s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 690.9ms/step
01/08/2024 11:28:14 - INFO - root -   

01/08/2024 11:28:14 - INFO - root -   ***** Eval results  *****
01/08/2024 11:28:14 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 - loss: 31.8356 
01/08/2024 11:28:14 - INFO - root -   ***** Entity results  *****
01/08/2024 11:28:14 - INFO - root -   ******* GPE.NAM results ********
01/08/2024 11:28:14 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:28:14 - INFO - root -   ******* GPE.NOM results ********
01/08/2024 11:28:14 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:28:14 - INFO - root -   ******* LOC.NAM results ********
01/08/2024 11:28:14 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:28:14 - INFO - root -   ******* LOC.NOM results ********
01/08/2024 11:28:14 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:28:14 - INFO - root -   ******* ORG.NAM results ********
01/08/2024 11:28:14 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:28:14 - INFO - root -   ******* ORG.NOM results ********
01/08/2024 11:28:14 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:28:14 - INFO - root -   ******* PER.NAM results ********
01/08/2024 11:28:14 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:28:14 - INFO - root -   ******* PER.NOM results ********
01/08/2024 11:28:14 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:28:36 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-171
01/08/2024 11:28:36 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-171
01/08/2024 11:28:36 - INFO - root -   

01/08/2024 11:28:36 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 3/50
[Training] 1/57 [..............................] - ETA: 1:33  [ loss=39.3491 ][Training] 2/57 [>.............................] - ETA: 1:49  [ loss=47.2170 ][Training] 3/57 [>.............................] - ETA: 1:53  [ loss=53.6124 ][Training] 4/57 [=>............................] - ETA: 1:46  [ loss=38.4818 ][Training] 5/57 [=>............................] - ETA: 1:42  [ loss=30.7100 ][Training] 6/57 [==>...........................] - ETA: 1:38  [ loss=29.9424 ][Training] 7/57 [==>...........................] - ETA: 1:35  [ loss=34.7619 ][Training] 8/57 [===>..........................] - ETA: 1:31  [ loss=30.9564 ][Training] 9/57 [===>..........................] - ETA: 1:29  [ loss=29.1643 ][Training] 10/57 [====>.........................] - ETA: 1:30  [ loss=36.2081 ][Training] 11/57 [====>.........................] - ETA: 1:28  [ loss=31.9065 ][Training] 12/57 [=====>........................] - ETA: 1:25  [ loss=29.0614 ][Training] 13/57 [=====>........................] - ETA: 1:25  [ loss=36.8990 ][Training] 14/57 [======>.......................] - ETA: 1:22  [ loss=32.7400 ][Training] 15/57 [======>.......................] - ETA: 1:20  [ loss=32.9892 ][Training] 16/57 [=======>......................] - ETA: 1:17  [ loss=20.3464 ][Training] 17/57 [=======>......................] - ETA: 1:15  [ loss=24.6329 ][Training] 18/57 [========>.....................] - ETA: 1:14  [ loss=30.1736 ][Training] 19/57 [=========>....................] - ETA: 1:12  [ loss=30.3792 ][Training] 20/57 [=========>....................] - ETA: 1:10  [ loss=33.8435 ][Training] 21/57 [==========>...................] - ETA: 1:08  [ loss=32.4679 ][Training] 22/57 [==========>...................] - ETA: 1:06  [ loss=22.9808 ][Training] 23/57 [===========>..................] - ETA: 1:03  [ loss=25.7172 ][Training] 24/57 [===========>..................] - ETA: 1:02  [ loss=35.1204 ][Training] 25/57 [============>.................] - ETA: 1:00  [ loss=33.7688 ][Training] 26/57 [============>.................] - ETA: 58s  [ loss=24.4091 ][Training] 27/57 [=============>................] - ETA: 56s  [ loss=26.2202 ][Training] 28/57 [=============>................] - ETA: 54s  [ loss=30.4413 ][Training] 29/57 [==============>...............] - ETA: 51s  [ loss=17.0296 ][Training] 30/57 [==============>...............] - ETA: 49s  [ loss=21.7808 ][Training] 31/57 [===============>..............] - ETA: 48s  [ loss=29.7197 ][Training] 32/57 [===============>..............] - ETA: 46s  [ loss=26.6755 ][Training] 33/57 [================>.............] - ETA: 44s  [ loss=34.0745 ][Training] 34/57 [================>.............] - ETA: 42s  [ loss=24.1100 ][Training] 35/57 [=================>............] - ETA: 41s  [ loss=27.7543 ][Training] 36/57 [=================>............] - ETA: 39s  [ loss=34.9834 ][Training] 37/57 [==================>...........] - ETA: 37s  [ loss=27.3567 ][Training] 38/57 [===================>..........] - ETA: 35s  [ loss=21.4903 ][Training] 39/57 [===================>..........] - ETA: 34s  [ loss=25.1731 ][Training] 40/57 [====================>.........] - ETA: 32s  [ loss=22.0772 ][Training] 41/57 [====================>.........] - ETA: 30s  [ loss=28.1634 ][Training] 42/57 [=====================>........] - ETA: 28s  [ loss=27.2675 ][Training] 43/57 [=====================>........] - ETA: 26s  [ loss=26.2863 ][Training] 44/57 [======================>.......] - ETA: 24s  [ loss=20.5834 ][Training] 45/57 [======================>.......] - ETA: 22s  [ loss=24.1904 ][Training] 46/57 [=======================>......] - ETA: 20s  [ loss=22.5576 ][Training] 47/57 [=======================>......] - ETA: 18s  [ loss=19.1825 ][Training] 48/57 [========================>.....] - ETA: 16s  [ loss=22.4232 ][Training] 49/57 [========================>.....] - ETA: 15s  [ loss=20.9053 ][Training] 50/57 [=========================>....] - ETA: 13s  [ loss=23.8438 ][Training] 51/57 [=========================>....] - ETA: 11s  [ loss=19.6088 ][Training] 52/57 [==========================>...] - ETA: 9s  [ loss=15.5013 ][Training] 53/57 [==========================>...] - ETA: 7s  [ loss=19.5991 ][Training] 54/57 [===========================>..] - ETA: 5s  [ loss=17.9378 ][Training] 55/57 [===========================>..] - ETA: 3s  [ loss=21.5002 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=15.3267 ][Training] 57/57 [==============================] 1.8s/step  [ loss=17.2313 ]
01/08/2024 11:30:21 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/08/2024 11:30:21 - INFO - root -   ***** Running evaluation on test dataset  *****
01/08/2024 11:30:21 - INFO - root -     Num examples = 269
01/08/2024 11:30:21 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 11s[Evaluating] 2/12 [====>.........................] - ETA: 9s[Evaluating] 3/12 [======>.......................] - ETA: 7s[Evaluating] 4/12 [=========>....................] - ETA: 7s[Evaluating] 5/12 [===========>..................] - ETA: 6s[Evaluating] 6/12 [==============>...............] - ETA: 5s[Evaluating] 7/12 [================>.............] - ETA: 4s[Evaluating] 8/12 [===================>..........] - ETA: 3s[Evaluating] 9/12 [=====================>........] - ETA: 2s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 850.8ms/step
01/08/2024 11:30:31 - INFO - root -   

01/08/2024 11:30:31 - INFO - root -   ***** Eval results  *****
01/08/2024 11:30:31 - INFO - root -    acc: 1.0000 - recall: 0.0048 - f1: 0.0096 - loss: 19.3057 
01/08/2024 11:30:31 - INFO - root -   ***** Entity results  *****
01/08/2024 11:30:31 - INFO - root -   ******* GPE.NAM results ********
01/08/2024 11:30:31 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:30:31 - INFO - root -   ******* GPE.NOM results ********
01/08/2024 11:30:31 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:30:31 - INFO - root -   ******* LOC.NAM results ********
01/08/2024 11:30:31 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:30:31 - INFO - root -   ******* LOC.NOM results ********
01/08/2024 11:30:31 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:30:31 - INFO - root -   ******* ORG.NAM results ********
01/08/2024 11:30:31 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:30:31 - INFO - root -   ******* ORG.NOM results ********
01/08/2024 11:30:31 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:30:31 - INFO - root -   ******* PER.NAM results ********
01/08/2024 11:30:31 - INFO - root -    acc: 1.0000 - recall: 0.0182 - f1: 0.0357 
01/08/2024 11:30:31 - INFO - root -   ******* PER.NOM results ********
01/08/2024 11:30:31 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:30:41 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-228
01/08/2024 11:30:41 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-228
01/08/2024 11:30:41 - INFO - root -   

01/08/2024 11:30:41 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 4/50
[Training] 1/57 [..............................] - ETA: 1:54  [ loss=21.2816 ][Training] 2/57 [>.............................] - ETA: 1:48  [ loss=17.6727 ][Training] 3/57 [>.............................] - ETA: 1:42  [ loss=24.0610 ][Training] 4/57 [=>............................] - ETA: 1:32  [ loss=18.5587 ][Training] 5/57 [=>............................] - ETA: 1:28  [ loss=19.5550 ][Training] 6/57 [==>...........................] - ETA: 1:23  [ loss=13.9359 ][Training] 7/57 [==>...........................] - ETA: 1:19  [ loss=14.0312 ][Training] 8/57 [===>..........................] - ETA: 1:17  [ loss=17.3681 ][Training] 9/57 [===>..........................] - ETA: 1:16  [ loss=18.0429 ][Training] 10/57 [====>.........................] - ETA: 1:17  [ loss=27.6271 ][Training] 11/57 [====>.........................] - ETA: 1:15  [ loss=16.8887 ][Training] 12/57 [=====>........................] - ETA: 1:14  [ loss=12.8100 ][Training] 13/57 [=====>........................] - ETA: 1:13  [ loss=18.6299 ][Training] 14/57 [======>.......................] - ETA: 1:12  [ loss=20.2745 ][Training] 15/57 [======>.......................] - ETA: 1:11  [ loss=14.1916 ][Training] 16/57 [=======>......................] - ETA: 1:09  [ loss=11.0818 ][Training] 17/57 [=======>......................] - ETA: 1:06  [ loss=12.7795 ][Training] 18/57 [========>.....................] - ETA: 1:04  [ loss=18.2846 ][Training] 19/57 [=========>....................] - ETA: 1:03  [ loss=22.4496 ][Training] 20/57 [=========>....................] - ETA: 1:01  [ loss=15.2185 ][Training] 21/57 [==========>...................] - ETA: 1:00  [ loss=13.4779 ][Training] 22/57 [==========>...................] - ETA: 59s  [ loss=16.0892 ][Training] 23/57 [===========>..................] - ETA: 58s  [ loss=20.8396 ][Training] 24/57 [===========>..................] - ETA: 56s  [ loss=21.2517 ][Training] 25/57 [============>.................] - ETA: 55s  [ loss=13.1398 ][Training] 26/57 [============>.................] - ETA: 54s  [ loss=12.3936 ][Training] 27/57 [=============>................] - ETA: 52s  [ loss=13.6539 ][Training] 28/57 [=============>................] - ETA: 50s  [ loss=18.3209 ][Training] 29/57 [==============>...............] - ETA: 48s  [ loss=22.4099 ][Training] 30/57 [==============>...............] - ETA: 47s  [ loss=14.6918 ][Training] 31/57 [===============>..............] - ETA: 45s  [ loss=21.9322 ][Training] 32/57 [===============>..............] - ETA: 44s  [ loss=17.2490 ][Training] 33/57 [================>.............] - ETA: 43s  [ loss=11.9158 ][Training] 34/57 [================>.............] - ETA: 41s  [ loss=18.4956 ][Training] 35/57 [=================>............] - ETA: 39s  [ loss=15.2706 ][Training] 36/57 [=================>............] - ETA: 37s  [ loss=13.4643 ][Training] 37/57 [==================>...........] - ETA: 36s  [ loss=18.3599 ][Training] 38/57 [===================>..........] - ETA: 34s  [ loss=14.9001 ][Training] 39/57 [===================>..........] - ETA: 33s  [ loss=22.4978 ][Training] 40/57 [====================>.........] - ETA: 31s  [ loss=15.3315 ][Training] 41/57 [====================>.........] - ETA: 29s  [ loss=13.1277 ][Training] 42/57 [=====================>........] - ETA: 27s  [ loss=12.7801 ][Training] 43/57 [=====================>........] - ETA: 25s  [ loss=15.4282 ][Training] 44/57 [======================>.......] - ETA: 23s  [ loss=13.1964 ][Training] 45/57 [======================>.......] - ETA: 22s  [ loss=17.2512 ][Training] 46/57 [=======================>......] - ETA: 20s  [ loss=18.4983 ][Training] 47/57 [=======================>......] - ETA: 18s  [ loss=22.4763 ][Training] 48/57 [========================>.....] - ETA: 16s  [ loss=17.6538 ][Training] 49/57 [========================>.....] - ETA: 14s  [ loss=12.3616 ][Training] 50/57 [=========================>....] - ETA: 13s  [ loss=12.5144 ][Training] 51/57 [=========================>....] - ETA: 11s  [ loss=12.5215 ][Training] 52/57 [==========================>...] - ETA: 9s  [ loss=23.1245 ][Training] 53/57 [==========================>...] - ETA: 7s  [ loss=13.2089 ][Training] 54/57 [===========================>..] - ETA: 5s  [ loss=9.3991 ][Training] 55/57 [===========================>..] - ETA: 3s  [ loss=13.1311 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=15.0013 ][Training] 57/57 [==============================] 1.8s/step  [ loss=7.8945 ]
01/08/2024 11:32:26 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/08/2024 11:32:26 - INFO - root -   ***** Running evaluation on test dataset  *****
01/08/2024 11:32:26 - INFO - root -     Num examples = 269
01/08/2024 11:32:26 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 10s[Evaluating] 2/12 [====>.........................] - ETA: 8s[Evaluating] 3/12 [======>.......................] - ETA: 7s[Evaluating] 4/12 [=========>....................] - ETA: 6s[Evaluating] 5/12 [===========>..................] - ETA: 5s[Evaluating] 6/12 [==============>...............] - ETA: 4s[Evaluating] 7/12 [================>.............] - ETA: 4s[Evaluating] 8/12 [===================>..........] - ETA: 3s[Evaluating] 9/12 [=====================>........] - ETA: 2s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 824.8ms/step
01/08/2024 11:32:36 - INFO - root -   

01/08/2024 11:32:36 - INFO - root -   ***** Eval results  *****
01/08/2024 11:32:36 - INFO - root -    acc: 0.8293 - recall: 0.0823 - f1: 0.1498 - loss: 13.7716 
01/08/2024 11:32:36 - INFO - root -   ***** Entity results  *****
01/08/2024 11:32:36 - INFO - root -   ******* GPE.NAM results ********
01/08/2024 11:32:36 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:32:36 - INFO - root -   ******* GPE.NOM results ********
01/08/2024 11:32:36 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:32:36 - INFO - root -   ******* LOC.NAM results ********
01/08/2024 11:32:36 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:32:36 - INFO - root -   ******* LOC.NOM results ********
01/08/2024 11:32:36 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:32:36 - INFO - root -   ******* ORG.NAM results ********
01/08/2024 11:32:36 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:32:36 - INFO - root -   ******* ORG.NOM results ********
01/08/2024 11:32:36 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:32:36 - INFO - root -   ******* PER.NAM results ********
01/08/2024 11:32:36 - INFO - root -    acc: 0.8293 - recall: 0.3091 - f1: 0.4503 
01/08/2024 11:32:36 - INFO - root -   ******* PER.NOM results ********
01/08/2024 11:32:36 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:32:43 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-285
01/08/2024 11:32:43 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-285
01/08/2024 11:32:43 - INFO - root -   

01/08/2024 11:32:43 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 5/50
[Training] 1/57 [..............................] - ETA: 1:42  [ loss=7.7704 ][Training] 2/57 [>.............................] - ETA: 1:43  [ loss=12.1534 ][Training] 3/57 [>.............................] - ETA: 1:45  [ loss=13.6834 ][Training] 4/57 [=>............................] - ETA: 1:38  [ loss=10.7644 ][Training] 5/57 [=>............................] - ETA: 1:34  [ loss=12.5189 ][Training] 6/57 [==>...........................] - ETA: 1:37  [ loss=23.8991 ][Training] 7/57 [==>...........................] - ETA: 1:34  [ loss=10.8814 ][Training] 8/57 [===>..........................] - ETA: 1:28  [ loss=7.0937 ][Training] 9/57 [===>..........................] - ETA: 1:26  [ loss=10.5457 ][Training] 10/57 [====>.........................] - ETA: 1:27  [ loss=13.7321 ][Training] 11/57 [====>.........................] - ETA: 1:28  [ loss=12.9912 ][Training] 12/57 [=====>........................] - ETA: 1:26  [ loss=20.3132 ][Training] 13/57 [=====>........................] - ETA: 1:23  [ loss=11.2290 ][Training] 14/57 [======>.......................] - ETA: 1:21  [ loss=13.3527 ][Training] 15/57 [======>.......................] - ETA: 1:17  [ loss=11.6012 ][Training] 16/57 [=======>......................] - ETA: 1:14  [ loss=10.9608 ][Training] 17/57 [=======>......................] - ETA: 1:12  [ loss=10.8662 ][Training] 18/57 [========>.....................] - ETA: 1:10  [ loss=15.7818 ][Training] 19/57 [=========>....................] - ETA: 1:09  [ loss=14.6369 ][Training] 20/57 [=========>....................] - ETA: 1:07  [ loss=11.1766 ][Training] 21/57 [==========>...................] - ETA: 1:05  [ loss=8.1064 ][Training] 22/57 [==========>...................] - ETA: 1:03  [ loss=13.0752 ][Training] 23/57 [===========>..................] - ETA: 1:01  [ loss=9.4917 ][Training] 24/57 [===========>..................] - ETA: 1:00  [ loss=8.8025 ][Training] 25/57 [============>.................] - ETA: 59s  [ loss=14.1014 ][Training] 26/57 [============>.................] - ETA: 57s  [ loss=18.3541 ][Training] 27/57 [=============>................] - ETA: 55s  [ loss=10.6842 ][Training] 28/57 [=============>................] - ETA: 53s  [ loss=7.8070 ][Training] 29/57 [==============>...............] - ETA: 51s  [ loss=12.2959 ][Training] 30/57 [==============>...............] - ETA: 50s  [ loss=19.8455 ][Training] 31/57 [===============>..............] - ETA: 48s  [ loss=18.2591 ][Training] 32/57 [===============>..............] - ETA: 46s  [ loss=12.2113 ][Training] 33/57 [================>.............] - ETA: 44s  [ loss=8.1007 ][Training] 34/57 [================>.............] - ETA: 42s  [ loss=14.0581 ][Training] 35/57 [=================>............] - ETA: 41s  [ loss=6.6295 ][Training] 36/57 [=================>............] - ETA: 39s  [ loss=6.8825 ][Training] 37/57 [==================>...........] - ETA: 37s  [ loss=18.8664 ][Training] 38/57 [===================>..........] - ETA: 35s  [ loss=6.3941 ][Training] 39/57 [===================>..........] - ETA: 33s  [ loss=9.7751 ][Training] 40/57 [====================>.........] - ETA: 31s  [ loss=11.3966 ][Training] 41/57 [====================>.........] - ETA: 30s  [ loss=12.7358 ][Training] 42/57 [=====================>........] - ETA: 28s  [ loss=9.9665 ][Training] 43/57 [=====================>........] - ETA: 26s  [ loss=5.5047 ][Training] 44/57 [======================>.......] - ETA: 24s  [ loss=16.6225 ][Training] 45/57 [======================>.......] - ETA: 22s  [ loss=9.2863 ][Training] 46/57 [=======================>......] - ETA: 20s  [ loss=8.5374 ][Training] 47/57 [=======================>......] - ETA: 18s  [ loss=15.3588 ][Training] 48/57 [========================>.....] - ETA: 16s  [ loss=12.9041 ][Training] 49/57 [========================>.....] - ETA: 14s  [ loss=8.8766 ][Training] 50/57 [=========================>....] - ETA: 13s  [ loss=12.9917 ][Training] 51/57 [=========================>....] - ETA: 11s  [ loss=9.6714 ][Training] 52/57 [==========================>...] - ETA: 9s  [ loss=5.3312 ][Training] 53/57 [==========================>...] - ETA: 7s  [ loss=8.3191 ][Training] 54/57 [===========================>..] - ETA: 5s  [ loss=9.9131 ][Training] 55/57 [===========================>..] - ETA: 3s  [ loss=11.2313 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=6.5863 ][Training] 57/57 [==============================] 1.8s/step  [ loss=11.4764 ]
01/08/2024 11:34:28 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/08/2024 11:34:28 - INFO - root -   ***** Running evaluation on test dataset  *****
01/08/2024 11:34:28 - INFO - root -     Num examples = 269
01/08/2024 11:34:28 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 8s[Evaluating] 2/12 [====>.........................] - ETA: 9s[Evaluating] 3/12 [======>.......................] - ETA: 7s[Evaluating] 4/12 [=========>....................] - ETA: 7s[Evaluating] 5/12 [===========>..................] - ETA: 6s[Evaluating] 6/12 [==============>...............] - ETA: 5s[Evaluating] 7/12 [================>.............] - ETA: 4s[Evaluating] 8/12 [===================>..........] - ETA: 3s[Evaluating] 9/12 [=====================>........] - ETA: 2s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 831.6ms/step
01/08/2024 11:34:38 - INFO - root -   

01/08/2024 11:34:38 - INFO - root -   ***** Eval results  *****
01/08/2024 11:34:38 - INFO - root -    acc: 0.7477 - recall: 0.1937 - f1: 0.3077 - loss: 10.6385 
01/08/2024 11:34:38 - INFO - root -   ***** Entity results  *****
01/08/2024 11:34:38 - INFO - root -   ******* GPE.NAM results ********
01/08/2024 11:34:38 - INFO - root -    acc: 0.9000 - recall: 0.1915 - f1: 0.3158 
01/08/2024 11:34:38 - INFO - root -   ******* GPE.NOM results ********
01/08/2024 11:34:38 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:34:38 - INFO - root -   ******* LOC.NAM results ********
01/08/2024 11:34:38 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:34:38 - INFO - root -   ******* LOC.NOM results ********
01/08/2024 11:34:38 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:34:38 - INFO - root -   ******* ORG.NAM results ********
01/08/2024 11:34:38 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:34:38 - INFO - root -   ******* ORG.NOM results ********
01/08/2024 11:34:38 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:34:38 - INFO - root -   ******* PER.NAM results ********
01/08/2024 11:34:38 - INFO - root -    acc: 0.8033 - recall: 0.4455 - f1: 0.5731 
01/08/2024 11:34:38 - INFO - root -   ******* PER.NOM results ********
01/08/2024 11:34:38 - INFO - root -    acc: 0.6111 - recall: 0.1294 - f1: 0.2136 
01/08/2024 11:34:46 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-342
01/08/2024 11:34:46 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-342
01/08/2024 11:34:46 - INFO - root -   

01/08/2024 11:34:46 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 6/50
[Training] 1/57 [..............................] - ETA: 1:44  [ loss=10.6012 ][Training] 2/57 [>.............................] - ETA: 1:53  [ loss=11.4197 ][Training] 3/57 [>.............................] - ETA: 1:50  [ loss=9.0811 ][Training] 4/57 [=>............................] - ETA: 1:49  [ loss=16.6999 ][Training] 5/57 [=>............................] - ETA: 1:43  [ loss=7.3660 ][Training] 6/57 [==>...........................] - ETA: 1:40  [ loss=9.2330 ][Training] 7/57 [==>...........................] - ETA: 1:36  [ loss=15.2070 ][Training] 8/57 [===>..........................] - ETA: 1:36  [ loss=11.9008 ][Training] 9/57 [===>..........................] - ETA: 1:32  [ loss=7.8419 ][Training] 10/57 [====>.........................] - ETA: 1:31  [ loss=10.3330 ][Training] 11/57 [====>.........................] - ETA: 1:30  [ loss=12.5534 ][Training] 12/57 [=====>........................] - ETA: 1:26  [ loss=8.7238 ][Training] 13/57 [=====>........................] - ETA: 1:24  [ loss=8.6298 ][Training] 14/57 [======>.......................] - ETA: 1:23  [ loss=7.5764 ][Training] 15/57 [======>.......................] - ETA: 1:22  [ loss=10.3538 ][Training] 16/57 [=======>......................] - ETA: 1:20  [ loss=17.6695 ][Training] 17/57 [=======>......................] - ETA: 1:18  [ loss=6.4945 ][Training] 18/57 [========>.....................] - ETA: 1:16  [ loss=6.2281 ][Training] 19/57 [=========>....................] - ETA: 1:14  [ loss=10.1656 ][Training] 20/57 [=========>....................] - ETA: 1:12  [ loss=14.2392 ][Training] 21/57 [==========>...................] - ETA: 1:10  [ loss=8.1359 ][Training] 22/57 [==========>...................] - ETA: 1:07  [ loss=9.3044 ][Training] 23/57 [===========>..................] - ETA: 1:04  [ loss=7.0308 ][Training] 24/57 [===========>..................] - ETA: 1:02  [ loss=9.3068 ][Training] 25/57 [============>.................] - ETA: 1:00  [ loss=7.4569 ][Training] 26/57 [============>.................] - ETA: 58s  [ loss=5.7698 ][Training] 27/57 [=============>................] - ETA: 56s  [ loss=8.4016 ][Training] 28/57 [=============>................] - ETA: 54s  [ loss=15.4495 ][Training] 29/57 [==============>...............] - ETA: 52s  [ loss=10.0575 ][Training] 30/57 [==============>...............] - ETA: 50s  [ loss=11.9364 ][Training] 31/57 [===============>..............] - ETA: 48s  [ loss=8.6846 ][Training] 32/57 [===============>..............] - ETA: 47s  [ loss=7.2889 ][Training] 33/57 [================>.............] - ETA: 45s  [ loss=6.9040 ][Training] 34/57 [================>.............] - ETA: 43s  [ loss=7.8180 ][Training] 35/57 [=================>............] - ETA: 42s  [ loss=9.8813 ][Training] 36/57 [=================>............] - ETA: 40s  [ loss=6.7390 ][Training] 37/57 [==================>...........] - ETA: 38s  [ loss=6.9706 ][Training] 38/57 [===================>..........] - ETA: 36s  [ loss=6.5857 ][Training] 39/57 [===================>..........] - ETA: 34s  [ loss=6.5174 ][Training] 40/57 [====================>.........] - ETA: 32s  [ loss=12.1304 ][Training] 41/57 [====================>.........] - ETA: 30s  [ loss=14.6546 ][Training] 42/57 [=====================>........] - ETA: 28s  [ loss=8.0722 ][Training] 43/57 [=====================>........] - ETA: 26s  [ loss=9.4766 ][Training] 44/57 [======================>.......] - ETA: 24s  [ loss=8.1501 ][Training] 45/57 [======================>.......] - ETA: 22s  [ loss=7.9221 ][Training] 46/57 [=======================>......] - ETA: 20s  [ loss=6.6408 ][Training] 47/57 [=======================>......] - ETA: 18s  [ loss=13.4318 ][Training] 48/57 [========================>.....] - ETA: 16s  [ loss=8.6097 ][Training] 49/57 [========================>.....] - ETA: 14s  [ loss=15.2280 ][Training] 50/57 [=========================>....] - ETA: 12s  [ loss=6.0391 ][Training] 51/57 [=========================>....] - ETA: 10s  [ loss=5.1846 ][Training] 52/57 [==========================>...] - ETA: 8s  [ loss=9.3935 ][Training] 53/57 [==========================>...] - ETA: 7s  [ loss=12.4129 ][Training] 54/57 [===========================>..] - ETA: 5s  [ loss=5.5766 ][Training] 55/57 [===========================>..] - ETA: 3s  [ loss=6.8558 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=5.2208 ][Training] 57/57 [==============================] 1.8s/step  [ loss=3.2615 ]
01/08/2024 11:36:27 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/08/2024 11:36:27 - INFO - root -   ***** Running evaluation on test dataset  *****
01/08/2024 11:36:27 - INFO - root -     Num examples = 269
01/08/2024 11:36:27 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 11s[Evaluating] 2/12 [====>.........................] - ETA: 9s[Evaluating] 3/12 [======>.......................] - ETA: 7s[Evaluating] 4/12 [=========>....................] - ETA: 7s[Evaluating] 5/12 [===========>..................] - ETA: 6s[Evaluating] 6/12 [==============>...............] - ETA: 5s[Evaluating] 7/12 [================>.............] - ETA: 4s[Evaluating] 8/12 [===================>..........] - ETA: 3s[Evaluating] 9/12 [=====================>........] - ETA: 2s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 743.1ms/step
01/08/2024 11:36:36 - INFO - root -   

01/08/2024 11:36:36 - INFO - root -   ***** Eval results  *****
01/08/2024 11:36:36 - INFO - root -    acc: 0.7453 - recall: 0.2906 - f1: 0.4181 - loss: 9.0845 
01/08/2024 11:36:36 - INFO - root -   ***** Entity results  *****
01/08/2024 11:36:36 - INFO - root -   ******* GPE.NAM results ********
01/08/2024 11:36:36 - INFO - root -    acc: 1.0000 - recall: 0.4255 - f1: 0.5970 
01/08/2024 11:36:36 - INFO - root -   ******* GPE.NOM results ********
01/08/2024 11:36:36 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:36:36 - INFO - root -   ******* LOC.NAM results ********
01/08/2024 11:36:36 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:36:36 - INFO - root -   ******* LOC.NOM results ********
01/08/2024 11:36:36 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:36:36 - INFO - root -   ******* ORG.NAM results ********
01/08/2024 11:36:36 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:36:36 - INFO - root -   ******* ORG.NOM results ********
01/08/2024 11:36:36 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:36:36 - INFO - root -   ******* PER.NAM results ********
01/08/2024 11:36:36 - INFO - root -    acc: 0.8108 - recall: 0.5455 - f1: 0.6522 
01/08/2024 11:36:36 - INFO - root -   ******* PER.NOM results ********
01/08/2024 11:36:36 - INFO - root -    acc: 0.5970 - recall: 0.2353 - f1: 0.3376 
01/08/2024 11:36:42 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-399
01/08/2024 11:36:42 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-399
01/08/2024 11:36:42 - INFO - root -   

01/08/2024 11:36:42 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 7/50
[Training] 1/57 [..............................] - ETA: 1:39  [ loss=9.1305 ][Training] 2/57 [>.............................] - ETA: 2:01  [ loss=12.1072 ][Training] 3/57 [>.............................] - ETA: 1:50  [ loss=6.2502 ][Training] 4/57 [=>............................] - ETA: 1:45  [ loss=8.9926 ][Training] 5/57 [=>............................] - ETA: 1:49  [ loss=11.1044 ][Training] 6/57 [==>...........................] - ETA: 1:44  [ loss=5.6638 ][Training] 7/57 [==>...........................] - ETA: 1:44  [ loss=9.0117 ][Training] 8/57 [===>..........................] - ETA: 1:39  [ loss=5.7931 ][Training] 9/57 [===>..........................] - ETA: 1:36  [ loss=5.3350 ][Training] 10/57 [====>.........................] - ETA: 1:33  [ loss=7.0741 ][Training] 11/57 [====>.........................] - ETA: 1:30  [ loss=11.6887 ][Training] 12/57 [=====>........................] - ETA: 1:29  [ loss=6.4275 ][Training] 13/57 [=====>........................] - ETA: 1:27  [ loss=8.2476 ][Training] 14/57 [======>.......................] - ETA: 1:27  [ loss=11.2755 ][Training] 15/57 [======>.......................] - ETA: 1:25  [ loss=10.0172 ][Training] 16/57 [=======>......................] - ETA: 1:24  [ loss=10.7506 ][Training] 17/57 [=======>......................] - ETA: 1:21  [ loss=7.0258 ][Training] 18/57 [========>.....................] - ETA: 1:19  [ loss=3.4464 ][Training] 19/57 [=========>....................] - ETA: 1:16  [ loss=8.4172 ][Training] 20/57 [=========>....................] - ETA: 1:14  [ loss=7.3617 ][Training] 21/57 [==========>...................] - ETA: 1:13  [ loss=9.2463 ][Training] 22/57 [==========>...................] - ETA: 1:11  [ loss=7.3346 ][Training] 23/57 [===========>..................] - ETA: 1:09  [ loss=6.5524 ][Training] 24/57 [===========>..................] - ETA: 1:08  [ loss=9.6656 ][Training] 25/57 [============>.................] - ETA: 1:06  [ loss=8.5982 ][Training] 26/57 [============>.................] - ETA: 1:04  [ loss=4.9686 ][Training] 27/57 [=============>................] - ETA: 1:02  [ loss=8.8300 ][Training] 28/57 [=============>................] - ETA: 1:00  [ loss=7.1383 ][Training] 29/57 [==============>...............] - ETA: 58s  [ loss=5.8702 ][Training] 30/57 [==============>...............] - ETA: 56s  [ loss=6.7575 ][Training] 31/57 [===============>..............] - ETA: 54s  [ loss=8.9627 ][Training] 32/57 [===============>..............] - ETA: 53s  [ loss=8.8301 ][Training] 33/57 [================>.............] - ETA: 50s  [ loss=6.5969 ][Training] 34/57 [================>.............] - ETA: 47s  [ loss=8.2988 ][Training] 35/57 [=================>............] - ETA: 45s  [ loss=5.5479 ][Training] 36/57 [=================>............] - ETA: 43s  [ loss=7.9447 ][Training] 37/57 [==================>...........] - ETA: 41s  [ loss=12.8285 ][Training] 38/57 [===================>..........] - ETA: 39s  [ loss=5.8695 ][Training] 39/57 [===================>..........] - ETA: 37s  [ loss=7.1517 ][Training] 40/57 [====================>.........] - ETA: 35s  [ loss=4.5761 ][Training] 41/57 [====================>.........] - ETA: 33s  [ loss=7.4304 ][Training] 42/57 [=====================>........] - ETA: 31s  [ loss=9.8687 ][Training] 43/57 [=====================>........] - ETA: 28s  [ loss=6.0708 ][Training] 44/57 [======================>.......] - ETA: 26s  [ loss=14.1562 ][Training] 45/57 [======================>.......] - ETA: 24s  [ loss=13.1021 ][Training] 46/57 [=======================>......] - ETA: 22s  [ loss=7.6743 ][Training] 47/57 [=======================>......] - ETA: 20s  [ loss=6.8052 ][Training] 48/57 [========================>.....] - ETA: 18s  [ loss=7.8657 ][Training] 49/57 [========================>.....] - ETA: 16s  [ loss=9.7155 ][Training] 50/57 [=========================>....] - ETA: 14s  [ loss=11.1903 ][Training] 51/57 [=========================>....] - ETA: 12s  [ loss=9.9323 ][Training] 52/57 [==========================>...] - ETA: 10s  [ loss=4.5722 ][Training] 53/57 [==========================>...] - ETA: 8s  [ loss=4.7319 ][Training] 54/57 [===========================>..] - ETA: 6s  [ loss=8.4696 ][Training] 55/57 [===========================>..] - ETA: 4s  [ loss=8.7046 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=4.9233 ][Training] 57/57 [==============================] 2.0s/step  [ loss=4.5830 ]
01/08/2024 11:38:34 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/08/2024 11:38:35 - INFO - root -   ***** Running evaluation on test dataset  *****
01/08/2024 11:38:35 - INFO - root -     Num examples = 269
01/08/2024 11:38:35 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 5s[Evaluating] 2/12 [====>.........................] - ETA: 5s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 5s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 4s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 630.5ms/step
01/08/2024 11:38:42 - INFO - root -   

01/08/2024 11:38:42 - INFO - root -   ***** Eval results  *****
01/08/2024 11:38:42 - INFO - root -    acc: 0.7451 - recall: 0.3680 - f1: 0.4927 - loss: 8.0068 
01/08/2024 11:38:42 - INFO - root -   ***** Entity results  *****
01/08/2024 11:38:42 - INFO - root -   ******* GPE.NAM results ********
01/08/2024 11:38:42 - INFO - root -    acc: 1.0000 - recall: 0.5106 - f1: 0.6761 
01/08/2024 11:38:42 - INFO - root -   ******* GPE.NOM results ********
01/08/2024 11:38:42 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:38:42 - INFO - root -   ******* LOC.NAM results ********
01/08/2024 11:38:42 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:38:42 - INFO - root -   ******* LOC.NOM results ********
01/08/2024 11:38:42 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:38:42 - INFO - root -   ******* ORG.NAM results ********
01/08/2024 11:38:42 - INFO - root -    acc: 1.0000 - recall: 0.0256 - f1: 0.0500 
01/08/2024 11:38:42 - INFO - root -   ******* ORG.NOM results ********
01/08/2024 11:38:42 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:38:42 - INFO - root -   ******* PER.NAM results ********
01/08/2024 11:38:42 - INFO - root -    acc: 0.8095 - recall: 0.6182 - f1: 0.7010 
01/08/2024 11:38:42 - INFO - root -   ******* PER.NOM results ********
01/08/2024 11:38:42 - INFO - root -    acc: 0.6211 - recall: 0.3471 - f1: 0.4453 
01/08/2024 11:38:55 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-456
01/08/2024 11:38:55 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-456
01/08/2024 11:38:55 - INFO - root -   

01/08/2024 11:38:55 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 8/50
[Training] 1/57 [..............................] - ETA: 1:55  [ loss=7.1376 ][Training] 2/57 [>.............................] - ETA: 1:55  [ loss=7.2509 ][Training] 3/57 [>.............................] - ETA: 1:53  [ loss=7.2928 ][Training] 4/57 [=>............................] - ETA: 1:44  [ loss=10.4905 ][Training] 5/57 [=>............................] - ETA: 1:45  [ loss=18.9881 ][Training] 6/57 [==>...........................] - ETA: 1:39  [ loss=4.6357 ][Training] 7/57 [==>...........................] - ETA: 1:38  [ loss=7.9852 ][Training] 8/57 [===>..........................] - ETA: 1:36  [ loss=8.0449 ][Training] 9/57 [===>..........................] - ETA: 1:34  [ loss=7.7579 ][Training] 10/57 [====>.........................] - ETA: 1:31  [ loss=3.6429 ][Training] 11/57 [====>.........................] - ETA: 1:29  [ loss=4.2699 ][Training] 12/57 [=====>........................] - ETA: 1:29  [ loss=10.0331 ][Training] 13/57 [=====>........................] - ETA: 1:26  [ loss=5.3334 ][Training] 14/57 [======>.......................] - ETA: 1:25  [ loss=5.9102 ][Training] 15/57 [======>.......................] - ETA: 1:22  [ loss=8.2204 ][Training] 16/57 [=======>......................] - ETA: 1:20  [ loss=4.6232 ][Training] 17/57 [=======>......................] - ETA: 1:18  [ loss=7.9520 ][Training] 18/57 [========>.....................] - ETA: 1:16  [ loss=5.3679 ][Training] 19/57 [=========>....................] - ETA: 1:13  [ loss=6.1553 ][Training] 20/57 [=========>....................] - ETA: 1:12  [ loss=10.2484 ][Training] 21/57 [==========>...................] - ETA: 1:10  [ loss=7.2396 ][Training] 22/57 [==========>...................] - ETA: 1:08  [ loss=8.2815 ][Training] 23/57 [===========>..................] - ETA: 1:05  [ loss=4.8757 ][Training] 24/57 [===========>..................] - ETA: 1:03  [ loss=6.0723 ][Training] 25/57 [============>.................] - ETA: 1:01  [ loss=5.7986 ][Training] 26/57 [============>.................] - ETA: 59s  [ loss=4.7150 ][Training] 27/57 [=============>................] - ETA: 57s  [ loss=6.1036 ][Training] 28/57 [=============>................] - ETA: 55s  [ loss=10.0530 ][Training] 29/57 [==============>...............] - ETA: 54s  [ loss=5.3525 ][Training] 30/57 [==============>...............] - ETA: 52s  [ loss=10.8148 ][Training] 31/57 [===============>..............] - ETA: 50s  [ loss=5.6070 ][Training] 32/57 [===============>..............] - ETA: 48s  [ loss=8.7536 ][Training] 33/57 [================>.............] - ETA: 46s  [ loss=6.9961 ][Training] 34/57 [================>.............] - ETA: 44s  [ loss=5.4774 ][Training] 35/57 [=================>............] - ETA: 42s  [ loss=7.3581 ][Training] 36/57 [=================>............] - ETA: 39s  [ loss=5.7716 ][Training] 37/57 [==================>...........] - ETA: 37s  [ loss=6.6638 ][Training] 38/57 [===================>..........] - ETA: 35s  [ loss=4.7364 ][Training] 39/57 [===================>..........] - ETA: 33s  [ loss=7.7745 ][Training] 40/57 [====================>.........] - ETA: 32s  [ loss=8.3716 ][Training] 41/57 [====================>.........] - ETA: 30s  [ loss=6.0996 ][Training] 42/57 [=====================>........] - ETA: 28s  [ loss=5.4415 ][Training] 43/57 [=====================>........] - ETA: 26s  [ loss=7.2872 ][Training] 44/57 [======================>.......] - ETA: 24s  [ loss=9.4896 ][Training] 45/57 [======================>.......] - ETA: 22s  [ loss=8.9806 ][Training] 46/57 [=======================>......] - ETA: 20s  [ loss=5.4726 ][Training] 47/57 [=======================>......] - ETA: 19s  [ loss=9.9120 ][Training] 48/57 [========================>.....] - ETA: 17s  [ loss=4.3325 ][Training] 49/57 [========================>.....] - ETA: 15s  [ loss=6.7095 ][Training] 50/57 [=========================>....] - ETA: 13s  [ loss=6.3625 ][Training] 51/57 [=========================>....] - ETA: 11s  [ loss=8.3411 ][Training] 52/57 [==========================>...] - ETA: 9s  [ loss=3.8635 ][Training] 53/57 [==========================>...] - ETA: 7s  [ loss=5.7225 ][Training] 54/57 [===========================>..] - ETA: 5s  [ loss=12.0087 ][Training] 55/57 [===========================>..] - ETA: 3s  [ loss=10.2092 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=4.0065 ][Training] 57/57 [==============================] 1.9s/step  [ loss=3.5849 ]
01/08/2024 11:40:42 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/08/2024 11:40:42 - INFO - root -   ***** Running evaluation on test dataset  *****
01/08/2024 11:40:42 - INFO - root -     Num examples = 269
01/08/2024 11:40:42 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 9s[Evaluating] 2/12 [====>.........................] - ETA: 8s[Evaluating] 3/12 [======>.......................] - ETA: 8s[Evaluating] 4/12 [=========>....................] - ETA: 6s[Evaluating] 5/12 [===========>..................] - ETA: 5s[Evaluating] 6/12 [==============>...............] - ETA: 4s[Evaluating] 7/12 [================>.............] - ETA: 4s[Evaluating] 8/12 [===================>..........] - ETA: 3s[Evaluating] 9/12 [=====================>........] - ETA: 2s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 825.8ms/step
01/08/2024 11:40:52 - INFO - root -   

01/08/2024 11:40:52 - INFO - root -   ***** Eval results  *****
01/08/2024 11:40:52 - INFO - root -    acc: 0.7318 - recall: 0.3898 - f1: 0.5087 - loss: 7.2770 
01/08/2024 11:40:52 - INFO - root -   ***** Entity results  *****
01/08/2024 11:40:52 - INFO - root -   ******* GPE.NAM results ********
01/08/2024 11:40:52 - INFO - root -    acc: 0.9630 - recall: 0.5532 - f1: 0.7027 
01/08/2024 11:40:52 - INFO - root -   ******* GPE.NOM results ********
01/08/2024 11:40:52 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:40:52 - INFO - root -   ******* LOC.NAM results ********
01/08/2024 11:40:52 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:40:52 - INFO - root -   ******* LOC.NOM results ********
01/08/2024 11:40:52 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:40:52 - INFO - root -   ******* ORG.NAM results ********
01/08/2024 11:40:52 - INFO - root -    acc: 0.5000 - recall: 0.0256 - f1: 0.0488 
01/08/2024 11:40:52 - INFO - root -   ******* ORG.NOM results ********
01/08/2024 11:40:52 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:40:52 - INFO - root -   ******* PER.NAM results ********
01/08/2024 11:40:52 - INFO - root -    acc: 0.7865 - recall: 0.6364 - f1: 0.7035 
01/08/2024 11:40:52 - INFO - root -   ******* PER.NOM results ********
01/08/2024 11:40:52 - INFO - root -    acc: 0.6275 - recall: 0.3765 - f1: 0.4706 
01/08/2024 11:41:01 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-513
01/08/2024 11:41:01 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-513
01/08/2024 11:41:01 - INFO - root -   

01/08/2024 11:41:01 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 9/50
[Training] 1/57 [..............................] - ETA: 1:58  [ loss=11.5332 ][Training] 2/57 [>.............................] - ETA: 1:57  [ loss=7.0675 ][Training] 3/57 [>.............................] - ETA: 1:53  [ loss=4.5929 ][Training] 4/57 [=>............................] - ETA: 1:50  [ loss=7.9860 ][Training] 5/57 [=>............................] - ETA: 1:43  [ loss=5.3154 ][Training] 6/57 [==>...........................] - ETA: 1:38  [ loss=4.3532 ][Training] 7/57 [==>...........................] - ETA: 1:36  [ loss=3.6332 ][Training] 8/57 [===>..........................] - ETA: 1:33  [ loss=5.0030 ][Training] 9/57 [===>..........................] - ETA: 1:32  [ loss=6.2888 ][Training] 10/57 [====>.........................] - ETA: 1:31  [ loss=6.8948 ][Training] 11/57 [====>.........................] - ETA: 1:30  [ loss=11.1065 ][Training] 12/57 [=====>........................] - ETA: 1:28  [ loss=6.4843 ][Training] 13/57 [=====>........................] - ETA: 1:24  [ loss=4.2709 ][Training] 14/57 [======>.......................] - ETA: 1:21  [ loss=6.1298 ][Training] 15/57 [======>.......................] - ETA: 1:19  [ loss=6.0223 ][Training] 16/57 [=======>......................] - ETA: 1:17  [ loss=6.1898 ][Training] 17/57 [=======>......................] - ETA: 1:15  [ loss=4.8686 ][Training] 18/57 [========>.....................] - ETA: 1:12  [ loss=4.9888 ][Training] 19/57 [=========>....................] - ETA: 1:10  [ loss=5.1291 ][Training] 20/57 [=========>....................] - ETA: 1:09  [ loss=5.6633 ][Training] 21/57 [==========>...................] - ETA: 1:07  [ loss=5.8179 ][Training] 22/57 [==========>...................] - ETA: 1:06  [ loss=6.7253 ][Training] 23/57 [===========>..................] - ETA: 1:04  [ loss=6.9419 ][Training] 24/57 [===========>..................] - ETA: 1:02  [ loss=3.8100 ][Training] 25/57 [============>.................] - ETA: 59s  [ loss=4.2301 ][Training] 26/57 [============>.................] - ETA: 58s  [ loss=7.9302 ][Training] 27/57 [=============>................] - ETA: 56s  [ loss=8.2360 ][Training] 28/57 [=============>................] - ETA: 54s  [ loss=7.7490 ][Training] 29/57 [==============>...............] - ETA: 52s  [ loss=9.3538 ][Training] 30/57 [==============>...............] - ETA: 50s  [ loss=6.7929 ][Training] 31/57 [===============>..............] - ETA: 48s  [ loss=5.3067 ][Training] 32/57 [===============>..............] - ETA: 47s  [ loss=10.5882 ][Training] 33/57 [================>.............] - ETA: 45s  [ loss=5.7384 ][Training] 34/57 [================>.............] - ETA: 43s  [ loss=8.2886 ][Training] 35/57 [=================>............] - ETA: 41s  [ loss=4.0729 ][Training] 36/57 [=================>............] - ETA: 39s  [ loss=3.7473 ][Training] 37/57 [==================>...........] - ETA: 38s  [ loss=6.1501 ][Training] 38/57 [===================>..........] - ETA: 36s  [ loss=7.2243 ][Training] 39/57 [===================>..........] - ETA: 34s  [ loss=7.9168 ][Training] 40/57 [====================>.........] - ETA: 33s  [ loss=8.0348 ][Training] 41/57 [====================>.........] - ETA: 31s  [ loss=5.5771 ][Training] 42/57 [=====================>........] - ETA: 29s  [ loss=8.9687 ][Training] 43/57 [=====================>........] - ETA: 26s  [ loss=7.1151 ][Training] 44/57 [======================>.......] - ETA: 24s  [ loss=5.6824 ][Training] 45/57 [======================>.......] - ETA: 22s  [ loss=8.8428 ][Training] 46/57 [=======================>......] - ETA: 20s  [ loss=4.7151 ][Training] 47/57 [=======================>......] - ETA: 18s  [ loss=9.7534 ][Training] 48/57 [========================>.....] - ETA: 16s  [ loss=6.4729 ][Training] 49/57 [========================>.....] - ETA: 15s  [ loss=7.0406 ][Training] 50/57 [=========================>....] - ETA: 13s  [ loss=5.6604 ][Training] 51/57 [=========================>....] - ETA: 11s  [ loss=11.3640 ][Training] 52/57 [==========================>...] - ETA: 9s  [ loss=3.8599 ][Training] 53/57 [==========================>...] - ETA: 7s  [ loss=8.1519 ][Training] 54/57 [===========================>..] - ETA: 5s  [ loss=3.6951 ][Training] 55/57 [===========================>..] - ETA: 3s  [ loss=4.7288 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=4.6870 ][Training] 57/57 [==============================] 1.9s/step  [ loss=6.0430 ]
01/08/2024 11:42:46 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/08/2024 11:42:47 - INFO - root -   ***** Running evaluation on test dataset  *****
01/08/2024 11:42:47 - INFO - root -     Num examples = 269
01/08/2024 11:42:47 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 7s[Evaluating] 2/12 [====>.........................] - ETA: 9s[Evaluating] 3/12 [======>.......................] - ETA: 8s[Evaluating] 4/12 [=========>....................] - ETA: 6s[Evaluating] 5/12 [===========>..................] - ETA: 6s[Evaluating] 6/12 [==============>...............] - ETA: 5s[Evaluating] 7/12 [================>.............] - ETA: 4s[Evaluating] 8/12 [===================>..........] - ETA: 3s[Evaluating] 9/12 [=====================>........] - ETA: 2s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 793.6ms/step
01/08/2024 11:42:56 - INFO - root -   

01/08/2024 11:42:56 - INFO - root -   ***** Eval results  *****
01/08/2024 11:42:56 - INFO - root -    acc: 0.7339 - recall: 0.4140 - f1: 0.5294 - loss: 6.7438 
01/08/2024 11:42:56 - INFO - root -   ***** Entity results  *****
01/08/2024 11:42:56 - INFO - root -   ******* GPE.NAM results ********
01/08/2024 11:42:56 - INFO - root -    acc: 0.8710 - recall: 0.5745 - f1: 0.6923 
01/08/2024 11:42:56 - INFO - root -   ******* GPE.NOM results ********
01/08/2024 11:42:56 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:42:56 - INFO - root -   ******* LOC.NAM results ********
01/08/2024 11:42:56 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:42:56 - INFO - root -   ******* LOC.NOM results ********
01/08/2024 11:42:56 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:42:56 - INFO - root -   ******* ORG.NAM results ********
01/08/2024 11:42:56 - INFO - root -    acc: 0.5000 - recall: 0.0513 - f1: 0.0930 
01/08/2024 11:42:56 - INFO - root -   ******* ORG.NOM results ********
01/08/2024 11:42:56 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:42:56 - INFO - root -   ******* PER.NAM results ********
01/08/2024 11:42:56 - INFO - root -    acc: 0.7978 - recall: 0.6455 - f1: 0.7136 
01/08/2024 11:42:56 - INFO - root -   ******* PER.NOM results ********
01/08/2024 11:42:56 - INFO - root -    acc: 0.6514 - recall: 0.4176 - f1: 0.5090 
01/08/2024 11:43:04 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-570
01/08/2024 11:43:04 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-570
01/08/2024 11:43:04 - INFO - root -   

01/08/2024 11:43:04 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 10/50
[Training] 1/57 [..............................] - ETA: 1:35  [ loss=5.2671 ][Training] 2/57 [>.............................] - ETA: 1:28  [ loss=3.6413 ][Training] 3/57 [>.............................] - ETA: 1:26  [ loss=6.2324 ][Training] 4/57 [=>............................] - ETA: 1:26  [ loss=9.0964 ][Training] 5/57 [=>............................] - ETA: 1:25  [ loss=5.3975 ][Training] 6/57 [==>...........................] - ETA: 1:22  [ loss=4.4314 ][Training] 7/57 [==>...........................] - ETA: 1:26  [ loss=7.0374 ][Training] 8/57 [===>..........................] - ETA: 1:23  [ loss=2.9216 ][Training] 9/57 [===>..........................] - ETA: 1:21  [ loss=5.4242 ][Training] 10/57 [====>.........................] - ETA: 1:20  [ loss=6.2543 ][Training] 11/57 [====>.........................] - ETA: 1:19  [ loss=5.4632 ][Training] 12/57 [=====>........................] - ETA: 1:18  [ loss=9.6232 ][Training] 13/57 [=====>........................] - ETA: 1:18  [ loss=9.1167 ][Training] 14/57 [======>.......................] - ETA: 1:16  [ loss=6.3736 ][Training] 15/57 [======>.......................] - ETA: 1:14  [ loss=7.5681 ][Training] 16/57 [=======>......................] - ETA: 1:13  [ loss=8.3794 ][Training] 17/57 [=======>......................] - ETA: 1:12  [ loss=6.3903 ][Training] 18/57 [========>.....................] - ETA: 1:10  [ loss=4.6216 ][Training] 19/57 [=========>....................] - ETA: 1:09  [ loss=8.6530 ][Training] 20/57 [=========>....................] - ETA: 1:08  [ loss=9.5319 ][Training] 21/57 [==========>...................] - ETA: 1:06  [ loss=4.6550 ][Training] 22/57 [==========>...................] - ETA: 1:04  [ loss=6.5131 ][Training] 23/57 [===========>..................] - ETA: 1:03  [ loss=8.8808 ][Training] 24/57 [===========>..................] - ETA: 1:01  [ loss=4.2768 ][Training] 25/57 [============>.................] - ETA: 59s  [ loss=3.8235 ][Training] 26/57 [============>.................] - ETA: 57s  [ loss=5.1480 ][Training] 27/57 [=============>................] - ETA: 55s  [ loss=5.3807 ][Training] 28/57 [=============>................] - ETA: 54s  [ loss=4.9554 ][Training] 29/57 [==============>...............] - ETA: 52s  [ loss=7.4139 ][Training] 30/57 [==============>...............] - ETA: 50s  [ loss=6.1555 ][Training] 31/57 [===============>..............] - ETA: 48s  [ loss=5.0033 ][Training] 32/57 [===============>..............] - ETA: 46s  [ loss=4.0886 ][Training] 33/57 [================>.............] - ETA: 44s  [ loss=6.3833 ][Training] 34/57 [================>.............] - ETA: 42s  [ loss=5.6584 ][Training] 35/57 [=================>............] - ETA: 40s  [ loss=3.5082 ][Training] 36/57 [=================>............] - ETA: 38s  [ loss=4.5246 ][Training] 37/57 [==================>...........] - ETA: 36s  [ loss=6.2376 ][Training] 38/57 [===================>..........] - ETA: 34s  [ loss=10.3121 ][Training] 39/57 [===================>..........] - ETA: 33s  [ loss=9.6437 ][Training] 40/57 [====================>.........] - ETA: 31s  [ loss=6.0549 ][Training] 41/57 [====================>.........] - ETA: 29s  [ loss=5.7993 ][Training] 42/57 [=====================>........] - ETA: 27s  [ loss=6.6615 ][Training] 43/57 [=====================>........] - ETA: 25s  [ loss=5.5580 ][Training] 44/57 [======================>.......] - ETA: 23s  [ loss=5.1263 ][Training] 45/57 [======================>.......] - ETA: 22s  [ loss=5.3713 ][Training] 46/57 [=======================>......] - ETA: 20s  [ loss=2.2678 ][Training] 47/57 [=======================>......] - ETA: 18s  [ loss=4.7951 ][Training] 48/57 [========================>.....] - ETA: 16s  [ loss=4.8623 ][Training] 49/57 [========================>.....] - ETA: 14s  [ loss=7.3862 ][Training] 50/57 [=========================>....] - ETA: 12s  [ loss=5.2288 ][Training] 51/57 [=========================>....] - ETA: 11s  [ loss=2.7577 ][Training] 52/57 [==========================>...] - ETA: 9s  [ loss=5.4649 ][Training] 53/57 [==========================>...] - ETA: 7s  [ loss=10.7206 ][Training] 54/57 [===========================>..] - ETA: 5s  [ loss=3.3649 ][Training] 55/57 [===========================>..] - ETA: 3s  [ loss=4.3914 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=5.1782 ][Training] 57/57 [==============================] 1.8s/step  [ loss=5.0251 ]
01/08/2024 11:44:46 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/08/2024 11:44:46 - INFO - root -   ***** Running evaluation on test dataset  *****
01/08/2024 11:44:46 - INFO - root -     Num examples = 269
01/08/2024 11:44:46 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 9s[Evaluating] 2/12 [====>.........................] - ETA: 9s[Evaluating] 3/12 [======>.......................] - ETA: 7s[Evaluating] 4/12 [=========>....................] - ETA: 6s[Evaluating] 5/12 [===========>..................] - ETA: 5s[Evaluating] 6/12 [==============>...............] - ETA: 4s[Evaluating] 7/12 [================>.............] - ETA: 4s[Evaluating] 8/12 [===================>..........] - ETA: 3s[Evaluating] 9/12 [=====================>........] - ETA: 2s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 814.7ms/step
01/08/2024 11:44:56 - INFO - root -   

01/08/2024 11:44:56 - INFO - root -   ***** Eval results  *****
01/08/2024 11:44:56 - INFO - root -    acc: 0.7283 - recall: 0.4479 - f1: 0.5547 - loss: 6.2605 
01/08/2024 11:44:56 - INFO - root -   ***** Entity results  *****
01/08/2024 11:44:56 - INFO - root -   ******* GPE.NAM results ********
01/08/2024 11:44:56 - INFO - root -    acc: 0.8056 - recall: 0.6170 - f1: 0.6988 
01/08/2024 11:44:56 - INFO - root -   ******* GPE.NOM results ********
01/08/2024 11:44:56 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:44:56 - INFO - root -   ******* LOC.NAM results ********
01/08/2024 11:44:56 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:44:56 - INFO - root -   ******* LOC.NOM results ********
01/08/2024 11:44:56 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:44:56 - INFO - root -   ******* ORG.NAM results ********
01/08/2024 11:44:56 - INFO - root -    acc: 0.5714 - recall: 0.1026 - f1: 0.1739 
01/08/2024 11:44:56 - INFO - root -   ******* ORG.NOM results ********
01/08/2024 11:44:56 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:44:56 - INFO - root -   ******* PER.NAM results ********
01/08/2024 11:44:56 - INFO - root -    acc: 0.7826 - recall: 0.6545 - f1: 0.7129 
01/08/2024 11:44:56 - INFO - root -   ******* PER.NOM results ********
01/08/2024 11:44:56 - INFO - root -    acc: 0.6723 - recall: 0.4706 - f1: 0.5536 
01/08/2024 11:45:04 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-627
01/08/2024 11:45:04 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-627
01/08/2024 11:45:04 - INFO - root -   

01/08/2024 11:45:04 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 11/50
[Training] 1/57 [..............................] - ETA: 1:48  [ loss=8.1310 ][Training] 2/57 [>.............................] - ETA: 1:40  [ loss=7.9748 ][Training] 3/57 [>.............................] - ETA: 1:36  [ loss=4.2229 ][Training] 4/57 [=>............................] - ETA: 1:37  [ loss=4.7392 ][Training] 5/57 [=>............................] - ETA: 1:36  [ loss=7.0432 ][Training] 6/57 [==>...........................] - ETA: 1:34  [ loss=5.5819 ][Training] 7/57 [==>...........................] - ETA: 1:32  [ loss=3.4597 ][Training] 8/57 [===>..........................] - ETA: 1:28  [ loss=4.6732 ][Training] 9/57 [===>..........................] - ETA: 1:28  [ loss=3.2185 ][Training] 10/57 [====>.........................] - ETA: 1:26  [ loss=4.2021 ][Training] 11/57 [====>.........................] - ETA: 1:23  [ loss=4.7681 ][Training] 12/57 [=====>........................] - ETA: 1:21  [ loss=5.7988 ][Training] 13/57 [=====>........................] - ETA: 1:19  [ loss=6.7062 ][Training] 14/57 [======>.......................] - ETA: 1:17  [ loss=4.5740 ][Training] 15/57 [======>.......................] - ETA: 1:16  [ loss=9.2794 ][Training] 16/57 [=======>......................] - ETA: 1:14  [ loss=5.3002 ][Training] 17/57 [=======>......................] - ETA: 1:13  [ loss=8.1347 ][Training] 18/57 [========>.....................] - ETA: 1:10  [ loss=3.6617 ][Training] 19/57 [=========>....................] - ETA: 1:07  [ loss=3.5519 ][Training] 20/57 [=========>....................] - ETA: 1:05  [ loss=4.4676 ][Training] 21/57 [==========>...................] - ETA: 1:04  [ loss=3.7195 ][Training] 22/57 [==========>...................] - ETA: 1:02  [ loss=4.6327 ][Training] 23/57 [===========>..................] - ETA: 1:00  [ loss=6.5303 ][Training] 24/57 [===========>..................] - ETA: 58s  [ loss=4.4278 ][Training] 25/57 [============>.................] - ETA: 56s  [ loss=2.6247 ][Training] 26/57 [============>.................] - ETA: 54s  [ loss=5.5241 ][Training] 27/57 [=============>................] - ETA: 53s  [ loss=4.6862 ][Training] 28/57 [=============>................] - ETA: 51s  [ loss=4.1613 ][Training] 29/57 [==============>...............] - ETA: 49s  [ loss=5.5351 ][Training] 30/57 [==============>...............] - ETA: 48s  [ loss=4.7564 ][Training] 31/57 [===============>..............] - ETA: 46s  [ loss=7.1630 ][Training] 32/57 [===============>..............] - ETA: 45s  [ loss=5.1772 ][Training] 33/57 [================>.............] - ETA: 43s  [ loss=6.6918 ][Training] 34/57 [================>.............] - ETA: 42s  [ loss=8.8314 ][Training] 35/57 [=================>............] - ETA: 40s  [ loss=6.0524 ][Training] 36/57 [=================>............] - ETA: 38s  [ loss=9.3790 ][Training] 37/57 [==================>...........] - ETA: 36s  [ loss=8.5780 ][Training] 38/57 [===================>..........] - ETA: 35s  [ loss=6.1756 ][Training] 39/57 [===================>..........] - ETA: 33s  [ loss=7.0264 ][Training] 40/57 [====================>.........] - ETA: 31s  [ loss=8.6516 ][Training] 41/57 [====================>.........] - ETA: 29s  [ loss=2.0098 ][Training] 42/57 [=====================>........] - ETA: 28s  [ loss=4.5625 ][Training] 43/57 [=====================>........] - ETA: 26s  [ loss=4.8218 ][Training] 44/57 [======================>.......] - ETA: 24s  [ loss=4.6157 ][Training] 45/57 [======================>.......] - ETA: 22s  [ loss=4.0684 ][Training] 46/57 [=======================>......] - ETA: 20s  [ loss=4.5175 ][Training] 47/57 [=======================>......] - ETA: 18s  [ loss=6.1069 ][Training] 48/57 [========================>.....] - ETA: 16s  [ loss=7.4173 ][Training] 49/57 [========================>.....] - ETA: 14s  [ loss=3.5249 ][Training] 50/57 [=========================>....] - ETA: 13s  [ loss=4.6265 ][Training] 51/57 [=========================>....] - ETA: 11s  [ loss=6.7024 ][Training] 52/57 [==========================>...] - ETA: 9s  [ loss=7.3715 ][Training] 53/57 [==========================>...] - ETA: 7s  [ loss=5.7089 ][Training] 54/57 [===========================>..] - ETA: 5s  [ loss=4.9760 ][Training] 55/57 [===========================>..] - ETA: 3s  [ loss=3.6345 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=8.7570 ][Training] 57/57 [==============================] 1.8s/step  [ loss=2.7902 ]
01/08/2024 11:46:49 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/08/2024 11:46:49 - INFO - root -   ***** Running evaluation on test dataset  *****
01/08/2024 11:46:49 - INFO - root -     Num examples = 269
01/08/2024 11:46:49 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 10s[Evaluating] 2/12 [====>.........................] - ETA: 10s[Evaluating] 3/12 [======>.......................] - ETA: 8s[Evaluating] 4/12 [=========>....................] - ETA: 7s[Evaluating] 5/12 [===========>..................] - ETA: 5s[Evaluating] 6/12 [==============>...............] - ETA: 4s[Evaluating] 7/12 [================>.............] - ETA: 4s[Evaluating] 8/12 [===================>..........] - ETA: 3s[Evaluating] 9/12 [=====================>........] - ETA: 2s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 737.3ms/step
01/08/2024 11:46:58 - INFO - root -   

01/08/2024 11:46:58 - INFO - root -   ***** Eval results  *****
01/08/2024 11:46:58 - INFO - root -    acc: 0.7164 - recall: 0.4770 - f1: 0.5727 - loss: 5.8982 
01/08/2024 11:46:58 - INFO - root -   ***** Entity results  *****
01/08/2024 11:46:58 - INFO - root -   ******* GPE.NAM results ********
01/08/2024 11:46:58 - INFO - root -    acc: 0.7949 - recall: 0.6596 - f1: 0.7209 
01/08/2024 11:46:58 - INFO - root -   ******* GPE.NOM results ********
01/08/2024 11:46:58 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:46:58 - INFO - root -   ******* LOC.NAM results ********
01/08/2024 11:46:58 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:46:58 - INFO - root -   ******* LOC.NOM results ********
01/08/2024 11:46:58 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:46:58 - INFO - root -   ******* ORG.NAM results ********
01/08/2024 11:46:58 - INFO - root -    acc: 0.5000 - recall: 0.1026 - f1: 0.1702 
01/08/2024 11:46:58 - INFO - root -   ******* ORG.NOM results ********
01/08/2024 11:46:58 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:46:58 - INFO - root -   ******* PER.NAM results ********
01/08/2024 11:46:58 - INFO - root -    acc: 0.7849 - recall: 0.6636 - f1: 0.7192 
01/08/2024 11:46:58 - INFO - root -   ******* PER.NOM results ********
01/08/2024 11:46:58 - INFO - root -    acc: 0.6593 - recall: 0.5235 - f1: 0.5836 
01/08/2024 11:47:48 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-684
01/08/2024 11:47:48 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-684
01/08/2024 11:47:48 - INFO - root -   

01/08/2024 11:47:48 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 12/50
[Training] 1/57 [..............................] - ETA: 1:53  [ loss=3.6650 ][Training] 2/57 [>.............................] - ETA: 2:03  [ loss=9.8168 ][Training] 3/57 [>.............................] - ETA: 1:52  [ loss=5.6269 ][Training] 4/57 [=>............................] - ETA: 1:57  [ loss=6.2699 ][Training] 5/57 [=>............................] - ETA: 1:57  [ loss=5.9611 ][Training] 6/57 [==>...........................] - ETA: 1:55  [ loss=6.5891 ][Training] 7/57 [==>...........................] - ETA: 1:50  [ loss=2.2813 ][Training] 8/57 [===>..........................] - ETA: 1:48  [ loss=5.4112 ][Training] 9/57 [===>..........................] - ETA: 1:47  [ loss=3.5342 ][Training] 10/57 [====>.........................] - ETA: 1:46  [ loss=5.5621 ][Training] 11/57 [====>.........................] - ETA: 1:43  [ loss=3.5770 ][Training] 12/57 [=====>........................] - ETA: 1:39  [ loss=3.5555 ][Training] 13/57 [=====>........................] - ETA: 1:35  [ loss=6.8186 ][Training] 14/57 [======>.......................] - ETA: 1:32  [ loss=3.9986 ][Training] 15/57 [======>.......................] - ETA: 1:28  [ loss=2.5399 ][Training] 16/57 [=======>......................] - ETA: 1:23  [ loss=5.5940 ][Training] 17/57 [=======>......................] - ETA: 1:21  [ loss=3.9142 ][Training] 18/57 [========>.....................] - ETA: 1:18  [ loss=4.1903 ][Training] 19/57 [=========>....................] - ETA: 1:15  [ loss=4.4695 ][Training] 20/57 [=========>....................] - ETA: 1:12  [ loss=5.5332 ][Training] 21/57 [==========>...................] - ETA: 1:10  [ loss=4.9837 ][Training] 22/57 [==========>...................] - ETA: 1:08  [ loss=4.1089 ][Training] 23/57 [===========>..................] - ETA: 1:05  [ loss=5.7425 ][Training] 24/57 [===========>..................] - ETA: 1:02  [ loss=5.4033 ][Training] 25/57 [============>.................] - ETA: 1:00  [ loss=4.1962 ][Training] 26/57 [============>.................] - ETA: 58s  [ loss=8.3368 ][Training] 27/57 [=============>................] - ETA: 56s  [ loss=4.4470 ][Training] 28/57 [=============>................] - ETA: 54s  [ loss=4.2556 ][Training] 29/57 [==============>...............] - ETA: 53s  [ loss=5.0049 ][Training] 30/57 [==============>...............] - ETA: 51s  [ loss=8.4387 ][Training] 31/57 [===============>..............] - ETA: 49s  [ loss=4.0962 ][Training] 32/57 [===============>..............] - ETA: 48s  [ loss=6.5672 ][Training] 33/57 [================>.............] - ETA: 46s  [ loss=3.7273 ][Training] 34/57 [================>.............] - ETA: 44s  [ loss=3.6858 ][Training] 35/57 [=================>............] - ETA: 42s  [ loss=3.3956 ][Training] 36/57 [=================>............] - ETA: 40s  [ loss=6.2762 ][Training] 37/57 [==================>...........] - ETA: 38s  [ loss=3.2006 ][Training] 38/57 [===================>..........] - ETA: 37s  [ loss=4.7223 ][Training] 39/57 [===================>..........] - ETA: 35s  [ loss=6.9776 ][Training] 40/57 [====================>.........] - ETA: 33s  [ loss=3.2577 ][Training] 41/57 [====================>.........] - ETA: 31s  [ loss=5.2160 ][Training] 42/57 [=====================>........] - ETA: 29s  [ loss=2.4562 ][Training] 43/57 [=====================>........] - ETA: 27s  [ loss=6.1462 ][Training] 44/57 [======================>.......] - ETA: 25s  [ loss=3.1549 ][Training] 45/57 [======================>.......] - ETA: 23s  [ loss=6.1316 ][Training] 46/57 [=======================>......] - ETA: 21s  [ loss=5.1289 ][Training] 47/57 [=======================>......] - ETA: 19s  [ loss=6.5753 ][Training] 48/57 [========================>.....] - ETA: 17s  [ loss=9.3603 ][Training] 49/57 [========================>.....] - ETA: 15s  [ loss=4.4623 ][Training] 50/57 [=========================>....] - ETA: 13s  [ loss=6.2237 ][Training] 51/57 [=========================>....] - ETA: 11s  [ loss=9.6895 ][Training] 52/57 [==========================>...] - ETA: 9s  [ loss=7.0751 ][Training] 53/57 [==========================>...] - ETA: 7s  [ loss=3.7174 ][Training] 54/57 [===========================>..] - ETA: 5s  [ loss=4.3369 ][Training] 55/57 [===========================>..] - ETA: 3s  [ loss=7.6595 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=5.3719 ][Training] 57/57 [==============================] 1.8s/step  [ loss=5.7433 ]
01/08/2024 11:49:34 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/08/2024 11:49:34 - INFO - root -   ***** Running evaluation on test dataset  *****
01/08/2024 11:49:34 - INFO - root -     Num examples = 269
01/08/2024 11:49:34 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 5s[Evaluating] 2/12 [====>.........................] - ETA: 6s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 3s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 2s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 537.6ms/step
01/08/2024 11:49:40 - INFO - root -   

01/08/2024 11:49:40 - INFO - root -   ***** Eval results  *****
01/08/2024 11:49:40 - INFO - root -    acc: 0.7298 - recall: 0.5036 - f1: 0.5960 - loss: 5.6187 
01/08/2024 11:49:40 - INFO - root -   ***** Entity results  *****
01/08/2024 11:49:40 - INFO - root -   ******* GPE.NAM results ********
01/08/2024 11:49:40 - INFO - root -    acc: 0.8000 - recall: 0.6809 - f1: 0.7356 
01/08/2024 11:49:40 - INFO - root -   ******* GPE.NOM results ********
01/08/2024 11:49:40 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:49:40 - INFO - root -   ******* LOC.NAM results ********
01/08/2024 11:49:40 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:49:40 - INFO - root -   ******* LOC.NOM results ********
01/08/2024 11:49:40 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:49:40 - INFO - root -   ******* ORG.NAM results ********
01/08/2024 11:49:40 - INFO - root -    acc: 0.7500 - recall: 0.1538 - f1: 0.2553 
01/08/2024 11:49:40 - INFO - root -   ******* ORG.NOM results ********
01/08/2024 11:49:40 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:49:40 - INFO - root -   ******* PER.NAM results ********
01/08/2024 11:49:40 - INFO - root -    acc: 0.7872 - recall: 0.6727 - f1: 0.7255 
01/08/2024 11:49:40 - INFO - root -   ******* PER.NOM results ********
01/08/2024 11:49:40 - INFO - root -    acc: 0.6713 - recall: 0.5647 - f1: 0.6134 
01/08/2024 11:50:30 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-741
01/08/2024 11:50:30 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-741
01/08/2024 11:50:30 - INFO - root -   

01/08/2024 11:50:30 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 13/50
[Training] 1/57 [..............................] - ETA: 1:17  [ loss=5.2461 ][Training] 2/57 [>.............................] - ETA: 1:12  [ loss=2.4678 ][Training] 3/57 [>.............................] - ETA: 1:17  [ loss=4.6924 ][Training] 4/57 [=>............................] - ETA: 1:15  [ loss=4.4615 ][Training] 5/57 [=>............................] - ETA: 1:09  [ loss=4.5088 ][Training] 6/57 [==>...........................] - ETA: 1:11  [ loss=3.1898 ][Training] 7/57 [==>...........................] - ETA: 1:09  [ loss=3.6922 ][Training] 8/57 [===>..........................] - ETA: 1:09  [ loss=7.9331 ][Training] 9/57 [===>..........................] - ETA: 1:08  [ loss=6.1412 ][Training] 10/57 [====>.........................] - ETA: 1:07  [ loss=4.8974 ][Training] 11/57 [====>.........................] - ETA: 1:05  [ loss=4.9308 ][Training] 12/57 [=====>........................] - ETA: 1:04  [ loss=3.7056 ][Training] 13/57 [=====>........................] - ETA: 1:05  [ loss=4.2503 ][Training] 14/57 [======>.......................] - ETA: 1:06  [ loss=2.8236 ][Training] 15/57 [======>.......................] - ETA: 1:03  [ loss=3.3541 ][Training] 16/57 [=======>......................] - ETA: 1:01  [ loss=3.7716 ][Training] 17/57 [=======>......................] - ETA: 1:02  [ loss=8.8445 ][Training] 18/57 [========>.....................] - ETA: 1:00  [ loss=3.8143 ][Training] 19/57 [=========>....................] - ETA: 1:01  [ loss=7.6634 ][Training] 20/57 [=========>....................] - ETA: 1:00  [ loss=6.7229 ][Training] 21/57 [==========>...................] - ETA: 58s  [ loss=5.0643 ][Training] 22/57 [==========>...................] - ETA: 57s  [ loss=3.7676 ][Training] 23/57 [===========>..................] - ETA: 55s  [ loss=5.0130 ][Training] 24/57 [===========>..................] - ETA: 54s  [ loss=4.4296 ][Training] 25/57 [============>.................] - ETA: 53s  [ loss=4.9285 ][Training] 26/57 [============>.................] - ETA: 52s  [ loss=5.0329 ][Training] 27/57 [=============>................] - ETA: 51s  [ loss=7.4442 ][Training] 28/57 [=============>................] - ETA: 49s  [ loss=4.9993 ][Training] 29/57 [==============>...............] - ETA: 48s  [ loss=4.5930 ][Training] 30/57 [==============>...............] - ETA: 46s  [ loss=5.5742 ][Training] 31/57 [===============>..............] - ETA: 44s  [ loss=4.3181 ][Training] 32/57 [===============>..............] - ETA: 42s  [ loss=3.1109 ][Training] 33/57 [================>.............] - ETA: 41s  [ loss=8.0166 ][Training] 34/57 [================>.............] - ETA: 39s  [ loss=5.0643 ][Training] 35/57 [=================>............] - ETA: 37s  [ loss=3.3950 ][Training] 36/57 [=================>............] - ETA: 36s  [ loss=5.5737 ][Training] 37/57 [==================>...........] - ETA: 34s  [ loss=2.7646 ][Training] 38/57 [===================>..........] - ETA: 32s  [ loss=4.6727 ][Training] 39/57 [===================>..........] - ETA: 31s  [ loss=4.3378 ][Training] 40/57 [====================>.........] - ETA: 29s  [ loss=6.0795 ][Training] 41/57 [====================>.........] - ETA: 28s  [ loss=7.8868 ][Training] 42/57 [=====================>........] - ETA: 26s  [ loss=3.4634 ][Training] 43/57 [=====================>........] - ETA: 24s  [ loss=5.2325 ][Training] 44/57 [======================>.......] - ETA: 22s  [ loss=4.1724 ][Training] 45/57 [======================>.......] - ETA: 21s  [ loss=5.8300 ][Training] 46/57 [=======================>......] - ETA: 19s  [ loss=4.2427 ][Training] 47/57 [=======================>......] - ETA: 17s  [ loss=7.8172 ][Training] 48/57 [========================>.....] - ETA: 15s  [ loss=3.1851 ][Training] 49/57 [========================>.....] - ETA: 14s  [ loss=3.2800 ][Training] 50/57 [=========================>....] - ETA: 12s  [ loss=4.0458 ][Training] 51/57 [=========================>....] - ETA: 10s  [ loss=5.0581 ][Training] 52/57 [==========================>...] - ETA: 8s  [ loss=5.0864 ][Training] 53/57 [==========================>...] - ETA: 7s  [ loss=4.4950 ][Training] 54/57 [===========================>..] - ETA: 5s  [ loss=5.0311 ][Training] 55/57 [===========================>..] - ETA: 3s  [ loss=4.0167 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=7.2693 ][Training] 57/57 [==============================] 1.8s/step  [ loss=2.6271 ]
01/08/2024 11:52:10 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/08/2024 11:52:11 - INFO - root -   ***** Running evaluation on test dataset  *****
01/08/2024 11:52:11 - INFO - root -     Num examples = 269
01/08/2024 11:52:11 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 9s[Evaluating] 2/12 [====>.........................] - ETA: 8s[Evaluating] 3/12 [======>.......................] - ETA: 7s[Evaluating] 4/12 [=========>....................] - ETA: 7s[Evaluating] 5/12 [===========>..................] - ETA: 5s[Evaluating] 6/12 [==============>...............] - ETA: 4s[Evaluating] 7/12 [================>.............] - ETA: 4s[Evaluating] 8/12 [===================>..........] - ETA: 3s[Evaluating] 9/12 [=====================>........] - ETA: 2s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 825.2ms/step
01/08/2024 11:52:20 - INFO - root -   

01/08/2024 11:52:20 - INFO - root -   ***** Eval results  *****
01/08/2024 11:52:20 - INFO - root -    acc: 0.7215 - recall: 0.5206 - f1: 0.6048 - loss: 5.3272 
01/08/2024 11:52:20 - INFO - root -   ***** Entity results  *****
01/08/2024 11:52:20 - INFO - root -   ******* GPE.NAM results ********
01/08/2024 11:52:20 - INFO - root -    acc: 0.7907 - recall: 0.7234 - f1: 0.7556 
01/08/2024 11:52:20 - INFO - root -   ******* GPE.NOM results ********
01/08/2024 11:52:20 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:52:20 - INFO - root -   ******* LOC.NAM results ********
01/08/2024 11:52:20 - INFO - root -    acc: 1.0000 - recall: 0.0526 - f1: 0.1000 
01/08/2024 11:52:20 - INFO - root -   ******* LOC.NOM results ********
01/08/2024 11:52:20 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:52:20 - INFO - root -   ******* ORG.NAM results ********
01/08/2024 11:52:20 - INFO - root -    acc: 0.6000 - recall: 0.2308 - f1: 0.3333 
01/08/2024 11:52:20 - INFO - root -   ******* ORG.NOM results ********
01/08/2024 11:52:20 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:52:20 - INFO - root -   ******* PER.NAM results ********
01/08/2024 11:52:20 - INFO - root -    acc: 0.7789 - recall: 0.6727 - f1: 0.7220 
01/08/2024 11:52:20 - INFO - root -   ******* PER.NOM results ********
01/08/2024 11:52:20 - INFO - root -    acc: 0.6736 - recall: 0.5706 - f1: 0.6178 
01/08/2024 11:52:30 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-798
01/08/2024 11:52:30 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-798
01/08/2024 11:52:30 - INFO - root -   

01/08/2024 11:52:30 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 14/50
[Training] 1/57 [..............................] - ETA: 2:08  [ loss=4.8073 ][Training] 2/57 [>.............................] - ETA: 1:53  [ loss=5.0749 ][Training] 3/57 [>.............................] - ETA: 1:56  [ loss=9.0812 ][Training] 4/57 [=>............................] - ETA: 1:46  [ loss=2.4591 ][Training] 5/57 [=>............................] - ETA: 1:43  [ loss=5.1818 ][Training] 6/57 [==>...........................] - ETA: 1:43  [ loss=5.4044 ][Training] 7/57 [==>...........................] - ETA: 1:38  [ loss=4.3619 ][Training] 8/57 [===>..........................] - ETA: 1:36  [ loss=4.6795 ][Training] 9/57 [===>..........................] - ETA: 1:34  [ loss=3.4318 ][Training] 10/57 [====>.........................] - ETA: 1:32  [ loss=5.9569 ][Training] 11/57 [====>.........................] - ETA: 1:33  [ loss=9.1821 ][Training] 12/57 [=====>........................] - ETA: 1:29  [ loss=2.7347 ][Training] 13/57 [=====>........................] - ETA: 1:26  [ loss=3.6195 ][Training] 14/57 [======>.......................] - ETA: 1:23  [ loss=7.8163 ][Training] 15/57 [======>.......................] - ETA: 1:20  [ loss=3.8724 ][Training] 16/57 [=======>......................] - ETA: 1:17  [ loss=8.0294 ][Training] 17/57 [=======>......................] - ETA: 1:14  [ loss=2.1037 ][Training] 18/57 [========>.....................] - ETA: 1:12  [ loss=4.4891 ][Training] 19/57 [=========>....................] - ETA: 1:10  [ loss=6.2344 ][Training] 20/57 [=========>....................] - ETA: 1:09  [ loss=6.1567 ][Training] 21/57 [==========>...................] - ETA: 1:07  [ loss=4.4878 ][Training] 22/57 [==========>...................] - ETA: 1:05  [ loss=4.0191 ][Training] 23/57 [===========>..................] - ETA: 1:04  [ loss=3.3486 ][Training] 24/57 [===========>..................] - ETA: 1:02  [ loss=4.2625 ][Training] 25/57 [============>.................] - ETA: 1:00  [ loss=8.7850 ][Training] 26/57 [============>.................] - ETA: 58s  [ loss=2.7383 ][Training] 27/57 [=============>................] - ETA: 57s  [ loss=4.6976 ][Training] 28/57 [=============>................] - ETA: 54s  [ loss=4.5021 ][Training] 29/57 [==============>...............] - ETA: 53s  [ loss=6.2269 ][Training] 30/57 [==============>...............] - ETA: 50s  [ loss=3.5850 ][Training] 31/57 [===============>..............] - ETA: 48s  [ loss=2.3279 ][Training] 32/57 [===============>..............] - ETA: 46s  [ loss=4.5865 ][Training] 33/57 [================>.............] - ETA: 44s  [ loss=4.4273 ][Training] 34/57 [================>.............] - ETA: 42s  [ loss=3.9184 ][Training] 35/57 [=================>............] - ETA: 41s  [ loss=3.6367 ][Training] 36/57 [=================>............] - ETA: 39s  [ loss=4.9308 ][Training] 37/57 [==================>...........] - ETA: 37s  [ loss=4.1603 ][Training] 38/57 [===================>..........] - ETA: 35s  [ loss=4.5515 ][Training] 39/57 [===================>..........] - ETA: 34s  [ loss=2.8107 ][Training] 40/57 [====================>.........] - ETA: 32s  [ loss=4.3968 ][Training] 41/57 [====================>.........] - ETA: 30s  [ loss=7.3561 ][Training] 42/57 [=====================>........] - ETA: 28s  [ loss=2.4692 ][Training] 43/57 [=====================>........] - ETA: 26s  [ loss=4.7069 ][Training] 44/57 [======================>.......] - ETA: 24s  [ loss=4.6072 ][Training] 45/57 [======================>.......] - ETA: 22s  [ loss=1.8392 ][Training] 46/57 [=======================>......] - ETA: 20s  [ loss=5.6570 ][Training] 47/57 [=======================>......] - ETA: 18s  [ loss=8.8537 ][Training] 48/57 [========================>.....] - ETA: 16s  [ loss=3.0021 ][Training] 49/57 [========================>.....] - ETA: 14s  [ loss=5.5325 ][Training] 50/57 [=========================>....] - ETA: 12s  [ loss=4.4443 ][Training] 51/57 [=========================>....] - ETA: 10s  [ loss=3.1298 ][Training] 52/57 [==========================>...] - ETA: 9s  [ loss=3.5676 ][Training] 53/57 [==========================>...] - ETA: 7s  [ loss=4.5003 ][Training] 54/57 [===========================>..] - ETA: 5s  [ loss=2.5840 ][Training] 55/57 [===========================>..] - ETA: 3s  [ loss=6.5734 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=2.9517 ][Training] 57/57 [==============================] 1.8s/step  [ loss=3.8517 ]
01/08/2024 11:54:10 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/08/2024 11:54:10 - INFO - root -   ***** Running evaluation on test dataset  *****
01/08/2024 11:54:10 - INFO - root -     Num examples = 269
01/08/2024 11:54:10 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 9s[Evaluating] 2/12 [====>.........................] - ETA: 7s[Evaluating] 3/12 [======>.......................] - ETA: 6s[Evaluating] 4/12 [=========>....................] - ETA: 5s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 4s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 2s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 716.6ms/step
01/08/2024 11:54:19 - INFO - root -   

01/08/2024 11:54:19 - INFO - root -   ***** Eval results  *****
01/08/2024 11:54:19 - INFO - root -    acc: 0.7258 - recall: 0.5254 - f1: 0.6096 - loss: 5.1176 
01/08/2024 11:54:19 - INFO - root -   ***** Entity results  *****
01/08/2024 11:54:19 - INFO - root -   ******* GPE.NAM results ********
01/08/2024 11:54:19 - INFO - root -    acc: 0.7907 - recall: 0.7234 - f1: 0.7556 
01/08/2024 11:54:19 - INFO - root -   ******* GPE.NOM results ********
01/08/2024 11:54:19 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:54:19 - INFO - root -   ******* LOC.NAM results ********
01/08/2024 11:54:19 - INFO - root -    acc: 1.0000 - recall: 0.0526 - f1: 0.1000 
01/08/2024 11:54:19 - INFO - root -   ******* LOC.NOM results ********
01/08/2024 11:54:19 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:54:19 - INFO - root -   ******* ORG.NAM results ********
01/08/2024 11:54:19 - INFO - root -    acc: 0.6000 - recall: 0.2308 - f1: 0.3333 
01/08/2024 11:54:19 - INFO - root -   ******* ORG.NOM results ********
01/08/2024 11:54:19 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:54:19 - INFO - root -   ******* PER.NAM results ********
01/08/2024 11:54:19 - INFO - root -    acc: 0.7917 - recall: 0.6909 - f1: 0.7379 
01/08/2024 11:54:19 - INFO - root -   ******* PER.NOM results ********
01/08/2024 11:54:19 - INFO - root -    acc: 0.6736 - recall: 0.5706 - f1: 0.6178 
01/08/2024 11:55:06 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-855
01/08/2024 11:55:06 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-855
01/08/2024 11:55:06 - INFO - root -   

01/08/2024 11:55:06 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 15/50
[Training] 1/57 [..............................] - ETA: 1:08  [ loss=3.9232 ][Training] 2/57 [>.............................] - ETA: 1:19  [ loss=3.8100 ][Training] 3/57 [>.............................] - ETA: 1:12  [ loss=3.9096 ][Training] 4/57 [=>............................] - ETA: 1:07  [ loss=3.9360 ][Training] 5/57 [=>............................] - ETA: 1:08  [ loss=3.1649 ][Training] 6/57 [==>...........................] - ETA: 1:07  [ loss=3.1763 ][Training] 7/57 [==>...........................] - ETA: 1:11  [ loss=2.5146 ][Training] 8/57 [===>..........................] - ETA: 1:15  [ loss=7.8043 ][Training] 9/57 [===>..........................] - ETA: 1:16  [ loss=3.5270 ][Training] 10/57 [====>.........................] - ETA: 1:15  [ loss=4.3766 ][Training] 11/57 [====>.........................] - ETA: 1:14  [ loss=2.1881 ][Training] 12/57 [=====>........................] - ETA: 1:15  [ loss=7.3655 ][Training] 13/57 [=====>........................] - ETA: 1:14  [ loss=3.1124 ][Training] 14/57 [======>.......................] - ETA: 1:13  [ loss=4.4095 ][Training] 15/57 [======>.......................] - ETA: 1:12  [ loss=5.4829 ][Training] 16/57 [=======>......................] - ETA: 1:11  [ loss=4.2073 ][Training] 17/57 [=======>......................] - ETA: 1:09  [ loss=5.7767 ][Training] 18/57 [========>.....................] - ETA: 1:08  [ loss=6.7399 ][Training] 19/57 [=========>....................] - ETA: 1:06  [ loss=3.8306 ][Training] 20/57 [=========>....................] - ETA: 1:06  [ loss=3.4869 ][Training] 21/57 [==========>...................] - ETA: 1:04  [ loss=4.1887 ][Training] 22/57 [==========>...................] - ETA: 1:02  [ loss=4.3711 ][Training] 23/57 [===========>..................] - ETA: 1:01  [ loss=3.9489 ][Training] 24/57 [===========>..................] - ETA: 59s  [ loss=4.3086 ][Training] 25/57 [============>.................] - ETA: 57s  [ loss=5.0934 ][Training] 26/57 [============>.................] - ETA: 55s  [ loss=4.7745 ][Training] 27/57 [=============>................] - ETA: 54s  [ loss=4.2178 ][Training] 28/57 [=============>................] - ETA: 52s  [ loss=7.1963 ][Training] 29/57 [==============>...............] - ETA: 50s  [ loss=3.3419 ][Training] 30/57 [==============>...............] - ETA: 49s  [ loss=3.9218 ][Training] 31/57 [===============>..............] - ETA: 47s  [ loss=4.1314 ][Training] 32/57 [===============>..............] - ETA: 45s  [ loss=2.4788 ][Training] 33/57 [================>.............] - ETA: 43s  [ loss=3.6875 ][Training] 34/57 [================>.............] - ETA: 41s  [ loss=2.5707 ][Training] 35/57 [=================>............] - ETA: 40s  [ loss=5.8078 ][Training] 36/57 [=================>............] - ETA: 38s  [ loss=6.0135 ][Training] 37/57 [==================>...........] - ETA: 36s  [ loss=5.2300 ][Training] 38/57 [===================>..........] - ETA: 34s  [ loss=4.6898 ][Training] 39/57 [===================>..........] - ETA: 33s  [ loss=2.8229 ][Training] 40/57 [====================>.........] - ETA: 31s  [ loss=4.7092 ][Training] 41/57 [====================>.........] - ETA: 29s  [ loss=1.5561 ][Training] 42/57 [=====================>........] - ETA: 27s  [ loss=5.2126 ][Training] 43/57 [=====================>........] - ETA: 25s  [ loss=4.9100 ][Training] 44/57 [======================>.......] - ETA: 23s  [ loss=3.1074 ][Training] 45/57 [======================>.......] - ETA: 22s  [ loss=5.7536 ][Training] 46/57 [=======================>......] - ETA: 20s  [ loss=2.8270 ][Training] 47/57 [=======================>......] - ETA: 18s  [ loss=4.8975 ][Training] 48/57 [========================>.....] - ETA: 16s  [ loss=6.5976 ][Training] 49/57 [========================>.....] - ETA: 14s  [ loss=3.9881 ][Training] 50/57 [=========================>....] - ETA: 12s  [ loss=5.2177 ][Training] 51/57 [=========================>....] - ETA: 10s  [ loss=4.3514 ][Training] 52/57 [==========================>...] - ETA: 9s  [ loss=6.3727 ][Training] 53/57 [==========================>...] - ETA: 7s  [ loss=6.2783 ][Training] 54/57 [===========================>..] - ETA: 5s  [ loss=4.2775 ][Training] 55/57 [===========================>..] - ETA: 3s  [ loss=4.6832 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=5.1084 ][Training] 57/57 [==============================] 1.8s/step  [ loss=3.7761 ]
01/08/2024 11:56:48 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/08/2024 11:56:48 - INFO - root -   ***** Running evaluation on test dataset  *****
01/08/2024 11:56:48 - INFO - root -     Num examples = 269
01/08/2024 11:56:48 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 8s[Evaluating] 2/12 [====>.........................] - ETA: 8s[Evaluating] 3/12 [======>.......................] - ETA: 7s[Evaluating] 4/12 [=========>....................] - ETA: 6s[Evaluating] 5/12 [===========>..................] - ETA: 5s[Evaluating] 6/12 [==============>...............] - ETA: 4s[Evaluating] 7/12 [================>.............] - ETA: 4s[Evaluating] 8/12 [===================>..........] - ETA: 3s[Evaluating] 9/12 [=====================>........] - ETA: 2s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 788.2ms/step
01/08/2024 11:56:57 - INFO - root -   

01/08/2024 11:56:57 - INFO - root -   ***** Eval results  *****
01/08/2024 11:56:57 - INFO - root -    acc: 0.7285 - recall: 0.5327 - f1: 0.6154 - loss: 4.9398 
01/08/2024 11:56:57 - INFO - root -   ***** Entity results  *****
01/08/2024 11:56:57 - INFO - root -   ******* GPE.NAM results ********
01/08/2024 11:56:57 - INFO - root -    acc: 0.7907 - recall: 0.7234 - f1: 0.7556 
01/08/2024 11:56:57 - INFO - root -   ******* GPE.NOM results ********
01/08/2024 11:56:57 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:56:57 - INFO - root -   ******* LOC.NAM results ********
01/08/2024 11:56:57 - INFO - root -    acc: 1.0000 - recall: 0.0526 - f1: 0.1000 
01/08/2024 11:56:57 - INFO - root -   ******* LOC.NOM results ********
01/08/2024 11:56:57 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:56:57 - INFO - root -   ******* ORG.NAM results ********
01/08/2024 11:56:57 - INFO - root -    acc: 0.6000 - recall: 0.2308 - f1: 0.3333 
01/08/2024 11:56:57 - INFO - root -   ******* ORG.NOM results ********
01/08/2024 11:56:57 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:56:57 - INFO - root -   ******* PER.NAM results ********
01/08/2024 11:56:57 - INFO - root -    acc: 0.8000 - recall: 0.6909 - f1: 0.7415 
01/08/2024 11:56:57 - INFO - root -   ******* PER.NOM results ********
01/08/2024 11:56:57 - INFO - root -    acc: 0.6757 - recall: 0.5882 - f1: 0.6289 
01/08/2024 11:57:18 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-912
01/08/2024 11:57:18 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-912
01/08/2024 11:57:18 - INFO - root -   

01/08/2024 11:57:18 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 16/50
[Training] 1/57 [..............................] - ETA: 2:19  [ loss=4.3659 ][Training] 2/57 [>.............................] - ETA: 1:56  [ loss=3.7916 ][Training] 3/57 [>.............................] - ETA: 1:36  [ loss=3.9728 ][Training] 4/57 [=>............................] - ETA: 1:34  [ loss=3.1685 ][Training] 5/57 [=>............................] - ETA: 1:29  [ loss=3.8771 ][Training] 6/57 [==>...........................] - ETA: 1:25  [ loss=2.8813 ][Training] 7/57 [==>...........................] - ETA: 1:23  [ loss=3.8721 ][Training] 8/57 [===>..........................] - ETA: 1:20  [ loss=3.1299 ][Training] 9/57 [===>..........................] - ETA: 1:17  [ loss=2.9211 ][Training] 10/57 [====>.........................] - ETA: 1:14  [ loss=3.0493 ][Training] 11/57 [====>.........................] - ETA: 1:13  [ loss=4.8290 ][Training] 12/57 [=====>........................] - ETA: 1:11  [ loss=4.4765 ][Training] 13/57 [=====>........................] - ETA: 1:09  [ loss=6.0396 ][Training] 14/57 [======>.......................] - ETA: 1:07  [ loss=5.3312 ][Training] 15/57 [======>.......................] - ETA: 1:04  [ loss=2.9274 ][Training] 16/57 [=======>......................] - ETA: 1:02  [ loss=3.4143 ][Training] 17/57 [=======>......................] - ETA: 1:00  [ loss=4.7091 ][Training] 18/57 [========>.....................] - ETA: 58s  [ loss=3.5054 ][Training] 19/57 [=========>....................] - ETA: 57s  [ loss=3.4043 ][Training] 20/57 [=========>....................] - ETA: 55s  [ loss=5.5712 ][Training] 21/57 [==========>...................] - ETA: 53s  [ loss=6.2662 ][Training] 22/57 [==========>...................] - ETA: 52s  [ loss=4.7841 ][Training] 23/57 [===========>..................] - ETA: 51s  [ loss=1.9318 ][Training] 24/57 [===========>..................] - ETA: 51s  [ loss=3.0586 ][Training] 25/57 [============>.................] - ETA: 49s  [ loss=2.0928 ][Training] 26/57 [============>.................] - ETA: 48s  [ loss=6.4192 ][Training] 27/57 [=============>................] - ETA: 47s  [ loss=4.5422 ][Training] 28/57 [=============>................] - ETA: 46s  [ loss=1.7525 ][Training] 29/57 [==============>...............] - ETA: 45s  [ loss=6.2056 ][Training] 30/57 [==============>...............] - ETA: 44s  [ loss=4.6873 ][Training] 31/57 [===============>..............] - ETA: 43s  [ loss=3.3394 ][Training] 32/57 [===============>..............] - ETA: 42s  [ loss=6.7304 ][Training] 33/57 [================>.............] - ETA: 41s  [ loss=4.8588 ][Training] 34/57 [================>.............] - ETA: 40s  [ loss=4.8758 ][Training] 35/57 [=================>............] - ETA: 39s  [ loss=3.2406 ][Training] 36/57 [=================>............] - ETA: 37s  [ loss=5.0274 ][Training] 37/57 [==================>...........] - ETA: 36s  [ loss=4.9553 ][Training] 38/57 [===================>..........] - ETA: 34s  [ loss=5.4580 ][Training] 39/57 [===================>..........] - ETA: 32s  [ loss=3.8956 ][Training] 40/57 [====================>.........] - ETA: 31s  [ loss=4.1984 ][Training] 41/57 [====================>.........] - ETA: 29s  [ loss=4.0878 ][Training] 42/57 [=====================>........] - ETA: 27s  [ loss=5.1309 ][Training] 43/57 [=====================>........] - ETA: 25s  [ loss=3.9254 ][Training] 44/57 [======================>.......] - ETA: 23s  [ loss=2.7592 ][Training] 45/57 [======================>.......] - ETA: 22s  [ loss=4.0396 ][Training] 46/57 [=======================>......] - ETA: 20s  [ loss=4.0213 ][Training] 47/57 [=======================>......] - ETA: 18s  [ loss=3.8346 ][Training] 48/57 [========================>.....] - ETA: 16s  [ loss=3.3423 ][Training] 49/57 [========================>.....] - ETA: 14s  [ loss=3.1870 ][Training] 50/57 [=========================>....] - ETA: 13s  [ loss=4.4022 ][Training] 51/57 [=========================>....] - ETA: 11s  [ loss=7.8432 ][Training] 52/57 [==========================>...] - ETA: 9s  [ loss=6.6589 ][Training] 53/57 [==========================>...] - ETA: 7s  [ loss=6.1713 ][Training] 54/57 [===========================>..] - ETA: 5s  [ loss=2.4836 ][Training] 55/57 [===========================>..] - ETA: 3s  [ loss=3.6662 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=5.1839 ][Training] 57/57 [==============================] 1.9s/step  [ loss=3.3978 ]
01/08/2024 11:59:07 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/08/2024 11:59:07 - INFO - root -   ***** Running evaluation on test dataset  *****
01/08/2024 11:59:07 - INFO - root -     Num examples = 269
01/08/2024 11:59:07 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 12s[Evaluating] 2/12 [====>.........................] - ETA: 11s[Evaluating] 3/12 [======>.......................] - ETA: 10s[Evaluating] 4/12 [=========>....................] - ETA: 8s[Evaluating] 5/12 [===========>..................] - ETA: 7s[Evaluating] 6/12 [==============>...............] - ETA: 6s[Evaluating] 7/12 [================>.............] - ETA: 5s[Evaluating] 8/12 [===================>..........] - ETA: 3s[Evaluating] 9/12 [=====================>........] - ETA: 2s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 936.3ms/step
01/08/2024 11:59:19 - INFO - root -   

01/08/2024 11:59:19 - INFO - root -   ***** Eval results  *****
01/08/2024 11:59:19 - INFO - root -    acc: 0.7344 - recall: 0.5424 - f1: 0.6240 - loss: 4.7622 
01/08/2024 11:59:19 - INFO - root -   ***** Entity results  *****
01/08/2024 11:59:19 - INFO - root -   ******* GPE.NAM results ********
01/08/2024 11:59:19 - INFO - root -    acc: 0.7727 - recall: 0.7234 - f1: 0.7473 
01/08/2024 11:59:19 - INFO - root -   ******* GPE.NOM results ********
01/08/2024 11:59:19 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:59:19 - INFO - root -   ******* LOC.NAM results ********
01/08/2024 11:59:19 - INFO - root -    acc: 0.5000 - recall: 0.0526 - f1: 0.0952 
01/08/2024 11:59:19 - INFO - root -   ******* LOC.NOM results ********
01/08/2024 11:59:19 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 11:59:19 - INFO - root -   ******* ORG.NAM results ********
01/08/2024 11:59:19 - INFO - root -    acc: 0.7143 - recall: 0.2564 - f1: 0.3774 
01/08/2024 11:59:19 - INFO - root -   ******* ORG.NOM results ********
01/08/2024 11:59:19 - INFO - root -    acc: 1.0000 - recall: 0.0588 - f1: 0.1111 
01/08/2024 11:59:19 - INFO - root -   ******* PER.NAM results ********
01/08/2024 11:59:19 - INFO - root -    acc: 0.7812 - recall: 0.6818 - f1: 0.7282 
01/08/2024 11:59:19 - INFO - root -   ******* PER.NOM results ********
01/08/2024 11:59:19 - INFO - root -    acc: 0.6959 - recall: 0.6059 - f1: 0.6478 
01/08/2024 11:59:36 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-969
01/08/2024 11:59:36 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-969
01/08/2024 11:59:36 - INFO - root -   

01/08/2024 11:59:36 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 17/50
[Training] 1/57 [..............................] - ETA: 1:08  [ loss=3.7124 ][Training] 2/57 [>.............................] - ETA: 1:03  [ loss=4.0917 ][Training] 3/57 [>.............................] - ETA: 1:05  [ loss=1.8528 ][Training] 4/57 [=>............................] - ETA: 1:02  [ loss=4.1200 ][Training] 5/57 [=>............................] - ETA: 1:04  [ loss=4.6662 ][Training] 6/57 [==>...........................] - ETA: 1:06  [ loss=3.3395 ][Training] 7/57 [==>...........................] - ETA: 1:08  [ loss=5.4134 ][Training] 8/57 [===>..........................] - ETA: 1:06  [ loss=2.4253 ][Training] 9/57 [===>..........................] - ETA: 1:04  [ loss=5.1029 ][Training] 10/57 [====>.........................] - ETA: 1:03  [ loss=4.0868 ][Training] 11/57 [====>.........................] - ETA: 1:01  [ loss=3.7793 ][Training] 12/57 [=====>........................] - ETA: 1:01  [ loss=7.8140 ][Training] 13/57 [=====>........................] - ETA: 1:00  [ loss=4.0316 ][Training] 14/57 [======>.......................] - ETA: 1:00  [ loss=4.1337 ][Training] 15/57 [======>.......................] - ETA: 58s  [ loss=3.1341 ][Training] 16/57 [=======>......................] - ETA: 57s  [ loss=3.7735 ][Training] 17/57 [=======>......................] - ETA: 56s  [ loss=2.2041 ][Training] 18/57 [========>.....................] - ETA: 54s  [ loss=8.9959 ][Training] 19/57 [=========>....................] - ETA: 54s  [ loss=7.5786 ][Training] 20/57 [=========>....................] - ETA: 53s  [ loss=4.3743 ][Training] 21/57 [==========>...................] - ETA: 51s  [ loss=2.6933 ][Training] 22/57 [==========>...................] - ETA: 49s  [ loss=4.1449 ][Training] 23/57 [===========>..................] - ETA: 48s  [ loss=5.7713 ][Training] 24/57 [===========>..................] - ETA: 46s  [ loss=2.7434 ][Training] 25/57 [============>.................] - ETA: 44s  [ loss=3.3365 ][Training] 26/57 [============>.................] - ETA: 43s  [ loss=5.1011 ][Training] 27/57 [=============>................] - ETA: 41s  [ loss=4.3499 ][Training] 28/57 [=============>................] - ETA: 39s  [ loss=2.6527 ][Training] 29/57 [==============>...............] - ETA: 37s  [ loss=5.2137 ][Training] 30/57 [==============>...............] - ETA: 35s  [ loss=4.4850 ][Training] 31/57 [===============>..............] - ETA: 33s  [ loss=2.6151 ][Training] 32/57 [===============>..............] - ETA: 32s  [ loss=4.1039 ][Training] 33/57 [================>.............] - ETA: 30s  [ loss=2.9886 ][Training] 34/57 [================>.............] - ETA: 28s  [ loss=5.0653 ][Training] 35/57 [=================>............] - ETA: 27s  [ loss=4.1460 ][Training] 36/57 [=================>............] - ETA: 25s  [ loss=4.0842 ][Training] 37/57 [==================>...........] - ETA: 24s  [ loss=3.6239 ][Training] 38/57 [===================>..........] - ETA: 22s  [ loss=3.9294 ][Training] 39/57 [===================>..........] - ETA: 21s  [ loss=2.7521 ][Training] 40/57 [====================>.........] - ETA: 20s  [ loss=2.8677 ][Training] 41/57 [====================>.........] - ETA: 18s  [ loss=2.4019 ][Training] 42/57 [=====================>........] - ETA: 17s  [ loss=4.7460 ][Training] 43/57 [=====================>........] - ETA: 16s  [ loss=2.6957 ][Training] 44/57 [======================>.......] - ETA: 14s  [ loss=2.2204 ][Training] 45/57 [======================>.......] - ETA: 13s  [ loss=4.3816 ][Training] 46/57 [=======================>......] - ETA: 12s  [ loss=4.0528 ][Training] 47/57 [=======================>......] - ETA: 11s  [ loss=5.7097 ][Training] 48/57 [========================>.....] - ETA: 10s  [ loss=3.3222 ][Training] 49/57 [========================>.....] - ETA: 9s  [ loss=6.1682 ][Training] 50/57 [=========================>....] - ETA: 8s  [ loss=4.6318 ][Training] 51/57 [=========================>....] - ETA: 6s  [ loss=4.1229 ][Training] 52/57 [==========================>...] - ETA: 5s  [ loss=1.9070 ][Training] 53/57 [==========================>...] - ETA: 4s  [ loss=2.5535 ][Training] 54/57 [===========================>..] - ETA: 3s  [ loss=2.1953 ][Training] 55/57 [===========================>..] - ETA: 2s  [ loss=3.8555 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=7.8892 ][Training] 57/57 [==============================] 1.1s/step  [ loss=1.7042 ]
01/08/2024 12:00:40 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/08/2024 12:00:40 - INFO - root -   ***** Running evaluation on test dataset  *****
01/08/2024 12:00:40 - INFO - root -     Num examples = 269
01/08/2024 12:00:40 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 6s[Evaluating] 2/12 [====>.........................] - ETA: 5s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 3s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 624.7ms/step
01/08/2024 12:00:48 - INFO - root -   

01/08/2024 12:00:48 - INFO - root -   ***** Eval results  *****
01/08/2024 12:00:48 - INFO - root -    acc: 0.7492 - recall: 0.5569 - f1: 0.6389 - loss: 4.6438 
01/08/2024 12:00:48 - INFO - root -   ***** Entity results  *****
01/08/2024 12:00:48 - INFO - root -   ******* GPE.NAM results ********
01/08/2024 12:00:48 - INFO - root -    acc: 0.7778 - recall: 0.7447 - f1: 0.7609 
01/08/2024 12:00:48 - INFO - root -   ******* GPE.NOM results ********
01/08/2024 12:00:48 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 12:00:48 - INFO - root -   ******* LOC.NAM results ********
01/08/2024 12:00:48 - INFO - root -    acc: 0.5000 - recall: 0.0526 - f1: 0.0952 
01/08/2024 12:00:48 - INFO - root -   ******* LOC.NOM results ********
01/08/2024 12:00:48 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 12:00:48 - INFO - root -   ******* ORG.NAM results ********
01/08/2024 12:00:48 - INFO - root -    acc: 0.6000 - recall: 0.2308 - f1: 0.3333 
01/08/2024 12:00:48 - INFO - root -   ******* ORG.NOM results ********
01/08/2024 12:00:48 - INFO - root -    acc: 1.0000 - recall: 0.1176 - f1: 0.2105 
01/08/2024 12:00:48 - INFO - root -   ******* PER.NAM results ********
01/08/2024 12:00:48 - INFO - root -    acc: 0.8065 - recall: 0.6818 - f1: 0.7389 
01/08/2024 12:00:48 - INFO - root -   ******* PER.NOM results ********
01/08/2024 12:00:48 - INFO - root -    acc: 0.7200 - recall: 0.6353 - f1: 0.6750 
01/08/2024 12:02:11 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1026
01/08/2024 12:02:11 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1026
01/08/2024 12:02:11 - INFO - root -   

01/08/2024 12:02:11 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 18/50
[Training] 1/57 [..............................] - ETA: 1:19  [ loss=5.9782 ][Training] 2/57 [>.............................] - ETA: 1:22  [ loss=6.5307 ][Training] 3/57 [>.............................] - ETA: 1:24  [ loss=4.3528 ][Training] 4/57 [=>............................] - ETA: 1:18  [ loss=3.8764 ][Training] 5/57 [=>............................] - ETA: 1:15  [ loss=3.4126 ][Training] 6/57 [==>...........................] - ETA: 1:13  [ loss=2.8221 ][Training] 7/57 [==>...........................] - ETA: 1:11  [ loss=4.2955 ][Training] 8/57 [===>..........................] - ETA: 1:10  [ loss=5.9562 ][Training] 9/57 [===>..........................] - ETA: 1:08  [ loss=4.5871 ][Training] 10/57 [====>.........................] - ETA: 1:06  [ loss=3.0250 ][Training] 11/57 [====>.........................] - ETA: 1:04  [ loss=1.2759 ][Training] 12/57 [=====>........................] - ETA: 1:04  [ loss=3.1841 ][Training] 13/57 [=====>........................] - ETA: 1:02  [ loss=2.7480 ][Training] 14/57 [======>.......................] - ETA: 1:02  [ loss=1.9230 ][Training] 15/57 [======>.......................] - ETA: 1:01  [ loss=4.4395 ][Training] 16/57 [=======>......................] - ETA: 59s  [ loss=3.0618 ][Training] 17/57 [=======>......................] - ETA: 1:00  [ loss=4.7702 ][Training] 18/57 [========>.....................] - ETA: 59s  [ loss=3.5112 ][Training] 19/57 [=========>....................] - ETA: 59s  [ loss=6.2375 ][Training] 20/57 [=========>....................] - ETA: 58s  [ loss=4.3384 ][Training] 21/57 [==========>...................] - ETA: 57s  [ loss=5.4481 ][Training] 22/57 [==========>...................] - ETA: 56s  [ loss=2.6041 ][Training] 23/57 [===========>..................] - ETA: 54s  [ loss=2.3275 ][Training] 24/57 [===========>..................] - ETA: 53s  [ loss=3.4944 ][Training] 25/57 [============>.................] - ETA: 51s  [ loss=4.8865 ][Training] 26/57 [============>.................] - ETA: 50s  [ loss=2.5578 ][Training] 27/57 [=============>................] - ETA: 49s  [ loss=4.4387 ][Training] 28/57 [=============>................] - ETA: 48s  [ loss=2.0517 ][Training] 29/57 [==============>...............] - ETA: 46s  [ loss=2.8516 ][Training] 30/57 [==============>...............] - ETA: 45s  [ loss=3.7751 ][Training] 31/57 [===============>..............] - ETA: 43s  [ loss=3.2154 ][Training] 32/57 [===============>..............] - ETA: 41s  [ loss=2.6193 ][Training] 33/57 [================>.............] - ETA: 39s  [ loss=2.2830 ][Training] 34/57 [================>.............] - ETA: 38s  [ loss=4.1205 ][Training] 35/57 [=================>............] - ETA: 36s  [ loss=4.8503 ][Training] 36/57 [=================>............] - ETA: 35s  [ loss=5.5010 ][Training] 37/57 [==================>...........] - ETA: 33s  [ loss=2.9101 ][Training] 38/57 [===================>..........] - ETA: 32s  [ loss=6.3222 ][Training] 39/57 [===================>..........] - ETA: 30s  [ loss=4.9026 ][Training] 40/57 [====================>.........] - ETA: 29s  [ loss=5.1742 ][Training] 41/57 [====================>.........] - ETA: 27s  [ loss=4.1962 ][Training] 42/57 [=====================>........] - ETA: 25s  [ loss=4.6749 ][Training] 43/57 [=====================>........] - ETA: 23s  [ loss=2.9552 ][Training] 44/57 [======================>.......] - ETA: 22s  [ loss=4.4187 ][Training] 45/57 [======================>.......] - ETA: 20s  [ loss=3.1129 ][Training] 46/57 [=======================>......] - ETA: 18s  [ loss=3.0574 ][Training] 47/57 [=======================>......] - ETA: 17s  [ loss=4.2964 ][Training] 48/57 [========================>.....] - ETA: 15s  [ loss=2.9740 ][Training] 49/57 [========================>.....] - ETA: 13s  [ loss=3.2002 ][Training] 50/57 [=========================>....] - ETA: 12s  [ loss=4.2007 ][Training] 51/57 [=========================>....] - ETA: 10s  [ loss=3.5317 ][Training] 52/57 [==========================>...] - ETA: 8s  [ loss=2.1437 ][Training] 53/57 [==========================>...] - ETA: 6s  [ loss=6.0650 ][Training] 54/57 [===========================>..] - ETA: 5s  [ loss=4.3487 ][Training] 55/57 [===========================>..] - ETA: 3s  [ loss=2.8568 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=4.5844 ][Training] 57/57 [==============================] 1.7s/step  [ loss=4.4802 ]
01/08/2024 12:03:49 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/08/2024 12:03:49 - INFO - root -   ***** Running evaluation on test dataset  *****
01/08/2024 12:03:49 - INFO - root -     Num examples = 269
01/08/2024 12:03:49 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 7s[Evaluating] 2/12 [====>.........................] - ETA: 8s[Evaluating] 3/12 [======>.......................] - ETA: 8s[Evaluating] 4/12 [=========>....................] - ETA: 7s[Evaluating] 5/12 [===========>..................] - ETA: 6s[Evaluating] 6/12 [==============>...............] - ETA: 5s[Evaluating] 7/12 [================>.............] - ETA: 4s[Evaluating] 8/12 [===================>..........] - ETA: 3s[Evaluating] 9/12 [=====================>........] - ETA: 2s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 820.6ms/step
01/08/2024 12:03:59 - INFO - root -   

01/08/2024 12:03:59 - INFO - root -   ***** Eval results  *****
01/08/2024 12:03:59 - INFO - root -    acc: 0.7476 - recall: 0.5666 - f1: 0.6446 - loss: 4.5164 
01/08/2024 12:03:59 - INFO - root -   ***** Entity results  *****
01/08/2024 12:03:59 - INFO - root -   ******* GPE.NAM results ********
01/08/2024 12:03:59 - INFO - root -    acc: 0.7826 - recall: 0.7660 - f1: 0.7742 
01/08/2024 12:03:59 - INFO - root -   ******* GPE.NOM results ********
01/08/2024 12:03:59 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 12:03:59 - INFO - root -   ******* LOC.NAM results ********
01/08/2024 12:03:59 - INFO - root -    acc: 0.3333 - recall: 0.0526 - f1: 0.0909 
01/08/2024 12:03:59 - INFO - root -   ******* LOC.NOM results ********
01/08/2024 12:03:59 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 12:03:59 - INFO - root -   ******* ORG.NAM results ********
01/08/2024 12:03:59 - INFO - root -    acc: 0.7857 - recall: 0.2821 - f1: 0.4151 
01/08/2024 12:03:59 - INFO - root -   ******* ORG.NOM results ********
01/08/2024 12:03:59 - INFO - root -    acc: 1.0000 - recall: 0.1176 - f1: 0.2105 
01/08/2024 12:03:59 - INFO - root -   ******* PER.NAM results ********
01/08/2024 12:03:59 - INFO - root -    acc: 0.7895 - recall: 0.6818 - f1: 0.7317 
01/08/2024 12:03:59 - INFO - root -   ******* PER.NOM results ********
01/08/2024 12:03:59 - INFO - root -    acc: 0.7124 - recall: 0.6412 - f1: 0.6749 
01/08/2024 12:04:33 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1083
01/08/2024 12:04:33 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1083
01/08/2024 12:04:33 - INFO - root -   

01/08/2024 12:04:33 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 19/50
[Training] 1/57 [..............................] - ETA: 1:49  [ loss=3.4714 ][Training] 2/57 [>.............................] - ETA: 2:04  [ loss=4.2107 ][Training] 3/57 [>.............................] - ETA: 1:51  [ loss=3.1725 ][Training] 4/57 [=>............................] - ETA: 1:37  [ loss=4.5472 ][Training] 5/57 [=>............................] - ETA: 1:30  [ loss=3.0473 ][Training] 6/57 [==>...........................] - ETA: 1:24  [ loss=2.6868 ][Training] 7/57 [==>...........................] - ETA: 1:20  [ loss=2.5189 ][Training] 8/57 [===>..........................] - ETA: 1:16  [ loss=5.4246 ][Training] 9/57 [===>..........................] - ETA: 1:14  [ loss=3.4199 ][Training] 10/57 [====>.........................] - ETA: 1:12  [ loss=3.4099 ][Training] 11/57 [====>.........................] - ETA: 1:12  [ loss=4.6173 ][Training] 12/57 [=====>........................] - ETA: 1:11  [ loss=3.1655 ][Training] 13/57 [=====>........................] - ETA: 1:08  [ loss=3.3643 ][Training] 14/57 [======>.......................] - ETA: 1:06  [ loss=4.8319 ][Training] 15/57 [======>.......................] - ETA: 1:04  [ loss=2.0531 ][Training] 16/57 [=======>......................] - ETA: 1:02  [ loss=3.4012 ][Training] 17/57 [=======>......................] - ETA: 1:00  [ loss=3.8913 ][Training] 18/57 [========>.....................] - ETA: 58s  [ loss=3.3572 ][Training] 19/57 [=========>....................] - ETA: 57s  [ loss=5.2357 ][Training] 20/57 [=========>....................] - ETA: 55s  [ loss=1.4093 ][Training] 21/57 [==========>...................] - ETA: 54s  [ loss=6.4380 ][Training] 22/57 [==========>...................] - ETA: 52s  [ loss=3.5462 ][Training] 23/57 [===========>..................] - ETA: 51s  [ loss=4.4829 ][Training] 24/57 [===========>..................] - ETA: 50s  [ loss=2.9319 ][Training] 25/57 [============>.................] - ETA: 49s  [ loss=1.4151 ][Training] 26/57 [============>.................] - ETA: 48s  [ loss=2.9614 ][Training] 27/57 [=============>................] - ETA: 46s  [ loss=3.9974 ][Training] 28/57 [=============>................] - ETA: 46s  [ loss=5.6034 ][Training] 29/57 [==============>...............] - ETA: 45s  [ loss=7.5511 ][Training] 30/57 [==============>...............] - ETA: 43s  [ loss=4.5916 ][Training] 31/57 [===============>..............] - ETA: 42s  [ loss=2.4265 ][Training] 32/57 [===============>..............] - ETA: 40s  [ loss=2.5918 ][Training] 33/57 [================>.............] - ETA: 38s  [ loss=2.8972 ][Training] 34/57 [================>.............] - ETA: 37s  [ loss=3.5122 ][Training] 35/57 [=================>............] - ETA: 36s  [ loss=3.1225 ][Training] 36/57 [=================>............] - ETA: 34s  [ loss=4.0054 ][Training] 37/57 [==================>...........] - ETA: 33s  [ loss=3.8591 ][Training] 38/57 [===================>..........] - ETA: 31s  [ loss=1.3199 ][Training] 39/57 [===================>..........] - ETA: 30s  [ loss=3.8163 ][Training] 40/57 [====================>.........] - ETA: 28s  [ loss=4.8703 ][Training] 41/57 [====================>.........] - ETA: 26s  [ loss=1.5916 ][Training] 42/57 [=====================>........] - ETA: 25s  [ loss=3.7782 ][Training] 43/57 [=====================>........] - ETA: 23s  [ loss=2.6520 ][Training] 44/57 [======================>.......] - ETA: 22s  [ loss=4.0135 ][Training] 45/57 [======================>.......] - ETA: 20s  [ loss=2.9094 ][Training] 46/57 [=======================>......] - ETA: 18s  [ loss=2.7242 ][Training] 47/57 [=======================>......] - ETA: 17s  [ loss=3.8584 ][Training] 48/57 [========================>.....] - ETA: 15s  [ loss=2.7480 ][Training] 49/57 [========================>.....] - ETA: 13s  [ loss=5.0344 ][Training] 50/57 [=========================>....] - ETA: 11s  [ loss=1.6873 ][Training] 51/57 [=========================>....] - ETA: 10s  [ loss=4.6373 ][Training] 52/57 [==========================>...] - ETA: 8s  [ loss=5.0230 ][Training] 53/57 [==========================>...] - ETA: 6s  [ loss=5.1590 ][Training] 54/57 [===========================>..] - ETA: 5s  [ loss=6.5382 ][Training] 55/57 [===========================>..] - ETA: 3s  [ loss=5.0711 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=3.5959 ][Training] 57/57 [==============================] 1.7s/step  [ loss=4.1399 ]
01/08/2024 12:06:11 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/08/2024 12:06:11 - INFO - root -   ***** Running evaluation on test dataset  *****
01/08/2024 12:06:11 - INFO - root -     Num examples = 269
01/08/2024 12:06:11 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 8s[Evaluating] 2/12 [====>.........................] - ETA: 7s[Evaluating] 3/12 [======>.......................] - ETA: 7s[Evaluating] 4/12 [=========>....................] - ETA: 6s[Evaluating] 5/12 [===========>..................] - ETA: 5s[Evaluating] 6/12 [==============>...............] - ETA: 4s[Evaluating] 7/12 [================>.............] - ETA: 4s[Evaluating] 8/12 [===================>..........] - ETA: 3s[Evaluating] 9/12 [=====================>........] - ETA: 2s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 823.1ms/step
01/08/2024 12:06:21 - INFO - root -   

01/08/2024 12:06:21 - INFO - root -   ***** Eval results  *****
01/08/2024 12:06:21 - INFO - root -    acc: 0.7548 - recall: 0.5738 - f1: 0.6520 - loss: 4.4035 
01/08/2024 12:06:21 - INFO - root -   ***** Entity results  *****
01/08/2024 12:06:21 - INFO - root -   ******* GPE.NAM results ********
01/08/2024 12:06:21 - INFO - root -    acc: 0.7872 - recall: 0.7872 - f1: 0.7872 
01/08/2024 12:06:21 - INFO - root -   ******* GPE.NOM results ********
01/08/2024 12:06:21 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 12:06:21 - INFO - root -   ******* LOC.NAM results ********
01/08/2024 12:06:21 - INFO - root -    acc: 0.2500 - recall: 0.0526 - f1: 0.0870 
01/08/2024 12:06:21 - INFO - root -   ******* LOC.NOM results ********
01/08/2024 12:06:21 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 12:06:21 - INFO - root -   ******* ORG.NAM results ********
01/08/2024 12:06:21 - INFO - root -    acc: 0.6471 - recall: 0.2821 - f1: 0.3929 
01/08/2024 12:06:21 - INFO - root -   ******* ORG.NOM results ********
01/08/2024 12:06:21 - INFO - root -    acc: 1.0000 - recall: 0.1176 - f1: 0.2105 
01/08/2024 12:06:21 - INFO - root -   ******* PER.NAM results ********
01/08/2024 12:06:21 - INFO - root -    acc: 0.8172 - recall: 0.6909 - f1: 0.7488 
01/08/2024 12:06:21 - INFO - root -   ******* PER.NOM results ********
01/08/2024 12:06:21 - INFO - root -    acc: 0.7285 - recall: 0.6471 - f1: 0.6854 
01/08/2024 12:06:44 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1140
01/08/2024 12:06:44 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1140
01/08/2024 12:06:44 - INFO - root -   

01/08/2024 12:06:44 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 20/50
[Training] 1/57 [..............................] - ETA: 1:46  [ loss=2.4268 ][Training] 2/57 [>.............................] - ETA: 1:41  [ loss=1.9867 ][Training] 3/57 [>.............................] - ETA: 1:46  [ loss=4.0458 ][Training] 4/57 [=>............................] - ETA: 1:39  [ loss=1.6448 ][Training] 5/57 [=>............................] - ETA: 1:40  [ loss=3.9319 ][Training] 6/57 [==>...........................] - ETA: 1:38  [ loss=4.3437 ][Training] 7/57 [==>...........................] - ETA: 1:38  [ loss=4.6714 ][Training] 8/57 [===>..........................] - ETA: 1:35  [ loss=3.9084 ][Training] 9/57 [===>..........................] - ETA: 1:33  [ loss=5.3017 ][Training] 10/57 [====>.........................] - ETA: 1:30  [ loss=3.2639 ][Training] 11/57 [====>.........................] - ETA: 1:29  [ loss=2.3941 ][Training] 12/57 [=====>........................] - ETA: 1:26  [ loss=4.4421 ][Training] 13/57 [=====>........................] - ETA: 1:25  [ loss=1.2690 ][Training] 14/57 [======>.......................] - ETA: 1:24  [ loss=3.6089 ][Training] 15/57 [======>.......................] - ETA: 1:22  [ loss=2.4592 ][Training] 16/57 [=======>......................] - ETA: 1:21  [ loss=4.0663 ][Training] 17/57 [=======>......................] - ETA: 1:18  [ loss=3.8278 ][Training] 18/57 [========>.....................] - ETA: 1:15  [ loss=4.6484 ][Training] 19/57 [=========>....................] - ETA: 1:13  [ loss=2.3273 ][Training] 20/57 [=========>....................] - ETA: 1:09  [ loss=2.3586 ][Training] 21/57 [==========>...................] - ETA: 1:07  [ loss=4.1269 ][Training] 22/57 [==========>...................] - ETA: 1:04  [ loss=5.9672 ][Training] 23/57 [===========>..................] - ETA: 1:02  [ loss=2.9195 ][Training] 24/57 [===========>..................] - ETA: 1:01  [ loss=4.0928 ][Training] 25/57 [============>.................] - ETA: 59s  [ loss=4.0237 ][Training] 26/57 [============>.................] - ETA: 58s  [ loss=4.7582 ][Training] 27/57 [=============>................] - ETA: 56s  [ loss=3.2473 ][Training] 28/57 [=============>................] - ETA: 55s  [ loss=4.4793 ][Training] 29/57 [==============>...............] - ETA: 53s  [ loss=3.8063 ][Training] 30/57 [==============>...............] - ETA: 51s  [ loss=2.9667 ][Training] 31/57 [===============>..............] - ETA: 49s  [ loss=2.6421 ][Training] 32/57 [===============>..............] - ETA: 47s  [ loss=3.2378 ][Training] 33/57 [================>.............] - ETA: 45s  [ loss=5.3808 ][Training] 34/57 [================>.............] - ETA: 43s  [ loss=2.7272 ][Training] 35/57 [=================>............] - ETA: 41s  [ loss=2.9665 ][Training] 36/57 [=================>............] - ETA: 39s  [ loss=3.6082 ][Training] 37/57 [==================>...........] - ETA: 36s  [ loss=2.7999 ][Training] 38/57 [===================>..........] - ETA: 34s  [ loss=4.3320 ][Training] 39/57 [===================>..........] - ETA: 32s  [ loss=2.5567 ][Training] 40/57 [====================>.........] - ETA: 31s  [ loss=2.6334 ][Training] 41/57 [====================>.........] - ETA: 29s  [ loss=5.0767 ][Training] 42/57 [=====================>........] - ETA: 27s  [ loss=5.2601 ][Training] 43/57 [=====================>........] - ETA: 25s  [ loss=2.5218 ][Training] 44/57 [======================>.......] - ETA: 23s  [ loss=3.4314 ][Training] 45/57 [======================>.......] - ETA: 21s  [ loss=2.4500 ][Training] 46/57 [=======================>......] - ETA: 19s  [ loss=3.4907 ][Training] 47/57 [=======================>......] - ETA: 17s  [ loss=3.7053 ][Training] 48/57 [========================>.....] - ETA: 16s  [ loss=4.4761 ][Training] 49/57 [========================>.....] - ETA: 14s  [ loss=5.6088 ][Training] 50/57 [=========================>....] - ETA: 12s  [ loss=1.6708 ][Training] 51/57 [=========================>....] - ETA: 10s  [ loss=4.4555 ][Training] 52/57 [==========================>...] - ETA: 9s  [ loss=4.9982 ][Training] 53/57 [==========================>...] - ETA: 7s  [ loss=2.0447 ][Training] 54/57 [===========================>..] - ETA: 5s  [ loss=3.2382 ][Training] 55/57 [===========================>..] - ETA: 3s  [ loss=3.4740 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=3.0380 ][Training] 57/57 [==============================] 1.8s/step  [ loss=1.8723 ]
01/08/2024 12:08:28 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/08/2024 12:08:28 - INFO - root -   ***** Running evaluation on test dataset  *****
01/08/2024 12:08:28 - INFO - root -     Num examples = 269
01/08/2024 12:08:28 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 11s[Evaluating] 2/12 [====>.........................] - ETA: 10s[Evaluating] 3/12 [======>.......................] - ETA: 8s[Evaluating] 4/12 [=========>....................] - ETA: 7s[Evaluating] 5/12 [===========>..................] - ETA: 6s[Evaluating] 6/12 [==============>...............] - ETA: 5s[Evaluating] 7/12 [================>.............] - ETA: 4s[Evaluating] 8/12 [===================>..........] - ETA: 3s[Evaluating] 9/12 [=====================>........] - ETA: 2s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 860.4ms/step
01/08/2024 12:08:38 - INFO - root -   

01/08/2024 12:08:38 - INFO - root -   ***** Eval results  *****
01/08/2024 12:08:38 - INFO - root -    acc: 0.7287 - recall: 0.5787 - f1: 0.6451 - loss: 4.2968 
01/08/2024 12:08:38 - INFO - root -   ***** Entity results  *****
01/08/2024 12:08:38 - INFO - root -   ******* GPE.NAM results ********
01/08/2024 12:08:38 - INFO - root -    acc: 0.7872 - recall: 0.7872 - f1: 0.7872 
01/08/2024 12:08:38 - INFO - root -   ******* GPE.NOM results ********
01/08/2024 12:08:38 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 12:08:38 - INFO - root -   ******* LOC.NAM results ********
01/08/2024 12:08:38 - INFO - root -    acc: 0.2857 - recall: 0.1053 - f1: 0.1538 
01/08/2024 12:08:38 - INFO - root -   ******* LOC.NOM results ********
01/08/2024 12:08:38 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 12:08:38 - INFO - root -   ******* ORG.NAM results ********
01/08/2024 12:08:38 - INFO - root -    acc: 0.5556 - recall: 0.2564 - f1: 0.3509 
01/08/2024 12:08:38 - INFO - root -   ******* ORG.NOM results ********
01/08/2024 12:08:38 - INFO - root -    acc: 1.0000 - recall: 0.1176 - f1: 0.2105 
01/08/2024 12:08:38 - INFO - root -   ******* PER.NAM results ********
01/08/2024 12:08:38 - INFO - root -    acc: 0.7849 - recall: 0.6636 - f1: 0.7192 
01/08/2024 12:08:38 - INFO - root -   ******* PER.NOM results ********
01/08/2024 12:08:38 - INFO - root -    acc: 0.7143 - recall: 0.6765 - f1: 0.6949 
01/08/2024 12:08:46 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1197
01/08/2024 12:08:46 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1197
01/08/2024 12:08:46 - INFO - root -   

01/08/2024 12:08:46 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 21/50
[Training] 1/57 [..............................] - ETA: 1:33  [ loss=3.8552 ][Training] 2/57 [>.............................] - ETA: 1:31  [ loss=5.1167 ][Training] 3/57 [>.............................] - ETA: 1:41  [ loss=6.7245 ][Training] 4/57 [=>............................] - ETA: 1:44  [ loss=2.6787 ][Training] 5/57 [=>............................] - ETA: 1:41  [ loss=3.4010 ][Training] 6/57 [==>...........................] - ETA: 1:42  [ loss=2.5355 ][Training] 7/57 [==>...........................] - ETA: 1:42  [ loss=2.6674 ][Training] 8/57 [===>..........................] - ETA: 1:41  [ loss=3.9522 ][Training] 9/57 [===>..........................] - ETA: 1:39  [ loss=1.8890 ][Training] 10/57 [====>.........................] - ETA: 1:37  [ loss=3.8478 ][Training] 11/57 [====>.........................] - ETA: 1:35  [ loss=4.2103 ][Training] 12/57 [=====>........................] - ETA: 1:31  [ loss=2.2063 ][Training] 13/57 [=====>........................] - ETA: 1:31  [ loss=2.8916 ][Training] 14/57 [======>.......................] - ETA: 1:28  [ loss=4.7976 ][Training] 15/57 [======>.......................] - ETA: 1:25  [ loss=4.3663 ][Training] 16/57 [=======>......................] - ETA: 1:23  [ loss=2.1937 ][Training] 17/57 [=======>......................] - ETA: 1:22  [ loss=3.1120 ][Training] 18/57 [========>.....................] - ETA: 1:20  [ loss=4.4647 ][Training] 19/57 [=========>....................] - ETA: 1:18  [ loss=3.1897 ][Training] 20/57 [=========>....................] - ETA: 1:16  [ loss=1.6004 ][Training] 21/57 [==========>...................] - ETA: 1:14  [ loss=2.9129 ][Training] 22/57 [==========>...................] - ETA: 1:13  [ loss=5.5187 ][Training] 23/57 [===========>..................] - ETA: 1:11  [ loss=2.8114 ][Training] 24/57 [===========>..................] - ETA: 1:08  [ loss=2.7737 ][Training] 25/57 [============>.................] - ETA: 1:06  [ loss=5.1358 ][Training] 26/57 [============>.................] - ETA: 1:05  [ loss=2.8131 ][Training] 27/57 [=============>................] - ETA: 1:03  [ loss=3.3419 ][Training] 28/57 [=============>................] - ETA: 1:01  [ loss=2.8509 ][Training] 29/57 [==============>...............] - ETA: 58s  [ loss=3.5822 ][Training] 30/57 [==============>...............] - ETA: 56s  [ loss=3.6245 ][Training] 31/57 [===============>..............] - ETA: 54s  [ loss=4.2384 ][Training] 32/57 [===============>..............] - ETA: 52s  [ loss=5.3591 ][Training] 33/57 [================>.............] - ETA: 49s  [ loss=2.8420 ][Training] 34/57 [================>.............] - ETA: 47s  [ loss=4.0735 ][Training] 35/57 [=================>............] - ETA: 44s  [ loss=4.4285 ][Training] 36/57 [=================>............] - ETA: 42s  [ loss=3.1813 ][Training] 37/57 [==================>...........] - ETA: 39s  [ loss=4.0364 ][Training] 38/57 [===================>..........] - ETA: 36s  [ loss=3.3751 ][Training] 39/57 [===================>..........] - ETA: 34s  [ loss=4.1889 ][Training] 40/57 [====================>.........] - ETA: 32s  [ loss=3.1968 ][Training] 41/57 [====================>.........] - ETA: 30s  [ loss=1.3737 ][Training] 42/57 [=====================>........] - ETA: 28s  [ loss=3.0813 ][Training] 43/57 [=====================>........] - ETA: 26s  [ loss=1.6813 ][Training] 44/57 [======================>.......] - ETA: 24s  [ loss=3.1936 ][Training] 45/57 [======================>.......] - ETA: 22s  [ loss=2.3966 ][Training] 46/57 [=======================>......] - ETA: 20s  [ loss=2.3333 ][Training] 47/57 [=======================>......] - ETA: 18s  [ loss=1.7115 ][Training] 48/57 [========================>.....] - ETA: 16s  [ loss=3.7371 ][Training] 49/57 [========================>.....] - ETA: 14s  [ loss=5.5809 ][Training] 50/57 [=========================>....] - ETA: 12s  [ loss=2.6710 ][Training] 51/57 [=========================>....] - ETA: 10s  [ loss=5.1516 ][Training] 52/57 [==========================>...] - ETA: 8s  [ loss=2.5386 ][Training] 53/57 [==========================>...] - ETA: 7s  [ loss=2.0499 ][Training] 54/57 [===========================>..] - ETA: 5s  [ loss=3.6680 ][Training] 55/57 [===========================>..] - ETA: 3s  [ loss=3.6191 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=2.4362 ][Training] 57/57 [==============================] 1.7s/step  [ loss=10.6897 ]
01/08/2024 12:10:25 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/08/2024 12:10:25 - INFO - root -   ***** Running evaluation on test dataset  *****
01/08/2024 12:10:25 - INFO - root -     Num examples = 269
01/08/2024 12:10:25 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 7s[Evaluating] 2/12 [====>.........................] - ETA: 7s[Evaluating] 3/12 [======>.......................] - ETA: 6s[Evaluating] 4/12 [=========>....................] - ETA: 5s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 4s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 2s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 708.7ms/step
01/08/2024 12:10:33 - INFO - root -   

01/08/2024 12:10:33 - INFO - root -   ***** Eval results  *****
01/08/2024 12:10:33 - INFO - root -    acc: 0.7438 - recall: 0.5835 - f1: 0.6540 - loss: 4.2325 
01/08/2024 12:10:33 - INFO - root -   ***** Entity results  *****
01/08/2024 12:10:33 - INFO - root -   ******* GPE.NAM results ********
01/08/2024 12:10:33 - INFO - root -    acc: 0.7872 - recall: 0.7872 - f1: 0.7872 
01/08/2024 12:10:33 - INFO - root -   ******* GPE.NOM results ********
01/08/2024 12:10:33 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 12:10:33 - INFO - root -   ******* LOC.NAM results ********
01/08/2024 12:10:33 - INFO - root -    acc: 0.3333 - recall: 0.1053 - f1: 0.1600 
01/08/2024 12:10:33 - INFO - root -   ******* LOC.NOM results ********
01/08/2024 12:10:33 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 12:10:33 - INFO - root -   ******* ORG.NAM results ********
01/08/2024 12:10:33 - INFO - root -    acc: 0.6190 - recall: 0.3333 - f1: 0.4333 
01/08/2024 12:10:33 - INFO - root -   ******* ORG.NOM results ********
01/08/2024 12:10:33 - INFO - root -    acc: 1.0000 - recall: 0.1765 - f1: 0.3000 
01/08/2024 12:10:33 - INFO - root -   ******* PER.NAM results ********
01/08/2024 12:10:33 - INFO - root -    acc: 0.8043 - recall: 0.6727 - f1: 0.7327 
01/08/2024 12:10:33 - INFO - root -   ******* PER.NOM results ********
01/08/2024 12:10:33 - INFO - root -    acc: 0.7226 - recall: 0.6588 - f1: 0.6892 
01/08/2024 12:10:48 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1254
01/08/2024 12:10:48 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1254
01/08/2024 12:10:48 - INFO - root -   

01/08/2024 12:10:48 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 22/50
[Training] 1/57 [..............................] - ETA: 1:48  [ loss=3.5618 ][Training] 2/57 [>.............................] - ETA: 1:35  [ loss=3.2062 ][Training] 3/57 [>.............................] - ETA: 1:57  [ loss=3.7112 ][Training] 4/57 [=>............................] - ETA: 1:54  [ loss=4.5962 ][Training] 5/57 [=>............................] - ETA: 1:48  [ loss=2.9714 ][Training] 6/57 [==>...........................] - ETA: 1:39  [ loss=2.2172 ][Training] 7/57 [==>...........................] - ETA: 1:36  [ loss=3.9730 ][Training] 8/57 [===>..........................] - ETA: 1:34  [ loss=4.2519 ][Training] 9/57 [===>..........................] - ETA: 1:31  [ loss=2.6710 ][Training] 10/57 [====>.........................] - ETA: 1:30  [ loss=5.0037 ][Training] 11/57 [====>.........................] - ETA: 1:28  [ loss=2.9913 ][Training] 12/57 [=====>........................] - ETA: 1:25  [ loss=3.4870 ][Training] 13/57 [=====>........................] - ETA: 1:23  [ loss=3.2836 ][Training] 14/57 [======>.......................] - ETA: 1:20  [ loss=1.3774 ][Training] 15/57 [======>.......................] - ETA: 1:19  [ loss=3.9016 ][Training] 16/57 [=======>......................] - ETA: 1:16  [ loss=2.9159 ][Training] 17/57 [=======>......................] - ETA: 1:15  [ loss=4.5947 ][Training] 18/57 [========>.....................] - ETA: 1:13  [ loss=3.1161 ][Training] 19/57 [=========>....................] - ETA: 1:11  [ loss=3.6811 ][Training] 20/57 [=========>....................] - ETA: 1:09  [ loss=3.7164 ][Training] 21/57 [==========>...................] - ETA: 1:07  [ loss=2.1270 ][Training] 22/57 [==========>...................] - ETA: 1:06  [ loss=2.4261 ][Training] 23/57 [===========>..................] - ETA: 1:04  [ loss=4.5319 ][Training] 24/57 [===========>..................] - ETA: 1:02  [ loss=4.2057 ][Training] 25/57 [============>.................] - ETA: 1:00  [ loss=3.2761 ][Training] 26/57 [============>.................] - ETA: 58s  [ loss=3.6049 ][Training] 27/57 [=============>................] - ETA: 56s  [ loss=4.6202 ][Training] 28/57 [=============>................] - ETA: 54s  [ loss=7.8104 ][Training] 29/57 [==============>...............] - ETA: 52s  [ loss=2.0887 ][Training] 30/57 [==============>...............] - ETA: 50s  [ loss=3.0888 ][Training] 31/57 [===============>..............] - ETA: 48s  [ loss=3.4385 ][Training] 32/57 [===============>..............] - ETA: 46s  [ loss=4.7190 ][Training] 33/57 [================>.............] - ETA: 44s  [ loss=2.5669 ][Training] 34/57 [================>.............] - ETA: 42s  [ loss=2.9937 ][Training] 35/57 [=================>............] - ETA: 40s  [ loss=3.4480 ][Training] 36/57 [=================>............] - ETA: 39s  [ loss=2.3842 ][Training] 37/57 [==================>...........] - ETA: 37s  [ loss=3.5722 ][Training] 38/57 [===================>..........] - ETA: 35s  [ loss=6.1435 ][Training] 39/57 [===================>..........] - ETA: 33s  [ loss=2.7394 ][Training] 40/57 [====================>.........] - ETA: 31s  [ loss=2.2094 ][Training] 41/57 [====================>.........] - ETA: 29s  [ loss=2.0333 ][Training] 42/57 [=====================>........] - ETA: 27s  [ loss=1.6800 ][Training] 43/57 [=====================>........] - ETA: 25s  [ loss=2.8228 ][Training] 44/57 [======================>.......] - ETA: 23s  [ loss=3.8201 ][Training] 45/57 [======================>.......] - ETA: 21s  [ loss=1.9806 ][Training] 46/57 [=======================>......] - ETA: 19s  [ loss=5.6228 ][Training] 47/57 [=======================>......] - ETA: 17s  [ loss=2.2191 ][Training] 48/57 [========================>.....] - ETA: 16s  [ loss=2.4620 ][Training] 49/57 [========================>.....] - ETA: 14s  [ loss=1.9545 ][Training] 50/57 [=========================>....] - ETA: 12s  [ loss=3.7443 ][Training] 51/57 [=========================>....] - ETA: 10s  [ loss=3.1366 ][Training] 52/57 [==========================>...] - ETA: 8s  [ loss=3.6706 ][Training] 53/57 [==========================>...] - ETA: 6s  [ loss=2.9272 ][Training] 54/57 [===========================>..] - ETA: 5s  [ loss=3.0592 ][Training] 55/57 [===========================>..] - ETA: 3s  [ loss=2.9988 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=4.1842 ][Training] 57/57 [==============================] 1.7s/step  [ loss=3.6984 ]
01/08/2024 12:12:26 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/08/2024 12:12:26 - INFO - root -   ***** Running evaluation on test dataset  *****
01/08/2024 12:12:26 - INFO - root -     Num examples = 269
01/08/2024 12:12:26 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 9s[Evaluating] 2/12 [====>.........................] - ETA: 9s[Evaluating] 3/12 [======>.......................] - ETA: 7s[Evaluating] 4/12 [=========>....................] - ETA: 7s[Evaluating] 5/12 [===========>..................] - ETA: 6s[Evaluating] 6/12 [==============>...............] - ETA: 5s[Evaluating] 7/12 [================>.............] - ETA: 4s[Evaluating] 8/12 [===================>..........] - ETA: 3s[Evaluating] 9/12 [=====================>........] - ETA: 2s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 804.7ms/step
01/08/2024 12:12:36 - INFO - root -   

01/08/2024 12:12:36 - INFO - root -   ***** Eval results  *****
01/08/2024 12:12:36 - INFO - root -    acc: 0.7438 - recall: 0.5835 - f1: 0.6540 - loss: 4.1729 
01/08/2024 12:12:36 - INFO - root -   ***** Entity results  *****
01/08/2024 12:12:36 - INFO - root -   ******* GPE.NAM results ********
01/08/2024 12:12:36 - INFO - root -    acc: 0.7917 - recall: 0.8085 - f1: 0.8000 
01/08/2024 12:12:36 - INFO - root -   ******* GPE.NOM results ********
01/08/2024 12:12:36 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 12:12:36 - INFO - root -   ******* LOC.NAM results ********
01/08/2024 12:12:36 - INFO - root -    acc: 0.4286 - recall: 0.1579 - f1: 0.2308 
01/08/2024 12:12:36 - INFO - root -   ******* LOC.NOM results ********
01/08/2024 12:12:36 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 12:12:36 - INFO - root -   ******* ORG.NAM results ********
01/08/2024 12:12:36 - INFO - root -    acc: 0.5500 - recall: 0.2821 - f1: 0.3729 
01/08/2024 12:12:36 - INFO - root -   ******* ORG.NOM results ********
01/08/2024 12:12:36 - INFO - root -    acc: 1.0000 - recall: 0.2353 - f1: 0.3810 
01/08/2024 12:12:36 - INFO - root -   ******* PER.NAM results ********
01/08/2024 12:12:36 - INFO - root -    acc: 0.8043 - recall: 0.6727 - f1: 0.7327 
01/08/2024 12:12:36 - INFO - root -   ******* PER.NOM results ********
01/08/2024 12:12:36 - INFO - root -    acc: 0.7255 - recall: 0.6529 - f1: 0.6873 
01/08/2024 12:12:46 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1311
01/08/2024 12:12:46 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1311
01/08/2024 12:12:46 - INFO - root -   

01/08/2024 12:12:46 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 23/50
[Training] 1/57 [..............................] - ETA: 1:26  [ loss=2.4486 ][Training] 2/57 [>.............................] - ETA: 1:41  [ loss=3.0726 ][Training] 3/57 [>.............................] - ETA: 1:43  [ loss=4.3854 ][Training] 4/57 [=>............................] - ETA: 1:36  [ loss=3.5073 ][Training] 5/57 [=>............................] - ETA: 1:35  [ loss=3.5986 ][Training] 6/57 [==>...........................] - ETA: 1:32  [ loss=2.8826 ][Training] 7/57 [==>...........................] - ETA: 1:29  [ loss=1.9695 ][Training] 8/57 [===>..........................] - ETA: 1:28  [ loss=3.4978 ][Training] 9/57 [===>..........................] - ETA: 1:25  [ loss=4.0796 ][Training] 10/57 [====>.........................] - ETA: 1:23  [ loss=3.1639 ][Training] 11/57 [====>.........................] - ETA: 1:21  [ loss=4.9634 ][Training] 12/57 [=====>........................] - ETA: 1:19  [ loss=2.9561 ][Training] 13/57 [=====>........................] - ETA: 1:18  [ loss=3.3951 ][Training] 14/57 [======>.......................] - ETA: 1:17  [ loss=2.8282 ][Training] 15/57 [======>.......................] - ETA: 1:16  [ loss=6.0700 ][Training] 16/57 [=======>......................] - ETA: 1:15  [ loss=2.2521 ][Training] 17/57 [=======>......................] - ETA: 1:13  [ loss=3.4732 ][Training] 18/57 [========>.....................] - ETA: 1:13  [ loss=5.4335 ][Training] 19/57 [=========>....................] - ETA: 1:11  [ loss=3.0278 ][Training] 20/57 [=========>....................] - ETA: 1:09  [ loss=2.5583 ][Training] 21/57 [==========>...................] - ETA: 1:08  [ loss=3.1352 ][Training] 22/57 [==========>...................] - ETA: 1:06  [ loss=1.8134 ][Training] 23/57 [===========>..................] - ETA: 1:05  [ loss=4.0721 ][Training] 24/57 [===========>..................] - ETA: 1:04  [ loss=2.7999 ][Training] 25/57 [============>.................] - ETA: 1:02  [ loss=3.1950 ][Training] 26/57 [============>.................] - ETA: 1:00  [ loss=3.4922 ][Training] 27/57 [=============>................] - ETA: 57s  [ loss=3.7702 ][Training] 28/57 [=============>................] - ETA: 55s  [ loss=3.3008 ][Training] 29/57 [==============>...............] - ETA: 53s  [ loss=2.7351 ][Training] 30/57 [==============>...............] - ETA: 50s  [ loss=1.5525 ][Training] 31/57 [===============>..............] - ETA: 48s  [ loss=3.7794 ][Training] 32/57 [===============>..............] - ETA: 45s  [ loss=1.5694 ][Training] 33/57 [================>.............] - ETA: 43s  [ loss=3.0821 ][Training] 34/57 [================>.............] - ETA: 41s  [ loss=2.1713 ][Training] 35/57 [=================>............] - ETA: 40s  [ loss=2.6109 ][Training] 36/57 [=================>............] - ETA: 38s  [ loss=2.7601 ][Training] 37/57 [==================>...........] - ETA: 36s  [ loss=3.7251 ][Training] 38/57 [===================>..........] - ETA: 34s  [ loss=2.4758 ][Training] 39/57 [===================>..........] - ETA: 32s  [ loss=4.8314 ][Training] 40/57 [====================>.........] - ETA: 30s  [ loss=4.7555 ][Training] 41/57 [====================>.........] - ETA: 28s  [ loss=5.8754 ][Training] 42/57 [=====================>........] - ETA: 26s  [ loss=1.6597 ][Training] 43/57 [=====================>........] - ETA: 24s  [ loss=1.9945 ][Training] 44/57 [======================>.......] - ETA: 22s  [ loss=5.9562 ][Training] 45/57 [======================>.......] - ETA: 21s  [ loss=1.4312 ][Training] 46/57 [=======================>......] - ETA: 19s  [ loss=3.2700 ][Training] 47/57 [=======================>......] - ETA: 17s  [ loss=1.8032 ][Training] 48/57 [========================>.....] - ETA: 15s  [ loss=4.9409 ][Training] 49/57 [========================>.....] - ETA: 14s  [ loss=3.6116 ][Training] 50/57 [=========================>....] - ETA: 12s  [ loss=3.4344 ][Training] 51/57 [=========================>....] - ETA: 10s  [ loss=2.5882 ][Training] 52/57 [==========================>...] - ETA: 8s  [ loss=3.5805 ][Training] 53/57 [==========================>...] - ETA: 7s  [ loss=2.6010 ][Training] 54/57 [===========================>..] - ETA: 5s  [ loss=2.2981 ][Training] 55/57 [===========================>..] - ETA: 3s  [ loss=4.3702 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=2.4159 ][Training] 57/57 [==============================] 1.8s/step  [ loss=1.8834 ]
01/08/2024 12:14:26 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/08/2024 12:14:26 - INFO - root -   ***** Running evaluation on test dataset  *****
01/08/2024 12:14:26 - INFO - root -     Num examples = 269
01/08/2024 12:14:26 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 5s[Evaluating] 2/12 [====>.........................] - ETA: 6s[Evaluating] 3/12 [======>.......................] - ETA: 6s[Evaluating] 4/12 [=========>....................] - ETA: 5s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 4s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 2s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 706.0ms/step
01/08/2024 12:14:34 - INFO - root -   

01/08/2024 12:14:34 - INFO - root -   ***** Eval results  *****
01/08/2024 12:14:34 - INFO - root -    acc: 0.7248 - recall: 0.5738 - f1: 0.6405 - loss: 4.0909 
01/08/2024 12:14:34 - INFO - root -   ***** Entity results  *****
01/08/2024 12:14:34 - INFO - root -   ******* GPE.NAM results ********
01/08/2024 12:14:34 - INFO - root -    acc: 0.7500 - recall: 0.7660 - f1: 0.7579 
01/08/2024 12:14:34 - INFO - root -   ******* GPE.NOM results ********
01/08/2024 12:14:34 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 12:14:34 - INFO - root -   ******* LOC.NAM results ********
01/08/2024 12:14:34 - INFO - root -    acc: 0.3333 - recall: 0.1579 - f1: 0.2143 
01/08/2024 12:14:34 - INFO - root -   ******* LOC.NOM results ********
01/08/2024 12:14:34 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 12:14:34 - INFO - root -   ******* ORG.NAM results ********
01/08/2024 12:14:34 - INFO - root -    acc: 0.5000 - recall: 0.2564 - f1: 0.3390 
01/08/2024 12:14:34 - INFO - root -   ******* ORG.NOM results ********
01/08/2024 12:14:34 - INFO - root -    acc: 1.0000 - recall: 0.2941 - f1: 0.4545 
01/08/2024 12:14:34 - INFO - root -   ******* PER.NAM results ********
01/08/2024 12:14:34 - INFO - root -    acc: 0.7889 - recall: 0.6455 - f1: 0.7100 
01/08/2024 12:14:34 - INFO - root -   ******* PER.NOM results ********
01/08/2024 12:14:34 - INFO - root -    acc: 0.7226 - recall: 0.6588 - f1: 0.6892 
01/08/2024 12:15:16 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1368
01/08/2024 12:15:16 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1368
01/08/2024 12:15:16 - INFO - root -   

01/08/2024 12:15:16 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 24/50
[Training] 1/57 [..............................] - ETA: 1:49  [ loss=5.2126 ][Training] 2/57 [>.............................] - ETA: 1:31  [ loss=2.2499 ][Training] 3/57 [>.............................] - ETA: 1:36  [ loss=4.8578 ][Training] 4/57 [=>............................] - ETA: 1:35  [ loss=2.0084 ][Training] 5/57 [=>............................] - ETA: 1:28  [ loss=1.6702 ][Training] 6/57 [==>...........................] - ETA: 1:28  [ loss=2.5453 ][Training] 7/57 [==>...........................] - ETA: 1:27  [ loss=1.8652 ][Training] 8/57 [===>..........................] - ETA: 1:25  [ loss=2.4354 ][Training] 9/57 [===>..........................] - ETA: 1:22  [ loss=3.5998 ][Training] 10/57 [====>.........................] - ETA: 1:21  [ loss=3.0966 ][Training] 11/57 [====>.........................] - ETA: 1:19  [ loss=2.7789 ][Training] 12/57 [=====>........................] - ETA: 1:18  [ loss=2.0716 ][Training] 13/57 [=====>........................] - ETA: 1:17  [ loss=3.2055 ][Training] 14/57 [======>.......................] - ETA: 1:16  [ loss=3.5831 ][Training] 15/57 [======>.......................] - ETA: 1:13  [ loss=6.2741 ][Training] 16/57 [=======>......................] - ETA: 1:12  [ loss=3.0739 ][Training] 17/57 [=======>......................] - ETA: 1:10  [ loss=3.1812 ][Training] 18/57 [========>.....................] - ETA: 1:08  [ loss=1.7297 ][Training] 19/57 [=========>....................] - ETA: 1:08  [ loss=2.4837 ][Training] 20/57 [=========>....................] - ETA: 1:06  [ loss=3.0624 ][Training] 21/57 [==========>...................] - ETA: 1:04  [ loss=2.5209 ][Training] 22/57 [==========>...................] - ETA: 1:01  [ loss=2.4384 ][Training] 23/57 [===========>..................] - ETA: 1:00  [ loss=3.8821 ][Training] 24/57 [===========>..................] - ETA: 58s  [ loss=3.0533 ][Training] 25/57 [============>.................] - ETA: 57s  [ loss=4.0391 ][Training] 26/57 [============>.................] - ETA: 56s  [ loss=3.8924 ][Training] 27/57 [=============>................] - ETA: 54s  [ loss=4.0849 ][Training] 28/57 [=============>................] - ETA: 52s  [ loss=2.7877 ][Training] 29/57 [==============>...............] - ETA: 50s  [ loss=3.5858 ][Training] 30/57 [==============>...............] - ETA: 49s  [ loss=4.6321 ][Training] 31/57 [===============>..............] - ETA: 47s  [ loss=1.8357 ][Training] 32/57 [===============>..............] - ETA: 45s  [ loss=2.6638 ][Training] 33/57 [================>.............] - ETA: 43s  [ loss=4.3811 ][Training] 34/57 [================>.............] - ETA: 42s  [ loss=2.7688 ][Training] 35/57 [=================>............] - ETA: 40s  [ loss=1.3048 ][Training] 36/57 [=================>............] - ETA: 38s  [ loss=1.3027 ][Training] 37/57 [==================>...........] - ETA: 36s  [ loss=3.8163 ][Training] 38/57 [===================>..........] - ETA: 34s  [ loss=4.7679 ][Training] 39/57 [===================>..........] - ETA: 33s  [ loss=2.5988 ][Training] 40/57 [====================>.........] - ETA: 31s  [ loss=4.7409 ][Training] 41/57 [====================>.........] - ETA: 29s  [ loss=2.8464 ][Training] 42/57 [=====================>........] - ETA: 27s  [ loss=1.9602 ][Training] 43/57 [=====================>........] - ETA: 25s  [ loss=1.8421 ][Training] 44/57 [======================>.......] - ETA: 23s  [ loss=3.5217 ][Training] 45/57 [======================>.......] - ETA: 22s  [ loss=4.8505 ][Training] 46/57 [=======================>......] - ETA: 20s  [ loss=1.6314 ][Training] 47/57 [=======================>......] - ETA: 18s  [ loss=1.5166 ][Training] 48/57 [========================>.....] - ETA: 16s  [ loss=5.9568 ][Training] 49/57 [========================>.....] - ETA: 14s  [ loss=3.6201 ][Training] 50/57 [=========================>....] - ETA: 13s  [ loss=2.6514 ][Training] 51/57 [=========================>....] - ETA: 11s  [ loss=4.0422 ][Training] 52/57 [==========================>...] - ETA: 9s  [ loss=2.1513 ][Training] 53/57 [==========================>...] - ETA: 7s  [ loss=3.3046 ][Training] 54/57 [===========================>..] - ETA: 5s  [ loss=3.1897 ][Training] 55/57 [===========================>..] - ETA: 3s  [ loss=3.6568 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=1.6329 ][Training] 57/57 [==============================] 1.8s/step  [ loss=1.6860 ]
01/08/2024 12:16:59 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/08/2024 12:16:59 - INFO - root -   ***** Running evaluation on test dataset  *****
01/08/2024 12:16:59 - INFO - root -     Num examples = 269
01/08/2024 12:16:59 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 9s[Evaluating] 2/12 [====>.........................] - ETA: 8s[Evaluating] 3/12 [======>.......................] - ETA: 7s[Evaluating] 4/12 [=========>....................] - ETA: 6s[Evaluating] 5/12 [===========>..................] - ETA: 5s[Evaluating] 6/12 [==============>...............] - ETA: 4s[Evaluating] 7/12 [================>.............] - ETA: 4s[Evaluating] 8/12 [===================>..........] - ETA: 3s[Evaluating] 9/12 [=====================>........] - ETA: 2s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 792.7ms/step
01/08/2024 12:17:08 - INFO - root -   

01/08/2024 12:17:08 - INFO - root -   ***** Eval results  *****
01/08/2024 12:17:08 - INFO - root -    acc: 0.7325 - recall: 0.5835 - f1: 0.6496 - loss: 4.0578 
01/08/2024 12:17:08 - INFO - root -   ***** Entity results  *****
01/08/2024 12:17:08 - INFO - root -   ******* GPE.NAM results ********
01/08/2024 12:17:08 - INFO - root -    acc: 0.7708 - recall: 0.7872 - f1: 0.7789 
01/08/2024 12:17:08 - INFO - root -   ******* GPE.NOM results ********
01/08/2024 12:17:08 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 12:17:08 - INFO - root -   ******* LOC.NAM results ********
01/08/2024 12:17:08 - INFO - root -    acc: 0.3750 - recall: 0.1579 - f1: 0.2222 
01/08/2024 12:17:08 - INFO - root -   ******* LOC.NOM results ********
01/08/2024 12:17:08 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 12:17:08 - INFO - root -   ******* ORG.NAM results ********
01/08/2024 12:17:08 - INFO - root -    acc: 0.5217 - recall: 0.3077 - f1: 0.3871 
01/08/2024 12:17:08 - INFO - root -   ******* ORG.NOM results ********
01/08/2024 12:17:08 - INFO - root -    acc: 1.0000 - recall: 0.2941 - f1: 0.4545 
01/08/2024 12:17:08 - INFO - root -   ******* PER.NAM results ********
01/08/2024 12:17:08 - INFO - root -    acc: 0.7935 - recall: 0.6636 - f1: 0.7228 
01/08/2024 12:17:08 - INFO - root -   ******* PER.NOM results ********
01/08/2024 12:17:08 - INFO - root -    acc: 0.7255 - recall: 0.6529 - f1: 0.6873 
01/08/2024 12:17:16 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1425
01/08/2024 12:17:16 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1425
01/08/2024 12:17:16 - INFO - root -   

01/08/2024 12:17:16 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 25/50
[Training] 1/57 [..............................] - ETA: 1:27  [ loss=2.1235 ][Training] 2/57 [>.............................] - ETA: 1:23  [ loss=2.9588 ][Training] 3/57 [>.............................] - ETA: 1:29  [ loss=1.9014 ][Training] 4/57 [=>............................] - ETA: 1:30  [ loss=2.4944 ][Training] 5/57 [=>............................] - ETA: 1:32  [ loss=3.6064 ][Training] 6/57 [==>...........................] - ETA: 1:29  [ loss=2.7485 ][Training] 7/57 [==>...........................] - ETA: 1:25  [ loss=2.4315 ][Training] 8/57 [===>..........................] - ETA: 1:27  [ loss=6.2243 ][Training] 9/57 [===>..........................] - ETA: 1:24  [ loss=1.7984 ][Training] 10/57 [====>.........................] - ETA: 1:25  [ loss=5.1150 ][Training] 11/57 [====>.........................] - ETA: 1:24  [ loss=4.2526 ][Training] 12/57 [=====>........................] - ETA: 1:22  [ loss=1.9907 ][Training] 13/57 [=====>........................] - ETA: 1:21  [ loss=2.4729 ][Training] 14/57 [======>.......................] - ETA: 1:19  [ loss=4.6365 ][Training] 15/57 [======>.......................] - ETA: 1:18  [ loss=2.6451 ][Training] 16/57 [=======>......................] - ETA: 1:16  [ loss=1.6196 ][Training] 17/57 [=======>......................] - ETA: 1:14  [ loss=2.8699 ][Training] 18/57 [========>.....................] - ETA: 1:11  [ loss=1.4253 ][Training] 19/57 [=========>....................] - ETA: 1:09  [ loss=3.0368 ][Training] 20/57 [=========>....................] - ETA: 1:08  [ loss=2.6681 ][Training] 21/57 [==========>...................] - ETA: 1:06  [ loss=3.2360 ][Training] 22/57 [==========>...................] - ETA: 1:05  [ loss=2.4420 ][Training] 23/57 [===========>..................] - ETA: 1:03  [ loss=3.0781 ][Training] 24/57 [===========>..................] - ETA: 1:02  [ loss=4.8437 ][Training] 25/57 [============>.................] - ETA: 1:00  [ loss=1.9215 ][Training] 26/57 [============>.................] - ETA: 58s  [ loss=2.3083 ][Training] 27/57 [=============>................] - ETA: 56s  [ loss=4.9464 ][Training] 28/57 [=============>................] - ETA: 54s  [ loss=2.3228 ][Training] 29/57 [==============>...............] - ETA: 52s  [ loss=4.1956 ][Training] 30/57 [==============>...............] - ETA: 50s  [ loss=3.3538 ][Training] 31/57 [===============>..............] - ETA: 48s  [ loss=4.2076 ][Training] 32/57 [===============>..............] - ETA: 46s  [ loss=4.4602 ][Training] 33/57 [================>.............] - ETA: 44s  [ loss=2.3050 ][Training] 34/57 [================>.............] - ETA: 42s  [ loss=3.7196 ][Training] 35/57 [=================>............] - ETA: 41s  [ loss=4.5107 ][Training] 36/57 [=================>............] - ETA: 39s  [ loss=2.0082 ][Training] 37/57 [==================>...........] - ETA: 37s  [ loss=2.4297 ][Training] 38/57 [===================>..........] - ETA: 35s  [ loss=2.3776 ][Training] 39/57 [===================>..........] - ETA: 33s  [ loss=3.1925 ][Training] 40/57 [====================>.........] - ETA: 31s  [ loss=3.1502 ][Training] 41/57 [====================>.........] - ETA: 29s  [ loss=2.1624 ][Training] 42/57 [=====================>........] - ETA: 27s  [ loss=2.7378 ][Training] 43/57 [=====================>........] - ETA: 25s  [ loss=2.6516 ][Training] 44/57 [======================>.......] - ETA: 23s  [ loss=2.4450 ][Training] 45/57 [======================>.......] - ETA: 22s  [ loss=2.4814 ][Training] 46/57 [=======================>......] - ETA: 20s  [ loss=3.0277 ][Training] 47/57 [=======================>......] - ETA: 18s  [ loss=2.6868 ][Training] 48/57 [========================>.....] - ETA: 16s  [ loss=2.9427 ][Training] 49/57 [========================>.....] - ETA: 14s  [ loss=2.3598 ][Training] 50/57 [=========================>....] - ETA: 12s  [ loss=2.3833 ][Training] 51/57 [=========================>....] - ETA: 10s  [ loss=2.1313 ][Training] 52/57 [==========================>...] - ETA: 9s  [ loss=1.8583 ][Training] 53/57 [==========================>...] - ETA: 7s  [ loss=3.5754 ][Training] 54/57 [===========================>..] - ETA: 5s  [ loss=7.3442 ][Training] 55/57 [===========================>..] - ETA: 3s  [ loss=3.0126 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=2.5194 ][Training] 57/57 [==============================] 1.8s/step  [ loss=1.6117 ]
01/08/2024 12:18:59 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/08/2024 12:18:59 - INFO - root -   ***** Running evaluation on test dataset  *****
01/08/2024 12:18:59 - INFO - root -     Num examples = 269
01/08/2024 12:18:59 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 10s[Evaluating] 2/12 [====>.........................] - ETA: 9s[Evaluating] 3/12 [======>.......................] - ETA: 7s[Evaluating] 4/12 [=========>....................] - ETA: 7s[Evaluating] 5/12 [===========>..................] - ETA: 6s[Evaluating] 6/12 [==============>...............] - ETA: 5s[Evaluating] 7/12 [================>.............] - ETA: 4s[Evaluating] 8/12 [===================>..........] - ETA: 3s[Evaluating] 9/12 [=====================>........] - ETA: 2s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 794.5ms/step
01/08/2024 12:19:09 - INFO - root -   

01/08/2024 12:19:09 - INFO - root -   ***** Eval results  *****
01/08/2024 12:19:09 - INFO - root -    acc: 0.7339 - recall: 0.5811 - f1: 0.6486 - loss: 3.9686 
01/08/2024 12:19:09 - INFO - root -   ***** Entity results  *****
01/08/2024 12:19:09 - INFO - root -   ******* GPE.NAM results ********
01/08/2024 12:19:09 - INFO - root -    acc: 0.8085 - recall: 0.8085 - f1: 0.8085 
01/08/2024 12:19:09 - INFO - root -   ******* GPE.NOM results ********
01/08/2024 12:19:09 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 12:19:09 - INFO - root -   ******* LOC.NAM results ********
01/08/2024 12:19:09 - INFO - root -    acc: 0.3333 - recall: 0.1579 - f1: 0.2143 
01/08/2024 12:19:09 - INFO - root -   ******* LOC.NOM results ********
01/08/2024 12:19:09 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 12:19:09 - INFO - root -   ******* ORG.NAM results ********
01/08/2024 12:19:09 - INFO - root -    acc: 0.5000 - recall: 0.2564 - f1: 0.3390 
01/08/2024 12:19:09 - INFO - root -   ******* ORG.NOM results ********
01/08/2024 12:19:09 - INFO - root -    acc: 1.0000 - recall: 0.2941 - f1: 0.4545 
01/08/2024 12:19:09 - INFO - root -   ******* PER.NAM results ********
01/08/2024 12:19:09 - INFO - root -    acc: 0.7912 - recall: 0.6545 - f1: 0.7164 
01/08/2024 12:19:09 - INFO - root -   ******* PER.NOM results ********
01/08/2024 12:19:09 - INFO - root -    acc: 0.7226 - recall: 0.6588 - f1: 0.6892 
01/08/2024 12:19:48 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1482
01/08/2024 12:19:48 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1482
01/08/2024 12:19:48 - INFO - root -   

01/08/2024 12:19:48 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 26/50
[Training] 1/57 [..............................] - ETA: 1:48  [ loss=4.0182 ][Training] 2/57 [>.............................] - ETA: 1:41  [ loss=2.2593 ][Training] 3/57 [>.............................] - ETA: 1:51  [ loss=6.4580 ][Training] 4/57 [=>............................] - ETA: 1:44  [ loss=1.7836 ][Training] 5/57 [=>............................] - ETA: 1:39  [ loss=3.8545 ][Training] 6/57 [==>...........................] - ETA: 1:32  [ loss=2.9596 ][Training] 7/57 [==>...........................] - ETA: 1:29  [ loss=1.8547 ][Training] 8/57 [===>..........................] - ETA: 1:25  [ loss=2.8106 ][Training] 9/57 [===>..........................] - ETA: 1:23  [ loss=2.2961 ][Training] 10/57 [====>.........................] - ETA: 1:22  [ loss=4.5042 ][Training] 11/57 [====>.........................] - ETA: 1:19  [ loss=1.4626 ][Training] 12/57 [=====>........................] - ETA: 1:18  [ loss=1.2964 ][Training] 13/57 [=====>........................] - ETA: 1:17  [ loss=4.3093 ][Training] 14/57 [======>.......................] - ETA: 1:16  [ loss=3.3533 ][Training] 15/57 [======>.......................] - ETA: 1:15  [ loss=2.1970 ][Training] 16/57 [=======>......................] - ETA: 1:13  [ loss=3.0420 ][Training] 17/57 [=======>......................] - ETA: 1:13  [ loss=1.7638 ][Training] 18/57 [========>.....................] - ETA: 1:10  [ loss=2.5670 ][Training] 19/57 [=========>....................] - ETA: 1:09  [ loss=1.9861 ][Training] 20/57 [=========>....................] - ETA: 1:08  [ loss=3.2481 ][Training] 21/57 [==========>...................] - ETA: 1:06  [ loss=3.3828 ][Training] 22/57 [==========>...................] - ETA: 1:04  [ loss=2.1333 ][Training] 23/57 [===========>..................] - ETA: 1:02  [ loss=2.4285 ][Training] 24/57 [===========>..................] - ETA: 1:01  [ loss=4.0187 ][Training] 25/57 [============>.................] - ETA: 59s  [ loss=1.9176 ][Training] 26/57 [============>.................] - ETA: 58s  [ loss=3.3760 ][Training] 27/57 [=============>................] - ETA: 56s  [ loss=1.3250 ][Training] 28/57 [=============>................] - ETA: 55s  [ loss=5.7523 ][Training] 29/57 [==============>...............] - ETA: 53s  [ loss=4.8234 ][Training] 30/57 [==============>...............] - ETA: 52s  [ loss=3.7625 ][Training] 31/57 [===============>..............] - ETA: 49s  [ loss=3.2422 ][Training] 32/57 [===============>..............] - ETA: 47s  [ loss=2.9728 ][Training] 33/57 [================>.............] - ETA: 45s  [ loss=4.2563 ][Training] 34/57 [================>.............] - ETA: 43s  [ loss=3.0068 ][Training] 35/57 [=================>............] - ETA: 41s  [ loss=3.8223 ][Training] 36/57 [=================>............] - ETA: 39s  [ loss=2.0369 ][Training] 37/57 [==================>...........] - ETA: 37s  [ loss=3.8756 ][Training] 38/57 [===================>..........] - ETA: 35s  [ loss=3.3050 ][Training] 39/57 [===================>..........] - ETA: 32s  [ loss=1.6640 ][Training] 40/57 [====================>.........] - ETA: 30s  [ loss=2.5500 ][Training] 41/57 [====================>.........] - ETA: 28s  [ loss=2.4170 ][Training] 42/57 [=====================>........] - ETA: 26s  [ loss=1.5355 ][Training] 43/57 [=====================>........] - ETA: 24s  [ loss=0.9640 ][Training] 44/57 [======================>.......] - ETA: 23s  [ loss=3.4416 ][Training] 45/57 [======================>.......] - ETA: 21s  [ loss=2.2451 ][Training] 46/57 [=======================>......] - ETA: 19s  [ loss=3.7890 ][Training] 47/57 [=======================>......] - ETA: 17s  [ loss=4.0235 ][Training] 48/57 [========================>.....] - ETA: 15s  [ loss=2.3599 ][Training] 49/57 [========================>.....] - ETA: 14s  [ loss=1.6346 ][Training] 50/57 [=========================>....] - ETA: 12s  [ loss=3.4744 ][Training] 51/57 [=========================>....] - ETA: 10s  [ loss=2.9501 ][Training] 52/57 [==========================>...] - ETA: 8s  [ loss=4.1284 ][Training] 53/57 [==========================>...] - ETA: 6s  [ loss=3.5376 ][Training] 54/57 [===========================>..] - ETA: 5s  [ loss=3.0833 ][Training] 55/57 [===========================>..] - ETA: 3s  [ loss=3.9516 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=2.1931 ][Training] 57/57 [==============================] 1.6s/step  [ loss=1.4152 ]
01/08/2024 12:21:22 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/08/2024 12:21:22 - INFO - root -   ***** Running evaluation on test dataset  *****
01/08/2024 12:21:22 - INFO - root -     Num examples = 269
01/08/2024 12:21:22 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 5s[Evaluating] 2/12 [====>.........................] - ETA: 5s[Evaluating] 3/12 [======>.......................] - ETA: 5s[Evaluating] 4/12 [=========>....................] - ETA: 4s[Evaluating] 5/12 [===========>..................] - ETA: 3s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 2s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 500.7ms/step
01/08/2024 12:21:28 - INFO - root -   

01/08/2024 12:21:28 - INFO - root -   ***** Eval results  *****
01/08/2024 12:21:28 - INFO - root -    acc: 0.7348 - recall: 0.5835 - f1: 0.6505 - loss: 3.9290 
01/08/2024 12:21:28 - INFO - root -   ***** Entity results  *****
01/08/2024 12:21:28 - INFO - root -   ******* GPE.NAM results ********
01/08/2024 12:21:28 - INFO - root -    acc: 0.7872 - recall: 0.7872 - f1: 0.7872 
01/08/2024 12:21:28 - INFO - root -   ******* GPE.NOM results ********
01/08/2024 12:21:28 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 12:21:28 - INFO - root -   ******* LOC.NAM results ********
01/08/2024 12:21:28 - INFO - root -    acc: 0.4000 - recall: 0.2105 - f1: 0.2759 
01/08/2024 12:21:28 - INFO - root -   ******* LOC.NOM results ********
01/08/2024 12:21:28 - INFO - root -    acc: 1.0000 - recall: 0.1111 - f1: 0.2000 
01/08/2024 12:21:28 - INFO - root -   ******* ORG.NAM results ********
01/08/2024 12:21:28 - INFO - root -    acc: 0.5789 - recall: 0.2821 - f1: 0.3793 
01/08/2024 12:21:28 - INFO - root -   ******* ORG.NOM results ********
01/08/2024 12:21:28 - INFO - root -    acc: 1.0000 - recall: 0.2941 - f1: 0.4545 
01/08/2024 12:21:28 - INFO - root -   ******* PER.NAM results ********
01/08/2024 12:21:28 - INFO - root -    acc: 0.7802 - recall: 0.6455 - f1: 0.7065 
01/08/2024 12:21:28 - INFO - root -   ******* PER.NOM results ********
01/08/2024 12:21:28 - INFO - root -    acc: 0.7226 - recall: 0.6588 - f1: 0.6892 
01/08/2024 12:21:53 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1539
01/08/2024 12:21:53 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1539
01/08/2024 12:21:53 - INFO - root -   

01/08/2024 12:21:53 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 27/50
[Training] 1/57 [..............................] - ETA: 1:27  [ loss=1.7306 ][Training] 2/57 [>.............................] - ETA: 1:31  [ loss=2.8707 ][Training] 3/57 [>.............................] - ETA: 1:26  [ loss=2.5027 ][Training] 4/57 [=>............................] - ETA: 1:21  [ loss=2.8476 ][Training] 5/57 [=>............................] - ETA: 1:21  [ loss=1.9930 ][Training] 6/57 [==>...........................] - ETA: 1:24  [ loss=2.1219 ][Training] 7/57 [==>...........................] - ETA: 1:24  [ loss=1.6185 ][Training] 8/57 [===>..........................] - ETA: 1:26  [ loss=3.6379 ][Training] 9/57 [===>..........................] - ETA: 1:24  [ loss=3.3782 ][Training] 10/57 [====>.........................] - ETA: 1:23  [ loss=1.4201 ][Training] 11/57 [====>.........................] - ETA: 1:21  [ loss=3.1158 ][Training] 12/57 [=====>........................] - ETA: 1:18  [ loss=1.7586 ][Training] 13/57 [=====>........................] - ETA: 1:18  [ loss=2.4227 ][Training] 14/57 [======>.......................] - ETA: 1:15  [ loss=2.7124 ][Training] 15/57 [======>.......................] - ETA: 1:15  [ loss=3.3363 ][Training] 16/57 [=======>......................] - ETA: 1:13  [ loss=2.9813 ][Training] 17/57 [=======>......................] - ETA: 1:11  [ loss=4.2156 ][Training] 18/57 [========>.....................] - ETA: 1:09  [ loss=2.4238 ][Training] 19/57 [=========>....................] - ETA: 1:07  [ loss=2.8480 ][Training] 20/57 [=========>....................] - ETA: 1:06  [ loss=4.2138 ][Training] 21/57 [==========>...................] - ETA: 1:03  [ loss=3.1338 ][Training] 22/57 [==========>...................] - ETA: 1:02  [ loss=2.0835 ][Training] 23/57 [===========>..................] - ETA: 1:00  [ loss=2.1937 ][Training] 24/57 [===========>..................] - ETA: 58s  [ loss=3.8036 ][Training] 25/57 [============>.................] - ETA: 56s  [ loss=3.8014 ][Training] 26/57 [============>.................] - ETA: 55s  [ loss=2.1350 ][Training] 27/57 [=============>................] - ETA: 53s  [ loss=3.9834 ][Training] 28/57 [=============>................] - ETA: 51s  [ loss=2.7609 ][Training] 29/57 [==============>...............] - ETA: 50s  [ loss=1.6803 ][Training] 30/57 [==============>...............] - ETA: 48s  [ loss=3.2117 ][Training] 31/57 [===============>..............] - ETA: 47s  [ loss=5.2599 ][Training] 32/57 [===============>..............] - ETA: 45s  [ loss=1.7925 ][Training] 33/57 [================>.............] - ETA: 43s  [ loss=1.4801 ][Training] 34/57 [================>.............] - ETA: 42s  [ loss=2.3376 ][Training] 35/57 [=================>............] - ETA: 40s  [ loss=2.7424 ][Training] 36/57 [=================>............] - ETA: 38s  [ loss=2.0108 ][Training] 37/57 [==================>...........] - ETA: 37s  [ loss=2.7973 ][Training] 38/57 [===================>..........] - ETA: 35s  [ loss=1.2891 ][Training] 39/57 [===================>..........] - ETA: 33s  [ loss=1.6008 ][Training] 40/57 [====================>.........] - ETA: 31s  [ loss=4.1384 ][Training] 41/57 [====================>.........] - ETA: 29s  [ loss=2.7122 ][Training] 42/57 [=====================>........] - ETA: 27s  [ loss=3.5297 ][Training] 43/57 [=====================>........] - ETA: 25s  [ loss=2.6009 ][Training] 44/57 [======================>.......] - ETA: 23s  [ loss=3.7511 ][Training] 45/57 [======================>.......] - ETA: 21s  [ loss=2.4839 ][Training] 46/57 [=======================>......] - ETA: 20s  [ loss=3.4620 ][Training] 47/57 [=======================>......] - ETA: 18s  [ loss=3.6311 ][Training] 48/57 [========================>.....] - ETA: 16s  [ loss=3.2459 ][Training] 49/57 [========================>.....] - ETA: 14s  [ loss=4.2518 ][Training] 50/57 [=========================>....] - ETA: 12s  [ loss=1.8136 ][Training] 51/57 [=========================>....] - ETA: 10s  [ loss=3.9197 ][Training] 52/57 [==========================>...] - ETA: 9s  [ loss=2.7074 ][Training] 53/57 [==========================>...] - ETA: 7s  [ loss=2.5313 ][Training] 54/57 [===========================>..] - ETA: 5s  [ loss=3.7123 ][Training] 55/57 [===========================>..] - ETA: 3s  [ loss=2.7635 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=6.2211 ][Training] 57/57 [==============================] 1.8s/step  [ loss=5.0322 ]
01/08/2024 12:23:36 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/08/2024 12:23:37 - INFO - root -   ***** Running evaluation on test dataset  *****
01/08/2024 12:23:37 - INFO - root -     Num examples = 269
01/08/2024 12:23:37 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 10s[Evaluating] 2/12 [====>.........................] - ETA: 9s[Evaluating] 3/12 [======>.......................] - ETA: 8s[Evaluating] 4/12 [=========>....................] - ETA: 7s[Evaluating] 5/12 [===========>..................] - ETA: 6s[Evaluating] 6/12 [==============>...............] - ETA: 5s[Evaluating] 7/12 [================>.............] - ETA: 4s[Evaluating] 8/12 [===================>..........] - ETA: 3s[Evaluating] 9/12 [=====================>........] - ETA: 2s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 863.6ms/step
01/08/2024 12:23:47 - INFO - root -   

01/08/2024 12:23:47 - INFO - root -   ***** Eval results  *****
01/08/2024 12:23:47 - INFO - root -    acc: 0.7337 - recall: 0.6005 - f1: 0.6605 - loss: 3.9439 
01/08/2024 12:23:47 - INFO - root -   ***** Entity results  *****
01/08/2024 12:23:47 - INFO - root -   ******* GPE.NAM results ********
01/08/2024 12:23:47 - INFO - root -    acc: 0.8444 - recall: 0.8085 - f1: 0.8261 
01/08/2024 12:23:47 - INFO - root -   ******* GPE.NOM results ********
01/08/2024 12:23:47 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 12:23:47 - INFO - root -   ******* LOC.NAM results ********
01/08/2024 12:23:47 - INFO - root -    acc: 0.4000 - recall: 0.2105 - f1: 0.2759 
01/08/2024 12:23:47 - INFO - root -   ******* LOC.NOM results ********
01/08/2024 12:23:47 - INFO - root -    acc: 1.0000 - recall: 0.1111 - f1: 0.2000 
01/08/2024 12:23:47 - INFO - root -   ******* ORG.NAM results ********
01/08/2024 12:23:47 - INFO - root -    acc: 0.5000 - recall: 0.3077 - f1: 0.3810 
01/08/2024 12:23:47 - INFO - root -   ******* ORG.NOM results ********
01/08/2024 12:23:47 - INFO - root -    acc: 1.0000 - recall: 0.3529 - f1: 0.5217 
01/08/2024 12:23:47 - INFO - root -   ******* PER.NAM results ********
01/08/2024 12:23:47 - INFO - root -    acc: 0.7935 - recall: 0.6636 - f1: 0.7228 
01/08/2024 12:23:47 - INFO - root -   ******* PER.NOM results ********
01/08/2024 12:23:47 - INFO - root -    acc: 0.7125 - recall: 0.6706 - f1: 0.6909 
01/08/2024 12:23:58 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1596
01/08/2024 12:23:58 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1596
01/08/2024 12:23:58 - INFO - root -   

01/08/2024 12:23:58 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 28/50
[Training] 1/57 [..............................] - ETA: 1:53  [ loss=3.9544 ][Training] 2/57 [>.............................] - ETA: 2:03  [ loss=2.5799 ][Training] 3/57 [>.............................] - ETA: 1:55  [ loss=3.6680 ][Training] 4/57 [=>............................] - ETA: 1:43  [ loss=1.8912 ][Training] 5/57 [=>............................] - ETA: 1:43  [ loss=2.5700 ][Training] 6/57 [==>...........................] - ETA: 1:37  [ loss=2.0287 ][Training] 7/57 [==>...........................] - ETA: 1:40  [ loss=5.2676 ][Training] 8/57 [===>..........................] - ETA: 1:36  [ loss=1.3286 ][Training] 9/57 [===>..........................] - ETA: 1:35  [ loss=2.4899 ][Training] 10/57 [====>.........................] - ETA: 1:31  [ loss=1.4280 ][Training] 11/57 [====>.........................] - ETA: 1:30  [ loss=3.1924 ][Training] 12/57 [=====>........................] - ETA: 1:28  [ loss=2.5063 ][Training] 13/57 [=====>........................] - ETA: 1:26  [ loss=1.0101 ][Training] 14/57 [======>.......................] - ETA: 1:23  [ loss=1.6889 ][Training] 15/57 [======>.......................] - ETA: 1:20  [ loss=1.4552 ][Training] 16/57 [=======>......................] - ETA: 1:18  [ loss=4.4376 ][Training] 17/57 [=======>......................] - ETA: 1:16  [ loss=2.8949 ][Training] 18/57 [========>.....................] - ETA: 1:14  [ loss=2.3017 ][Training] 19/57 [=========>....................] - ETA: 1:12  [ loss=3.9736 ][Training] 20/57 [=========>....................] - ETA: 1:09  [ loss=3.1820 ][Training] 21/57 [==========>...................] - ETA: 1:07  [ loss=2.3052 ][Training] 22/57 [==========>...................] - ETA: 1:06  [ loss=2.6893 ][Training] 23/57 [===========>..................] - ETA: 1:04  [ loss=3.0108 ][Training] 24/57 [===========>..................] - ETA: 1:02  [ loss=1.8403 ][Training] 25/57 [============>.................] - ETA: 1:00  [ loss=2.8943 ][Training] 26/57 [============>.................] - ETA: 58s  [ loss=1.8498 ][Training] 27/57 [=============>................] - ETA: 56s  [ loss=2.1286 ][Training] 28/57 [=============>................] - ETA: 54s  [ loss=1.5625 ][Training] 29/57 [==============>...............] - ETA: 52s  [ loss=2.3407 ][Training] 30/57 [==============>...............] - ETA: 50s  [ loss=2.8730 ][Training] 31/57 [===============>..............] - ETA: 48s  [ loss=2.7209 ][Training] 32/57 [===============>..............] - ETA: 47s  [ loss=2.8655 ][Training] 33/57 [================>.............] - ETA: 45s  [ loss=1.9601 ][Training] 34/57 [================>.............] - ETA: 43s  [ loss=3.1572 ][Training] 35/57 [=================>............] - ETA: 41s  [ loss=1.9670 ][Training] 36/57 [=================>............] - ETA: 39s  [ loss=2.2393 ][Training] 37/57 [==================>...........] - ETA: 37s  [ loss=3.3270 ][Training] 38/57 [===================>..........] - ETA: 36s  [ loss=3.7359 ][Training] 39/57 [===================>..........] - ETA: 34s  [ loss=3.1478 ][Training] 40/57 [====================>.........] - ETA: 32s  [ loss=1.2483 ][Training] 41/57 [====================>.........] - ETA: 30s  [ loss=2.3283 ][Training] 42/57 [=====================>........] - ETA: 28s  [ loss=2.3211 ][Training] 43/57 [=====================>........] - ETA: 26s  [ loss=3.3754 ][Training] 44/57 [======================>.......] - ETA: 24s  [ loss=2.0910 ][Training] 45/57 [======================>.......] - ETA: 22s  [ loss=3.0129 ][Training] 46/57 [=======================>......] - ETA: 20s  [ loss=3.0212 ][Training] 47/57 [=======================>......] - ETA: 18s  [ loss=4.0730 ][Training] 48/57 [========================>.....] - ETA: 16s  [ loss=4.7018 ][Training] 49/57 [========================>.....] - ETA: 14s  [ loss=1.7805 ][Training] 50/57 [=========================>....] - ETA: 12s  [ loss=5.0683 ][Training] 51/57 [=========================>....] - ETA: 10s  [ loss=2.7930 ][Training] 52/57 [==========================>...] - ETA: 8s  [ loss=3.2198 ][Training] 53/57 [==========================>...] - ETA: 7s  [ loss=6.1291 ][Training] 54/57 [===========================>..] - ETA: 5s  [ loss=4.2921 ][Training] 55/57 [===========================>..] - ETA: 3s  [ loss=1.7427 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=3.4245 ][Training] 57/57 [==============================] 1.8s/step  [ loss=2.4831 ]
01/08/2024 12:25:39 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/08/2024 12:25:39 - INFO - root -   ***** Running evaluation on test dataset  *****
01/08/2024 12:25:39 - INFO - root -     Num examples = 269
01/08/2024 12:25:39 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 7s[Evaluating] 2/12 [====>.........................] - ETA: 7s[Evaluating] 3/12 [======>.......................] - ETA: 6s[Evaluating] 4/12 [=========>....................] - ETA: 6s[Evaluating] 5/12 [===========>..................] - ETA: 5s[Evaluating] 6/12 [==============>...............] - ETA: 4s[Evaluating] 7/12 [================>.............] - ETA: 4s[Evaluating] 8/12 [===================>..........] - ETA: 3s[Evaluating] 9/12 [=====================>........] - ETA: 2s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 791.9ms/step
01/08/2024 12:25:48 - INFO - root -   

01/08/2024 12:25:48 - INFO - root -   ***** Eval results  *****
01/08/2024 12:25:48 - INFO - root -    acc: 0.7321 - recall: 0.5956 - f1: 0.6569 - loss: 3.8225 
01/08/2024 12:25:48 - INFO - root -   ***** Entity results  *****
01/08/2024 12:25:48 - INFO - root -   ******* GPE.NAM results ********
01/08/2024 12:25:48 - INFO - root -    acc: 0.8261 - recall: 0.8085 - f1: 0.8172 
01/08/2024 12:25:48 - INFO - root -   ******* GPE.NOM results ********
01/08/2024 12:25:48 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 12:25:48 - INFO - root -   ******* LOC.NAM results ********
01/08/2024 12:25:48 - INFO - root -    acc: 0.4000 - recall: 0.2105 - f1: 0.2759 
01/08/2024 12:25:48 - INFO - root -   ******* LOC.NOM results ********
01/08/2024 12:25:48 - INFO - root -    acc: 0.6667 - recall: 0.2222 - f1: 0.3333 
01/08/2024 12:25:48 - INFO - root -   ******* ORG.NAM results ********
01/08/2024 12:25:48 - INFO - root -    acc: 0.6000 - recall: 0.3077 - f1: 0.4068 
01/08/2024 12:25:48 - INFO - root -   ******* ORG.NOM results ********
01/08/2024 12:25:48 - INFO - root -    acc: 1.0000 - recall: 0.3529 - f1: 0.5217 
01/08/2024 12:25:48 - INFO - root -   ******* PER.NAM results ********
01/08/2024 12:25:48 - INFO - root -    acc: 0.7742 - recall: 0.6545 - f1: 0.7094 
01/08/2024 12:25:48 - INFO - root -   ******* PER.NOM results ********
01/08/2024 12:25:48 - INFO - root -    acc: 0.7089 - recall: 0.6588 - f1: 0.6829 
01/08/2024 12:25:56 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1653
01/08/2024 12:25:56 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1653
01/08/2024 12:25:56 - INFO - root -   

01/08/2024 12:25:56 - INFO - root -   Backbone bert_estor_crf param is freeze

Epoch: 29/50
[Training] 1/57 [..............................] - ETA: 1:59  [ loss=1.8023 ][Training] 2/57 [>.............................] - ETA: 1:44  [ loss=3.2992 ][Training] 3/57 [>.............................] - ETA: 1:42  [ loss=2.2200 ][Training] 4/57 [=>............................] - ETA: 1:42  [ loss=2.6144 ][Training] 5/57 [=>............................] - ETA: 1:35  [ loss=1.7514 ][Training] 6/57 [==>...........................] - ETA: 1:27  [ loss=2.6098 ][Training] 7/57 [==>...........................] - ETA: 1:25  [ loss=2.7246 ][Training] 8/57 [===>..........................] - ETA: 1:22  [ loss=2.1281 ][Training] 9/57 [===>..........................] - ETA: 1:20  [ loss=3.0766 ][Training] 10/57 [====>.........................] - ETA: 1:18  [ loss=2.3471 ][Training] 11/57 [====>.........................] - ETA: 1:16  [ loss=3.8660 ][Training] 12/57 [=====>........................] - ETA: 1:13  [ loss=2.3353 ][Training] 13/57 [=====>........................] - ETA: 1:10  [ loss=2.4320 ][Training] 14/57 [======>.......................] - ETA: 1:08  [ loss=2.7032 ][Training] 15/57 [======>.......................] - ETA: 1:06  [ loss=2.2066 ][Training] 16/57 [=======>......................] - ETA: 1:05  [ loss=1.8185 ][Training] 17/57 [=======>......................] - ETA: 1:03  [ loss=4.0880 ][Training] 18/57 [========>.....................] - ETA: 1:02  [ loss=2.9831 ][Training] 19/57 [=========>....................] - ETA: 1:01  [ loss=2.3661 ][Training] 20/57 [=========>....................] - ETA: 59s  [ loss=1.2034 ][Training] 21/57 [==========>...................] - ETA: 57s  [ loss=3.1903 ][Training] 22/57 [==========>...................] - ETA: 56s  [ loss=4.3145 ][Training] 23/57 [===========>..................] - ETA: 54s  [ loss=3.8679 ][Training] 24/57 [===========>..................] - ETA: 53s  [ loss=3.3534 ][Training] 25/57 [============>.................] - ETA: 53s  [ loss=2.0065 ][Training] 26/57 [============>.................] - ETA: 51s  [ loss=1.2354 ][Training] 27/57 [=============>................] - ETA: 49s  [ loss=2.3404 ][Training] 28/57 [=============>................] - ETA: 48s  [ loss=2.1189 ][Training] 29/57 [==============>...............] - ETA: 47s  [ loss=4.2044 ][Training] 30/57 [==============>...............] - ETA: 45s  [ loss=1.8982 ][Training] 31/57 [===============>..............] - ETA: 44s  [ loss=1.7433 ][Training] 32/57 [===============>..............] - ETA: 42s  [ loss=4.4947 ][Training] 33/57 [================>.............] - ETA: 40s  [ loss=0.8763 ][Training] 34/57 [================>.............] - ETA: 39s  [ loss=2.8655 ][Training] 35/57 [=================>............] - ETA: 37s  [ loss=1.5672 ][Training] 36/57 [=================>............] - ETA: 36s  [ loss=2.9167 ][Training] 37/57 [==================>...........] - ETA: 34s  [ loss=1.5927 ][Training] 38/57 [===================>..........] - ETA: 33s  [ loss=3.2594 ][Training] 39/57 [===================>..........] - ETA: 31s  [ loss=3.2004 ][Training] 40/57 [====================>.........] - ETA: 29s  [ loss=2.9328 ][Training] 41/57 [====================>.........] - ETA: 27s  [ loss=2.6784 ][Training] 42/57 [=====================>........] - ETA: 26s  [ loss=3.0647 ][Training] 43/57 [=====================>........] - ETA: 24s  [ loss=2.7099 ][Training] 44/57 [======================>.......] - ETA: 22s  [ loss=4.8357 ][Training] 45/57 [======================>.......] - ETA: 21s  [ loss=5.3188 ][Training] 46/57 [=======================>......] - ETA: 19s  [ loss=3.0379 ][Training] 47/57 [=======================>......] - ETA: 17s  [ loss=2.4338 ][Training] 48/57 [========================>.....] - ETA: 16s  [ loss=3.4819 ][Training] 49/57 [========================>.....] - ETA: 14s  [ loss=3.5381 ][Training] 50/57 [=========================>....] - ETA: 12s  [ loss=3.2139 ][Training] 51/57 [=========================>....] - ETA: 10s  [ loss=1.7831 ][Training] 52/57 [==========================>...] - ETA: 8s  [ loss=1.0018 ][Training] 53/57 [==========================>...] - ETA: 7s  [ loss=2.5340 ][Training] 54/57 [===========================>..] - ETA: 5s  [ loss=2.1388 ][Training] 55/57 [===========================>..] - ETA: 3s  [ loss=3.9328 ][Training] 56/57 [============================>.] - ETA: 1s  [ loss=2.8980 ][Training] 57/57 [==============================] 1.8s/step  [ loss=11.4083 ]
01/08/2024 12:27:37 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/08/2024 12:27:37 - INFO - root -   ***** Running evaluation on test dataset  *****
01/08/2024 12:27:37 - INFO - root -     Num examples = 269
01/08/2024 12:27:37 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 9s[Evaluating] 2/12 [====>.........................] - ETA: 8s[Evaluating] 3/12 [======>.......................] - ETA: 7s[Evaluating] 4/12 [=========>....................] - ETA: 6s[Evaluating] 5/12 [===========>..................] - ETA: 5s[Evaluating] 6/12 [==============>...............] - ETA: 4s[Evaluating] 7/12 [================>.............] - ETA: 4s[Evaluating] 8/12 [===================>..........] - ETA: 3s[Evaluating] 9/12 [=====================>........] - ETA: 2s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 828.2ms/step
01/08/2024 12:27:47 - INFO - root -   

01/08/2024 12:27:47 - INFO - root -   ***** Eval results  *****
01/08/2024 12:27:47 - INFO - root -    acc: 0.7180 - recall: 0.5981 - f1: 0.6526 - loss: 3.8311 
01/08/2024 12:27:47 - INFO - root -   ***** Entity results  *****
01/08/2024 12:27:47 - INFO - root -   ******* GPE.NAM results ********
01/08/2024 12:27:47 - INFO - root -    acc: 0.8261 - recall: 0.8085 - f1: 0.8172 
01/08/2024 12:27:47 - INFO - root -   ******* GPE.NOM results ********
01/08/2024 12:27:47 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 12:27:47 - INFO - root -   ******* LOC.NAM results ********
01/08/2024 12:27:47 - INFO - root -    acc: 0.4000 - recall: 0.2105 - f1: 0.2759 
01/08/2024 12:27:47 - INFO - root -   ******* LOC.NOM results ********
01/08/2024 12:27:47 - INFO - root -    acc: 0.5000 - recall: 0.2222 - f1: 0.3077 
01/08/2024 12:27:47 - INFO - root -   ******* ORG.NAM results ********
01/08/2024 12:27:47 - INFO - root -    acc: 0.5455 - recall: 0.3077 - f1: 0.3934 
01/08/2024 12:27:47 - INFO - root -   ******* ORG.NOM results ********
01/08/2024 12:27:47 - INFO - root -    acc: 1.0000 - recall: 0.3529 - f1: 0.5217 
01/08/2024 12:27:47 - INFO - root -   ******* PER.NAM results ********
01/08/2024 12:27:47 - INFO - root -    acc: 0.7660 - recall: 0.6545 - f1: 0.7059 
01/08/2024 12:27:47 - INFO - root -   ******* PER.NOM results ********
01/08/2024 12:27:47 - INFO - root -    acc: 0.6975 - recall: 0.6647 - f1: 0.6807 
01/08/2024 12:28:05 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1710
01/08/2024 12:28:05 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1710
01/08/2024 12:28:05 - INFO - root -   

01/08/2024 12:28:05 - INFO - root -   Backbone bert_estor_crf param is not freeze

Epoch: 30/50
[Training] 1/57 [..............................] - ETA: 2:13  [ loss=1.8912 ][Training] 2/57 [>.............................] - ETA: 1:51  [ loss=1.7264 ][Training] 3/57 [>.............................] - ETA: 1:56  [ loss=2.6820 ][Training] 4/57 [=>............................] - ETA: 2:02  [ loss=3.2375 ][Training] 5/57 [=>............................] - ETA: 2:01  [ loss=1.5836 ][Training] 6/57 [==>...........................] - ETA: 1:59  [ loss=3.2506 ][Training] 7/57 [==>...........................] - ETA: 1:58  [ loss=2.0625 ][Training] 8/57 [===>..........................] - ETA: 1:58  [ loss=2.5040 ][Training] 9/57 [===>..........................] - ETA: 1:56  [ loss=2.8140 ][Training] 10/57 [====>.........................] - ETA: 1:54  [ loss=1.4571 ][Training] 11/57 [====>.........................] - ETA: 1:51  [ loss=2.3614 ][Training] 12/57 [=====>........................] - ETA: 1:49  [ loss=3.9171 ][Training] 13/57 [=====>........................] - ETA: 1:48  [ loss=3.7912 ][Training] 14/57 [======>.......................] - ETA: 1:47  [ loss=1.6948 ][Training] 15/57 [======>.......................] - ETA: 1:46  [ loss=3.0226 ][Training] 16/57 [=======>......................] - ETA: 1:44  [ loss=2.5996 ][Training] 17/57 [=======>......................] - ETA: 1:40  [ loss=1.5672 ][Training] 18/57 [========>.....................] - ETA: 1:37  [ loss=2.4421 ][Training] 19/57 [=========>....................] - ETA: 1:34  [ loss=2.5962 ][Training] 20/57 [=========>....................] - ETA: 1:30  [ loss=1.3989 ][Training] 21/57 [==========>...................] - ETA: 1:27  [ loss=2.3910 ][Training] 22/57 [==========>...................] - ETA: 1:24  [ loss=2.4543 ][Training] 23/57 [===========>..................] - ETA: 1:21  [ loss=4.5824 ][Training] 24/57 [===========>..................] - ETA: 1:19  [ loss=4.0905 ][Training] 25/57 [============>.................] - ETA: 1:16  [ loss=2.8623 ][Training] 26/57 [============>.................] - ETA: 1:13  [ loss=2.5339 ][Training] 27/57 [=============>................] - ETA: 1:11  [ loss=2.3057 ][Training] 28/57 [=============>................] - ETA: 1:09  [ loss=1.8324 ][Training] 29/57 [==============>...............] - ETA: 1:06  [ loss=2.4866 ][Training] 30/57 [==============>...............] - ETA: 1:04  [ loss=2.1791 ][Training] 31/57 [===============>..............] - ETA: 1:01  [ loss=3.5091 ][Training] 32/57 [===============>..............] - ETA: 58s  [ loss=4.2661 ][Training] 33/57 [================>.............] - ETA: 56s  [ loss=2.0763 ][Training] 34/57 [================>.............] - ETA: 54s  [ loss=6.6989 ][Training] 35/57 [=================>............] - ETA: 52s  [ loss=4.6105 ][Training] 36/57 [=================>............] - ETA: 50s  [ loss=1.8955 ][Training] 37/57 [==================>...........] - ETA: 47s  [ loss=3.2847 ][Training] 38/57 [===================>..........] - ETA: 45s  [ loss=2.0779 ][Training] 39/57 [===================>..........] - ETA: 43s  [ loss=1.2168 ][Training] 40/57 [====================>.........] - ETA: 40s  [ loss=3.1928 ][Training] 41/57 [====================>.........] - ETA: 38s  [ loss=1.4725 ][Training] 42/57 [=====================>........] - ETA: 36s  [ loss=2.2917 ][Training] 43/57 [=====================>........] - ETA: 33s  [ loss=2.5562 ][Training] 44/57 [======================>.......] - ETA: 31s  [ loss=2.6147 ][Training] 45/57 [======================>.......] - ETA: 28s  [ loss=2.8302 ][Training] 46/57 [=======================>......] - ETA: 26s  [ loss=2.4975 ][Training] 47/57 [=======================>......] - ETA: 24s  [ loss=4.1199 ][Training] 48/57 [========================>.....] - ETA: 21s  [ loss=3.4418 ][Training] 49/57 [========================>.....] - ETA: 19s  [ loss=2.4037 ][Training] 50/57 [=========================>....] - ETA: 17s  [ loss=1.7287 ][Training] 51/57 [=========================>....] - ETA: 14s  [ loss=3.7435 ][Training] 52/57 [==========================>...] - ETA: 12s  [ loss=1.6656 ][Training] 53/57 [==========================>...] - ETA: 9s  [ loss=3.5553 ][Training] 54/57 [===========================>..] - ETA: 7s  [ loss=1.2759 ][Training] 55/57 [===========================>..] - ETA: 4s  [ loss=2.3734 ][Training] 56/57 [============================>.] - ETA: 2s  [ loss=1.4917 ][Training] 57/57 [==============================] 2.4s/step  [ loss=0.3252 ]
01/08/2024 12:30:22 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/08/2024 12:30:22 - INFO - root -   ***** Running evaluation on test dataset  *****
01/08/2024 12:30:22 - INFO - root -     Num examples = 269
01/08/2024 12:30:22 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 11s[Evaluating] 2/12 [====>.........................] - ETA: 9s[Evaluating] 3/12 [======>.......................] - ETA: 8s[Evaluating] 4/12 [=========>....................] - ETA: 7s[Evaluating] 5/12 [===========>..................] - ETA: 6s[Evaluating] 6/12 [==============>...............] - ETA: 5s[Evaluating] 7/12 [================>.............] - ETA: 4s[Evaluating] 8/12 [===================>..........] - ETA: 3s[Evaluating] 9/12 [=====================>........] - ETA: 2s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 849.1ms/step
01/08/2024 12:30:32 - INFO - root -   

01/08/2024 12:30:32 - INFO - root -   ***** Eval results  *****
01/08/2024 12:30:32 - INFO - root -    acc: 0.7748 - recall: 0.6247 - f1: 0.6917 - loss: 3.7089 
01/08/2024 12:30:32 - INFO - root -   ***** Entity results  *****
01/08/2024 12:30:32 - INFO - root -   ******* GPE.NAM results ********
01/08/2024 12:30:32 - INFO - root -    acc: 0.8667 - recall: 0.8298 - f1: 0.8478 
01/08/2024 12:30:32 - INFO - root -   ******* GPE.NOM results ********
01/08/2024 12:30:32 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 12:30:32 - INFO - root -   ******* LOC.NAM results ********
01/08/2024 12:30:32 - INFO - root -    acc: 0.6000 - recall: 0.3158 - f1: 0.4138 
01/08/2024 12:30:32 - INFO - root -   ******* LOC.NOM results ********
01/08/2024 12:30:32 - INFO - root -    acc: 0.5000 - recall: 0.2222 - f1: 0.3077 
01/08/2024 12:30:32 - INFO - root -   ******* ORG.NAM results ********
01/08/2024 12:30:32 - INFO - root -    acc: 0.5714 - recall: 0.4103 - f1: 0.4776 
01/08/2024 12:30:32 - INFO - root -   ******* ORG.NOM results ********
01/08/2024 12:30:32 - INFO - root -    acc: 1.0000 - recall: 0.3529 - f1: 0.5217 
01/08/2024 12:30:32 - INFO - root -   ******* PER.NAM results ********
01/08/2024 12:30:32 - INFO - root -    acc: 0.8652 - recall: 0.7000 - f1: 0.7739 
01/08/2024 12:30:32 - INFO - root -   ******* PER.NOM results ********
01/08/2024 12:30:32 - INFO - root -    acc: 0.7417 - recall: 0.6588 - f1: 0.6978 
01/08/2024 12:31:17 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1767
01/08/2024 12:31:17 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1767
01/08/2024 12:31:17 - INFO - root -   

01/08/2024 12:31:17 - INFO - root -   Backbone bert_estor_crf param is not freeze

Epoch: 31/50
[Training] 1/57 [..............................] - ETA: 2:35  [ loss=1.1926 ][Training] 2/57 [>.............................] - ETA: 2:43  [ loss=2.2826 ][Training] 3/57 [>.............................] - ETA: 2:52  [ loss=2.1270 ][Training] 4/57 [=>............................] - ETA: 2:49  [ loss=2.1697 ][Training] 5/57 [=>............................] - ETA: 2:45  [ loss=1.4513 ][Training] 6/57 [==>...........................] - ETA: 2:43  [ loss=1.4313 ][Training] 7/57 [==>...........................] - ETA: 2:35  [ loss=1.3992 ][Training] 8/57 [===>..........................] - ETA: 2:25  [ loss=1.9157 ][Training] 9/57 [===>..........................] - ETA: 2:18  [ loss=1.6349 ][Training] 10/57 [====>.........................] - ETA: 2:12  [ loss=1.2945 ][Training] 11/57 [====>.........................] - ETA: 2:06  [ loss=0.9681 ][Training] 12/57 [=====>........................] - ETA: 1:59  [ loss=1.0853 ][Training] 13/57 [=====>........................] - ETA: 1:56  [ loss=1.4753 ][Training] 14/57 [======>.......................] - ETA: 1:55  [ loss=2.7207 ][Training] 15/57 [======>.......................] - ETA: 1:53  [ loss=1.6694 ][Training] 16/57 [=======>......................] - ETA: 1:51  [ loss=2.5751 ][Training] 17/57 [=======>......................] - ETA: 1:48  [ loss=1.6373 ][Training] 18/57 [========>.....................] - ETA: 1:46  [ loss=1.7623 ][Training] 19/57 [=========>....................] - ETA: 1:43  [ loss=1.3798 ][Training] 20/57 [=========>....................] - ETA: 1:41  [ loss=1.9414 ][Training] 21/57 [==========>...................] - ETA: 1:40  [ loss=2.1583 ][Training] 22/57 [==========>...................] - ETA: 1:37  [ loss=3.4800 ][Training] 23/57 [===========>..................] - ETA: 1:35  [ loss=1.6937 ][Training] 24/57 [===========>..................] - ETA: 1:32  [ loss=3.6037 ][Training] 25/57 [============>.................] - ETA: 1:29  [ loss=1.2166 ][Training] 26/57 [============>.................] - ETA: 1:27  [ loss=2.7670 ][Training] 27/57 [=============>................] - ETA: 1:25  [ loss=1.3559 ][Training] 28/57 [=============>................] - ETA: 1:22  [ loss=2.8492 ][Training] 29/57 [==============>...............] - ETA: 1:19  [ loss=2.0128 ][Training] 30/57 [==============>...............] - ETA: 1:16  [ loss=2.2400 ][Training] 31/57 [===============>..............] - ETA: 1:12  [ loss=1.4341 ][Training] 32/57 [===============>..............] - ETA: 1:09  [ loss=1.3802 ][Training] 33/57 [================>.............] - ETA: 1:05  [ loss=0.8568 ][Training] 34/57 [================>.............] - ETA: 1:02  [ loss=0.5943 ][Training] 35/57 [=================>............] - ETA: 59s  [ loss=1.6667 ][Training] 36/57 [=================>............] - ETA: 56s  [ loss=1.4592 ][Training] 37/57 [==================>...........] - ETA: 52s  [ loss=0.8779 ][Training] 38/57 [===================>..........] - ETA: 50s  [ loss=1.3805 ][Training] 39/57 [===================>..........] - ETA: 47s  [ loss=1.5409 ][Training] 40/57 [====================>.........] - ETA: 44s  [ loss=3.3742 ][Training] 41/57 [====================>.........] - ETA: 42s  [ loss=1.6983 ][Training] 42/57 [=====================>........] - ETA: 39s  [ loss=1.6700 ][Training] 43/57 [=====================>........] - ETA: 36s  [ loss=1.9451 ][Training] 44/57 [======================>.......] - ETA: 34s  [ loss=2.1756 ][Training] 45/57 [======================>.......] - ETA: 31s  [ loss=1.1538 ][Training] 46/57 [=======================>......] - ETA: 29s  [ loss=3.0042 ][Training] 47/57 [=======================>......] - ETA: 26s  [ loss=4.4302 ][Training] 48/57 [========================>.....] - ETA: 23s  [ loss=2.2073 ][Training] 49/57 [========================>.....] - ETA: 21s  [ loss=3.2289 ][Training] 50/57 [=========================>....] - ETA: 18s  [ loss=1.0412 ][Training] 51/57 [=========================>....] - ETA: 15s  [ loss=4.4777 ][Training] 52/57 [==========================>...] - ETA: 13s  [ loss=2.4016 ][Training] 53/57 [==========================>...] - ETA: 10s  [ loss=2.5254 ][Training] 54/57 [===========================>..] - ETA: 7s  [ loss=3.8111 ][Training] 55/57 [===========================>..] - ETA: 5s  [ loss=3.1940 ][Training] 56/57 [============================>.] - ETA: 2s  [ loss=2.0252 ][Training] 57/57 [==============================] 2.6s/step  [ loss=4.1875 ]
01/08/2024 12:33:45 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/08/2024 12:33:45 - INFO - root -   ***** Running evaluation on test dataset  *****
01/08/2024 12:33:45 - INFO - root -     Num examples = 269
01/08/2024 12:33:45 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 8s[Evaluating] 2/12 [====>.........................] - ETA: 9s[Evaluating] 3/12 [======>.......................] - ETA: 8s[Evaluating] 4/12 [=========>....................] - ETA: 7s[Evaluating] 5/12 [===========>..................] - ETA: 6s[Evaluating] 6/12 [==============>...............] - ETA: 5s[Evaluating] 7/12 [================>.............] - ETA: 4s[Evaluating] 8/12 [===================>..........] - ETA: 3s[Evaluating] 9/12 [=====================>........] - ETA: 2s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 836.2ms/step
01/08/2024 12:33:55 - INFO - root -   

01/08/2024 12:33:55 - INFO - root -   ***** Eval results  *****
01/08/2024 12:33:55 - INFO - root -    acc: 0.7083 - recall: 0.6586 - f1: 0.6826 - loss: 4.0777 
01/08/2024 12:33:55 - INFO - root -   ***** Entity results  *****
01/08/2024 12:33:55 - INFO - root -   ******* GPE.NAM results ********
01/08/2024 12:33:55 - INFO - root -    acc: 0.8039 - recall: 0.8723 - f1: 0.8367 
01/08/2024 12:33:55 - INFO - root -   ******* GPE.NOM results ********
01/08/2024 12:33:55 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 12:33:55 - INFO - root -   ******* LOC.NAM results ********
01/08/2024 12:33:55 - INFO - root -    acc: 0.6154 - recall: 0.4211 - f1: 0.5000 
01/08/2024 12:33:55 - INFO - root -   ******* LOC.NOM results ********
01/08/2024 12:33:55 - INFO - root -    acc: 0.3333 - recall: 0.3333 - f1: 0.3333 
01/08/2024 12:33:55 - INFO - root -   ******* ORG.NAM results ********
01/08/2024 12:33:55 - INFO - root -    acc: 0.6000 - recall: 0.5385 - f1: 0.5676 
01/08/2024 12:33:55 - INFO - root -   ******* ORG.NOM results ********
01/08/2024 12:33:55 - INFO - root -    acc: 0.8889 - recall: 0.4706 - f1: 0.6154 
01/08/2024 12:33:55 - INFO - root -   ******* PER.NAM results ********
01/08/2024 12:33:55 - INFO - root -    acc: 0.7604 - recall: 0.6636 - f1: 0.7087 
01/08/2024 12:33:55 - INFO - root -   ******* PER.NOM results ********
01/08/2024 12:33:55 - INFO - root -    acc: 0.6901 - recall: 0.6941 - f1: 0.6921 
01/08/2024 12:34:18 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1824
01/08/2024 12:34:18 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1824
01/08/2024 12:34:18 - INFO - root -   

01/08/2024 12:34:19 - INFO - root -   Backbone bert_estor_crf param is not freeze

Epoch: 32/50
[Training] 1/57 [..............................] - ETA: 1:42  [ loss=0.9905 ][Training] 2/57 [>.............................] - ETA: 1:46  [ loss=0.6114 ][Training] 3/57 [>.............................] - ETA: 1:45  [ loss=1.1194 ][Training] 4/57 [=>............................] - ETA: 1:44  [ loss=0.8667 ][Training] 5/57 [=>............................] - ETA: 1:42  [ loss=0.6409 ][Training] 6/57 [==>...........................] - ETA: 1:42  [ loss=1.3564 ][Training] 7/57 [==>...........................] - ETA: 1:40  [ loss=0.2124 ][Training] 8/57 [===>..........................] - ETA: 1:41  [ loss=1.4988 ][Training] 9/57 [===>..........................] - ETA: 1:40  [ loss=1.6221 ][Training] 10/57 [====>.........................] - ETA: 1:41  [ loss=1.9716 ][Training] 11/57 [====>.........................] - ETA: 1:41  [ loss=2.7903 ][Training] 12/57 [=====>........................] - ETA: 1:39  [ loss=0.9055 ][Training] 13/57 [=====>........................] - ETA: 1:38  [ loss=1.9949 ][Training] 14/57 [======>.......................] - ETA: 1:36  [ loss=0.7271 ][Training] 15/57 [======>.......................] - ETA: 1:34  [ loss=0.8284 ][Training] 16/57 [=======>......................] - ETA: 1:33  [ loss=1.0517 ][Training] 17/57 [=======>......................] - ETA: 1:31  [ loss=2.6110 ][Training] 18/57 [========>.....................] - ETA: 1:30  [ loss=1.4721 ][Training] 19/57 [=========>....................] - ETA: 1:28  [ loss=0.7348 ][Training] 20/57 [=========>....................] - ETA: 1:26  [ loss=1.7891 ][Training] 21/57 [==========>...................] - ETA: 1:24  [ loss=1.4069 ][Training] 22/57 [==========>...................] - ETA: 1:23  [ loss=1.8793 ][Training] 23/57 [===========>..................] - ETA: 1:21  [ loss=1.7404 ][Training] 24/57 [===========>..................] - ETA: 1:18  [ loss=0.6222 ][Training] 25/57 [============>.................] - ETA: 1:16  [ loss=1.1284 ][Training] 26/57 [============>.................] - ETA: 1:13  [ loss=1.2447 ][Training] 27/57 [=============>................] - ETA: 1:11  [ loss=2.1355 ][Training] 28/57 [=============>................] - ETA: 1:09  [ loss=1.9871 ][Training] 29/57 [==============>...............] - ETA: 1:06  [ loss=1.0296 ][Training] 30/57 [==============>...............] - ETA: 1:05  [ loss=3.2650 ][Training] 31/57 [===============>..............] - ETA: 1:02  [ loss=0.7790 ][Training] 32/57 [===============>..............] - ETA: 1:00  [ loss=0.8195 ][Training] 33/57 [================>.............] - ETA: 57s  [ loss=0.9284 ][Training] 34/57 [================>.............] - ETA: 55s  [ loss=0.6722 ][Training] 35/57 [=================>............] - ETA: 53s  [ loss=1.3866 ][Training] 36/57 [=================>............] - ETA: 51s  [ loss=0.8441 ][Training] 37/57 [==================>...........] - ETA: 48s  [ loss=0.5483 ][Training] 38/57 [===================>..........] - ETA: 46s  [ loss=1.0492 ][Training] 39/57 [===================>..........] - ETA: 43s  [ loss=2.0484 ][Training] 40/57 [====================>.........] - ETA: 41s  [ loss=2.3232 ][Training] 41/57 [====================>.........] - ETA: 39s  [ loss=0.8598 ][Training] 42/57 [=====================>........] - ETA: 36s  [ loss=1.2822 ][Training] 43/57 [=====================>........] - ETA: 34s  [ loss=1.1772 ][Training] 44/57 [======================>.......] - ETA: 31s  [ loss=0.8729 ][Training] 45/57 [======================>.......] - ETA: 29s  [ loss=1.4521 ][Training] 46/57 [=======================>......] - ETA: 26s  [ loss=1.0932 ][Training] 47/57 [=======================>......] - ETA: 24s  [ loss=0.6454 ][Training] 48/57 [========================>.....] - ETA: 22s  [ loss=2.0097 ][Training] 49/57 [========================>.....] - ETA: 19s  [ loss=1.7071 ][Training] 50/57 [=========================>....] - ETA: 17s  [ loss=1.4964 ][Training] 51/57 [=========================>....] - ETA: 14s  [ loss=1.0499 ][Training] 52/57 [==========================>...] - ETA: 12s  [ loss=0.6738 ][Training] 53/57 [==========================>...] - ETA: 9s  [ loss=0.9549 ][Training] 54/57 [===========================>..] - ETA: 7s  [ loss=0.6078 ][Training] 55/57 [===========================>..] - ETA: 4s  [ loss=2.0899 ][Training] 56/57 [============================>.] - ETA: 2s  [ loss=0.3905 ][Training] 57/57 [==============================] 2.4s/step  [ loss=2.3423 ]
01/08/2024 12:36:37 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/08/2024 12:36:37 - INFO - root -   ***** Running evaluation on test dataset  *****
01/08/2024 12:36:37 - INFO - root -     Num examples = 269
01/08/2024 12:36:37 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 9s[Evaluating] 2/12 [====>.........................] - ETA: 8s[Evaluating] 3/12 [======>.......................] - ETA: 7s[Evaluating] 4/12 [=========>....................] - ETA: 7s[Evaluating] 5/12 [===========>..................] - ETA: 6s[Evaluating] 6/12 [==============>...............] - ETA: 5s[Evaluating] 7/12 [================>.............] - ETA: 4s[Evaluating] 8/12 [===================>..........] - ETA: 3s[Evaluating] 9/12 [=====================>........] - ETA: 2s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 812.8ms/step
01/08/2024 12:36:47 - INFO - root -   

01/08/2024 12:36:47 - INFO - root -   ***** Eval results  *****
01/08/2024 12:36:47 - INFO - root -    acc: 0.7472 - recall: 0.6441 - f1: 0.6918 - loss: 4.4101 
01/08/2024 12:36:47 - INFO - root -   ***** Entity results  *****
01/08/2024 12:36:47 - INFO - root -   ******* GPE.NAM results ********
01/08/2024 12:36:47 - INFO - root -    acc: 0.7885 - recall: 0.8723 - f1: 0.8283 
01/08/2024 12:36:47 - INFO - root -   ******* GPE.NOM results ********
01/08/2024 12:36:47 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 12:36:47 - INFO - root -   ******* LOC.NAM results ********
01/08/2024 12:36:47 - INFO - root -    acc: 0.5333 - recall: 0.4211 - f1: 0.4706 
01/08/2024 12:36:47 - INFO - root -   ******* LOC.NOM results ********
01/08/2024 12:36:47 - INFO - root -    acc: 0.6000 - recall: 0.3333 - f1: 0.4286 
01/08/2024 12:36:47 - INFO - root -   ******* ORG.NAM results ********
01/08/2024 12:36:47 - INFO - root -    acc: 0.6667 - recall: 0.4103 - f1: 0.5079 
01/08/2024 12:36:47 - INFO - root -   ******* ORG.NOM results ********
01/08/2024 12:36:47 - INFO - root -    acc: 0.7778 - recall: 0.4118 - f1: 0.5385 
01/08/2024 12:36:47 - INFO - root -   ******* PER.NAM results ********
01/08/2024 12:36:47 - INFO - root -    acc: 0.7900 - recall: 0.7182 - f1: 0.7524 
01/08/2024 12:36:47 - INFO - root -   ******* PER.NOM results ********
01/08/2024 12:36:47 - INFO - root -    acc: 0.7417 - recall: 0.6588 - f1: 0.6978 
01/08/2024 12:37:29 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1881
01/08/2024 12:37:29 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1881
01/08/2024 12:37:29 - INFO - root -   

01/08/2024 12:37:29 - INFO - root -   Backbone bert_estor_crf param is not freeze

Epoch: 33/50
[Training] 1/57 [..............................] - ETA: 1:46  [ loss=0.4556 ][Training] 2/57 [>.............................] - ETA: 1:52  [ loss=0.4675 ][Training] 3/57 [>.............................] - ETA: 1:51  [ loss=0.7630 ][Training] 4/57 [=>............................] - ETA: 1:48  [ loss=0.5753 ][Training] 5/57 [=>............................] - ETA: 1:49  [ loss=0.5007 ][Training] 6/57 [==>...........................] - ETA: 1:59  [ loss=0.6413 ][Training] 7/57 [==>...........................] - ETA: 1:59  [ loss=0.4839 ][Training] 8/57 [===>..........................] - ETA: 1:55  [ loss=0.5200 ][Training] 9/57 [===>..........................] - ETA: 1:53  [ loss=0.2984 ][Training] 10/57 [====>.........................] - ETA: 1:52  [ loss=0.4176 ][Training] 11/57 [====>.........................] - ETA: 1:50  [ loss=0.6696 ][Training] 12/57 [=====>........................] - ETA: 1:48  [ loss=0.4192 ][Training] 13/57 [=====>........................] - ETA: 1:45  [ loss=0.6973 ][Training] 14/57 [======>.......................] - ETA: 1:40  [ loss=0.6557 ][Training] 15/57 [======>.......................] - ETA: 1:37  [ loss=0.5573 ][Training] 16/57 [=======>......................] - ETA: 1:35  [ loss=1.5114 ][Training] 17/57 [=======>......................] - ETA: 1:31  [ loss=0.7575 ][Training] 18/57 [========>.....................] - ETA: 1:28  [ loss=1.3306 ][Training] 19/57 [=========>....................] - ETA: 1:25  [ loss=0.4622 ][Training] 20/57 [=========>....................] - ETA: 1:23  [ loss=0.4168 ][Training] 21/57 [==========>...................] - ETA: 1:20  [ loss=1.0193 ][Training] 22/57 [==========>...................] - ETA: 1:17  [ loss=0.5160 ][Training] 23/57 [===========>..................] - ETA: 1:15  [ loss=0.6739 ][Training] 24/57 [===========>..................] - ETA: 1:13  [ loss=0.8471 ][Training] 25/57 [============>.................] - ETA: 1:12  [ loss=1.5449 ][Training] 26/57 [============>.................] - ETA: 1:10  [ loss=1.0084 ][Training] 27/57 [=============>................] - ETA: 1:08  [ loss=0.5973 ][Training] 28/57 [=============>................] - ETA: 1:07  [ loss=1.2314 ][Training] 29/57 [==============>...............] - ETA: 1:05  [ loss=0.8139 ][Training] 30/57 [==============>...............] - ETA: 1:03  [ loss=1.5238 ][Training] 31/57 [===============>..............] - ETA: 1:01  [ loss=0.5552 ][Training] 32/57 [===============>..............] - ETA: 1:00  [ loss=0.8153 ][Training] 33/57 [================>.............] - ETA: 58s  [ loss=1.1883 ][Training] 34/57 [================>.............] - ETA: 55s  [ loss=0.6815 ][Training] 35/57 [=================>............] - ETA: 53s  [ loss=1.2169 ][Training] 36/57 [=================>............] - ETA: 51s  [ loss=0.5413 ][Training] 37/57 [==================>...........] - ETA: 49s  [ loss=0.7361 ][Training] 38/57 [===================>..........] - ETA: 47s  [ loss=0.7254 ][Training] 39/57 [===================>..........] - ETA: 44s  [ loss=1.1132 ][Training] 40/57 [====================>.........] - ETA: 42s  [ loss=0.9448 ][Training] 41/57 [====================>.........] - ETA: 40s  [ loss=0.4292 ][Training] 42/57 [=====================>........] - ETA: 37s  [ loss=1.8202 ][Training] 43/57 [=====================>........] - ETA: 35s  [ loss=2.7024 ][Training] 44/57 [======================>.......] - ETA: 32s  [ loss=0.3168 ][Training] 45/57 [======================>.......] - ETA: 30s  [ loss=1.2883 ][Training] 46/57 [=======================>......] - ETA: 28s  [ loss=1.0118 ][Training] 47/57 [=======================>......] - ETA: 25s  [ loss=0.6319 ][Training] 48/57 [========================>.....] - ETA: 23s  [ loss=2.3684 ][Training] 49/57 [========================>.....] - ETA: 20s  [ loss=0.9779 ][Training] 50/57 [=========================>....] - ETA: 17s  [ loss=0.6630 ][Training] 51/57 [=========================>....] - ETA: 15s  [ loss=1.5329 ][Training] 52/57 [==========================>...] - ETA: 12s  [ loss=1.5081 ][Training] 53/57 [==========================>...] - ETA: 10s  [ loss=1.5564 ][Training] 54/57 [===========================>..] - ETA: 7s  [ loss=0.5585 ][Training] 55/57 [===========================>..] - ETA: 5s  [ loss=1.2620 ][Training] 56/57 [============================>.] - ETA: 2s  [ loss=0.6572 ][Training] 57/57 [==============================] 2.6s/step  [ loss=1.7673 ]
01/08/2024 12:39:56 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/08/2024 12:39:56 - INFO - root -   ***** Running evaluation on test dataset  *****
01/08/2024 12:39:56 - INFO - root -     Num examples = 269
01/08/2024 12:39:56 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 9s[Evaluating] 2/12 [====>.........................] - ETA: 8s[Evaluating] 3/12 [======>.......................] - ETA: 8s[Evaluating] 4/12 [=========>....................] - ETA: 7s[Evaluating] 5/12 [===========>..................] - ETA: 6s[Evaluating] 6/12 [==============>...............] - ETA: 5s[Evaluating] 7/12 [================>.............] - ETA: 4s[Evaluating] 8/12 [===================>..........] - ETA: 3s[Evaluating] 9/12 [=====================>........] - ETA: 2s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 903.3ms/step
01/08/2024 12:40:07 - INFO - root -   

01/08/2024 12:40:07 - INFO - root -   ***** Eval results  *****
01/08/2024 12:40:07 - INFO - root -    acc: 0.6921 - recall: 0.6368 - f1: 0.6633 - loss: 4.5061 
01/08/2024 12:40:07 - INFO - root -   ***** Entity results  *****
01/08/2024 12:40:07 - INFO - root -   ******* GPE.NAM results ********
01/08/2024 12:40:07 - INFO - root -    acc: 0.8043 - recall: 0.7872 - f1: 0.7957 
01/08/2024 12:40:07 - INFO - root -   ******* GPE.NOM results ********
01/08/2024 12:40:07 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 12:40:07 - INFO - root -   ******* LOC.NAM results ********
01/08/2024 12:40:07 - INFO - root -    acc: 0.4286 - recall: 0.4737 - f1: 0.4500 
01/08/2024 12:40:07 - INFO - root -   ******* LOC.NOM results ********
01/08/2024 12:40:07 - INFO - root -    acc: 0.5000 - recall: 0.3333 - f1: 0.4000 
01/08/2024 12:40:07 - INFO - root -   ******* ORG.NAM results ********
01/08/2024 12:40:07 - INFO - root -    acc: 0.5938 - recall: 0.4872 - f1: 0.5352 
01/08/2024 12:40:07 - INFO - root -   ******* ORG.NOM results ********
01/08/2024 12:40:07 - INFO - root -    acc: 0.6667 - recall: 0.4706 - f1: 0.5517 
01/08/2024 12:40:07 - INFO - root -   ******* PER.NAM results ********
01/08/2024 12:40:07 - INFO - root -    acc: 0.7400 - recall: 0.6727 - f1: 0.7048 
01/08/2024 12:40:07 - INFO - root -   ******* PER.NOM results ********
01/08/2024 12:40:07 - INFO - root -    acc: 0.6933 - recall: 0.6647 - f1: 0.6787 
01/08/2024 12:40:36 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1938
01/08/2024 12:40:36 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1938
01/08/2024 12:40:36 - INFO - root -   

01/08/2024 12:40:36 - INFO - root -   Backbone bert_estor_crf param is not freeze

Epoch: 34/50
[Training] 1/57 [..............................] - ETA: 2:10  [ loss=0.5476 ][Training] 2/57 [>.............................] - ETA: 2:12  [ loss=0.6708 ][Training] 3/57 [>.............................] - ETA: 2:29  [ loss=1.0762 ][Training] 4/57 [=>............................] - ETA: 2:23  [ loss=0.4567 ][Training] 5/57 [=>............................] - ETA: 2:24  [ loss=1.2047 ][Training] 6/57 [==>...........................] - ETA: 2:19  [ loss=0.8432 ][Training] 7/57 [==>...........................] - ETA: 2:16  [ loss=0.4685 ][Training] 8/57 [===>..........................] - ETA: 2:16  [ loss=0.4396 ][Training] 9/57 [===>..........................] - ETA: 2:12  [ loss=0.1679 ][Training] 10/57 [====>.........................] - ETA: 2:13  [ loss=0.6870 ][Training] 11/57 [====>.........................] - ETA: 2:08  [ loss=0.3999 ][Training] 12/57 [=====>........................] - ETA: 2:05  [ loss=0.1264 ][Training] 13/57 [=====>........................] - ETA: 2:01  [ loss=0.3459 ][Training] 14/57 [======>.......................] - ETA: 2:00  [ loss=1.0161 ][Training] 15/57 [======>.......................] - ETA: 1:55  [ loss=0.3420 ][Training] 16/57 [=======>......................] - ETA: 1:52  [ loss=1.5109 ][Training] 17/57 [=======>......................] - ETA: 1:49  [ loss=0.4133 ][Training] 18/57 [========>.....................] - ETA: 1:46  [ loss=0.8586 ][Training] 19/57 [=========>....................] - ETA: 1:43  [ loss=0.2882 ][Training] 20/57 [=========>....................] - ETA: 1:41  [ loss=1.0465 ][Training] 21/57 [==========>...................] - ETA: 1:38  [ loss=0.9166 ][Training] 22/57 [==========>...................] - ETA: 1:36  [ loss=0.1258 ][Training] 23/57 [===========>..................] - ETA: 1:33  [ loss=0.2641 ][Training] 24/57 [===========>..................] - ETA: 1:30  [ loss=0.9035 ][Training] 25/57 [============>.................] - ETA: 1:27  [ loss=0.2128 ][Training] 26/57 [============>.................] - ETA: 1:24  [ loss=0.2709 ][Training] 27/57 [=============>................] - ETA: 1:21  [ loss=0.6250 ][Training] 28/57 [=============>................] - ETA: 1:19  [ loss=0.3431 ][Training] 29/57 [==============>...............] - ETA: 1:16  [ loss=0.3872 ][Training] 30/57 [==============>...............] - ETA: 1:13  [ loss=0.3498 ][Training] 31/57 [===============>..............] - ETA: 1:10  [ loss=0.9861 ][Training] 32/57 [===============>..............] - ETA: 1:08  [ loss=1.8029 ][Training] 33/57 [================>.............] - ETA: 1:05  [ loss=0.5010 ][Training] 34/57 [================>.............] - ETA: 1:02  [ loss=0.7944 ][Training] 35/57 [=================>............] - ETA: 1:00  [ loss=0.6621 ][Training] 36/57 [=================>............] - ETA: 57s  [ loss=0.4640 ][Training] 37/57 [==================>...........] - ETA: 54s  [ loss=0.5774 ][Training] 38/57 [===================>..........] - ETA: 51s  [ loss=0.6502 ][Training] 39/57 [===================>..........] - ETA: 49s  [ loss=0.7412 ][Training] 40/57 [====================>.........] - ETA: 46s  [ loss=1.2935 ][Training] 41/57 [====================>.........] - ETA: 43s  [ loss=0.7429 ][Training] 42/57 [=====================>........] - ETA: 41s  [ loss=0.4626 ][Training] 43/57 [=====================>........] - ETA: 38s  [ loss=0.7945 ][Training] 44/57 [======================>.......] - ETA: 35s  [ loss=0.5879 ][Training] 45/57 [======================>.......] - ETA: 32s  [ loss=0.3455 ][Training] 46/57 [=======================>......] - ETA: 30s  [ loss=0.7663 ][Training] 47/57 [=======================>......] - ETA: 27s  [ loss=0.7869 ][Training] 48/57 [========================>.....] - ETA: 24s  [ loss=1.1477 ][Training] 49/57 [========================>.....] - ETA: 22s  [ loss=0.6559 ][Training] 50/57 [=========================>....] - ETA: 19s  [ loss=0.6726 ][Training] 51/57 [=========================>....] - ETA: 16s  [ loss=0.8132 ][Training] 52/57 [==========================>...] - ETA: 13s  [ loss=1.0663 ][Training] 53/57 [==========================>...] - ETA: 11s  [ loss=1.7244 ][Training] 54/57 [===========================>..] - ETA: 8s  [ loss=2.0421 ][Training] 55/57 [===========================>..] - ETA: 5s  [ loss=0.3407 ][Training] 56/57 [============================>.] - ETA: 2s  [ loss=0.3702 ][Training] 57/57 [==============================] 2.8s/step  [ loss=0.9398 ]
01/08/2024 12:43:16 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/08/2024 12:43:17 - INFO - root -   ***** Running evaluation on test dataset  *****
01/08/2024 12:43:17 - INFO - root -     Num examples = 269
01/08/2024 12:43:17 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 13s[Evaluating] 2/12 [====>.........................] - ETA: 10s[Evaluating] 3/12 [======>.......................] - ETA: 10s[Evaluating] 4/12 [=========>....................] - ETA: 9s[Evaluating] 5/12 [===========>..................] - ETA: 7s[Evaluating] 6/12 [==============>...............] - ETA: 6s[Evaluating] 7/12 [================>.............] - ETA: 5s[Evaluating] 8/12 [===================>..........] - ETA: 4s[Evaluating] 9/12 [=====================>........] - ETA: 3s[Evaluating] 10/12 [========================>.....] - ETA: 2s[Evaluating] 11/12 [==========================>...] - ETA: 1s[Evaluating] 12/12 [==============================] 1.1s/step
01/08/2024 12:43:30 - INFO - root -   

01/08/2024 12:43:30 - INFO - root -   ***** Eval results  *****
01/08/2024 12:43:30 - INFO - root -    acc: 0.7288 - recall: 0.6441 - f1: 0.6838 - loss: 5.0308 
01/08/2024 12:43:30 - INFO - root -   ***** Entity results  *****
01/08/2024 12:43:30 - INFO - root -   ******* GPE.NAM results ********
01/08/2024 12:43:30 - INFO - root -    acc: 0.7586 - recall: 0.9362 - f1: 0.8381 
01/08/2024 12:43:30 - INFO - root -   ******* GPE.NOM results ********
01/08/2024 12:43:30 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 12:43:30 - INFO - root -   ******* LOC.NAM results ********
01/08/2024 12:43:30 - INFO - root -    acc: 0.5556 - recall: 0.2632 - f1: 0.3571 
01/08/2024 12:43:30 - INFO - root -   ******* LOC.NOM results ********
01/08/2024 12:43:30 - INFO - root -    acc: 0.6667 - recall: 0.2222 - f1: 0.3333 
01/08/2024 12:43:30 - INFO - root -   ******* ORG.NAM results ********
01/08/2024 12:43:30 - INFO - root -    acc: 0.5926 - recall: 0.4103 - f1: 0.4848 
01/08/2024 12:43:30 - INFO - root -   ******* ORG.NOM results ********
01/08/2024 12:43:30 - INFO - root -    acc: 0.7273 - recall: 0.4706 - f1: 0.5714 
01/08/2024 12:43:30 - INFO - root -   ******* PER.NAM results ********
01/08/2024 12:43:30 - INFO - root -    acc: 0.7767 - recall: 0.7273 - f1: 0.7512 
01/08/2024 12:43:30 - INFO - root -   ******* PER.NOM results ********
01/08/2024 12:43:30 - INFO - root -    acc: 0.7208 - recall: 0.6529 - f1: 0.6852 
01/08/2024 12:43:47 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1995
01/08/2024 12:43:47 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-1995
01/08/2024 12:43:47 - INFO - root -   

01/08/2024 12:43:47 - INFO - root -   Backbone bert_estor_crf param is not freeze

Epoch: 35/50
[Training] 1/57 [..............................] - ETA: 2:32  [ loss=0.8059 ][Training] 2/57 [>.............................] - ETA: 2:25  [ loss=0.9563 ][Training] 3/57 [>.............................] - ETA: 2:14  [ loss=0.3556 ][Training] 4/57 [=>............................] - ETA: 2:15  [ loss=0.5460 ][Training] 5/57 [=>............................] - ETA: 2:14  [ loss=0.2832 ][Training] 6/57 [==>...........................] - ETA: 2:10  [ loss=0.3139 ][Training] 7/57 [==>...........................] - ETA: 2:07  [ loss=0.2397 ][Training] 8/57 [===>..........................] - ETA: 2:07  [ loss=0.6722 ][Training] 9/57 [===>..........................] - ETA: 2:05  [ loss=0.4314 ][Training] 10/57 [====>.........................] - ETA: 2:02  [ loss=0.5107 ][Training] 11/57 [====>.........................] - ETA: 2:00  [ loss=0.2340 ][Training] 12/57 [=====>........................] - ETA: 1:56  [ loss=0.5380 ][Training] 13/57 [=====>........................] - ETA: 1:56  [ loss=0.4898 ][Training] 14/57 [======>.......................] - ETA: 1:53  [ loss=0.7347 ][Training] 15/57 [======>.......................] - ETA: 1:52  [ loss=0.3920 ][Training] 16/57 [=======>......................] - ETA: 1:48  [ loss=0.1253 ][Training] 17/57 [=======>......................] - ETA: 1:45  [ loss=0.4890 ][Training] 18/57 [========>.....................] - ETA: 1:41  [ loss=0.4972 ][Training] 19/57 [=========>....................] - ETA: 1:36  [ loss=0.3164 ][Training] 20/57 [=========>....................] - ETA: 1:33  [ loss=0.3093 ][Training] 21/57 [==========>...................] - ETA: 1:29  [ loss=0.3756 ][Training] 22/57 [==========>...................] - ETA: 1:25  [ loss=0.3767 ][Training] 23/57 [===========>..................] - ETA: 1:22  [ loss=0.2742 ][Training] 24/57 [===========>..................] - ETA: 1:18  [ loss=0.8676 ][Training] 25/57 [============>.................] - ETA: 1:15  [ loss=0.1892 ][Training] 26/57 [============>.................] - ETA: 1:11  [ loss=0.1381 ][Training] 27/57 [=============>................] - ETA: 1:08  [ loss=0.1620 ][Training] 28/57 [=============>................] - ETA: 1:06  [ loss=0.6011 ][Training] 29/57 [==============>...............] - ETA: 1:03  [ loss=0.8897 ][Training] 30/57 [==============>...............] - ETA: 1:01  [ loss=0.9179 ][Training] 31/57 [===============>..............] - ETA: 58s  [ loss=0.1164 ][Training] 32/57 [===============>..............] - ETA: 55s  [ loss=0.6665 ][Training] 33/57 [================>.............] - ETA: 53s  [ loss=0.1854 ][Training] 34/57 [================>.............] - ETA: 50s  [ loss=2.2651 ][Training] 35/57 [=================>............] - ETA: 48s  [ loss=0.5904 ][Training] 36/57 [=================>............] - ETA: 45s  [ loss=0.3176 ][Training] 37/57 [==================>...........] - ETA: 43s  [ loss=0.5213 ][Training] 38/57 [===================>..........] - ETA: 41s  [ loss=0.4812 ][Training] 39/57 [===================>..........] - ETA: 39s  [ loss=1.0857 ][Training] 40/57 [====================>.........] - ETA: 37s  [ loss=0.5588 ][Training] 41/57 [====================>.........] - ETA: 35s  [ loss=0.5117 ][Training] 42/57 [=====================>........] - ETA: 32s  [ loss=0.2905 ][Training] 43/57 [=====================>........] - ETA: 30s  [ loss=1.2144 ][Training] 44/57 [======================>.......] - ETA: 28s  [ loss=1.2567 ][Training] 45/57 [======================>.......] - ETA: 26s  [ loss=1.3714 ][Training] 46/57 [=======================>......] - ETA: 24s  [ loss=0.0917 ][Training] 47/57 [=======================>......] - ETA: 22s  [ loss=0.4444 ][Training] 48/57 [========================>.....] - ETA: 19s  [ loss=0.1547 ][Training] 49/57 [========================>.....] - ETA: 17s  [ loss=1.0416 ][Training] 50/57 [=========================>....] - ETA: 15s  [ loss=0.8542 ][Training] 51/57 [=========================>....] - ETA: 13s  [ loss=0.1009 ][Training] 52/57 [==========================>...] - ETA: 11s  [ loss=0.3172 ][Training] 53/57 [==========================>...] - ETA: 8s  [ loss=0.1872 ][Training] 54/57 [===========================>..] - ETA: 6s  [ loss=0.2683 ][Training] 55/57 [===========================>..] - ETA: 4s  [ loss=0.6746 ][Training] 56/57 [============================>.] - ETA: 2s  [ loss=1.0349 ][Training] 57/57 [==============================] 2.2s/step  [ loss=0.6247 ]
01/08/2024 12:45:53 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/08/2024 12:45:53 - INFO - root -   ***** Running evaluation on test dataset  *****
01/08/2024 12:45:53 - INFO - root -     Num examples = 269
01/08/2024 12:45:53 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 9s[Evaluating] 2/12 [====>.........................] - ETA: 8s[Evaluating] 3/12 [======>.......................] - ETA: 7s[Evaluating] 4/12 [=========>....................] - ETA: 6s[Evaluating] 5/12 [===========>..................] - ETA: 5s[Evaluating] 6/12 [==============>...............] - ETA: 4s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 2s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 620.3ms/step
01/08/2024 12:46:01 - INFO - root -   

01/08/2024 12:46:01 - INFO - root -   ***** Eval results  *****
01/08/2024 12:46:01 - INFO - root -    acc: 0.7275 - recall: 0.6659 - f1: 0.6953 - loss: 5.1291 
01/08/2024 12:46:01 - INFO - root -   ***** Entity results  *****
01/08/2024 12:46:01 - INFO - root -   ******* GPE.NAM results ********
01/08/2024 12:46:01 - INFO - root -    acc: 0.8163 - recall: 0.8511 - f1: 0.8333 
01/08/2024 12:46:01 - INFO - root -   ******* GPE.NOM results ********
01/08/2024 12:46:01 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 12:46:01 - INFO - root -   ******* LOC.NAM results ********
01/08/2024 12:46:01 - INFO - root -    acc: 0.5625 - recall: 0.4737 - f1: 0.5143 
01/08/2024 12:46:01 - INFO - root -   ******* LOC.NOM results ********
01/08/2024 12:46:01 - INFO - root -    acc: 0.6667 - recall: 0.2222 - f1: 0.3333 
01/08/2024 12:46:01 - INFO - root -   ******* ORG.NAM results ********
01/08/2024 12:46:01 - INFO - root -    acc: 0.5405 - recall: 0.5128 - f1: 0.5263 
01/08/2024 12:46:01 - INFO - root -   ******* ORG.NOM results ********
01/08/2024 12:46:01 - INFO - root -    acc: 0.6667 - recall: 0.4706 - f1: 0.5517 
01/08/2024 12:46:01 - INFO - root -   ******* PER.NAM results ********
01/08/2024 12:46:01 - INFO - root -    acc: 0.7500 - recall: 0.7091 - f1: 0.7290 
01/08/2024 12:46:01 - INFO - root -   ******* PER.NOM results ********
01/08/2024 12:46:01 - INFO - root -    acc: 0.7516 - recall: 0.6941 - f1: 0.7217 
01/08/2024 12:46:48 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2052
01/08/2024 12:46:48 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2052
01/08/2024 12:46:48 - INFO - root -   

01/08/2024 12:46:48 - INFO - root -   Backbone bert_estor_crf param is not freeze

Epoch: 36/50
[Training] 1/57 [..............................] - ETA: 1:43  [ loss=0.1447 ][Training] 2/57 [>.............................] - ETA: 2:08  [ loss=1.1296 ][Training] 3/57 [>.............................] - ETA: 2:08  [ loss=0.0541 ][Training] 4/57 [=>............................] - ETA: 2:11  [ loss=0.5495 ][Training] 5/57 [=>............................] - ETA: 2:03  [ loss=0.2115 ][Training] 6/57 [==>...........................] - ETA: 2:01  [ loss=0.1061 ][Training] 7/57 [==>...........................] - ETA: 1:57  [ loss=0.2199 ][Training] 8/57 [===>..........................] - ETA: 1:53  [ loss=0.2723 ][Training] 9/57 [===>..........................] - ETA: 1:52  [ loss=0.3313 ][Training] 10/57 [====>.........................] - ETA: 1:47  [ loss=0.0563 ][Training] 11/57 [====>.........................] - ETA: 1:45  [ loss=0.2379 ][Training] 12/57 [=====>........................] - ETA: 1:43  [ loss=0.0966 ][Training] 13/57 [=====>........................] - ETA: 1:42  [ loss=0.1396 ][Training] 14/57 [======>.......................] - ETA: 1:41  [ loss=0.3168 ][Training] 15/57 [======>.......................] - ETA: 1:39  [ loss=0.1746 ][Training] 16/57 [=======>......................] - ETA: 1:36  [ loss=0.1700 ][Training] 17/57 [=======>......................] - ETA: 1:34  [ loss=0.4072 ][Training] 18/57 [========>.....................] - ETA: 1:32  [ loss=0.3110 ][Training] 19/57 [=========>....................] - ETA: 1:29  [ loss=1.3176 ][Training] 20/57 [=========>....................] - ETA: 1:27  [ loss=1.0385 ][Training] 21/57 [==========>...................] - ETA: 1:24  [ loss=0.3792 ][Training] 22/57 [==========>...................] - ETA: 1:22  [ loss=0.4177 ][Training] 23/57 [===========>..................] - ETA: 1:20  [ loss=0.2008 ][Training] 24/57 [===========>..................] - ETA: 1:17  [ loss=0.1281 ][Training] 25/57 [============>.................] - ETA: 1:15  [ loss=0.1685 ][Training] 26/57 [============>.................] - ETA: 1:12  [ loss=0.3660 ][Training] 27/57 [=============>................] - ETA: 1:10  [ loss=0.9313 ][Training] 28/57 [=============>................] - ETA: 1:08  [ loss=0.4493 ][Training] 29/57 [==============>...............] - ETA: 1:06  [ loss=0.4910 ][Training] 30/57 [==============>...............] - ETA: 1:03  [ loss=0.3904 ][Training] 31/57 [===============>..............] - ETA: 1:00  [ loss=0.2479 ][Training] 32/57 [===============>..............] - ETA: 58s  [ loss=0.2382 ][Training] 33/57 [================>.............] - ETA: 55s  [ loss=0.3428 ][Training] 34/57 [================>.............] - ETA: 53s  [ loss=1.1037 ][Training] 35/57 [=================>............] - ETA: 51s  [ loss=0.8730 ][Training] 36/57 [=================>............] - ETA: 48s  [ loss=0.7018 ][Training] 37/57 [==================>...........] - ETA: 46s  [ loss=0.3131 ][Training] 38/57 [===================>..........] - ETA: 44s  [ loss=0.1761 ][Training] 39/57 [===================>..........] - ETA: 42s  [ loss=0.0483 ][Training] 40/57 [====================>.........] - ETA: 39s  [ loss=0.3497 ][Training] 41/57 [====================>.........] - ETA: 37s  [ loss=0.3597 ][Training] 42/57 [=====================>........] - ETA: 35s  [ loss=0.1361 ][Training] 43/57 [=====================>........] - ETA: 32s  [ loss=1.1834 ][Training] 44/57 [======================>.......] - ETA: 30s  [ loss=0.1344 ][Training] 45/57 [======================>.......] - ETA: 28s  [ loss=0.5676 ][Training] 46/57 [=======================>......] - ETA: 25s  [ loss=1.1248 ][Training] 47/57 [=======================>......] - ETA: 23s  [ loss=1.0398 ][Training] 48/57 [========================>.....] - ETA: 20s  [ loss=0.6329 ][Training] 49/57 [========================>.....] - ETA: 18s  [ loss=0.5836 ][Training] 50/57 [=========================>....] - ETA: 16s  [ loss=0.5583 ][Training] 51/57 [=========================>....] - ETA: 13s  [ loss=1.4568 ][Training] 52/57 [==========================>...] - ETA: 11s  [ loss=0.0991 ][Training] 53/57 [==========================>...] - ETA: 9s  [ loss=0.0737 ][Training] 54/57 [===========================>..] - ETA: 6s  [ loss=0.3527 ][Training] 55/57 [===========================>..] - ETA: 4s  [ loss=0.1035 ][Training] 56/57 [============================>.] - ETA: 2s  [ loss=0.5101 ][Training] 57/57 [==============================] 2.3s/step  [ loss=0.1039 ]
01/08/2024 12:48:59 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/08/2024 12:48:59 - INFO - root -   ***** Running evaluation on test dataset  *****
01/08/2024 12:48:59 - INFO - root -     Num examples = 269
01/08/2024 12:48:59 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 13s[Evaluating] 2/12 [====>.........................] - ETA: 8s[Evaluating] 3/12 [======>.......................] - ETA: 8s[Evaluating] 4/12 [=========>....................] - ETA: 7s[Evaluating] 5/12 [===========>..................] - ETA: 5s[Evaluating] 6/12 [==============>...............] - ETA: 5s[Evaluating] 7/12 [================>.............] - ETA: 4s[Evaluating] 8/12 [===================>..........] - ETA: 3s[Evaluating] 9/12 [=====================>........] - ETA: 2s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 786.0ms/step
01/08/2024 12:49:08 - INFO - root -   

01/08/2024 12:49:08 - INFO - root -   ***** Eval results  *****
01/08/2024 12:49:08 - INFO - root -    acc: 0.7062 - recall: 0.6634 - f1: 0.6841 - loss: 5.6304 
01/08/2024 12:49:08 - INFO - root -   ***** Entity results  *****
01/08/2024 12:49:08 - INFO - root -   ******* GPE.NAM results ********
01/08/2024 12:49:08 - INFO - root -    acc: 0.7692 - recall: 0.8511 - f1: 0.8081 
01/08/2024 12:49:08 - INFO - root -   ******* GPE.NOM results ********
01/08/2024 12:49:08 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 12:49:08 - INFO - root -   ******* LOC.NAM results ********
01/08/2024 12:49:08 - INFO - root -    acc: 0.5263 - recall: 0.5263 - f1: 0.5263 
01/08/2024 12:49:08 - INFO - root -   ******* LOC.NOM results ********
01/08/2024 12:49:08 - INFO - root -    acc: 0.7500 - recall: 0.3333 - f1: 0.4615 
01/08/2024 12:49:08 - INFO - root -   ******* ORG.NAM results ********
01/08/2024 12:49:08 - INFO - root -    acc: 0.6250 - recall: 0.5128 - f1: 0.5634 
01/08/2024 12:49:08 - INFO - root -   ******* ORG.NOM results ********
01/08/2024 12:49:08 - INFO - root -    acc: 0.7500 - recall: 0.5294 - f1: 0.6207 
01/08/2024 12:49:08 - INFO - root -   ******* PER.NAM results ********
01/08/2024 12:49:08 - INFO - root -    acc: 0.6983 - recall: 0.7364 - f1: 0.7168 
01/08/2024 12:49:08 - INFO - root -   ******* PER.NOM results ********
01/08/2024 12:49:08 - INFO - root -    acc: 0.7255 - recall: 0.6529 - f1: 0.6873 
01/08/2024 12:49:33 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2109
01/08/2024 12:49:33 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2109
01/08/2024 12:49:33 - INFO - root -   

01/08/2024 12:49:33 - INFO - root -   Backbone bert_estor_crf param is not freeze

Epoch: 37/50
[Training] 1/57 [..............................] - ETA: 2:11  [ loss=0.2103 ][Training] 2/57 [>.............................] - ETA: 2:27  [ loss=0.8959 ][Training] 3/57 [>.............................] - ETA: 2:15  [ loss=0.1521 ][Training] 4/57 [=>............................] - ETA: 2:11  [ loss=0.1544 ][Training] 5/57 [=>............................] - ETA: 2:14  [ loss=0.0721 ][Training] 6/57 [==>...........................] - ETA: 2:10  [ loss=0.3282 ][Training] 7/57 [==>...........................] - ETA: 2:03  [ loss=0.2034 ][Training] 8/57 [===>..........................] - ETA: 1:58  [ loss=0.1013 ][Training] 9/57 [===>..........................] - ETA: 1:53  [ loss=0.6317 ][Training] 10/57 [====>.........................] - ETA: 1:51  [ loss=0.0706 ][Training] 11/57 [====>.........................] - ETA: 1:49  [ loss=1.0059 ][Training] 12/57 [=====>........................] - ETA: 1:46  [ loss=0.8126 ][Training] 13/57 [=====>........................] - ETA: 1:43  [ loss=0.0864 ][Training] 14/57 [======>.......................] - ETA: 1:40  [ loss=1.1444 ][Training] 15/57 [======>.......................] - ETA: 1:37  [ loss=0.1134 ][Training] 16/57 [=======>......................] - ETA: 1:34  [ loss=0.1808 ][Training] 17/57 [=======>......................] - ETA: 1:32  [ loss=0.3212 ][Training] 18/57 [========>.....................] - ETA: 1:30  [ loss=0.4348 ][Training] 19/57 [=========>....................] - ETA: 1:27  [ loss=1.4172 ][Training] 20/57 [=========>....................] - ETA: 1:25  [ loss=0.1096 ][Training] 21/57 [==========>...................] - ETA: 1:23  [ loss=0.3634 ][Training] 22/57 [==========>...................] - ETA: 1:20  [ loss=0.6364 ][Training] 23/57 [===========>..................] - ETA: 1:18  [ loss=0.0858 ][Training] 24/57 [===========>..................] - ETA: 1:15  [ loss=0.3112 ][Training] 25/57 [============>.................] - ETA: 1:13  [ loss=0.2044 ][Training] 26/57 [============>.................] - ETA: 1:11  [ loss=1.3676 ][Training] 27/57 [=============>................] - ETA: 1:08  [ loss=0.0584 ][Training] 28/57 [=============>................] - ETA: 1:07  [ loss=0.2231 ][Training] 29/57 [==============>...............] - ETA: 1:04  [ loss=0.0262 ][Training] 30/57 [==============>...............] - ETA: 1:02  [ loss=0.1031 ][Training] 31/57 [===============>..............] - ETA: 1:00  [ loss=0.2688 ][Training] 32/57 [===============>..............] - ETA: 57s  [ loss=0.0472 ][Training] 33/57 [================>.............] - ETA: 55s  [ loss=0.2931 ][Training] 34/57 [================>.............] - ETA: 52s  [ loss=0.0739 ][Training] 35/57 [=================>............] - ETA: 50s  [ loss=0.2309 ][Training] 36/57 [=================>............] - ETA: 48s  [ loss=0.0647 ][Training] 37/57 [==================>...........] - ETA: 46s  [ loss=0.0524 ][Training] 38/57 [===================>..........] - ETA: 43s  [ loss=0.1724 ][Training] 39/57 [===================>..........] - ETA: 41s  [ loss=0.9947 ][Training] 40/57 [====================>.........] - ETA: 39s  [ loss=0.8993 ][Training] 41/57 [====================>.........] - ETA: 36s  [ loss=0.3330 ][Training] 42/57 [=====================>........] - ETA: 34s  [ loss=0.3575 ][Training] 43/57 [=====================>........] - ETA: 31s  [ loss=0.0592 ][Training] 44/57 [======================>.......] - ETA: 29s  [ loss=0.2414 ][Training] 45/57 [======================>.......] - ETA: 27s  [ loss=0.7495 ][Training] 46/57 [=======================>......] - ETA: 24s  [ loss=0.8796 ][Training] 47/57 [=======================>......] - ETA: 22s  [ loss=0.0572 ][Training] 48/57 [========================>.....] - ETA: 20s  [ loss=0.4072 ][Training] 49/57 [========================>.....] - ETA: 18s  [ loss=0.1191 ][Training] 50/57 [=========================>....] - ETA: 15s  [ loss=0.3012 ][Training] 51/57 [=========================>....] - ETA: 13s  [ loss=0.5587 ][Training] 52/57 [==========================>...] - ETA: 11s  [ loss=0.5922 ][Training] 53/57 [==========================>...] - ETA: 9s  [ loss=0.8243 ][Training] 54/57 [===========================>..] - ETA: 6s  [ loss=1.6590 ][Training] 55/57 [===========================>..] - ETA: 4s  [ loss=1.1024 ][Training] 56/57 [============================>.] - ETA: 2s  [ loss=0.1497 ][Training] 57/57 [==============================] 2.3s/step  [ loss=0.1152 ]
01/08/2024 12:51:43 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/08/2024 12:51:43 - INFO - root -   ***** Running evaluation on test dataset  *****
01/08/2024 12:51:43 - INFO - root -     Num examples = 269
01/08/2024 12:51:43 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 6s[Evaluating] 2/12 [====>.........................] - ETA: 8s[Evaluating] 3/12 [======>.......................] - ETA: 7s[Evaluating] 4/12 [=========>....................] - ETA: 6s[Evaluating] 5/12 [===========>..................] - ETA: 5s[Evaluating] 6/12 [==============>...............] - ETA: 4s[Evaluating] 7/12 [================>.............] - ETA: 4s[Evaluating] 8/12 [===================>..........] - ETA: 3s[Evaluating] 9/12 [=====================>........] - ETA: 2s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 751.9ms/step
01/08/2024 12:51:52 - INFO - root -   

01/08/2024 12:51:52 - INFO - root -   ***** Eval results  *****
01/08/2024 12:51:52 - INFO - root -    acc: 0.7093 - recall: 0.6852 - f1: 0.6970 - loss: 5.9017 
01/08/2024 12:51:52 - INFO - root -   ***** Entity results  *****
01/08/2024 12:51:52 - INFO - root -   ******* GPE.NAM results ********
01/08/2024 12:51:52 - INFO - root -    acc: 0.7692 - recall: 0.8511 - f1: 0.8081 
01/08/2024 12:51:52 - INFO - root -   ******* GPE.NOM results ********
01/08/2024 12:51:52 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 12:51:52 - INFO - root -   ******* LOC.NAM results ********
01/08/2024 12:51:52 - INFO - root -    acc: 0.5000 - recall: 0.5263 - f1: 0.5128 
01/08/2024 12:51:52 - INFO - root -   ******* LOC.NOM results ********
01/08/2024 12:51:52 - INFO - root -    acc: 0.5000 - recall: 0.3333 - f1: 0.4000 
01/08/2024 12:51:52 - INFO - root -   ******* ORG.NAM results ********
01/08/2024 12:51:52 - INFO - root -    acc: 0.5484 - recall: 0.4359 - f1: 0.4857 
01/08/2024 12:51:52 - INFO - root -   ******* ORG.NOM results ********
01/08/2024 12:51:52 - INFO - root -    acc: 1.0000 - recall: 0.4706 - f1: 0.6400 
01/08/2024 12:51:52 - INFO - root -   ******* PER.NAM results ********
01/08/2024 12:51:52 - INFO - root -    acc: 0.7788 - recall: 0.7364 - f1: 0.7570 
01/08/2024 12:51:52 - INFO - root -   ******* PER.NOM results ********
01/08/2024 12:51:52 - INFO - root -    acc: 0.6966 - recall: 0.7294 - f1: 0.7126 
01/08/2024 12:51:57 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2166
01/08/2024 12:51:57 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2166
01/08/2024 12:51:57 - INFO - root -   

01/08/2024 12:51:57 - INFO - root -   Backbone bert_estor_crf param is not freeze

Epoch: 38/50
[Training] 1/57 [..............................] - ETA: 2:41  [ loss=1.2460 ][Training] 2/57 [>.............................] - ETA: 2:27  [ loss=0.1540 ][Training] 3/57 [>.............................] - ETA: 2:19  [ loss=0.1820 ][Training] 4/57 [=>............................] - ETA: 2:18  [ loss=0.3747 ][Training] 5/57 [=>............................] - ETA: 2:14  [ loss=0.0656 ][Training] 6/57 [==>...........................] - ETA: 2:05  [ loss=0.0355 ][Training] 7/57 [==>...........................] - ETA: 2:03  [ loss=0.4640 ][Training] 8/57 [===>..........................] - ETA: 2:03  [ loss=0.1633 ][Training] 9/57 [===>..........................] - ETA: 2:01  [ loss=0.0783 ][Training] 10/57 [====>.........................] - ETA: 1:54  [ loss=0.0359 ][Training] 11/57 [====>.........................] - ETA: 1:50  [ loss=0.0703 ][Training] 12/57 [=====>........................] - ETA: 1:46  [ loss=0.7043 ][Training] 13/57 [=====>........................] - ETA: 1:44  [ loss=0.2784 ][Training] 14/57 [======>.......................] - ETA: 1:42  [ loss=0.3778 ][Training] 15/57 [======>.......................] - ETA: 1:39  [ loss=0.2041 ][Training] 16/57 [=======>......................] - ETA: 1:37  [ loss=0.0404 ][Training] 17/57 [=======>......................] - ETA: 1:35  [ loss=0.5063 ][Training] 18/57 [========>.....................] - ETA: 1:33  [ loss=0.1859 ][Training] 19/57 [=========>....................] - ETA: 1:30  [ loss=0.0463 ][Training] 20/57 [=========>....................] - ETA: 1:27  [ loss=0.5389 ][Training] 21/57 [==========>...................] - ETA: 1:25  [ loss=0.5534 ][Training] 22/57 [==========>...................] - ETA: 1:23  [ loss=0.2045 ][Training] 23/57 [===========>..................] - ETA: 1:20  [ loss=1.3433 ][Training] 24/57 [===========>..................] - ETA: 1:18  [ loss=0.0540 ][Training] 25/57 [============>.................] - ETA: 1:15  [ loss=0.8931 ][Training] 26/57 [============>.................] - ETA: 1:12  [ loss=0.0192 ][Training] 27/57 [=============>................] - ETA: 1:10  [ loss=0.0753 ][Training] 28/57 [=============>................] - ETA: 1:08  [ loss=0.1020 ][Training] 29/57 [==============>...............] - ETA: 1:05  [ loss=0.3837 ][Training] 30/57 [==============>...............] - ETA: 1:03  [ loss=0.4319 ][Training] 31/57 [===============>..............] - ETA: 1:00  [ loss=0.3269 ][Training] 32/57 [===============>..............] - ETA: 58s  [ loss=0.0880 ][Training] 33/57 [================>.............] - ETA: 55s  [ loss=0.5846 ][Training] 34/57 [================>.............] - ETA: 53s  [ loss=0.8840 ][Training] 35/57 [=================>............] - ETA: 50s  [ loss=0.5866 ][Training] 36/57 [=================>............] - ETA: 48s  [ loss=0.0788 ][Training] 37/57 [==================>...........] - ETA: 46s  [ loss=0.7477 ][Training] 38/57 [===================>..........] - ETA: 43s  [ loss=0.2906 ][Training] 39/57 [===================>..........] - ETA: 41s  [ loss=0.3950 ][Training] 40/57 [====================>.........] - ETA: 38s  [ loss=0.2920 ][Training] 41/57 [====================>.........] - ETA: 35s  [ loss=0.0448 ][Training] 42/57 [=====================>........] - ETA: 33s  [ loss=0.6062 ][Training] 43/57 [=====================>........] - ETA: 30s  [ loss=0.2685 ][Training] 44/57 [======================>.......] - ETA: 28s  [ loss=0.2731 ][Training] 45/57 [======================>.......] - ETA: 26s  [ loss=0.2168 ][Training] 46/57 [=======================>......] - ETA: 24s  [ loss=0.0530 ][Training] 47/57 [=======================>......] - ETA: 22s  [ loss=0.2480 ][Training] 48/57 [========================>.....] - ETA: 20s  [ loss=0.1680 ][Training] 49/57 [========================>.....] - ETA: 17s  [ loss=0.7666 ][Training] 50/57 [=========================>....] - ETA: 15s  [ loss=0.0435 ][Training] 51/57 [=========================>....] - ETA: 13s  [ loss=0.0583 ][Training] 52/57 [==========================>...] - ETA: 11s  [ loss=0.0683 ][Training] 53/57 [==========================>...] - ETA: 9s  [ loss=0.7588 ][Training] 54/57 [===========================>..] - ETA: 6s  [ loss=0.4326 ][Training] 55/57 [===========================>..] - ETA: 4s  [ loss=0.5358 ][Training] 56/57 [============================>.] - ETA: 2s  [ loss=0.0282 ][Training] 57/57 [==============================] 2.3s/step  [ loss=2.6625 ]
01/08/2024 12:54:08 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/08/2024 12:54:08 - INFO - root -   ***** Running evaluation on test dataset  *****
01/08/2024 12:54:08 - INFO - root -     Num examples = 269
01/08/2024 12:54:08 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 8s[Evaluating] 2/12 [====>.........................] - ETA: 7s[Evaluating] 3/12 [======>.......................] - ETA: 8s[Evaluating] 4/12 [=========>....................] - ETA: 7s[Evaluating] 5/12 [===========>..................] - ETA: 6s[Evaluating] 6/12 [==============>...............] - ETA: 5s[Evaluating] 7/12 [================>.............] - ETA: 4s[Evaluating] 8/12 [===================>..........] - ETA: 3s[Evaluating] 9/12 [=====================>........] - ETA: 2s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 888.2ms/step
01/08/2024 12:54:18 - INFO - root -   

01/08/2024 12:54:18 - INFO - root -   ***** Eval results  *****
01/08/2024 12:54:18 - INFO - root -    acc: 0.7093 - recall: 0.6852 - f1: 0.6970 - loss: 6.6539 
01/08/2024 12:54:18 - INFO - root -   ***** Entity results  *****
01/08/2024 12:54:18 - INFO - root -   ******* GPE.NAM results ********
01/08/2024 12:54:18 - INFO - root -    acc: 0.7736 - recall: 0.8723 - f1: 0.8200 
01/08/2024 12:54:18 - INFO - root -   ******* GPE.NOM results ********
01/08/2024 12:54:18 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 12:54:18 - INFO - root -   ******* LOC.NAM results ********
01/08/2024 12:54:18 - INFO - root -    acc: 0.5833 - recall: 0.3684 - f1: 0.4516 
01/08/2024 12:54:18 - INFO - root -   ******* LOC.NOM results ********
01/08/2024 12:54:18 - INFO - root -    acc: 0.5000 - recall: 0.3333 - f1: 0.4000 
01/08/2024 12:54:18 - INFO - root -   ******* ORG.NAM results ********
01/08/2024 12:54:18 - INFO - root -    acc: 0.5405 - recall: 0.5128 - f1: 0.5263 
01/08/2024 12:54:18 - INFO - root -   ******* ORG.NOM results ********
01/08/2024 12:54:18 - INFO - root -    acc: 0.6923 - recall: 0.5294 - f1: 0.6000 
01/08/2024 12:54:18 - INFO - root -   ******* PER.NAM results ********
01/08/2024 12:54:18 - INFO - root -    acc: 0.7788 - recall: 0.7364 - f1: 0.7570 
01/08/2024 12:54:18 - INFO - root -   ******* PER.NOM results ********
01/08/2024 12:54:18 - INFO - root -    acc: 0.7011 - recall: 0.7176 - f1: 0.7093 
01/08/2024 12:54:53 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2223
01/08/2024 12:54:54 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2223
01/08/2024 12:54:54 - INFO - root -   

01/08/2024 12:54:54 - INFO - root -   Backbone bert_estor_crf param is not freeze

Epoch: 39/50
[Training] 1/57 [..............................] - ETA: 2:41  [ loss=0.0675 ][Training] 2/57 [>.............................] - ETA: 2:30  [ loss=0.0510 ][Training] 3/57 [>.............................] - ETA: 2:15  [ loss=0.0363 ][Training] 4/57 [=>............................] - ETA: 2:14  [ loss=0.0276 ][Training] 5/57 [=>............................] - ETA: 2:12  [ loss=0.0498 ][Training] 6/57 [==>...........................] - ETA: 2:08  [ loss=0.0309 ][Training] 7/57 [==>...........................] - ETA: 1:59  [ loss=0.0743 ][Training] 8/57 [===>..........................] - ETA: 1:54  [ loss=0.2658 ][Training] 9/57 [===>..........................] - ETA: 1:50  [ loss=0.1795 ][Training] 10/57 [====>.........................] - ETA: 1:44  [ loss=0.0530 ][Training] 11/57 [====>.........................] - ETA: 1:40  [ loss=0.0635 ][Training] 12/57 [=====>........................] - ETA: 1:37  [ loss=0.0433 ][Training] 13/57 [=====>........................] - ETA: 1:33  [ loss=0.4756 ][Training] 14/57 [======>.......................] - ETA: 1:30  [ loss=0.1823 ][Training] 15/57 [======>.......................] - ETA: 1:28  [ loss=0.1451 ][Training] 16/57 [=======>......................] - ETA: 1:25  [ loss=0.0745 ][Training] 17/57 [=======>......................] - ETA: 1:23  [ loss=0.2030 ][Training] 18/57 [========>.....................] - ETA: 1:21  [ loss=0.0483 ][Training] 19/57 [=========>....................] - ETA: 1:19  [ loss=0.2048 ][Training] 20/57 [=========>....................] - ETA: 1:17  [ loss=0.1020 ][Training] 21/57 [==========>...................] - ETA: 1:14  [ loss=0.3381 ][Training] 22/57 [==========>...................] - ETA: 1:13  [ loss=0.7137 ][Training] 23/57 [===========>..................] - ETA: 1:11  [ loss=0.0457 ][Training] 24/57 [===========>..................] - ETA: 1:09  [ loss=0.2681 ][Training] 25/57 [============>.................] - ETA: 1:07  [ loss=0.1611 ][Training] 26/57 [============>.................] - ETA: 1:05  [ loss=0.7030 ][Training] 27/57 [=============>................] - ETA: 1:03  [ loss=0.6290 ][Training] 28/57 [=============>................] - ETA: 1:02  [ loss=0.0638 ][Training] 29/57 [==============>...............] - ETA: 1:00  [ loss=0.3820 ][Training] 30/57 [==============>...............] - ETA: 58s  [ loss=0.3201 ][Training] 31/57 [===============>..............] - ETA: 56s  [ loss=0.9907 ][Training] 32/57 [===============>..............] - ETA: 54s  [ loss=0.0746 ][Training] 33/57 [================>.............] - ETA: 52s  [ loss=0.7959 ][Training] 34/57 [================>.............] - ETA: 50s  [ loss=0.1881 ][Training] 35/57 [=================>............] - ETA: 48s  [ loss=0.1641 ][Training] 36/57 [=================>............] - ETA: 46s  [ loss=0.3771 ][Training] 37/57 [==================>...........] - ETA: 43s  [ loss=0.0510 ][Training] 38/57 [===================>..........] - ETA: 41s  [ loss=0.2380 ][Training] 39/57 [===================>..........] - ETA: 39s  [ loss=0.0540 ][Training] 40/57 [====================>.........] - ETA: 37s  [ loss=0.7424 ][Training] 41/57 [====================>.........] - ETA: 35s  [ loss=0.7608 ][Training] 42/57 [=====================>........] - ETA: 33s  [ loss=0.2565 ][Training] 43/57 [=====================>........] - ETA: 31s  [ loss=1.2435 ][Training] 44/57 [======================>.......] - ETA: 28s  [ loss=0.0381 ][Training] 45/57 [======================>.......] - ETA: 26s  [ loss=0.0618 ][Training] 46/57 [=======================>......] - ETA: 24s  [ loss=0.4395 ][Training] 47/57 [=======================>......] - ETA: 22s  [ loss=0.0305 ][Training] 48/57 [========================>.....] - ETA: 19s  [ loss=0.0378 ][Training] 49/57 [========================>.....] - ETA: 17s  [ loss=0.0724 ][Training] 50/57 [=========================>....] - ETA: 15s  [ loss=0.8245 ][Training] 51/57 [=========================>....] - ETA: 13s  [ loss=1.8921 ][Training] 52/57 [==========================>...] - ETA: 11s  [ loss=0.1219 ][Training] 53/57 [==========================>...] - ETA: 8s  [ loss=0.3874 ][Training] 54/57 [===========================>..] - ETA: 6s  [ loss=0.2866 ][Training] 55/57 [===========================>..] - ETA: 4s  [ loss=0.4652 ][Training] 56/57 [============================>.] - ETA: 2s  [ loss=0.9077 ][Training] 57/57 [==============================] 2.2s/step  [ loss=1.6202 ]
01/08/2024 12:57:00 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/08/2024 12:57:00 - INFO - root -   ***** Running evaluation on test dataset  *****
01/08/2024 12:57:00 - INFO - root -     Num examples = 269
01/08/2024 12:57:00 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 8s[Evaluating] 2/12 [====>.........................] - ETA: 9s[Evaluating] 3/12 [======>.......................] - ETA: 7s[Evaluating] 4/12 [=========>....................] - ETA: 6s[Evaluating] 5/12 [===========>..................] - ETA: 5s[Evaluating] 6/12 [==============>...............] - ETA: 4s[Evaluating] 7/12 [================>.............] - ETA: 4s[Evaluating] 8/12 [===================>..........] - ETA: 3s[Evaluating] 9/12 [=====================>........] - ETA: 2s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 778.0ms/step
01/08/2024 12:57:09 - INFO - root -   

01/08/2024 12:57:09 - INFO - root -   ***** Eval results  *****
01/08/2024 12:57:09 - INFO - root -    acc: 0.7030 - recall: 0.6877 - f1: 0.6952 - loss: 6.7944 
01/08/2024 12:57:09 - INFO - root -   ***** Entity results  *****
01/08/2024 12:57:09 - INFO - root -   ******* GPE.NAM results ********
01/08/2024 12:57:09 - INFO - root -    acc: 0.8200 - recall: 0.8723 - f1: 0.8454 
01/08/2024 12:57:09 - INFO - root -   ******* GPE.NOM results ********
01/08/2024 12:57:09 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 12:57:09 - INFO - root -   ******* LOC.NAM results ********
01/08/2024 12:57:09 - INFO - root -    acc: 0.5385 - recall: 0.3684 - f1: 0.4375 
01/08/2024 12:57:09 - INFO - root -   ******* LOC.NOM results ********
01/08/2024 12:57:09 - INFO - root -    acc: 0.5000 - recall: 0.2222 - f1: 0.3077 
01/08/2024 12:57:09 - INFO - root -   ******* ORG.NAM results ********
01/08/2024 12:57:09 - INFO - root -    acc: 0.5789 - recall: 0.5641 - f1: 0.5714 
01/08/2024 12:57:09 - INFO - root -   ******* ORG.NOM results ********
01/08/2024 12:57:09 - INFO - root -    acc: 0.8571 - recall: 0.3529 - f1: 0.5000 
01/08/2024 12:57:09 - INFO - root -   ******* PER.NAM results ********
01/08/2024 12:57:09 - INFO - root -    acc: 0.7297 - recall: 0.7364 - f1: 0.7330 
01/08/2024 12:57:09 - INFO - root -   ******* PER.NOM results ********
01/08/2024 12:57:09 - INFO - root -    acc: 0.6906 - recall: 0.7353 - f1: 0.7123 
01/08/2024 12:57:22 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2280
01/08/2024 12:57:22 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2280
01/08/2024 12:57:22 - INFO - root -   

01/08/2024 12:57:22 - INFO - root -   Backbone bert_estor_crf param is not freeze

Epoch: 40/50
[Training] 1/57 [..............................] - ETA: 2:00  [ loss=0.1646 ][Training] 2/57 [>.............................] - ETA: 1:59  [ loss=0.4550 ][Training] 3/57 [>.............................] - ETA: 2:06  [ loss=0.1330 ][Training] 4/57 [=>............................] - ETA: 2:02  [ loss=0.0370 ][Training] 5/57 [=>............................] - ETA: 1:56  [ loss=0.6022 ][Training] 6/57 [==>...........................] - ETA: 1:55  [ loss=0.4950 ][Training] 7/57 [==>...........................] - ETA: 1:51  [ loss=0.0264 ][Training] 8/57 [===>..........................] - ETA: 1:52  [ loss=0.2242 ][Training] 9/57 [===>..........................] - ETA: 1:49  [ loss=0.0572 ][Training] 10/57 [====>.........................] - ETA: 1:47  [ loss=0.0296 ][Training] 11/57 [====>.........................] - ETA: 1:44  [ loss=0.3059 ][Training] 12/57 [=====>........................] - ETA: 1:44  [ loss=0.1296 ][Training] 13/57 [=====>........................] - ETA: 1:41  [ loss=0.0460 ][Training] 14/57 [======>.......................] - ETA: 1:38  [ loss=0.1273 ][Training] 15/57 [======>.......................] - ETA: 1:35  [ loss=0.3771 ][Training] 16/57 [=======>......................] - ETA: 1:33  [ loss=0.0693 ][Training] 17/57 [=======>......................] - ETA: 1:31  [ loss=0.6781 ][Training] 18/57 [========>.....................] - ETA: 1:28  [ loss=0.5443 ][Training] 19/57 [=========>....................] - ETA: 1:27  [ loss=0.1485 ][Training] 20/57 [=========>....................] - ETA: 1:24  [ loss=0.0355 ][Training] 21/57 [==========>...................] - ETA: 1:23  [ loss=0.2291 ][Training] 22/57 [==========>...................] - ETA: 1:21  [ loss=0.1989 ][Training] 23/57 [===========>..................] - ETA: 1:17  [ loss=0.2146 ][Training] 24/57 [===========>..................] - ETA: 1:15  [ loss=0.0643 ][Training] 25/57 [============>.................] - ETA: 1:13  [ loss=0.0282 ][Training] 26/57 [============>.................] - ETA: 1:10  [ loss=0.8603 ][Training] 27/57 [=============>................] - ETA: 1:08  [ loss=0.4392 ][Training] 28/57 [=============>................] - ETA: 1:05  [ loss=0.0699 ][Training] 29/57 [==============>...............] - ETA: 1:02  [ loss=0.0201 ][Training] 30/57 [==============>...............] - ETA: 1:00  [ loss=0.0221 ][Training] 31/57 [===============>..............] - ETA: 58s  [ loss=0.2682 ][Training] 32/57 [===============>..............] - ETA: 56s  [ loss=0.0807 ][Training] 33/57 [================>.............] - ETA: 53s  [ loss=0.3315 ][Training] 34/57 [================>.............] - ETA: 51s  [ loss=0.1217 ][Training] 35/57 [=================>............] - ETA: 49s  [ loss=0.2775 ][Training] 36/57 [=================>............] - ETA: 46s  [ loss=0.8275 ][Training] 37/57 [==================>...........] - ETA: 44s  [ loss=0.3300 ][Training] 38/57 [===================>..........] - ETA: 42s  [ loss=0.6625 ][Training] 39/57 [===================>..........] - ETA: 40s  [ loss=0.1930 ][Training] 40/57 [====================>.........] - ETA: 37s  [ loss=0.0197 ][Training] 41/57 [====================>.........] - ETA: 35s  [ loss=0.4262 ][Training] 42/57 [=====================>........] - ETA: 33s  [ loss=0.0225 ][Training] 43/57 [=====================>........] - ETA: 31s  [ loss=0.6106 ][Training] 44/57 [======================>.......] - ETA: 28s  [ loss=0.0238 ][Training] 45/57 [======================>.......] - ETA: 26s  [ loss=0.3288 ][Training] 46/57 [=======================>......] - ETA: 24s  [ loss=1.1108 ][Training] 47/57 [=======================>......] - ETA: 22s  [ loss=0.3547 ][Training] 48/57 [========================>.....] - ETA: 20s  [ loss=0.6377 ][Training] 49/57 [========================>.....] - ETA: 18s  [ loss=0.0878 ][Training] 50/57 [=========================>....] - ETA: 15s  [ loss=0.9135 ][Training] 51/57 [=========================>....] - ETA: 13s  [ loss=0.2775 ][Training] 52/57 [==========================>...] - ETA: 11s  [ loss=0.4127 ][Training] 53/57 [==========================>...] - ETA: 9s  [ loss=0.3690 ][Training] 54/57 [===========================>..] - ETA: 6s  [ loss=0.0278 ][Training] 55/57 [===========================>..] - ETA: 4s  [ loss=0.0198 ][Training] 56/57 [============================>.] - ETA: 2s  [ loss=0.0476 ][Training] 57/57 [==============================] 2.2s/step  [ loss=0.0621 ]
01/08/2024 12:59:31 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/08/2024 12:59:31 - INFO - root -   ***** Running evaluation on test dataset  *****
01/08/2024 12:59:31 - INFO - root -     Num examples = 269
01/08/2024 12:59:31 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 8s[Evaluating] 2/12 [====>.........................] - ETA: 7s[Evaluating] 3/12 [======>.......................] - ETA: 6s[Evaluating] 4/12 [=========>....................] - ETA: 6s[Evaluating] 5/12 [===========>..................] - ETA: 5s[Evaluating] 6/12 [==============>...............] - ETA: 4s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 3s[Evaluating] 9/12 [=====================>........] - ETA: 2s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 733.6ms/step
01/08/2024 12:59:40 - INFO - root -   

01/08/2024 12:59:40 - INFO - root -   ***** Eval results  *****
01/08/2024 12:59:40 - INFO - root -    acc: 0.7065 - recall: 0.6877 - f1: 0.6969 - loss: 7.4089 
01/08/2024 12:59:40 - INFO - root -   ***** Entity results  *****
01/08/2024 12:59:40 - INFO - root -   ******* GPE.NAM results ********
01/08/2024 12:59:40 - INFO - root -    acc: 0.7778 - recall: 0.8936 - f1: 0.8317 
01/08/2024 12:59:40 - INFO - root -   ******* GPE.NOM results ********
01/08/2024 12:59:40 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 12:59:40 - INFO - root -   ******* LOC.NAM results ********
01/08/2024 12:59:40 - INFO - root -    acc: 0.5333 - recall: 0.4211 - f1: 0.4706 
01/08/2024 12:59:40 - INFO - root -   ******* LOC.NOM results ********
01/08/2024 12:59:40 - INFO - root -    acc: 0.6667 - recall: 0.2222 - f1: 0.3333 
01/08/2024 12:59:40 - INFO - root -   ******* ORG.NAM results ********
01/08/2024 12:59:40 - INFO - root -    acc: 0.5556 - recall: 0.5128 - f1: 0.5333 
01/08/2024 12:59:40 - INFO - root -   ******* ORG.NOM results ********
01/08/2024 12:59:40 - INFO - root -    acc: 0.8571 - recall: 0.3529 - f1: 0.5000 
01/08/2024 12:59:40 - INFO - root -   ******* PER.NAM results ********
01/08/2024 12:59:40 - INFO - root -    acc: 0.7788 - recall: 0.7364 - f1: 0.7570 
01/08/2024 12:59:40 - INFO - root -   ******* PER.NOM results ********
01/08/2024 12:59:40 - INFO - root -    acc: 0.6831 - recall: 0.7353 - f1: 0.7082 
01/08/2024 12:59:50 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2337
01/08/2024 12:59:50 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2337
01/08/2024 12:59:50 - INFO - root -   

01/08/2024 12:59:50 - INFO - root -   Backbone bert_estor_crf param is not freeze

Epoch: 41/50
[Training] 1/57 [..............................] - ETA: 2:21  [ loss=0.0949 ][Training] 2/57 [>.............................] - ETA: 2:18  [ loss=0.0208 ][Training] 3/57 [>.............................] - ETA: 2:18  [ loss=0.1255 ][Training] 4/57 [=>............................] - ETA: 2:13  [ loss=1.0032 ][Training] 5/57 [=>............................] - ETA: 2:09  [ loss=0.0588 ][Training] 6/57 [==>...........................] - ETA: 2:02  [ loss=0.1477 ][Training] 7/57 [==>...........................] - ETA: 2:00  [ loss=0.0290 ][Training] 8/57 [===>..........................] - ETA: 1:54  [ loss=0.3908 ][Training] 9/57 [===>..........................] - ETA: 1:52  [ loss=0.5143 ][Training] 10/57 [====>.........................] - ETA: 1:48  [ loss=0.0261 ][Training] 11/57 [====>.........................] - ETA: 1:46  [ loss=0.8715 ][Training] 12/57 [=====>........................] - ETA: 1:43  [ loss=0.1426 ][Training] 13/57 [=====>........................] - ETA: 1:38  [ loss=0.6254 ][Training] 14/57 [======>.......................] - ETA: 1:34  [ loss=0.0217 ][Training] 15/57 [======>.......................] - ETA: 1:31  [ loss=0.1064 ][Training] 16/57 [=======>......................] - ETA: 1:27  [ loss=0.3447 ][Training] 17/57 [=======>......................] - ETA: 1:25  [ loss=0.1220 ][Training] 18/57 [========>.....................] - ETA: 1:22  [ loss=0.0315 ][Training] 19/57 [=========>....................] - ETA: 1:20  [ loss=0.4317 ][Training] 20/57 [=========>....................] - ETA: 1:17  [ loss=0.5569 ][Training] 21/57 [==========>...................] - ETA: 1:14  [ loss=0.2303 ][Training] 22/57 [==========>...................] - ETA: 1:12  [ loss=0.6547 ][Training] 23/57 [===========>..................] - ETA: 1:09  [ loss=0.0439 ][Training] 24/57 [===========>..................] - ETA: 1:07  [ loss=0.3728 ][Training] 25/57 [============>.................] - ETA: 1:04  [ loss=0.0697 ][Training] 26/57 [============>.................] - ETA: 1:02  [ loss=0.1358 ][Training] 27/57 [=============>................] - ETA: 59s  [ loss=0.5457 ][Training] 28/57 [=============>................] - ETA: 57s  [ loss=0.0744 ][Training] 29/57 [==============>...............] - ETA: 55s  [ loss=0.2857 ][Training] 30/57 [==============>...............] - ETA: 52s  [ loss=0.5018 ][Training] 31/57 [===============>..............] - ETA: 50s  [ loss=0.3284 ][Training] 32/57 [===============>..............] - ETA: 48s  [ loss=0.2185 ][Training] 33/57 [================>.............] - ETA: 46s  [ loss=0.0985 ][Training] 34/57 [================>.............] - ETA: 44s  [ loss=0.2584 ][Training] 35/57 [=================>............] - ETA: 43s  [ loss=0.0238 ][Training] 36/57 [=================>............] - ETA: 41s  [ loss=0.0274 ][Training] 37/57 [==================>...........] - ETA: 39s  [ loss=0.2228 ][Training] 38/57 [===================>..........] - ETA: 37s  [ loss=0.0866 ][Training] 39/57 [===================>..........] - ETA: 35s  [ loss=0.1310 ][Training] 40/57 [====================>.........] - ETA: 34s  [ loss=0.0404 ][Training] 41/57 [====================>.........] - ETA: 32s  [ loss=0.4078 ][Training] 42/57 [=====================>........] - ETA: 30s  [ loss=0.0249 ][Training] 43/57 [=====================>........] - ETA: 28s  [ loss=0.4016 ][Training] 44/57 [======================>.......] - ETA: 26s  [ loss=0.2203 ][Training] 45/57 [======================>.......] - ETA: 24s  [ loss=0.2898 ][Training] 46/57 [=======================>......] - ETA: 22s  [ loss=1.0917 ][Training] 47/57 [=======================>......] - ETA: 20s  [ loss=0.0203 ][Training] 48/57 [========================>.....] - ETA: 18s  [ loss=0.0229 ][Training] 49/57 [========================>.....] - ETA: 16s  [ loss=1.2058 ][Training] 50/57 [=========================>....] - ETA: 14s  [ loss=0.0345 ][Training] 51/57 [=========================>....] - ETA: 12s  [ loss=0.9398 ][Training] 52/57 [==========================>...] - ETA: 10s  [ loss=0.0216 ][Training] 53/57 [==========================>...] - ETA: 8s  [ loss=0.2543 ][Training] 54/57 [===========================>..] - ETA: 6s  [ loss=0.5491 ][Training] 55/57 [===========================>..] - ETA: 4s  [ loss=0.0174 ][Training] 56/57 [============================>.] - ETA: 2s  [ loss=0.5284 ][Training] 57/57 [==============================] 2.1s/step  [ loss=0.0356 ]
01/08/2024 13:01:50 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/08/2024 13:01:50 - INFO - root -   ***** Running evaluation on test dataset  *****
01/08/2024 13:01:50 - INFO - root -     Num examples = 269
01/08/2024 13:01:50 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 7s[Evaluating] 2/12 [====>.........................] - ETA: 8s[Evaluating] 3/12 [======>.......................] - ETA: 7s[Evaluating] 4/12 [=========>....................] - ETA: 6s[Evaluating] 5/12 [===========>..................] - ETA: 5s[Evaluating] 6/12 [==============>...............] - ETA: 5s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 3s[Evaluating] 9/12 [=====================>........] - ETA: 2s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 775.9ms/step
01/08/2024 13:01:59 - INFO - root -   

01/08/2024 13:01:59 - INFO - root -   ***** Eval results  *****
01/08/2024 13:01:59 - INFO - root -    acc: 0.7199 - recall: 0.7094 - f1: 0.7146 - loss: 7.2816 
01/08/2024 13:01:59 - INFO - root -   ***** Entity results  *****
01/08/2024 13:01:59 - INFO - root -   ******* GPE.NAM results ********
01/08/2024 13:01:59 - INFO - root -    acc: 0.7736 - recall: 0.8723 - f1: 0.8200 
01/08/2024 13:01:59 - INFO - root -   ******* GPE.NOM results ********
01/08/2024 13:01:59 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 13:01:59 - INFO - root -   ******* LOC.NAM results ********
01/08/2024 13:01:59 - INFO - root -    acc: 0.5625 - recall: 0.4737 - f1: 0.5143 
01/08/2024 13:01:59 - INFO - root -   ******* LOC.NOM results ********
01/08/2024 13:01:59 - INFO - root -    acc: 0.4286 - recall: 0.3333 - f1: 0.3750 
01/08/2024 13:01:59 - INFO - root -   ******* ORG.NAM results ********
01/08/2024 13:01:59 - INFO - root -    acc: 0.5882 - recall: 0.5128 - f1: 0.5479 
01/08/2024 13:01:59 - INFO - root -   ******* ORG.NOM results ********
01/08/2024 13:01:59 - INFO - root -    acc: 0.8000 - recall: 0.4706 - f1: 0.5926 
01/08/2024 13:01:59 - INFO - root -   ******* PER.NAM results ********
01/08/2024 13:01:59 - INFO - root -    acc: 0.7345 - recall: 0.7545 - f1: 0.7444 
01/08/2024 13:01:59 - INFO - root -   ******* PER.NOM results ********
01/08/2024 13:01:59 - INFO - root -    acc: 0.7414 - recall: 0.7588 - f1: 0.7500 
01/08/2024 13:02:21 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2394
01/08/2024 13:02:21 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2394
01/08/2024 13:02:21 - INFO - root -   

01/08/2024 13:02:22 - INFO - root -   Backbone bert_estor_crf param is not freeze

Epoch: 42/50
[Training] 1/57 [..............................] - ETA: 2:24  [ loss=0.0446 ][Training] 2/57 [>.............................] - ETA: 2:09  [ loss=0.0943 ][Training] 3/57 [>.............................] - ETA: 2:14  [ loss=0.2135 ][Training] 4/57 [=>............................] - ETA: 2:11  [ loss=0.3399 ][Training] 5/57 [=>............................] - ETA: 2:03  [ loss=0.0156 ][Training] 6/57 [==>...........................] - ETA: 2:01  [ loss=0.4880 ][Training] 7/57 [==>...........................] - ETA: 1:58  [ loss=0.2956 ][Training] 8/57 [===>..........................] - ETA: 1:53  [ loss=0.0257 ][Training] 9/57 [===>..........................] - ETA: 1:53  [ loss=0.0332 ][Training] 10/57 [====>.........................] - ETA: 1:51  [ loss=0.4208 ][Training] 11/57 [====>.........................] - ETA: 1:48  [ loss=0.0524 ][Training] 12/57 [=====>........................] - ETA: 1:45  [ loss=0.0180 ][Training] 13/57 [=====>........................] - ETA: 1:41  [ loss=0.2146 ][Training] 14/57 [======>.......................] - ETA: 1:39  [ loss=0.0134 ][Training] 15/57 [======>.......................] - ETA: 1:37  [ loss=0.0250 ][Training] 16/57 [=======>......................] - ETA: 1:35  [ loss=0.4522 ][Training] 17/57 [=======>......................] - ETA: 1:33  [ loss=0.1178 ][Training] 18/57 [========>.....................] - ETA: 1:30  [ loss=0.0710 ][Training] 19/57 [=========>....................] - ETA: 1:27  [ loss=0.1292 ][Training] 20/57 [=========>....................] - ETA: 1:25  [ loss=0.2333 ][Training] 21/57 [==========>...................] - ETA: 1:22  [ loss=0.1548 ][Training] 22/57 [==========>...................] - ETA: 1:20  [ loss=0.2017 ][Training] 23/57 [===========>..................] - ETA: 1:17  [ loss=0.0338 ][Training] 24/57 [===========>..................] - ETA: 1:16  [ loss=0.0280 ][Training] 25/57 [============>.................] - ETA: 1:14  [ loss=0.0354 ][Training] 26/57 [============>.................] - ETA: 1:12  [ loss=0.0249 ][Training] 27/57 [=============>................] - ETA: 1:10  [ loss=0.0239 ][Training] 28/57 [=============>................] - ETA: 1:07  [ loss=0.0236 ][Training] 29/57 [==============>...............] - ETA: 1:05  [ loss=0.0243 ][Training] 30/57 [==============>...............] - ETA: 1:03  [ loss=0.0250 ][Training] 31/57 [===============>..............] - ETA: 1:01  [ loss=0.0210 ][Training] 32/57 [===============>..............] - ETA: 58s  [ loss=0.0886 ][Training] 33/57 [================>.............] - ETA: 56s  [ loss=0.0421 ][Training] 34/57 [================>.............] - ETA: 54s  [ loss=0.3688 ][Training] 35/57 [=================>............] - ETA: 52s  [ loss=0.4162 ][Training] 36/57 [=================>............] - ETA: 49s  [ loss=0.3030 ][Training] 37/57 [==================>...........] - ETA: 47s  [ loss=0.2279 ][Training] 38/57 [===================>..........] - ETA: 45s  [ loss=0.1113 ][Training] 39/57 [===================>..........] - ETA: 43s  [ loss=0.7259 ][Training] 40/57 [====================>.........] - ETA: 40s  [ loss=0.1789 ][Training] 41/57 [====================>.........] - ETA: 38s  [ loss=0.2002 ][Training] 42/57 [=====================>........] - ETA: 35s  [ loss=0.0679 ][Training] 43/57 [=====================>........] - ETA: 33s  [ loss=0.5249 ][Training] 44/57 [======================>.......] - ETA: 31s  [ loss=0.1602 ][Training] 45/57 [======================>.......] - ETA: 28s  [ loss=2.1102 ][Training] 46/57 [=======================>......] - ETA: 26s  [ loss=1.3370 ][Training] 47/57 [=======================>......] - ETA: 23s  [ loss=0.4386 ][Training] 48/57 [========================>.....] - ETA: 21s  [ loss=0.1114 ][Training] 49/57 [========================>.....] - ETA: 19s  [ loss=0.1387 ][Training] 50/57 [=========================>....] - ETA: 16s  [ loss=0.3993 ][Training] 51/57 [=========================>....] - ETA: 14s  [ loss=0.0135 ][Training] 52/57 [==========================>...] - ETA: 11s  [ loss=0.0289 ][Training] 53/57 [==========================>...] - ETA: 9s  [ loss=0.0147 ][Training] 54/57 [===========================>..] - ETA: 7s  [ loss=0.0530 ][Training] 55/57 [===========================>..] - ETA: 4s  [ loss=0.2911 ][Training] 56/57 [============================>.] - ETA: 2s  [ loss=1.0733 ][Training] 57/57 [==============================] 2.3s/step  [ loss=0.3132 ]
01/08/2024 13:04:34 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/08/2024 13:04:35 - INFO - root -   ***** Running evaluation on test dataset  *****
01/08/2024 13:04:35 - INFO - root -     Num examples = 269
01/08/2024 13:04:35 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 9s[Evaluating] 2/12 [====>.........................] - ETA: 9s[Evaluating] 3/12 [======>.......................] - ETA: 7s[Evaluating] 4/12 [=========>....................] - ETA: 6s[Evaluating] 5/12 [===========>..................] - ETA: 6s[Evaluating] 6/12 [==============>...............] - ETA: 5s[Evaluating] 7/12 [================>.............] - ETA: 4s[Evaluating] 8/12 [===================>..........] - ETA: 3s[Evaluating] 9/12 [=====================>........] - ETA: 2s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 861.4ms/step
01/08/2024 13:04:45 - INFO - root -   

01/08/2024 13:04:45 - INFO - root -   ***** Eval results  *****
01/08/2024 13:04:45 - INFO - root -    acc: 0.6978 - recall: 0.7046 - f1: 0.7012 - loss: 7.8466 
01/08/2024 13:04:45 - INFO - root -   ***** Entity results  *****
01/08/2024 13:04:45 - INFO - root -   ******* GPE.NAM results ********
01/08/2024 13:04:45 - INFO - root -    acc: 0.7885 - recall: 0.8723 - f1: 0.8283 
01/08/2024 13:04:45 - INFO - root -   ******* GPE.NOM results ********
01/08/2024 13:04:45 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 13:04:45 - INFO - root -   ******* LOC.NAM results ********
01/08/2024 13:04:45 - INFO - root -    acc: 0.5294 - recall: 0.4737 - f1: 0.5000 
01/08/2024 13:04:45 - INFO - root -   ******* LOC.NOM results ********
01/08/2024 13:04:45 - INFO - root -    acc: 0.5000 - recall: 0.3333 - f1: 0.4000 
01/08/2024 13:04:45 - INFO - root -   ******* ORG.NAM results ********
01/08/2024 13:04:45 - INFO - root -    acc: 0.5882 - recall: 0.5128 - f1: 0.5479 
01/08/2024 13:04:45 - INFO - root -   ******* ORG.NOM results ********
01/08/2024 13:04:45 - INFO - root -    acc: 0.8889 - recall: 0.4706 - f1: 0.6154 
01/08/2024 13:04:45 - INFO - root -   ******* PER.NAM results ********
01/08/2024 13:04:45 - INFO - root -    acc: 0.6891 - recall: 0.7455 - f1: 0.7162 
01/08/2024 13:04:45 - INFO - root -   ******* PER.NOM results ********
01/08/2024 13:04:45 - INFO - root -    acc: 0.7111 - recall: 0.7529 - f1: 0.7314 
01/08/2024 13:05:07 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2451
01/08/2024 13:05:07 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2451
01/08/2024 13:05:07 - INFO - root -   

01/08/2024 13:05:08 - INFO - root -   Backbone bert_estor_crf param is not freeze

Epoch: 43/50
[Training] 1/57 [..............................] - ETA: 2:03  [ loss=0.4748 ][Training] 2/57 [>.............................] - ETA: 2:12  [ loss=0.0532 ][Training] 3/57 [>.............................] - ETA: 2:03  [ loss=0.0309 ][Training] 4/57 [=>............................] - ETA: 2:04  [ loss=0.2633 ][Training] 5/57 [=>............................] - ETA: 2:01  [ loss=0.0223 ][Training] 6/57 [==>...........................] - ETA: 2:02  [ loss=0.2022 ][Training] 7/57 [==>...........................] - ETA: 2:01  [ loss=0.0199 ][Training] 8/57 [===>..........................] - ETA: 2:00  [ loss=0.2445 ][Training] 9/57 [===>..........................] - ETA: 1:59  [ loss=0.0195 ][Training] 10/57 [====>.........................] - ETA: 1:56  [ loss=0.0197 ][Training] 11/57 [====>.........................] - ETA: 1:55  [ loss=0.0654 ][Training] 12/57 [=====>........................] - ETA: 1:52  [ loss=0.0161 ][Training] 13/57 [=====>........................] - ETA: 1:49  [ loss=0.1117 ][Training] 14/57 [======>.......................] - ETA: 1:48  [ loss=0.0141 ][Training] 15/57 [======>.......................] - ETA: 1:47  [ loss=0.0252 ][Training] 16/57 [=======>......................] - ETA: 1:45  [ loss=0.1275 ][Training] 17/57 [=======>......................] - ETA: 1:41  [ loss=0.0114 ][Training] 18/57 [========>.....................] - ETA: 1:40  [ loss=0.4107 ][Training] 19/57 [=========>....................] - ETA: 1:38  [ loss=0.0879 ][Training] 20/57 [=========>....................] - ETA: 1:35  [ loss=0.0170 ][Training] 21/57 [==========>...................] - ETA: 1:32  [ loss=0.4313 ][Training] 22/57 [==========>...................] - ETA: 1:30  [ loss=0.7925 ][Training] 23/57 [===========>..................] - ETA: 1:28  [ loss=0.1583 ][Training] 24/57 [===========>..................] - ETA: 1:25  [ loss=0.0217 ][Training] 25/57 [============>.................] - ETA: 1:23  [ loss=0.1305 ][Training] 26/57 [============>.................] - ETA: 1:21  [ loss=0.2753 ][Training] 27/57 [=============>................] - ETA: 1:19  [ loss=0.2000 ][Training] 28/57 [=============>................] - ETA: 1:15  [ loss=0.0422 ][Training] 29/57 [==============>...............] - ETA: 1:12  [ loss=0.3073 ][Training] 30/57 [==============>...............] - ETA: 1:09  [ loss=0.3229 ][Training] 31/57 [===============>..............] - ETA: 1:05  [ loss=0.0147 ][Training] 32/57 [===============>..............] - ETA: 1:02  [ loss=0.1143 ][Training] 33/57 [================>.............] - ETA: 59s  [ loss=0.0978 ][Training] 34/57 [================>.............] - ETA: 57s  [ loss=0.4160 ][Training] 35/57 [=================>............] - ETA: 54s  [ loss=0.0320 ][Training] 36/57 [=================>............] - ETA: 51s  [ loss=0.1323 ][Training] 37/57 [==================>...........] - ETA: 48s  [ loss=0.3099 ][Training] 38/57 [===================>..........] - ETA: 46s  [ loss=0.3833 ][Training] 39/57 [===================>..........] - ETA: 43s  [ loss=0.0212 ][Training] 40/57 [====================>.........] - ETA: 40s  [ loss=0.4250 ][Training] 41/57 [====================>.........] - ETA: 38s  [ loss=0.2776 ][Training] 42/57 [=====================>........] - ETA: 35s  [ loss=1.3998 ][Training] 43/57 [=====================>........] - ETA: 32s  [ loss=0.1445 ][Training] 44/57 [======================>.......] - ETA: 30s  [ loss=0.3065 ][Training] 45/57 [======================>.......] - ETA: 28s  [ loss=0.1383 ][Training] 46/57 [=======================>......] - ETA: 25s  [ loss=0.0158 ][Training] 47/57 [=======================>......] - ETA: 23s  [ loss=0.0364 ][Training] 48/57 [========================>.....] - ETA: 21s  [ loss=0.0183 ][Training] 49/57 [========================>.....] - ETA: 19s  [ loss=0.0846 ][Training] 50/57 [=========================>....] - ETA: 16s  [ loss=0.7199 ][Training] 51/57 [=========================>....] - ETA: 14s  [ loss=0.3841 ][Training] 52/57 [==========================>...] - ETA: 11s  [ loss=0.0164 ][Training] 53/57 [==========================>...] - ETA: 9s  [ loss=0.2551 ][Training] 54/57 [===========================>..] - ETA: 7s  [ loss=0.1774 ][Training] 55/57 [===========================>..] - ETA: 4s  [ loss=0.2728 ][Training] 56/57 [============================>.] - ETA: 2s  [ loss=0.0146 ][Training] 57/57 [==============================] 2.4s/step  [ loss=0.0317 ]
01/08/2024 13:07:22 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/08/2024 13:07:22 - INFO - root -   ***** Running evaluation on test dataset  *****
01/08/2024 13:07:22 - INFO - root -     Num examples = 269
01/08/2024 13:07:22 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 8s[Evaluating] 2/12 [====>.........................] - ETA: 7s[Evaluating] 3/12 [======>.......................] - ETA: 6s[Evaluating] 4/12 [=========>....................] - ETA: 5s[Evaluating] 5/12 [===========>..................] - ETA: 5s[Evaluating] 6/12 [==============>...............] - ETA: 4s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 3s[Evaluating] 9/12 [=====================>........] - ETA: 2s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 739.8ms/step
01/08/2024 13:07:31 - INFO - root -   

01/08/2024 13:07:31 - INFO - root -   ***** Eval results  *****
01/08/2024 13:07:31 - INFO - root -    acc: 0.7316 - recall: 0.6998 - f1: 0.7153 - loss: 7.9043 
01/08/2024 13:07:31 - INFO - root -   ***** Entity results  *****
01/08/2024 13:07:31 - INFO - root -   ******* GPE.NAM results ********
01/08/2024 13:07:31 - INFO - root -    acc: 0.8039 - recall: 0.8723 - f1: 0.8367 
01/08/2024 13:07:31 - INFO - root -   ******* GPE.NOM results ********
01/08/2024 13:07:31 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 13:07:31 - INFO - root -   ******* LOC.NAM results ********
01/08/2024 13:07:31 - INFO - root -    acc: 0.5294 - recall: 0.4737 - f1: 0.5000 
01/08/2024 13:07:31 - INFO - root -   ******* LOC.NOM results ********
01/08/2024 13:07:31 - INFO - root -    acc: 0.4286 - recall: 0.3333 - f1: 0.3750 
01/08/2024 13:07:31 - INFO - root -   ******* ORG.NAM results ********
01/08/2024 13:07:31 - INFO - root -    acc: 0.5714 - recall: 0.5128 - f1: 0.5405 
01/08/2024 13:07:31 - INFO - root -   ******* ORG.NOM results ********
01/08/2024 13:07:31 - INFO - root -    acc: 0.8000 - recall: 0.4706 - f1: 0.5926 
01/08/2024 13:07:31 - INFO - root -   ******* PER.NAM results ********
01/08/2024 13:07:31 - INFO - root -    acc: 0.7961 - recall: 0.7455 - f1: 0.7700 
01/08/2024 13:07:31 - INFO - root -   ******* PER.NOM results ********
01/08/2024 13:07:31 - INFO - root -    acc: 0.7326 - recall: 0.7412 - f1: 0.7368 
01/08/2024 13:07:42 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2508
01/08/2024 13:07:42 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2508
01/08/2024 13:07:42 - INFO - root -   

01/08/2024 13:07:42 - INFO - root -   Backbone bert_estor_crf param is not freeze

Epoch: 44/50
[Training] 1/57 [..............................] - ETA: 1:14  [ loss=0.0400 ][Training] 2/57 [>.............................] - ETA: 1:23  [ loss=0.0126 ][Training] 3/57 [>.............................] - ETA: 1:25  [ loss=0.0473 ][Training] 4/57 [=>............................] - ETA: 1:25  [ loss=0.0977 ][Training] 5/57 [=>............................] - ETA: 1:23  [ loss=0.2408 ][Training] 6/57 [==>...........................] - ETA: 1:23  [ loss=0.1066 ][Training] 7/57 [==>...........................] - ETA: 1:23  [ loss=0.1607 ][Training] 8/57 [===>..........................] - ETA: 1:21  [ loss=0.4766 ][Training] 9/57 [===>..........................] - ETA: 1:19  [ loss=0.0163 ][Training] 10/57 [====>.........................] - ETA: 1:21  [ loss=0.0226 ][Training] 11/57 [====>.........................] - ETA: 1:20  [ loss=0.1109 ][Training] 12/57 [=====>........................] - ETA: 1:21  [ loss=0.3209 ][Training] 13/57 [=====>........................] - ETA: 1:20  [ loss=0.1124 ][Training] 14/57 [======>.......................] - ETA: 1:20  [ loss=0.0155 ][Training] 15/57 [======>.......................] - ETA: 1:18  [ loss=0.5689 ][Training] 16/57 [=======>......................] - ETA: 1:19  [ loss=0.0173 ][Training] 17/57 [=======>......................] - ETA: 1:19  [ loss=0.1936 ][Training] 18/57 [========>.....................] - ETA: 1:16  [ loss=0.0158 ][Training] 19/57 [=========>....................] - ETA: 1:15  [ loss=0.1668 ][Training] 20/57 [=========>....................] - ETA: 1:13  [ loss=0.1088 ][Training] 21/57 [==========>...................] - ETA: 1:11  [ loss=0.1857 ][Training] 22/57 [==========>...................] - ETA: 1:10  [ loss=0.1637 ][Training] 23/57 [===========>..................] - ETA: 1:09  [ loss=0.0982 ][Training] 24/57 [===========>..................] - ETA: 1:07  [ loss=0.1457 ][Training] 25/57 [============>.................] - ETA: 1:04  [ loss=0.0169 ][Training] 26/57 [============>.................] - ETA: 1:03  [ loss=0.0423 ][Training] 27/57 [=============>................] - ETA: 1:02  [ loss=0.6463 ][Training] 28/57 [=============>................] - ETA: 1:00  [ loss=0.2256 ][Training] 29/57 [==============>...............] - ETA: 58s  [ loss=0.2202 ][Training] 30/57 [==============>...............] - ETA: 57s  [ loss=0.1183 ][Training] 31/57 [===============>..............] - ETA: 55s  [ loss=0.2146 ][Training] 32/57 [===============>..............] - ETA: 53s  [ loss=0.0187 ][Training] 33/57 [================>.............] - ETA: 50s  [ loss=0.0663 ][Training] 34/57 [================>.............] - ETA: 48s  [ loss=0.1341 ][Training] 35/57 [=================>............] - ETA: 46s  [ loss=0.6841 ][Training] 36/57 [=================>............] - ETA: 44s  [ loss=0.0156 ][Training] 37/57 [==================>...........] - ETA: 42s  [ loss=0.0167 ][Training] 38/57 [===================>..........] - ETA: 40s  [ loss=1.2787 ][Training] 39/57 [===================>..........] - ETA: 38s  [ loss=0.2849 ][Training] 40/57 [====================>.........] - ETA: 36s  [ loss=0.1569 ][Training] 41/57 [====================>.........] - ETA: 34s  [ loss=0.6822 ][Training] 42/57 [=====================>........] - ETA: 32s  [ loss=0.1347 ][Training] 43/57 [=====================>........] - ETA: 30s  [ loss=0.3062 ][Training] 44/57 [======================>.......] - ETA: 28s  [ loss=0.1253 ][Training] 45/57 [======================>.......] - ETA: 26s  [ loss=0.0257 ][Training] 46/57 [=======================>......] - ETA: 24s  [ loss=0.2048 ][Training] 47/57 [=======================>......] - ETA: 21s  [ loss=0.1452 ][Training] 48/57 [========================>.....] - ETA: 19s  [ loss=0.1040 ][Training] 49/57 [========================>.....] - ETA: 17s  [ loss=0.0191 ][Training] 50/57 [=========================>....] - ETA: 15s  [ loss=0.2262 ][Training] 51/57 [=========================>....] - ETA: 13s  [ loss=0.0147 ][Training] 52/57 [==========================>...] - ETA: 11s  [ loss=0.0228 ][Training] 53/57 [==========================>...] - ETA: 8s  [ loss=0.2571 ][Training] 54/57 [===========================>..] - ETA: 6s  [ loss=0.3787 ][Training] 55/57 [===========================>..] - ETA: 4s  [ loss=0.1010 ][Training] 56/57 [============================>.] - ETA: 2s  [ loss=0.0137 ][Training] 57/57 [==============================] 2.2s/step  [ loss=0.0220 ]
01/08/2024 13:09:47 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/08/2024 13:09:47 - INFO - root -   ***** Running evaluation on test dataset  *****
01/08/2024 13:09:47 - INFO - root -     Num examples = 269
01/08/2024 13:09:47 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 9s[Evaluating] 2/12 [====>.........................] - ETA: 7s[Evaluating] 3/12 [======>.......................] - ETA: 6s[Evaluating] 4/12 [=========>....................] - ETA: 6s[Evaluating] 5/12 [===========>..................] - ETA: 5s[Evaluating] 6/12 [==============>...............] - ETA: 4s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 3s[Evaluating] 9/12 [=====================>........] - ETA: 2s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 762.9ms/step
01/08/2024 13:09:56 - INFO - root -   

01/08/2024 13:09:56 - INFO - root -   ***** Eval results  *****
01/08/2024 13:09:56 - INFO - root -    acc: 0.7084 - recall: 0.7119 - f1: 0.7101 - loss: 8.5304 
01/08/2024 13:09:56 - INFO - root -   ***** Entity results  *****
01/08/2024 13:09:56 - INFO - root -   ******* GPE.NAM results ********
01/08/2024 13:09:56 - INFO - root -    acc: 0.7736 - recall: 0.8723 - f1: 0.8200 
01/08/2024 13:09:56 - INFO - root -   ******* GPE.NOM results ********
01/08/2024 13:09:56 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 13:09:56 - INFO - root -   ******* LOC.NAM results ********
01/08/2024 13:09:56 - INFO - root -    acc: 0.4706 - recall: 0.4211 - f1: 0.4444 
01/08/2024 13:09:56 - INFO - root -   ******* LOC.NOM results ********
01/08/2024 13:09:56 - INFO - root -    acc: 0.6000 - recall: 0.3333 - f1: 0.4286 
01/08/2024 13:09:56 - INFO - root -   ******* ORG.NAM results ********
01/08/2024 13:09:56 - INFO - root -    acc: 0.5238 - recall: 0.5641 - f1: 0.5432 
01/08/2024 13:09:56 - INFO - root -   ******* ORG.NOM results ********
01/08/2024 13:09:56 - INFO - root -    acc: 0.7273 - recall: 0.4706 - f1: 0.5714 
01/08/2024 13:09:56 - INFO - root -   ******* PER.NAM results ********
01/08/2024 13:09:56 - INFO - root -    acc: 0.7642 - recall: 0.7364 - f1: 0.7500 
01/08/2024 13:09:56 - INFO - root -   ******* PER.NOM results ********
01/08/2024 13:09:56 - INFO - root -    acc: 0.7238 - recall: 0.7706 - f1: 0.7464 
01/08/2024 13:10:11 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2565
01/08/2024 13:10:11 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2565
01/08/2024 13:10:11 - INFO - root -   

01/08/2024 13:10:11 - INFO - root -   Backbone bert_estor_crf param is not freeze

Epoch: 45/50
[Training] 1/57 [..............................] - ETA: 2:31  [ loss=0.0154 ][Training] 2/57 [>.............................] - ETA: 2:15  [ loss=0.0802 ][Training] 3/57 [>.............................] - ETA: 2:08  [ loss=0.0359 ][Training] 4/57 [=>............................] - ETA: 2:04  [ loss=0.1810 ][Training] 5/57 [=>............................] - ETA: 2:03  [ loss=0.1379 ][Training] 6/57 [==>...........................] - ETA: 1:58  [ loss=0.1319 ][Training] 7/57 [==>...........................] - ETA: 1:55  [ loss=0.2610 ][Training] 8/57 [===>..........................] - ETA: 1:52  [ loss=0.1950 ][Training] 9/57 [===>..........................] - ETA: 1:51  [ loss=0.0745 ][Training] 10/57 [====>.........................] - ETA: 1:49  [ loss=0.0318 ][Training] 11/57 [====>.........................] - ETA: 1:48  [ loss=0.0105 ][Training] 12/57 [=====>........................] - ETA: 1:44  [ loss=0.0493 ][Training] 13/57 [=====>........................] - ETA: 1:42  [ loss=0.0139 ][Training] 14/57 [======>.......................] - ETA: 1:39  [ loss=0.0376 ][Training] 15/57 [======>.......................] - ETA: 1:38  [ loss=0.0153 ][Training] 16/57 [=======>......................] - ETA: 1:36  [ loss=0.1371 ][Training] 17/57 [=======>......................] - ETA: 1:33  [ loss=0.1569 ][Training] 18/57 [========>.....................] - ETA: 1:30  [ loss=0.0155 ][Training] 19/57 [=========>....................] - ETA: 1:28  [ loss=0.3866 ][Training] 20/57 [=========>....................] - ETA: 1:26  [ loss=0.0211 ][Training] 21/57 [==========>...................] - ETA: 1:23  [ loss=0.2061 ][Training] 22/57 [==========>...................] - ETA: 1:21  [ loss=0.0960 ][Training] 23/57 [===========>..................] - ETA: 1:19  [ loss=0.0208 ][Training] 24/57 [===========>..................] - ETA: 1:17  [ loss=0.0387 ][Training] 25/57 [============>.................] - ETA: 1:14  [ loss=0.0177 ][Training] 26/57 [============>.................] - ETA: 1:12  [ loss=0.3970 ][Training] 27/57 [=============>................] - ETA: 1:10  [ loss=0.0140 ][Training] 28/57 [=============>................] - ETA: 1:07  [ loss=0.1732 ][Training] 29/57 [==============>...............] - ETA: 1:05  [ loss=0.0215 ][Training] 30/57 [==============>...............] - ETA: 1:02  [ loss=0.1404 ][Training] 31/57 [===============>..............] - ETA: 1:00  [ loss=0.4985 ][Training] 32/57 [===============>..............] - ETA: 58s  [ loss=0.8406 ][Training] 33/57 [================>.............] - ETA: 56s  [ loss=0.3071 ][Training] 34/57 [================>.............] - ETA: 54s  [ loss=0.2571 ][Training] 35/57 [=================>............] - ETA: 51s  [ loss=0.2241 ][Training] 36/57 [=================>............] - ETA: 49s  [ loss=0.3488 ][Training] 37/57 [==================>...........] - ETA: 46s  [ loss=0.0413 ][Training] 38/57 [===================>..........] - ETA: 44s  [ loss=0.6300 ][Training] 39/57 [===================>..........] - ETA: 42s  [ loss=0.1163 ][Training] 40/57 [====================>.........] - ETA: 40s  [ loss=0.2351 ][Training] 41/57 [====================>.........] - ETA: 37s  [ loss=0.0192 ][Training] 42/57 [=====================>........] - ETA: 35s  [ loss=0.0316 ][Training] 43/57 [=====================>........] - ETA: 32s  [ loss=0.5209 ][Training] 44/57 [======================>.......] - ETA: 30s  [ loss=0.1987 ][Training] 45/57 [======================>.......] - ETA: 28s  [ loss=0.1142 ][Training] 46/57 [=======================>......] - ETA: 25s  [ loss=0.2366 ][Training] 47/57 [=======================>......] - ETA: 23s  [ loss=0.3389 ][Training] 48/57 [========================>.....] - ETA: 21s  [ loss=0.3880 ][Training] 49/57 [========================>.....] - ETA: 18s  [ loss=0.7662 ][Training] 50/57 [=========================>....] - ETA: 16s  [ loss=0.1283 ][Training] 51/57 [=========================>....] - ETA: 14s  [ loss=0.2316 ][Training] 52/57 [==========================>...] - ETA: 11s  [ loss=0.1079 ][Training] 53/57 [==========================>...] - ETA: 9s  [ loss=0.0111 ][Training] 54/57 [===========================>..] - ETA: 7s  [ loss=0.1895 ][Training] 55/57 [===========================>..] - ETA: 4s  [ loss=0.2485 ][Training] 56/57 [============================>.] - ETA: 2s  [ loss=0.1985 ][Training] 57/57 [==============================] 2.3s/step  [ loss=0.0152 ]
01/08/2024 13:12:23 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/08/2024 13:12:23 - INFO - root -   ***** Running evaluation on test dataset  *****
01/08/2024 13:12:23 - INFO - root -     Num examples = 269
01/08/2024 13:12:23 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 9s[Evaluating] 2/12 [====>.........................] - ETA: 8s[Evaluating] 3/12 [======>.......................] - ETA: 7s[Evaluating] 4/12 [=========>....................] - ETA: 7s[Evaluating] 5/12 [===========>..................] - ETA: 6s[Evaluating] 6/12 [==============>...............] - ETA: 5s[Evaluating] 7/12 [================>.............] - ETA: 4s[Evaluating] 8/12 [===================>..........] - ETA: 3s[Evaluating] 9/12 [=====================>........] - ETA: 2s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 795.0ms/step
01/08/2024 13:12:33 - INFO - root -   

01/08/2024 13:12:33 - INFO - root -   ***** Eval results  *****
01/08/2024 13:12:33 - INFO - root -    acc: 0.7234 - recall: 0.6901 - f1: 0.7063 - loss: 8.2088 
01/08/2024 13:12:33 - INFO - root -   ***** Entity results  *****
01/08/2024 13:12:33 - INFO - root -   ******* GPE.NAM results ********
01/08/2024 13:12:33 - INFO - root -    acc: 0.7885 - recall: 0.8723 - f1: 0.8283 
01/08/2024 13:12:33 - INFO - root -   ******* GPE.NOM results ********
01/08/2024 13:12:33 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 13:12:33 - INFO - root -   ******* LOC.NAM results ********
01/08/2024 13:12:33 - INFO - root -    acc: 0.5294 - recall: 0.4737 - f1: 0.5000 
01/08/2024 13:12:33 - INFO - root -   ******* LOC.NOM results ********
01/08/2024 13:12:33 - INFO - root -    acc: 0.5000 - recall: 0.3333 - f1: 0.4000 
01/08/2024 13:12:33 - INFO - root -   ******* ORG.NAM results ********
01/08/2024 13:12:33 - INFO - root -    acc: 0.5556 - recall: 0.5128 - f1: 0.5333 
01/08/2024 13:12:33 - INFO - root -   ******* ORG.NOM results ********
01/08/2024 13:12:33 - INFO - root -    acc: 0.7273 - recall: 0.4706 - f1: 0.5714 
01/08/2024 13:12:33 - INFO - root -   ******* PER.NAM results ********
01/08/2024 13:12:33 - INFO - root -    acc: 0.7788 - recall: 0.7364 - f1: 0.7570 
01/08/2024 13:12:33 - INFO - root -   ******* PER.NOM results ********
01/08/2024 13:12:33 - INFO - root -    acc: 0.7321 - recall: 0.7235 - f1: 0.7278 
01/08/2024 13:12:44 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2622
01/08/2024 13:12:44 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2622
01/08/2024 13:12:44 - INFO - root -   

01/08/2024 13:12:44 - INFO - root -   Backbone bert_estor_crf param is not freeze

Epoch: 46/50
[Training] 1/57 [..............................] - ETA: 2:23  [ loss=0.0246 ][Training] 2/57 [>.............................] - ETA: 2:01  [ loss=0.0143 ][Training] 3/57 [>.............................] - ETA: 2:04  [ loss=0.0527 ][Training] 4/57 [=>............................] - ETA: 2:08  [ loss=0.0160 ][Training] 5/57 [=>............................] - ETA: 2:04  [ loss=0.1403 ][Training] 6/57 [==>...........................] - ETA: 2:02  [ loss=0.1204 ][Training] 7/57 [==>...........................] - ETA: 2:02  [ loss=0.0672 ][Training] 8/57 [===>..........................] - ETA: 2:02  [ loss=0.0547 ][Training] 9/57 [===>..........................] - ETA: 1:59  [ loss=0.1423 ][Training] 10/57 [====>.........................] - ETA: 1:53  [ loss=0.0229 ][Training] 11/57 [====>.........................] - ETA: 1:51  [ loss=0.3092 ][Training] 12/57 [=====>........................] - ETA: 1:47  [ loss=0.1369 ][Training] 13/57 [=====>........................] - ETA: 1:43  [ loss=0.1682 ][Training] 14/57 [======>.......................] - ETA: 1:40  [ loss=0.5294 ][Training] 15/57 [======>.......................] - ETA: 1:38  [ loss=0.0485 ][Training] 16/57 [=======>......................] - ETA: 1:35  [ loss=0.0774 ][Training] 17/57 [=======>......................] - ETA: 1:34  [ loss=0.0144 ][Training] 18/57 [========>.....................] - ETA: 1:32  [ loss=0.2549 ][Training] 19/57 [=========>....................] - ETA: 1:28  [ loss=0.0168 ][Training] 20/57 [=========>....................] - ETA: 1:26  [ loss=0.1123 ][Training] 21/57 [==========>...................] - ETA: 1:23  [ loss=0.0239 ][Training] 22/57 [==========>...................] - ETA: 1:20  [ loss=0.1720 ][Training] 23/57 [===========>..................] - ETA: 1:18  [ loss=0.1678 ][Training] 24/57 [===========>..................] - ETA: 1:15  [ loss=0.1310 ][Training] 25/57 [============>.................] - ETA: 1:13  [ loss=0.6840 ][Training] 26/57 [============>.................] - ETA: 1:10  [ loss=0.0961 ][Training] 27/57 [=============>................] - ETA: 1:08  [ loss=0.6227 ][Training] 28/57 [=============>................] - ETA: 1:06  [ loss=0.0423 ][Training] 29/57 [==============>...............] - ETA: 1:04  [ loss=0.3081 ][Training] 30/57 [==============>...............] - ETA: 1:02  [ loss=0.0127 ][Training] 31/57 [===============>..............] - ETA: 1:00  [ loss=0.1199 ][Training] 32/57 [===============>..............] - ETA: 58s  [ loss=0.1907 ][Training] 33/57 [================>.............] - ETA: 55s  [ loss=0.1063 ][Training] 34/57 [================>.............] - ETA: 53s  [ loss=0.1835 ][Training] 35/57 [=================>............] - ETA: 51s  [ loss=0.0263 ][Training] 36/57 [=================>............] - ETA: 48s  [ loss=0.1096 ][Training] 37/57 [==================>...........] - ETA: 46s  [ loss=0.3642 ][Training] 38/57 [===================>..........] - ETA: 44s  [ loss=0.0523 ][Training] 39/57 [===================>..........] - ETA: 41s  [ loss=0.0104 ][Training] 40/57 [====================>.........] - ETA: 39s  [ loss=0.0185 ][Training] 41/57 [====================>.........] - ETA: 36s  [ loss=0.0131 ][Training] 42/57 [=====================>........] - ETA: 34s  [ loss=0.0159 ][Training] 43/57 [=====================>........] - ETA: 32s  [ loss=0.0198 ][Training] 44/57 [======================>.......] - ETA: 30s  [ loss=0.1218 ][Training] 45/57 [======================>.......] - ETA: 27s  [ loss=0.5608 ][Training] 46/57 [=======================>......] - ETA: 25s  [ loss=0.0376 ][Training] 47/57 [=======================>......] - ETA: 23s  [ loss=0.1257 ][Training] 48/57 [========================>.....] - ETA: 20s  [ loss=0.0594 ][Training] 49/57 [========================>.....] - ETA: 18s  [ loss=0.9861 ][Training] 50/57 [=========================>....] - ETA: 16s  [ loss=0.0797 ][Training] 51/57 [=========================>....] - ETA: 13s  [ loss=0.0167 ][Training] 52/57 [==========================>...] - ETA: 11s  [ loss=0.2640 ][Training] 53/57 [==========================>...] - ETA: 9s  [ loss=0.1946 ][Training] 54/57 [===========================>..] - ETA: 6s  [ loss=0.0554 ][Training] 55/57 [===========================>..] - ETA: 4s  [ loss=0.2872 ][Training] 56/57 [============================>.] - ETA: 2s  [ loss=0.2799 ][Training] 57/57 [==============================] 2.3s/step  [ loss=0.0300 ]
01/08/2024 13:14:53 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/08/2024 13:14:53 - INFO - root -   ***** Running evaluation on test dataset  *****
01/08/2024 13:14:53 - INFO - root -     Num examples = 269
01/08/2024 13:14:53 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 6s[Evaluating] 2/12 [====>.........................] - ETA: 7s[Evaluating] 3/12 [======>.......................] - ETA: 6s[Evaluating] 4/12 [=========>....................] - ETA: 5s[Evaluating] 5/12 [===========>..................] - ETA: 4s[Evaluating] 6/12 [==============>...............] - ETA: 3s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 2s[Evaluating] 9/12 [=====================>........] - ETA: 1s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 644.5ms/step
01/08/2024 13:15:01 - INFO - root -   

01/08/2024 13:15:01 - INFO - root -   ***** Eval results  *****
01/08/2024 13:15:01 - INFO - root -    acc: 0.7294 - recall: 0.6852 - f1: 0.7066 - loss: 8.4257 
01/08/2024 13:15:01 - INFO - root -   ***** Entity results  *****
01/08/2024 13:15:01 - INFO - root -   ******* GPE.NAM results ********
01/08/2024 13:15:01 - INFO - root -    acc: 0.7736 - recall: 0.8723 - f1: 0.8200 
01/08/2024 13:15:01 - INFO - root -   ******* GPE.NOM results ********
01/08/2024 13:15:01 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 13:15:01 - INFO - root -   ******* LOC.NAM results ********
01/08/2024 13:15:01 - INFO - root -    acc: 0.5556 - recall: 0.5263 - f1: 0.5405 
01/08/2024 13:15:01 - INFO - root -   ******* LOC.NOM results ********
01/08/2024 13:15:01 - INFO - root -    acc: 0.5000 - recall: 0.3333 - f1: 0.4000 
01/08/2024 13:15:01 - INFO - root -   ******* ORG.NAM results ********
01/08/2024 13:15:01 - INFO - root -    acc: 0.5938 - recall: 0.4872 - f1: 0.5352 
01/08/2024 13:15:01 - INFO - root -   ******* ORG.NOM results ********
01/08/2024 13:15:01 - INFO - root -    acc: 0.8000 - recall: 0.4706 - f1: 0.5926 
01/08/2024 13:15:01 - INFO - root -   ******* PER.NAM results ********
01/08/2024 13:15:01 - INFO - root -    acc: 0.7788 - recall: 0.7364 - f1: 0.7570 
01/08/2024 13:15:01 - INFO - root -   ******* PER.NOM results ********
01/08/2024 13:15:01 - INFO - root -    acc: 0.7333 - recall: 0.7118 - f1: 0.7224 
01/08/2024 13:15:28 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2679
01/08/2024 13:15:28 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2679
01/08/2024 13:15:28 - INFO - root -   

01/08/2024 13:15:28 - INFO - root -   Backbone bert_estor_crf param is not freeze

Epoch: 47/50
[Training] 1/57 [..............................] - ETA: 2:01  [ loss=0.0695 ][Training] 2/57 [>.............................] - ETA: 2:01  [ loss=0.0467 ][Training] 3/57 [>.............................] - ETA: 1:56  [ loss=0.0120 ][Training] 4/57 [=>............................] - ETA: 1:48  [ loss=0.0104 ][Training] 5/57 [=>............................] - ETA: 1:44  [ loss=0.2780 ][Training] 6/57 [==>...........................] - ETA: 1:48  [ loss=0.3043 ][Training] 7/57 [==>...........................] - ETA: 1:49  [ loss=0.0121 ][Training] 8/57 [===>..........................] - ETA: 1:52  [ loss=0.1225 ][Training] 9/57 [===>..........................] - ETA: 1:54  [ loss=0.0168 ][Training] 10/57 [====>.........................] - ETA: 1:53  [ loss=0.1219 ][Training] 11/57 [====>.........................] - ETA: 1:49  [ loss=0.1416 ][Training] 12/57 [=====>........................] - ETA: 1:45  [ loss=0.0457 ][Training] 13/57 [=====>........................] - ETA: 1:43  [ loss=0.1588 ][Training] 14/57 [======>.......................] - ETA: 1:41  [ loss=0.0322 ][Training] 15/57 [======>.......................] - ETA: 1:39  [ loss=0.0306 ][Training] 16/57 [=======>......................] - ETA: 1:37  [ loss=0.1137 ][Training] 17/57 [=======>......................] - ETA: 1:34  [ loss=0.0756 ][Training] 18/57 [========>.....................] - ETA: 1:33  [ loss=0.1036 ][Training] 19/57 [=========>....................] - ETA: 1:31  [ loss=0.1362 ][Training] 20/57 [=========>....................] - ETA: 1:29  [ loss=0.2303 ][Training] 21/57 [==========>...................] - ETA: 1:26  [ loss=0.1908 ][Training] 22/57 [==========>...................] - ETA: 1:25  [ loss=0.3403 ][Training] 23/57 [===========>..................] - ETA: 1:23  [ loss=0.0169 ][Training] 24/57 [===========>..................] - ETA: 1:21  [ loss=0.2101 ][Training] 25/57 [============>.................] - ETA: 1:18  [ loss=0.1746 ][Training] 26/57 [============>.................] - ETA: 1:17  [ loss=0.0540 ][Training] 27/57 [=============>................] - ETA: 1:15  [ loss=0.1570 ][Training] 28/57 [=============>................] - ETA: 1:12  [ loss=0.1241 ][Training] 29/57 [==============>...............] - ETA: 1:09  [ loss=0.1806 ][Training] 30/57 [==============>...............] - ETA: 1:07  [ loss=0.6271 ][Training] 31/57 [===============>..............] - ETA: 1:05  [ loss=0.0777 ][Training] 32/57 [===============>..............] - ETA: 1:02  [ loss=0.0996 ][Training] 33/57 [================>.............] - ETA: 1:00  [ loss=0.0652 ][Training] 34/57 [================>.............] - ETA: 57s  [ loss=0.2746 ][Training] 35/57 [=================>............] - ETA: 55s  [ loss=0.0149 ][Training] 36/57 [=================>............] - ETA: 52s  [ loss=0.2724 ][Training] 37/57 [==================>...........] - ETA: 50s  [ loss=0.0969 ][Training] 38/57 [===================>..........] - ETA: 47s  [ loss=0.0143 ][Training] 39/57 [===================>..........] - ETA: 45s  [ loss=0.1766 ][Training] 40/57 [====================>.........] - ETA: 43s  [ loss=0.0205 ][Training] 41/57 [====================>.........] - ETA: 40s  [ loss=0.1803 ][Training] 42/57 [=====================>........] - ETA: 38s  [ loss=0.1228 ][Training] 43/57 [=====================>........] - ETA: 35s  [ loss=0.1377 ][Training] 44/57 [======================>.......] - ETA: 33s  [ loss=0.0553 ][Training] 45/57 [======================>.......] - ETA: 30s  [ loss=0.0269 ][Training] 46/57 [=======================>......] - ETA: 28s  [ loss=0.1396 ][Training] 47/57 [=======================>......] - ETA: 25s  [ loss=0.3719 ][Training] 48/57 [========================>.....] - ETA: 23s  [ loss=0.0134 ][Training] 49/57 [========================>.....] - ETA: 20s  [ loss=0.0652 ][Training] 50/57 [=========================>....] - ETA: 17s  [ loss=0.2387 ][Training] 51/57 [=========================>....] - ETA: 15s  [ loss=0.1961 ][Training] 52/57 [==========================>...] - ETA: 12s  [ loss=0.2321 ][Training] 53/57 [==========================>...] - ETA: 9s  [ loss=0.0892 ][Training] 54/57 [===========================>..] - ETA: 7s  [ loss=0.3377 ][Training] 55/57 [===========================>..] - ETA: 4s  [ loss=0.0153 ][Training] 56/57 [============================>.] - ETA: 2s  [ loss=0.0180 ][Training] 57/57 [==============================] 2.4s/step  [ loss=0.0346 ]
01/08/2024 13:17:47 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/08/2024 13:17:47 - INFO - root -   ***** Running evaluation on test dataset  *****
01/08/2024 13:17:47 - INFO - root -     Num examples = 269
01/08/2024 13:17:47 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 6s[Evaluating] 2/12 [====>.........................] - ETA: 7s[Evaluating] 3/12 [======>.......................] - ETA: 7s[Evaluating] 4/12 [=========>....................] - ETA: 6s[Evaluating] 5/12 [===========>..................] - ETA: 5s[Evaluating] 6/12 [==============>...............] - ETA: 4s[Evaluating] 7/12 [================>.............] - ETA: 4s[Evaluating] 8/12 [===================>..........] - ETA: 3s[Evaluating] 9/12 [=====================>........] - ETA: 2s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 770.8ms/step
01/08/2024 13:17:57 - INFO - root -   

01/08/2024 13:17:57 - INFO - root -   ***** Eval results  *****
01/08/2024 13:17:57 - INFO - root -    acc: 0.7282 - recall: 0.6877 - f1: 0.7073 - loss: 8.5745 
01/08/2024 13:17:57 - INFO - root -   ***** Entity results  *****
01/08/2024 13:17:57 - INFO - root -   ******* GPE.NAM results ********
01/08/2024 13:17:57 - INFO - root -    acc: 0.7736 - recall: 0.8723 - f1: 0.8200 
01/08/2024 13:17:57 - INFO - root -   ******* GPE.NOM results ********
01/08/2024 13:17:57 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 13:17:57 - INFO - root -   ******* LOC.NAM results ********
01/08/2024 13:17:57 - INFO - root -    acc: 0.5625 - recall: 0.4737 - f1: 0.5143 
01/08/2024 13:17:57 - INFO - root -   ******* LOC.NOM results ********
01/08/2024 13:17:57 - INFO - root -    acc: 0.5000 - recall: 0.3333 - f1: 0.4000 
01/08/2024 13:17:57 - INFO - root -   ******* ORG.NAM results ********
01/08/2024 13:17:57 - INFO - root -    acc: 0.5938 - recall: 0.4872 - f1: 0.5352 
01/08/2024 13:17:57 - INFO - root -   ******* ORG.NOM results ********
01/08/2024 13:17:57 - INFO - root -    acc: 0.7273 - recall: 0.4706 - f1: 0.5714 
01/08/2024 13:17:57 - INFO - root -   ******* PER.NAM results ********
01/08/2024 13:17:57 - INFO - root -    acc: 0.7864 - recall: 0.7364 - f1: 0.7606 
01/08/2024 13:17:57 - INFO - root -   ******* PER.NOM results ********
01/08/2024 13:17:57 - INFO - root -    acc: 0.7278 - recall: 0.7235 - f1: 0.7257 
01/08/2024 13:18:16 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2736
01/08/2024 13:18:16 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2736
01/08/2024 13:18:16 - INFO - root -   

01/08/2024 13:18:16 - INFO - root -   Backbone bert_estor_crf param is not freeze

Epoch: 48/50
[Training] 1/57 [..............................] - ETA: 1:42  [ loss=0.0805 ][Training] 2/57 [>.............................] - ETA: 1:51  [ loss=0.3671 ][Training] 3/57 [>.............................] - ETA: 2:03  [ loss=0.0760 ][Training] 4/57 [=>............................] - ETA: 2:05  [ loss=0.0468 ][Training] 5/57 [=>............................] - ETA: 2:01  [ loss=0.1175 ][Training] 6/57 [==>...........................] - ETA: 1:53  [ loss=0.1634 ][Training] 7/57 [==>...........................] - ETA: 1:59  [ loss=0.1280 ][Training] 8/57 [===>..........................] - ETA: 1:58  [ loss=0.0505 ][Training] 9/57 [===>..........................] - ETA: 1:56  [ loss=0.0209 ][Training] 10/57 [====>.........................] - ETA: 1:53  [ loss=0.3932 ][Training] 11/57 [====>.........................] - ETA: 1:48  [ loss=0.0941 ][Training] 12/57 [=====>........................] - ETA: 1:47  [ loss=0.2222 ][Training] 13/57 [=====>........................] - ETA: 1:45  [ loss=0.1031 ][Training] 14/57 [======>.......................] - ETA: 1:41  [ loss=0.1089 ][Training] 15/57 [======>.......................] - ETA: 1:39  [ loss=0.0777 ][Training] 16/57 [=======>......................] - ETA: 1:37  [ loss=0.0151 ][Training] 17/57 [=======>......................] - ETA: 1:35  [ loss=0.3133 ][Training] 18/57 [========>.....................] - ETA: 1:32  [ loss=0.0540 ][Training] 19/57 [=========>....................] - ETA: 1:30  [ loss=0.5518 ][Training] 20/57 [=========>....................] - ETA: 1:27  [ loss=0.0156 ][Training] 21/57 [==========>...................] - ETA: 1:24  [ loss=0.1885 ][Training] 22/57 [==========>...................] - ETA: 1:21  [ loss=0.0377 ][Training] 23/57 [===========>..................] - ETA: 1:19  [ loss=0.1624 ][Training] 24/57 [===========>..................] - ETA: 1:17  [ loss=0.2816 ][Training] 25/57 [============>.................] - ETA: 1:15  [ loss=0.0157 ][Training] 26/57 [============>.................] - ETA: 1:12  [ loss=0.1081 ][Training] 27/57 [=============>................] - ETA: 1:10  [ loss=0.1292 ][Training] 28/57 [=============>................] - ETA: 1:07  [ loss=0.0126 ][Training] 29/57 [==============>...............] - ETA: 1:05  [ loss=0.1611 ][Training] 30/57 [==============>...............] - ETA: 1:02  [ loss=0.0363 ][Training] 31/57 [===============>..............] - ETA: 1:00  [ loss=0.0096 ][Training] 32/57 [===============>..............] - ETA: 58s  [ loss=0.2525 ][Training] 33/57 [================>.............] - ETA: 55s  [ loss=0.0122 ][Training] 34/57 [================>.............] - ETA: 53s  [ loss=0.1220 ][Training] 35/57 [=================>............] - ETA: 51s  [ loss=0.0704 ][Training] 36/57 [=================>............] - ETA: 49s  [ loss=0.1019 ][Training] 37/57 [==================>...........] - ETA: 46s  [ loss=0.2182 ][Training] 38/57 [===================>..........] - ETA: 44s  [ loss=0.2104 ][Training] 39/57 [===================>..........] - ETA: 41s  [ loss=0.0217 ][Training] 40/57 [====================>.........] - ETA: 39s  [ loss=0.0163 ][Training] 41/57 [====================>.........] - ETA: 37s  [ loss=0.0958 ][Training] 42/57 [=====================>........] - ETA: 34s  [ loss=0.0228 ][Training] 43/57 [=====================>........] - ETA: 32s  [ loss=0.0270 ][Training] 44/57 [======================>.......] - ETA: 30s  [ loss=0.1073 ][Training] 45/57 [======================>.......] - ETA: 27s  [ loss=0.0121 ][Training] 46/57 [=======================>......] - ETA: 25s  [ loss=0.0320 ][Training] 47/57 [=======================>......] - ETA: 23s  [ loss=0.3520 ][Training] 48/57 [========================>.....] - ETA: 20s  [ loss=0.5574 ][Training] 49/57 [========================>.....] - ETA: 18s  [ loss=0.1976 ][Training] 50/57 [=========================>....] - ETA: 16s  [ loss=0.0118 ][Training] 51/57 [=========================>....] - ETA: 13s  [ loss=0.0911 ][Training] 52/57 [==========================>...] - ETA: 11s  [ loss=0.6151 ][Training] 53/57 [==========================>...] - ETA: 9s  [ loss=0.0748 ][Training] 54/57 [===========================>..] - ETA: 6s  [ loss=0.0096 ][Training] 55/57 [===========================>..] - ETA: 4s  [ loss=0.0637 ][Training] 56/57 [============================>.] - ETA: 2s  [ loss=0.0098 ][Training] 57/57 [==============================] 2.3s/step  [ loss=0.2849 ]
01/08/2024 13:20:27 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/08/2024 13:20:27 - INFO - root -   ***** Running evaluation on test dataset  *****
01/08/2024 13:20:27 - INFO - root -     Num examples = 269
01/08/2024 13:20:27 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 7s[Evaluating] 2/12 [====>.........................] - ETA: 7s[Evaluating] 3/12 [======>.......................] - ETA: 6s[Evaluating] 4/12 [=========>....................] - ETA: 5s[Evaluating] 5/12 [===========>..................] - ETA: 5s[Evaluating] 6/12 [==============>...............] - ETA: 4s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 3s[Evaluating] 9/12 [=====================>........] - ETA: 2s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 748.0ms/step
01/08/2024 13:20:36 - INFO - root -   

01/08/2024 13:20:36 - INFO - root -   ***** Eval results  *****
01/08/2024 13:20:36 - INFO - root -    acc: 0.7286 - recall: 0.7022 - f1: 0.7152 - loss: 8.6300 
01/08/2024 13:20:36 - INFO - root -   ***** Entity results  *****
01/08/2024 13:20:36 - INFO - root -   ******* GPE.NAM results ********
01/08/2024 13:20:36 - INFO - root -    acc: 0.7778 - recall: 0.8936 - f1: 0.8317 
01/08/2024 13:20:36 - INFO - root -   ******* GPE.NOM results ********
01/08/2024 13:20:36 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 13:20:36 - INFO - root -   ******* LOC.NAM results ********
01/08/2024 13:20:36 - INFO - root -    acc: 0.6000 - recall: 0.4737 - f1: 0.5294 
01/08/2024 13:20:36 - INFO - root -   ******* LOC.NOM results ********
01/08/2024 13:20:36 - INFO - root -    acc: 0.5000 - recall: 0.3333 - f1: 0.4000 
01/08/2024 13:20:36 - INFO - root -   ******* ORG.NAM results ********
01/08/2024 13:20:36 - INFO - root -    acc: 0.6061 - recall: 0.5128 - f1: 0.5556 
01/08/2024 13:20:36 - INFO - root -   ******* ORG.NOM results ********
01/08/2024 13:20:36 - INFO - root -    acc: 0.7273 - recall: 0.4706 - f1: 0.5714 
01/08/2024 13:20:36 - INFO - root -   ******* PER.NAM results ********
01/08/2024 13:20:36 - INFO - root -    acc: 0.7714 - recall: 0.7364 - f1: 0.7535 
01/08/2024 13:20:36 - INFO - root -   ******* PER.NOM results ********
01/08/2024 13:20:36 - INFO - root -    acc: 0.7299 - recall: 0.7471 - f1: 0.7384 
01/08/2024 13:20:49 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2793
01/08/2024 13:20:49 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2793
01/08/2024 13:20:49 - INFO - root -   

01/08/2024 13:20:50 - INFO - root -   Backbone bert_estor_crf param is not freeze

Epoch: 49/50
[Training] 1/57 [..............................] - ETA: 2:02  [ loss=0.0105 ][Training] 2/57 [>.............................] - ETA: 2:00  [ loss=0.0420 ][Training] 3/57 [>.............................] - ETA: 2:02  [ loss=0.0584 ][Training] 4/57 [=>............................] - ETA: 1:58  [ loss=0.0474 ][Training] 5/57 [=>............................] - ETA: 1:56  [ loss=0.1300 ][Training] 6/57 [==>...........................] - ETA: 1:54  [ loss=0.1134 ][Training] 7/57 [==>...........................] - ETA: 1:50  [ loss=0.3285 ][Training] 8/57 [===>..........................] - ETA: 1:50  [ loss=0.1833 ][Training] 9/57 [===>..........................] - ETA: 1:45  [ loss=0.4279 ][Training] 10/57 [====>.........................] - ETA: 1:45  [ loss=0.1158 ][Training] 11/57 [====>.........................] - ETA: 1:41  [ loss=0.0635 ][Training] 12/57 [=====>........................] - ETA: 1:44  [ loss=0.0159 ][Training] 13/57 [=====>........................] - ETA: 1:40  [ loss=0.2109 ][Training] 14/57 [======>.......................] - ETA: 1:38  [ loss=0.1409 ][Training] 15/57 [======>.......................] - ETA: 1:36  [ loss=0.1902 ][Training] 16/57 [=======>......................] - ETA: 1:36  [ loss=0.1041 ][Training] 17/57 [=======>......................] - ETA: 1:33  [ loss=0.0838 ][Training] 18/57 [========>.....................] - ETA: 1:29  [ loss=0.0230 ][Training] 19/57 [=========>....................] - ETA: 1:27  [ loss=0.2361 ][Training] 20/57 [=========>....................] - ETA: 1:25  [ loss=0.0650 ][Training] 21/57 [==========>...................] - ETA: 1:22  [ loss=0.0965 ][Training] 22/57 [==========>...................] - ETA: 1:20  [ loss=0.2084 ][Training] 23/57 [===========>..................] - ETA: 1:18  [ loss=0.0160 ][Training] 24/57 [===========>..................] - ETA: 1:15  [ loss=0.0866 ][Training] 25/57 [============>.................] - ETA: 1:12  [ loss=0.1110 ][Training] 26/57 [============>.................] - ETA: 1:09  [ loss=0.0146 ][Training] 27/57 [=============>................] - ETA: 1:06  [ loss=0.3687 ][Training] 28/57 [=============>................] - ETA: 1:03  [ loss=0.0118 ][Training] 29/57 [==============>...............] - ETA: 1:00  [ loss=0.1469 ][Training] 30/57 [==============>...............] - ETA: 58s  [ loss=0.3056 ][Training] 31/57 [===============>..............] - ETA: 56s  [ loss=0.2334 ][Training] 32/57 [===============>..............] - ETA: 53s  [ loss=0.0303 ][Training] 33/57 [================>.............] - ETA: 51s  [ loss=0.0107 ][Training] 34/57 [================>.............] - ETA: 49s  [ loss=0.0121 ][Training] 35/57 [=================>............] - ETA: 47s  [ loss=0.0447 ][Training] 36/57 [=================>............] - ETA: 45s  [ loss=0.0377 ][Training] 37/57 [==================>...........] - ETA: 43s  [ loss=0.1090 ][Training] 38/57 [===================>..........] - ETA: 41s  [ loss=0.1266 ][Training] 39/57 [===================>..........] - ETA: 39s  [ loss=0.2191 ][Training] 40/57 [====================>.........] - ETA: 37s  [ loss=0.0157 ][Training] 41/57 [====================>.........] - ETA: 35s  [ loss=0.0535 ][Training] 42/57 [=====================>........] - ETA: 33s  [ loss=0.0516 ][Training] 43/57 [=====================>........] - ETA: 30s  [ loss=0.0705 ][Training] 44/57 [======================>.......] - ETA: 28s  [ loss=0.4796 ][Training] 45/57 [======================>.......] - ETA: 26s  [ loss=0.0394 ][Training] 46/57 [=======================>......] - ETA: 24s  [ loss=0.4526 ][Training] 47/57 [=======================>......] - ETA: 22s  [ loss=0.0140 ][Training] 48/57 [========================>.....] - ETA: 20s  [ loss=0.0185 ][Training] 49/57 [========================>.....] - ETA: 17s  [ loss=0.0555 ][Training] 50/57 [=========================>....] - ETA: 15s  [ loss=0.1330 ][Training] 51/57 [=========================>....] - ETA: 13s  [ loss=0.0147 ][Training] 52/57 [==========================>...] - ETA: 11s  [ loss=0.0112 ][Training] 53/57 [==========================>...] - ETA: 8s  [ loss=0.1364 ][Training] 54/57 [===========================>..] - ETA: 6s  [ loss=0.0143 ][Training] 55/57 [===========================>..] - ETA: 4s  [ loss=0.0780 ][Training] 56/57 [============================>.] - ETA: 2s  [ loss=0.0143 ][Training] 57/57 [==============================] 2.2s/step  [ loss=0.0146 ]
01/08/2024 13:22:56 - INFO - root -   Loading features from cached file /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/datasets/weibo/cached_crf-test_roberta-large-chinese_512_weibo
01/08/2024 13:22:56 - INFO - root -   ***** Running evaluation on test dataset  *****
01/08/2024 13:22:56 - INFO - root -     Num examples = 269
01/08/2024 13:22:56 - INFO - root -     Batch size = 24
 
[Evaluating] 1/12 [=>............................] - ETA: 7s[Evaluating] 2/12 [====>.........................] - ETA: 8s[Evaluating] 3/12 [======>.......................] - ETA: 7s[Evaluating] 4/12 [=========>....................] - ETA: 6s[Evaluating] 5/12 [===========>..................] - ETA: 5s[Evaluating] 6/12 [==============>...............] - ETA: 4s[Evaluating] 7/12 [================>.............] - ETA: 3s[Evaluating] 8/12 [===================>..........] - ETA: 3s[Evaluating] 9/12 [=====================>........] - ETA: 2s[Evaluating] 10/12 [========================>.....] - ETA: 1s[Evaluating] 11/12 [==========================>...] - ETA: 0s[Evaluating] 12/12 [==============================] 760.0ms/step
01/08/2024 13:23:05 - INFO - root -   

01/08/2024 13:23:05 - INFO - root -   ***** Eval results  *****
01/08/2024 13:23:05 - INFO - root -    acc: 0.7275 - recall: 0.7046 - f1: 0.7159 - loss: 8.6707 
01/08/2024 13:23:05 - INFO - root -   ***** Entity results  *****
01/08/2024 13:23:05 - INFO - root -   ******* GPE.NAM results ********
01/08/2024 13:23:05 - INFO - root -    acc: 0.7778 - recall: 0.8936 - f1: 0.8317 
01/08/2024 13:23:05 - INFO - root -   ******* GPE.NOM results ********
01/08/2024 13:23:05 - INFO - root -    acc: 0.0000 - recall: 0.0000 - f1: 0.0000 
01/08/2024 13:23:05 - INFO - root -   ******* LOC.NAM results ********
01/08/2024 13:23:05 - INFO - root -    acc: 0.5625 - recall: 0.4737 - f1: 0.5143 
01/08/2024 13:23:05 - INFO - root -   ******* LOC.NOM results ********
01/08/2024 13:23:05 - INFO - root -    acc: 0.6000 - recall: 0.3333 - f1: 0.4286 
01/08/2024 13:23:05 - INFO - root -   ******* ORG.NAM results ********
01/08/2024 13:23:05 - INFO - root -    acc: 0.6061 - recall: 0.5128 - f1: 0.5556 
01/08/2024 13:23:05 - INFO - root -   ******* ORG.NOM results ********
01/08/2024 13:23:05 - INFO - root -    acc: 0.7273 - recall: 0.4706 - f1: 0.5714 
01/08/2024 13:23:05 - INFO - root -   ******* PER.NAM results ********
01/08/2024 13:23:05 - INFO - root -    acc: 0.7714 - recall: 0.7364 - f1: 0.7535 
01/08/2024 13:23:05 - INFO - root -   ******* PER.NOM results ********
01/08/2024 13:23:05 - INFO - root -    acc: 0.7273 - recall: 0.7529 - f1: 0.7399 
01/08/2024 13:23:25 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2850
01/08/2024 13:23:25 - INFO - root -   Saving optimizer and scheduler states to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf/checkpoint-2850
01/08/2024 13:23:25 - INFO - root -   

01/08/2024 13:23:25 - INFO - root -    global_step = 2850, average loss = 9.932863035875846
01/08/2024 13:23:25 - INFO - root -   Saving model checkpoint to /mnt/storage/wubinghong.wbh/deepl/torch_ner_new/outputs/weibo_output/bert_estor_crf
